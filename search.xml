<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>获取 vcf 文件中每个个体携带的突变数量</title>
      <link href="/2024/10/10/%E8%8E%B7%E5%8F%96%20vcf%20%E6%96%87%E4%BB%B6%E4%B8%AD%E6%AF%8F%E4%B8%AA%E4%B8%AA%E4%BD%93%E6%90%BA%E5%B8%A6%E7%9A%84%E7%AA%81%E5%8F%98%E6%95%B0%E9%87%8F/"/>
      <url>/2024/10/10/%E8%8E%B7%E5%8F%96%20vcf%20%E6%96%87%E4%BB%B6%E4%B8%AD%E6%AF%8F%E4%B8%AA%E4%B8%AA%E4%BD%93%E6%90%BA%E5%B8%A6%E7%9A%84%E7%AA%81%E5%8F%98%E6%95%B0%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>最近的工作涉及到处理大量种群数据，其中有个分析需要统计每个个体携带的突变数量，在网上搜寻了诸多方法后确定了一些比较高效的策略，固有此文记录。</p><blockquote><p>本文的部分流程参考源：</p><p><a href="https://www.biostars.org/p/336206/">BioStars "how to count variants par sample per chromosome in a vcf file?"</a></p></blockquote><h2 id="提取每个个体携带的突变数量"><a href="#提取每个个体携带的突变数量" class="headerlink" title="提取每个个体携带的突变数量"></a>提取每个个体携带的突变数量</h2><p>该流程主要通过 plink2 实现：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plink2 --vcf [vcf file] --out [plink output1]</span><br><span class="line">plink2 --pfile [plink output1] --sample-counts --out [plink output2]</span><br></pre></td></tr></tbody></table></figure><ul><li><code>[vcf file]</code>：此处填入 vcf 文件的路径。</li><li><code>[plink output1]</code>：此处填入 plink2 输出的文件前缀。</li><li><code>[plink output2]</code>：此处填入 plink2 输出的文件前缀。</li></ul><p>运行结束后，可以得到以 <code>.scount</code> 结尾的文件，其中各列的含义如下：</p><ol><li><strong>#IID</strong>：标识每个样本的编号。</li><li><strong>HOM_REF_CT</strong>：纯合参考基因型计数，个体纯合参考基因型的位点数量。</li><li><strong>HOM_ALT_SNP_CT</strong>：纯合变异基因型计数，个体纯合变异基因型的单核苷酸多态性（SNP）数量。</li><li><strong>HET_SNP_CT</strong>：杂合基因型计数，个体在该位点上是杂合基因型的SNP数量（一条染色体是参考基因型，另一条是变异基因型）。</li><li><strong>DIPLOID_TRANSITION_CT</strong>：二倍体转换变异的数量（转换：嘌呤与嘌呤或嘧啶与嘧啶之间的替换）。</li><li><strong>DIPLOID_TRANSVERSION_CT</strong>：二倍体颠换变异的数量（颠换：嘌呤与嘧啶之间的替换）。</li><li><strong>DIPLOID_NONSNP_NONSYMBOLIC_CT</strong>：二倍体非SNP非符号变异计数。包括一些插入、缺失（INDELs）等。</li><li><strong>DIPLOID_SINGLETON_CT</strong>：二倍体单例变异计数，表示在整个样本集中只出现在该个体中的变异数量。</li><li><strong>HAP_REF_INCL_FEMALE_Y_CT</strong>：单倍体参考基因型计数，即在单倍体区域（Y 染色体）的参考等位基因数量。</li><li><strong>HAP_ALT_INCL_FEMALE_Y_CT</strong>：单倍体变异基因型计数，在单倍体区域中出现的变异等位基因的数量。</li><li><strong>MISSING_INCL_FEMALE_Y_CT</strong>：缺失基因型计数，在样本中缺失的基因型数据计数。</li></ol><p>更多可输出列的详细信息可见：<a href="https://www.cog-genomics.org/plink/2.0/formats#scount">https://www.cog-genomics.org/plink/2.0/formats#scount</a></p><p>具体参数的用法可见：<a href="https://www.cog-genomics.org/plink/2.0/basic_stats#sample_counts">https://www.cog-genomics.org/plink/2.0/basic_stats#sample_counts</a></p><p>通过 <code>HOM_ALT_SNP_CT</code> <code>HET_SNP_CT</code> <code>DIPLOID_NONSNP_NONSYMBOLIC_CT</code> 计算每个个体携带的突变数量。</p><h2 id="提取每个突变对应的携带者信息"><a href="#提取每个突变对应的携带者信息" class="headerlink" title="提取每个突变对应的携带者信息"></a>提取每个突变对应的携带者信息</h2><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bcftools norm -m -any [vcf file] | bcftools query -i 'GT="alt"' -f '%CHROM\t%POS\t%REF\t%ALT[\t%SAMPLE:%GT]\n' - &gt; [output]</span><br></pre></td></tr></tbody></table></figure><ul><li><code>[vcf file]</code>：此处填入 vcf 文件的路径。</li><li> <code>[output]</code>：此处填入输出文件的路径。</li></ul><p>此处通过 <code>bcftools norm -m -any</code> 对多等位基因进行了拆分，可视自身需求去除该部分，此处 <code>GT="alt"</code> 将所有携带替代等位基因的个体提取出并打印。</p><p>输出结果示例：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chr1    228424930       G       A       4922792:0/1     4884261:0/1     3988378:0/1     2479308:0/1     4414951:0/1     3862053:0/1</span><br></pre></td></tr></tbody></table></figure><p>前四列用于表示特定突变（分别指示染色体编号、位置、ref 和 alt），后续以制表符分隔记录该突变的携带者及基因型。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>vscode 在远程服务器上通过 jupyter notebook 使用 R</title>
      <link href="/2024/09/19/vscode%20%E5%9C%A8%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%80%9A%E8%BF%87%20jupyter%20notebook%20%E4%BD%BF%E7%94%A8%20R/"/>
      <url>/2024/09/19/vscode%20%E5%9C%A8%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%80%9A%E8%BF%87%20jupyter%20notebook%20%E4%BD%BF%E7%94%A8%20R/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>最近一段时间的关键分析要用到 R，但是办公电脑的机械硬盘前段时间出了问题，现在用 Rstudio 会非常卡顿，加上相关分析对计算资源的要求也比较高，就想着是否有什么办法能在服务器上也弄一个类似于 Rstudio 的可视化界面出来作为辅助。</p><p>不过看了一圈发现 Rstudio 的 server 版本似乎局限性不少，而且还要用到 root 权限。考虑到平时运行 Python 进行分析时大多数时候都在 jupyter notebook 上进行，就想着是否能套用过来，于是就有了这篇文章。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>该文章的具体实现在 Linux + mamba 环境下完成，如果你没有 conda/mamba 环境，可以参考网上资料进行安装。</p><p>首先确认你的环境中有 R，如果没有可以通过以下命令安装：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mamba install conda-forge::r-base</span><br><span class="line">R # 确认可以进入 R 终端，使用 q() 退出</span><br></pre></td></tr></tbody></table></figure><p>通过 mamba 安装 <a href="https://github.com/IRkernel/IRkernel">IRkernel</a> 和 jupyter（使用 conda 也行，本文章以 mamba 为准）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mamba install r::r-irkernel</span><br><span class="line">mamba install anaconda::jupyter</span><br></pre></td></tr></tbody></table></figure><p>完成上述步骤后，进入 R 终端，输入 <code>IRkernel::installspec()</code>：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ R</span><br><span class="line">&gt; IRkernel::installspec()</span><br></pre></td></tr></tbody></table></figure><p>如果在 VScode 中尚未安装 jupyter 扩展，则点开侧栏的 <strong><u>拓展</u></strong> 页面并搜索 jupyter 安装：</p><img src="/pic2/vscode_jupyter1.png" height="400px"><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>新建一个 jupyter notebook 文件，使用 vscode 打开它：</p><img src="/pic2/vscode_jupyter2.png" height="300px"><p>点击右上角的 <code>select kernel</code>，此时如果仅存在 Python 相关的 kernel，则先在服务器上运行 jupyter notebook：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></tbody></table></figure><p>此时屏幕输出里会返回 server 的链接，例如：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8888/tree?token=11d321403f5a4d62d94d07ddae56e48017cf641c059573b0</span><br></pre></td></tr></tbody></table></figure><p>在 <code>select kernel</code> 里，点击 <code>Select Another Kernel</code>，此后选择 <code>Existing Jupyter Server</code>，在弹出的窗口里输入上面得到的 server 链接，并选择弹出的 R。图示：</p><img src="/pic2/vscode_jupyter3.png" height="500px"><p>此后即可在 jupyter notebook 中使用 R 进行分析：</p><img src="/pic2/vscode_jupyter4.png" height="400px"></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>簇突变的类型简介及识别方法（Clustered mutation classification）</title>
      <link href="/2024/08/23/%E7%B0%87%E7%AA%81%E5%8F%98%E7%9A%84%E7%B1%BB%E5%9E%8B%E7%AE%80%E4%BB%8B%E5%8F%8A%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95/"/>
      <url>/2024/08/23/%E7%B0%87%E7%AA%81%E5%8F%98%E7%9A%84%E7%B1%BB%E5%9E%8B%E7%AE%80%E4%BB%8B%E5%8F%8A%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>基因组中，某些特殊的突变过程可能会导致一小段区域内连续的突变发生。这些突变在基因组中呈现成簇分布，因此被称作 <strong><u>clustered mutation</u><strong>（本文将称其为</strong>簇突变</strong>）。研究这些突变的分布及组成有助于我们揭示导致其发生的内源性和外源性过程。该文章将主要讲述簇突变的类别并列举一些会导致特定类别的生物学原因，同时介绍该领域中的某些生物信息学工具等。</p><h2 id="簇突变类型"><a href="#簇突变类型" class="headerlink" title="簇突变类型"></a>簇突变类型</h2><p>簇突变类型主要被分作六类，其中五类针对碱基水平的变化，一类针对插入及缺失（InDel）：</p><ul><li><p><strong>DSB（Doublet Base Substitutions）</strong>：双碱基替换，表示这两个突变<strong>发生在相邻的碱基上</strong>。某些外源性过程例如紫外线损伤会导致双碱基替换的发生（CC&gt;TT），此外 DNA 修复缺陷和聚合酶功能突变也会导致 DSB 发生。</p></li><li><p><strong>MBS (Multiple Base Substitutions)<strong>：多碱基替换，表示在</strong>很短的序列范围内发生多个碱基突变且这些突变彼此相邻</strong>。由于该簇突变的出现数量很有限，因此尚未得到全面研究。</p></li><li><p><strong>Omikli</strong>：源自希腊语，意为 <u>雾</u> 或 <u>薄雾</u>，也被称作 <strong>diffuse hypermutation（弥漫性超突变）</strong>，表现为 IMD（Inter-Mutation Distance，突变间距）小于预期的少数几个碱基突变（两到三个）。多种外源过程可导致 Omikli 事件，内源过程则有单链错配修复等。</p></li><li><p><strong>Kataegis</strong>：源自希腊语，意为 <u>暴雨</u>。其本质上是 <strong>Omikli 的更大规模事件</strong>。表现为 IMD 小于预期的多个碱基突变聚集在一起。当前认为大多数导致 Kataegis 的过程都归因于 <a href="https://en.wikipedia.org/wiki/APOBEC">AID/APOBEC 家族</a>（Omikli 也受部分影响），与双链断裂具有一定关系。</p></li><li><p><strong>Other：</strong>IMD 小于预期但是 <strong>VAF（Variant allele frequency，突变等位基因频率）不相等的一些碱基突变聚集在一起</strong>。而<strong>上述几种突变类型中，一个 clustered mutation group 里所包含的突变 VAF 都相同</strong>。</p><ul><li><blockquote><p>如果簇突变在同一个事件中发生（也可以当作在同一个细胞中发生），那么这些突变的细胞谱系树将完全相同，因此最后得到的 VAF 预期一致。不同则表明这些突变是在多次突变事件中独立发生的。<strong>Other 类型的突变可能表明其所处的基因组区域本身突变率高</strong>，所以严格意义上讲它并不算主流研究中关注的簇突变。</p></blockquote></li></ul></li><li><p><strong>indels</strong>：IMD 小于预期的插入或缺失事件。与微卫星不稳定性有关并常见于错配修复缺陷的细胞中。</p></li></ul><img src="/pic2/clustered_mutation.jpeg" height="500px"><center>Refer: https://osf.io/qpmzw/wiki/2.%20Workflow/</center><h2 id="簇突变的确定"><a href="#簇突变的确定" class="headerlink" title="簇突变的确定"></a>簇突变的确定</h2><p>一般而言，确定簇突变的步骤如下：</p><ol><li>计算一个 IMD 阈值。</li><li>对基因组上的突变进行判断，如果存在与其距离低于 IMD 阈值的突变，则认为其是簇突变。</li></ol><p>在一些比较久之前的文章中，IMD 的阈值是直接人为确定的。例如 <a href="https://www.cell.com/cell/fulltext/S0092-8674(17)30774-2">Supek 等人</a>采用了以下判断标准：</p><p>①、突变之间的距离 &lt;= 500bp。</p><p>②、突变的类型必须相同（例如都为 C&gt;T）且链对应（例如 C 都在正链上）。</p><p>这种划分方法虽然在一定程度上可靠，但是并不适用于所有应用场景，且不同研究采取的标准也不完全相同（例如阈值大小），导致不方便整合比较。</p><p>随着期刊对分析的可靠性要求越来越严格，现在已经有许多用于分析簇突变的生物信息学工具被开发出来，它们采用了更加严谨的策略并且保证了可再现性，例如突变特征分析领域的主流工具套件 SigProfiler 中也提供了用于分析簇突变的 <a href="https://osf.io/qpmzw/wiki/home/">SigProfilerClusters</a>。其运行过程大致如下：</p><p>①、根据突变的上下文（周边序列）等信息，对突变的位置进行打乱重排，以模拟随机情况下的突变分布情况。</p><p>②、根据真实数据与模拟数据的突变分布计算出每个样本的 IMD 阈值。</p><p>③、根据基因组各个窗口内的突变率对 IMD 阈值进行校正。</p><p>④、根据簇突变的 VAF 等信息对其进行分类。</p><p>该团队使用该工具对 PCAWG 项目的数据进行了分析，系统阐述了各癌症类型中的簇突变景观，并发现了 APOBEC3 Kataegis 对 Extrachromosomal DNA (ecDNA) 的作用（<a href="https://www.nature.com/articles/s41586-022-04398-6#Sec8">Bergstrom et al. 2022, Nature</a>）。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>常见的 DSB 特征及生物学成因：<a href="https://cancer.sanger.ac.uk/signatures/dbs/">https://cancer.sanger.ac.uk/signatures/dbs/</a></li><li>Clustered Mutation Signatures Reveal that Error-Prone DNA Repair Targets Mutations to Active Genes, Cell 2017</li><li>Examining clustered somatic mutations with SigProfilerClusters, Bioinformatics 2022</li><li>Mapping clustered mutations in cancer reveals APOBEC3 mutagenesis of ecDNA, Nature 2022</li></ol></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>rsync 中排除文件的规则详解（rsync --exclude）</title>
      <link href="/2024/08/15/rsync%20%E4%B8%AD%E6%8E%92%E9%99%A4%E6%96%87%E4%BB%B6%E7%9A%84%E8%A7%84%E5%88%99%E8%AF%A6%E8%A7%A3/"/>
      <url>/2024/08/15/rsync%20%E4%B8%AD%E6%8E%92%E9%99%A4%E6%96%87%E4%BB%B6%E7%9A%84%E8%A7%84%E5%88%99%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>前段时间在备份服务器时，由于备份策略的变化，对 rsync 的 exclude patterns 进行了一些更加深入的探索。</p><p>这篇文章将介绍如何设计 rsync 的 exclude patterns 以排除特定目录或文件。</p><h2 id="命令介绍"><a href="#命令介绍" class="headerlink" title="命令介绍"></a>命令介绍</h2><p>rsync 是 Linux 和 Unix 中常用的文件复制和同步命令，相比 cp 命令而言更加高效和完善，其优点包括但不限于：</p><ul><li><strong>增量复制</strong>：rsync 只会复制那些自上次同步后更改的文件部分，极大地减少了数据传输量。例如 a 文件已经同步过一次并且没有发生变化，则 rsync 会跳过。同样，rsync 也会进行完整性检查以确定传输的数据无误。</li><li><strong>保留属性</strong>：rsync 可以保持文件的权限、时间戳、软硬链接、所有权等属性。</li><li><strong>灵活的过滤规则</strong>：支持使用包括和排除规则来选择同步的文件或目录。</li></ul><img src="https://tse3-mm.cn.bing.net/th/id/OIP-C.m0CLH5eqL6kvqiFjEVu6VQHaD4?rs=1&amp;pid=ImgDetMain" height="200px"><h2 id="排除规则"><a href="#排除规则" class="headerlink" title="排除规则"></a>排除规则</h2><p>rsync 通过参数 <code>--exclude</code> 或 <code>--exclude-from</code> 指定排除的文件模式。其中 <code>--exclude-from</code> 用于指定包含排除模式的文件（包含多个排除规则）。</p><h3 id="排除指定文件"><a href="#排除指定文件" class="headerlink" title="排除指定文件"></a>排除指定文件</h3><p>输入文件名称（如 <code>123.txt</code>）即可排除所有命名为 <code>123.txt</code> 的文件。</p><h3 id="排除特定尾缀的文件"><a href="#排除特定尾缀的文件" class="headerlink" title="排除特定尾缀的文件"></a><strong>排除特定尾缀的文件</strong></h3><p>通过 <code>*.xxx</code> 排除包含特定尾缀的文件，例如：</p><ul><li><code>*.txt</code> 排除所有以 <code>.txt</code> 结尾的文件。</li><li><code>*vcf</code> 排除所有以 <code>vcf</code> 结尾的文件。注意这里<strong>并不推荐这样做</strong>，因为这<strong>也会排除掉所有以 vcf 结尾的目录</strong>，例如：<ul><li><code>source/dir1/dir_vcf/xxx</code>，这里 <code>dir_vcf</code> 及其中的所有文件也会被排除。</li></ul></li></ul><p>因此在根据尾缀排除文件时，最好添加尾缀前的 <code>.</code> 以避免其他文件夹的意外排除。</p><p>同理也可通过前缀进行文件排除，例如 <code>SRR*</code> 等，但同样地，这会排除符合该条件的所有目录。因此请<strong>谨慎使用</strong>。</p><h3 id="排除隐藏文件及文件夹"><a href="#排除隐藏文件及文件夹" class="headerlink" title="排除隐藏文件及文件夹"></a>排除隐藏文件及文件夹</h3><p>通过 <code>.*</code> <strong>排除所有隐藏文件及隐藏文件夹</strong>。</p><h3 id="排除特定文件夹"><a href="#排除特定文件夹" class="headerlink" title="排除特定文件夹"></a>排除特定文件夹</h3><p>直接使用文件夹名称，例如 <code>anaconda3</code> 等。但注意，<strong>如果有与该文件夹名同名的文件，那么该文件也会被排除</strong>，例如：</p><ul><li>使用 <code>juse</code> 时，<code>source/juse/</code>（目录）会被排除，此外 <code>source/other/juse</code>（文件名为 <code>juse</code>）也会被排除。</li></ul><p>因此如果你想排除特定文件夹但又担心具有同名文件，两个好的权衡方式是：</p><ul><li>添加该目录先前的信息，例如你已经知道其位于其他文件夹中：<code>dir1/dir2</code>（排除位于 dir1 下的 dir2）。</li><li>排除该目录中的所有文件，并保留空文件夹：<code>dir2/**</code>，该做法更加推荐，因为你也可以保留下 ‘哪些文件夹被排除’ 这个信息。</li></ul><p>这里使用两个星号是为了和之后的跨多目录匹配相一致，但其实只用一个 <code>*</code> 的效果是一样的。</p><h3 id="跨目录排除匹配的文件夹"><a href="#跨目录排除匹配的文件夹" class="headerlink" title="跨目录排除匹配的文件夹"></a>跨目录排除匹配的文件夹</h3><p>该方法的应用场景如下：</p><p>用户 <code>juse</code> 的目录里存在多个 <code>work</code> 文件夹，<code>juse</code> 想将它们全部排除掉，但是他认为仅使用 <code>work/**</code> 并不妥当，因为其他人的 <code>work</code> 文件夹中可能存在需要备份的文件，而根据单个目录路径进行排除也存在困难，因为 <code>juse</code> 目录中的 <code>work</code> 文件夹很多且位置不一。</p><ul><li><code>/juse/dir1/work/</code></li><li><code>/juse/work/</code></li><li><code>/juse/dir2/dir3/work/</code></li></ul><p>此时可以通过使用 <code>juse**/work</code> 排除 <code>juse</code> 目录下所有 <code>work</code> 子目录。请注意<strong>仅使用单个 <code>*</code> 时无法实现跨目录匹配</strong>：</p><ul><li><code>juse/*/work</code> 仅能识别到 <code>/juse/dir1/work/</code>，无法识别 <code>/juse/dir2/dir3/work/</code>。</li></ul><p>而使用 <code>juse/**/work</code> 则无法识别到 <code>juse</code> 目录下的 <code>work</code> 文件夹，可以通过去除第一个斜杠避免该问题。</p><p>相比之下 du 命令可以通过单个星号实现跨多个目录匹配，同时两个星号也不影响 du 的使用。</p><h2 id="rsync-使用建议"><a href="#rsync-使用建议" class="headerlink" title="rsync 使用建议"></a>rsync 使用建议</h2><p>首先需要明确一点，rsync <strong>以 source 目录作为根目录进行同步操作，因此并不会因为先前的绝对路径中存在排除模式就导致同步失败</strong>，例如：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -av --exclude 'juse' /juse/dir1/ /pathto/destination/</span><br></pre></td></tr></tbody></table></figure><p>上述命令并不会导致 <code>/juse/dir1/</code> 中的文件全部无法同步，因为其并不会考虑源目录本身的路径信息。</p><p>此外，在使用 rsync 推荐使用以下一些参数：</p><ul><li><code>-av</code>：归档模式 + 输出更多信息，前者保证 rsync 递归复制目录并保留文件的各种属性，后者有助于监控同步过程。</li><li><code>-z</code>：在数据传输过程中进行压缩，在慢速网络中进行同步时建议启用。</li><li><code>--bwlimit</code>：限制带宽（传输速度），避免影响其他进程。</li><li><code>--delete</code> &amp; <code>--delete-excluded</code>：前者删除目标文件夹中源文件夹里不存在的文件，后者删除目标文件夹中被排除模式匹配的文件，适合需要完全同步时使用。</li></ul><p>注意 rsync 可以通过 <code>--exclude-from</code> 使用多个排除模式。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Snakemake pipeline 搭建的进阶教程</title>
      <link href="/2024/07/06/Snakemake%20pipeline%20%E6%90%AD%E5%BB%BA%E7%9A%84%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B/"/>
      <url>/2024/07/06/Snakemake%20pipeline%20%E6%90%AD%E5%BB%BA%E7%9A%84%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="关于-Snakemake"><a href="#关于-Snakemake" class="headerlink" title="关于 Snakemake"></a>关于 Snakemake</h2><p>Snakemake 是一个工作流管理系统，可用于创建易于迁移和复现的数据分析流程（pipeline），因此被广泛应用于生物学分析中。虽然 Snakemake 算是一个独立的编程语言，但其本质是基于 Python 搭建的，因此如果你对 Python 有一定了解，那么上手 Snakemake 就会更容易很多。并且 Python 技能的掌握对于某些情况下 Pipeline 下游分析部分的拓展是有必要的。</p><img src="/pic2/snakemake1.png"><p>本文将结合多个近些年生物论文中公开的 Snakemake Pipeline，介绍如何搭建一个具有一定功能的 Pipeline。</p><p>Snakemake 安装：<a href="https://snakemake.readthedocs.io/en/stable/getting_started/installation.html">https://snakemake.readthedocs.io/en/stable/getting_started/installation.html</a></p><p>Snakemake Pipeline 示例教程：<a href="https://snakemake.readthedocs.io/en/stable/tutorial/basics.html">https://snakemake.readthedocs.io/en/stable/tutorial/basics.html</a></p><p>有利于提升阅读体验的一些条件：</p><ul><li>对于 Python 编程已经具备一定的了解，包括文件的一些基本读写操作和 lambda 表达式的应用。</li><li>具有初步的 Snakemake Pipeline 制作经验。</li></ul><p>阅读后有望获得的一些能力：</p><ul><li>知晓 Snakemake 中一些基本的语法和操作。</li><li>编写具有明确结构的 Snakemake Pipeline。</li></ul><h2 id="搭建-Pipeline"><a href="#搭建-Pipeline" class="headerlink" title="搭建 Pipeline"></a>搭建 Pipeline</h2><p>注意，该 Pipeline 的完整版本在以下 github repository 的 <a href="https://github.com/JuseTiZ/Blog-Snakemake-pipeline/tree/main/Tutorial-Pipeline">Tutorial-Pipeline</a> 可见，建议结合完整 Pipeline 阅读文章以避免不必要的混淆：</p><p><a href="https://github.com/JuseTiZ/Blog-Snakemake-pipeline">https://github.com/JuseTiZ/Blog-Snakemake-pipeline</a></p><p>该 Pipeline 的运行环境也可通过以上 repository 中的指引进行安装和配置。</p><h3 id="Pipeline-要求"><a href="#Pipeline-要求" class="headerlink" title="Pipeline 要求"></a>Pipeline 要求</h3><p><strong>目标：</strong>搭建一个可以根据 SRR accession number 自动下载数据、处理数据和进行表达定量的 Pipeline。</p><p><strong>流程：</strong></p><ol><li><code>prefetch</code> 下载数据，该步骤还需配置 <code>pigz</code>（多线程压缩）及 <code>fasterq-dump</code>（提取 fastq）。</li><li><code>trim_galore</code> 过滤数据</li><li><code>salmon</code> 进行定量</li></ol><p><strong>功能：</strong>①、Pipeline 可以识别来自不同样本的数据，并把同一样本的多个数据进行合并；②、Pipeline 可以分为单端和双端模式进行处理；③、可以自定义各个软件运行时使用的参数；④、下载数据时<strong>如果遇到网络错误应当可以自行重续下载</strong>。</p><p><strong>需要提前准备的：</strong>①、指定自行构建的 salmon 索引；②、已安装好的并放置于环境变量中的软件。</p><p>如果你想将软件的版本控制也考虑进 Pipeline 中，可见本文 <strong><u>Pipeline 拓展</u></strong> 部分。</p><p>你可以通过下述命令进行 hg38 salmon 索引的构建以在后文中使用，或者你可以在阅读本文后将该步骤嵌入 Pipeline 流程中（但并不建议，因为该步骤并不是每一次分析都需要复用，这种情况下最好作为参数指定）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir hg38_salmon_index</span><br><span class="line">wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/gencode.v44.pc_transcripts.fa.gz</span><br><span class="line">wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/GRCh38.primary_assembly.genome.fa.gz</span><br><span class="line">grep "^&gt;" &lt;(gunzip -c GRCh38.primary_assembly.genome.fa.gz) | cut -d " " -f 1 &gt; decoys.txt</span><br><span class="line">sed -i.bak -e 's/&gt;//g' decoys.txt</span><br><span class="line">cat gencode.v44.pc_transcripts.fa.gz GRCh38.primary_assembly.genome.fa.gz &gt; GRCh38.gentrome.fa.gz</span><br><span class="line">salmon index -t GRCh38.gentrome.fa.gz -d decoys.txt -p 12 -i hg38_salmon_index --gencode &gt; hg38_salmon_index/salmon_index.log 2&gt;&amp;1</span><br></pre></td></tr></tbody></table></figure><h3 id="Pipeline-管理"><a href="#Pipeline-管理" class="headerlink" title="Pipeline 管理"></a>Pipeline 管理</h3><p>首先，一个清晰的文件夹结构对于 Pipeline 的管理和拓展是有帮助的，因此请 <code>cd</code> 到拟存储 Pipeline 的路径，并输入以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd [path]</span><br><span class="line">tutorial_path=$(pwd)</span><br><span class="line">mkdir rules</span><br><span class="line">mkdir config</span><br><span class="line">touch config/config.yaml</span><br><span class="line">mkdir envs</span><br><span class="line">mkdir logs</span><br><span class="line">touch Snakefile</span><br></pre></td></tr></tbody></table></figure><p>这些文件夹的用途将在后续搭建过程中一一介绍。</p><img src="/pic2/snakemake2.png" style="zoom:80%;"><h3 id="Pipeline-搭建"><a href="#Pipeline-搭建" class="headerlink" title="Pipeline 搭建"></a>Pipeline 搭建</h3><p>阅读时请留意每个代码块指定的文件，文件头中的 <code>#</code> 仅作文件名说明用，在实际文件中请将该标头去除。</p><h4 id="1、输出目标文件确定"><a href="#1、输出目标文件确定" class="headerlink" title="1、输出目标文件确定"></a>1、输出目标文件确定</h4><p>搭建一个 Pipeline 具有一定的前置条件，首先<strong>你需要对每一个步骤会产生什么样的文件有具体的了解</strong>，因此<strong>建议完全跑过一套流程以后再进行这一步骤</strong>。</p><p>按照上述目标，我们首先希望 Pipeline 能够做到以下事情：</p><p>①、下载 SRR id 对应的原始数据。</p><p>②、经过一系列处理以后，将这些数据在样本层级进行定量。</p><p>已知第一步我们会得到一些以 <code>.sra</code> 结尾的文件，而完成 ② 后我们会得到所有样本的 <code>quant.sf</code> 文件，这些将决定我们如何<strong>定义 Snakemake 的输出目标</strong>。</p><p>因此我们先创建一个包含我们定量所用 sra id 及其对应的样本名的文件，命名为 <code>group.txt</code>，以下分析将以一个人类海拉细胞示例数据集为例进行：    </p><figure class="highlight txt"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># group.txt</span><br><span class="line">SRR25601734HeLa_Rep1</span><br><span class="line">SRR25601735HeLa_Rep1</span><br><span class="line">SRR25601736HeLa_Rep2</span><br><span class="line">SRR25601737HeLa_Rep2</span><br></pre></td></tr></tbody></table></figure><p>假设每个 sra 文件我们打算放置于 <code>rawfastq/[srrid]</code> 中，样本的定量结果我们打算放置于 <code>results/[sample]</code> 中，那我们预期得到的文件应该有：</p><figure class="highlight txt"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rawfastq/SRR25601734/SRR25601734.sra</span><br><span class="line">rawfastq/SRR25601735/SRR25601735.sra</span><br><span class="line">rawfastq/SRR25601736/SRR25601736.sra</span><br><span class="line">rawfastq/SRR25601737/SRR25601737.sra</span><br><span class="line">results/HeLa_Rep1/quant.sf</span><br><span class="line">results/HeLa_Rep2/quant.sf</span><br></pre></td></tr></tbody></table></figure><p>首先，我们需要一个方法指定 <code>group.txt</code> 能让 Snakemake 识别，请在 <code>config/config.yaml</code> 文件中添加以下内容：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">inputfile:</span></span><br><span class="line">  <span class="attr">groupfile:</span> <span class="string">"group.txt"</span></span><br></pre></td></tr></tbody></table></figure><p>这是一个 yaml 数据格式的文件，我们将在 Snakefile 中读取它并确定相关参数。在<strong>之后每次 Pipeline 的复用中一般只需要调整该文件</strong>。</p><p>现在，请打开之前新建的 <code>Snakefile</code> 文件，输入以下内容：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">configfile: <span class="string">"config/config.yaml"</span></span><br><span class="line"></span><br><span class="line">srrlist = <span class="built_in">set</span>([line.strip().split()[<span class="number">0</span>] <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(config[<span class="string">"inputfile"</span>][<span class="string">"groupfile"</span>], <span class="string">'r'</span>)])</span><br><span class="line">samples = <span class="built_in">set</span>([line.strip().split()[<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(config[<span class="string">"inputfile"</span>][<span class="string">"groupfile"</span>], <span class="string">'r'</span>)])</span><br><span class="line"></span><br><span class="line">rule <span class="built_in">all</span>:</span><br><span class="line">    <span class="built_in">input</span>:</span><br><span class="line">        expand(<span class="string">"rawfastq/{srr}/{srr}.sra"</span>, srr=srrlist) + </span><br><span class="line">        expand(<span class="string">"results/{sample}/quant.sf"</span>, sample=samples)</span><br></pre></td></tr></tbody></table></figure><p>逐段解释：</p><ol><li><p>首先我们通过 <code>configfile</code> <strong>指定配置文件</strong>，该命令行会将 <code>config/config.yaml</code> 读取为字典并赋予给 <code>config</code> 变量。</p></li><li><p>此后我们通过 Python 语法读取了先前在 config.yaml 中指定的 <code>group.txt</code>，并分别将 SRR id 和 Sample 的集合传入给了 <code>srrlist</code> 和 <code>samples</code> 两个变量。</p></li><li><p>通过 <code>rule all</code> 语句，<strong>确定 Snakemake 最终检查的文件（用于判断该 workflow 是否运行完成）</strong>，其中：</p><ul><li><p><code>expand</code> 为 Snakemake 的特殊语法，本质是遍历并得到一个新列表，即 <code>expand("{x}", x=xlist)</code> 功能上等价于 <code>[f"{x}" for x in xlist]</code>。</p></li><li><p>此处使用 <code>srrlist</code> 和 <code>samples</code> 通过 <code>expand</code> 语法将先前预期得到的文件列表传递给了 Snakemake，以使其监控工作流的运行结果。</p></li></ul></li></ol><p>这里需要注意的是，虽然我们最终的目的仅是得到每个样本的 <code>quant.sf</code>，但是由于后续 Snakemake 的运行中，其是<strong>通过 <code>rule all</code> 中的 <code>input</code> 为不同 rule 的 input 分配通配符的</strong>，因此<strong>如果不在 input 中给定 srr 文件相关的信息，它无法判断后续我们每个 rule 运行的意图</strong>，具体可见后文介绍。</p><h4 id="2、工作流框架实现"><a href="#2、工作流框架实现" class="headerlink" title="2、工作流框架实现"></a>2、工作流框架实现</h4><p>到这里，我们已经为工作流指定了最终的目标文件，现在我们可以开始搭建得到这一系列文件所需要的框架，接下来的步骤将主要在 <code>rule</code> 文件夹下进行，并涉及到一些 <code>config.yaml</code> 中参数的补充。</p><p>由于我们想要开发的 Pipeline <strong>能够根据单端和双端数据进行调整</strong>，因此我们现在 <code>config.yaml</code> 文件中添加一个新的参数：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mode:</span> <span class="string">"paired"</span></span><br></pre></td></tr></tbody></table></figure><p>该 mode 参数也可改为 single，后续我们框架中每个 rule 的行为将根据该 mode 的指定发生变化。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $tutorial_path/rules</span><br><span class="line">touch common.smk # 该文件将用于编写 Python 函数以拓展后续 rule 的动态性</span><br></pre></td></tr></tbody></table></figure><p>根据先前拟定的 Pipeline 流程，我们首先创建一个下载规则文件：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch 01_prefetch.smk</span><br></pre></td></tr></tbody></table></figure><p>下载部分中我们可能需要调整的参数：</p><ol><li>可以同时并行的下载任务数量。该点将通过运行 Snakemake 时指定 <code>--resources</code> 实现。</li><li>下载如果失败（因为网络原因）重试的次数。该点将通过在 <code>config.yaml</code> 中添加参数实现。</li></ol><p><code>config.yaml</code> 新添参数以让下载失败时重新运行，最多运行三次：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">download:</span></span><br><span class="line">  <span class="attr">retry:</span> <span class="number">3</span></span><br></pre></td></tr></tbody></table></figure><p><code>01_prefetch.smk</code> 内容：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">rule download:</span><br><span class="line">    output:</span><br><span class="line">        srafile = <span class="string">"rawfastq/{srr}/{srr}.sra"</span></span><br><span class="line">    log:</span><br><span class="line">        <span class="string">"logs/{srr}_download_prefetch.log"</span></span><br><span class="line">    params:</span><br><span class="line">        srrid = <span class="string">"{srr}"</span></span><br><span class="line">    threads: <span class="number">1</span></span><br><span class="line">    retries: config[<span class="string">"download"</span>][<span class="string">"retry"</span>]</span><br><span class="line">    resources:</span><br><span class="line">        download_slots = <span class="number">1</span> </span><br><span class="line">    shell:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        if [ -e {output.srafile}.lock ]; then</span></span><br><span class="line"><span class="string">            rm {output.srafile}.lock</span></span><br><span class="line"><span class="string">            echo "{output.srafile} lock found but no output file! Deleting..." &gt;&gt; {log}</span></span><br><span class="line"><span class="string">        fi</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        prefetch --max-size 100000000 --progress --output-directory rawfastq {params.srrid} &gt; {log} 2&gt;&amp;1</span></span><br><span class="line"><span class="string">        if [ -e {output.srafile} ]; then</span></span><br><span class="line"><span class="string">            echo "{output.srafile} download finished!" &gt;&gt; {log}</span></span><br><span class="line"><span class="string">        else</span></span><br><span class="line"><span class="string">            mv {output.srafile}* {output.srafile}</span></span><br><span class="line"><span class="string">            echo "{output.srafile} not find! May end with .sralite. Renaming..." &gt;&gt; {log}</span></span><br><span class="line"><span class="string">        fi</span></span><br><span class="line"><span class="string">        """</span></span><br></pre></td></tr></tbody></table></figure><p>逐段解释：</p><ol><li><code>output</code> 段用于<strong>定义该 rule 用于产生什么文件</strong>，Snakemake 会自行创建相应目录（如果不存在）。运行完该 rule 后 Snakemake 会检查是否有产生 <code>output</code> 中指定的输出文件，<strong>如果没有则判断其运行失败</strong>。上例中该段指定了一个输出文件 <code>srafile</code>，其中通配符 <code>{srr}</code> 的识别方式可见下文。</li><li><code>log</code> 段用于<strong>定义该 rule 的日志文件</strong>，可以在相应命令行中将屏幕输出记录在该文件中。<code>params</code> 段用于<strong>定义该 rule 使用的参数</strong>。<code>threads</code> 段用于<strong>定义该 rule 使用的线程数（核数）</strong>。</li><li><code>retries</code> 段用于<strong>定义该 rule 失败后重新运行的次数</strong>，如果不指定则该 rule 失败后即会停止 Pipeline 的运行（正在进行的任务不会中断）。可以在 snakemake 运行时通过 <code>--keep-going</code> 使工作流继续运行其他独立的任务。</li><li><code>resources</code> 段用于<strong>定义该 rule 所占用的资源</strong>，可以在 snakemake 运行时通过 <code>--resources</code> 指定资源总量。以该 rule 为例，每个下载任务在 rule 中指定会占用 1 个下载槽（download_slots），因此可以通过 <code>--resources download_slots=4</code> 分配四个下载槽，使下载任务最多同时进行四个。</li><li><code>shell</code> 段用于<strong>定义该 rule 执行的 shell 命令行</strong>，内容解释如下：<ul><li><code>{output.srafile}</code> 将替换为 output 段的 srafile 字段。首先，让其检查是否存在 <code>.lock</code> 文件（<code>prefetch</code> 在下载过程中会产生的文件，如果不移除则无法重续下载），这一步是<strong>为失败以后重试而准备的</strong>。此后通过 <code>prefetch</code> 下载，将日志输出到 <code>{log}</code> 中。下载结束后进行检查，将后缀统一为 <code>.sra</code>（部分 sra 文件以 <code>.sralite</code> 结尾）。</li></ul></li></ol><p>对于一个 rule 而言，最少仅需要 <code>output</code> 和指令（如 <code>shell</code>、<code>script</code>、<code>run</code>）部分，其他都是可选字段（增强 rule 的功能和可管理性）。</p><p>下载结束后就是我们还需要进行处理，即将 <code>sra</code> 文件提取为 fastq 文件（使用 <code>fasterq-dump</code>），考虑到这也属于原始数据的处理，因此新的规则可以继续添加在 <code>01_prefetch.smk</code> 中，首先我们确定一些要提前确定的参数：</p><ul><li><code>fasterq-dump</code> 和 <code>pigz</code> 使用的线程数。</li></ul><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># config.yaml</span></span><br><span class="line"><span class="attr">download:</span></span><br><span class="line">  <span class="attr">retry:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">extract_threads:</span> <span class="number">6</span></span><br></pre></td></tr></tbody></table></figure><p>此外，这一步中单端时仅产生一个文件，双端时产生两个文件。因此规则需要根据 <code>config</code> 中指定的 <code>mode</code> 进行行为调整：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 01_prefetch.smk</span></span><br><span class="line">rule extract:</span><br><span class="line">    <span class="built_in">input</span>:</span><br><span class="line">        srafile = <span class="string">"rawfastq/{srr}/{srr}.sra"</span></span><br><span class="line">    output:</span><br><span class="line">        fastq_files = <span class="string">"rawfastq/{srr}.fastq.gz"</span> <span class="keyword">if</span> config[<span class="string">"mode"</span>] == <span class="string">"single"</span> <span class="keyword">else</span> [<span class="string">"rawfastq/{srr}_1.fastq.gz"</span>, <span class="string">"rawfastq/{srr}_2.fastq.gz"</span>],</span><br><span class="line">    log:</span><br><span class="line">        <span class="string">"logs/{srr}_extract.log"</span></span><br><span class="line">    params:</span><br><span class="line">        srrid = <span class="string">"{srr}"</span></span><br><span class="line">    threads: config[<span class="string">"download"</span>][<span class="string">"extract_threads"</span>]</span><br><span class="line">    shell:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        fasterq-dump {input.srafile} --progress --details --split-files -v --outdir rawfastq --threads {threads} &gt; {log} 2&gt;&amp;1</span></span><br><span class="line"><span class="string">        pigz -p {threads} rawfastq/{params.srrid}*.fastq</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        if [ "{config[mode]}" == "single" ]; then</span></span><br><span class="line"><span class="string">            if [ -e rawfastq/{params.srrid}_1.fastq.gz ]; then</span></span><br><span class="line"><span class="string">                mv rawfastq/{params.srrid}_1.fastq.gz {output.fastq_files}</span></span><br><span class="line"><span class="string">                echo "Single extract finished! (Renamed _1.fastq.gz)" &gt;&gt; {log}</span></span><br><span class="line"><span class="string">            else</span></span><br><span class="line"><span class="string">                echo "Single extract finished!" &gt;&gt; {log}</span></span><br><span class="line"><span class="string">            fi</span></span><br><span class="line"><span class="string">        else</span></span><br><span class="line"><span class="string">            if [ -e rawfastq/{params.srrid}_1.fastq.gz ] &amp;&amp; [ -e rawfastq/{params.srrid}_2.fastq.gz ]; then</span></span><br><span class="line"><span class="string">                echo "Paired extract finished!" &gt;&gt; {log}</span></span><br><span class="line"><span class="string">            else</span></span><br><span class="line"><span class="string">                echo "Paired extract failed: one or both FASTQ files missing!" &gt;&gt; {log}</span></span><br><span class="line"><span class="string">                exit 1</span></span><br><span class="line"><span class="string">            fi</span></span><br><span class="line"><span class="string">        fi</span></span><br><span class="line"><span class="string">        """</span></span><br></pre></td></tr></tbody></table></figure><p>逐段解释：</p><ol><li><code>input</code> 段<strong>指定该 rule 需要的输入文件</strong>，snakemake 将进行监测直到这些文件出现后再开始运行该 rule。<u>这里涉及到 snakemake 中最重要的一个概念</u>：<ul><li>Snakemake <strong>将依据各个 rule 的 input 和 output 确认它们彼此之间的依赖关系，构建一个工作流的有向无环图</strong>，此后按照图的拓扑顺序运行，确保某一规则在依赖的其他规则结束后才会执行。同样也是在这个过程中，Snakemake 会自动根据目标文件向各规则的 input 和 output 中进行通配符填补（即上述的 <code>{srr}</code>）。以本文拟构建的 Pipeline 为例（<code>snakemake --dag | dot -Tpng &gt; dag.png</code>）：</li></ul></li></ol><img src="/pic2/dag.png" style="zoom:80%;"><ol start="2"><li><p><code>output</code> 段新增了根据 mode 进行的输出文件调整。</p></li><li><p><code>shell</code> 段中，首先通过 <code>fasterq-dump</code> 进行提取，并使用 <code>pigz</code> 进行压缩。此后，如果使用单端模式，则将后缀统一为 <code>[SRR id].fastq.gz</code>；如果使用双端模式，则检查是否两端数据都存在。</p></li></ol><p>到此即产生我们所需要的原始数据，将这些 rule 整合进 <code>Snakefile</code> 中（声明 <code>smk</code> 文件）：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Snakefile</span></span><br><span class="line"><span class="comment"># download and extract SRA files</span></span><br><span class="line">include: <span class="string">"rules/01_prefetch.smk"</span></span><br></pre></td></tr></tbody></table></figure><p>此后 <code>trim_galore</code> 的流程构建也遵循相同的思路（设定参数 —— 编写规则 —— 整合）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch 02_trimgalore.smk</span><br></pre></td></tr></tbody></table></figure><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># config.yaml</span></span><br><span class="line"><span class="attr">trim:</span></span><br><span class="line">  <span class="attr">threads:</span> <span class="number">8</span></span><br><span class="line">  <span class="attr">param:</span> <span class="string">""</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 02_trimgalore.smk</span></span><br><span class="line">rule trim_galore:</span><br><span class="line">    <span class="built_in">input</span>:</span><br><span class="line">        fastq_files = <span class="string">"rawfastq/{srr}.fastq.gz"</span> <span class="keyword">if</span> config[<span class="string">"mode"</span>] == <span class="string">"single"</span> <span class="keyword">else</span> [<span class="string">"rawfastq/{srr}_1.fastq.gz"</span>, <span class="string">"rawfastq/{srr}_2.fastq.gz"</span>]</span><br><span class="line">    output:</span><br><span class="line">        trimmed_fastq = <span class="string">"trimgalore_result/{srr}_trimmed.fq.gz"</span> <span class="keyword">if</span> config[<span class="string">"mode"</span>] == <span class="string">"single"</span> <span class="keyword">else</span> [<span class="string">"trimgalore_result/{srr}_1_val_1.fq.gz"</span>, <span class="string">"trimgalore_result/{srr}_2_val_2.fq.gz"</span>]</span><br><span class="line">    params:</span><br><span class="line">        option = config[<span class="string">"trim"</span>][<span class="string">"param"</span>]</span><br><span class="line">    log:</span><br><span class="line">        <span class="string">"logs/{srr}_trimgalore.log"</span></span><br><span class="line">    threads: config[<span class="string">"trim"</span>][<span class="string">"threads"</span>]</span><br><span class="line">    shell:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        if [ "{config[mode]}" == "single" ]; then</span></span><br><span class="line"><span class="string">            trim_galore {params.option} --cores {threads} {input.fastq_files} -o trimgalore_result/ &gt; {log} 2&gt;&amp;1</span></span><br><span class="line"><span class="string">        else</span></span><br><span class="line"><span class="string">            trim_galore --paired {params.option} --cores {threads} {input.fastq_files[0]} {input.fastq_files[1]} -o trimgalore_result/ &gt; {log} 2&gt;&amp;1</span></span><br><span class="line"><span class="string">        fi</span></span><br><span class="line"><span class="string">        """</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Snakefile</span></span><br><span class="line"><span class="comment"># Trim fastq</span></span><br><span class="line">include: <span class="string">"rules/02_trimgalore.smk"</span></span><br></pre></td></tr></tbody></table></figure><p>这里将监测先前 <code>extract</code> 规则输出的文件，如果 <code>extract</code> 规则运行完成则启动，并根据单端和双端模式自动调节输入的 fastq 文件和过滤后的 fastq 文件。可以设置的参数有两个，一个是每个 <code>trim_galore</code> 使用的线程数，另一个是 <code>trim_galore</code> 的额外参数。通过<strong>设置一个可以灵活调节的参数项可以让使用者依据自身的情况进行参数设定而不至于受 Pipeline 限制</strong>，例如自行设置最短长度和接头序列等。如果不需要则留空即可。</p><p><code>salmon</code> 的构造流程大致相同，但由于这里使用的通配符将变为样本名，因此这里需要进行一定变动：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch 03_salmon.smk</span><br></pre></td></tr></tbody></table></figure><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># config.yaml</span></span><br><span class="line"><span class="attr">salmon:</span></span><br><span class="line">  <span class="attr">threads:</span> <span class="number">16</span></span><br><span class="line">  <span class="attr">salmon_index:</span> <span class="string">"/path/to/hg38_salmon_index"</span></span><br><span class="line">  <span class="attr">param:</span> <span class="string">"--seqBias --gcBias --dumpEq"</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 03_salmon.smk</span></span><br><span class="line">rule salmon:</span><br><span class="line">    <span class="built_in">input</span>:</span><br><span class="line">        trimmed_fastq = <span class="keyword">lambda</span> wildcards: get_fastq_list(config[<span class="string">"mode"</span>], config[<span class="string">"inputfile"</span>][<span class="string">"groupfile"</span>], wildcards.sample)</span><br><span class="line">    output:</span><br><span class="line">        count_file = <span class="string">"results/{sample}/quant.sf"</span></span><br><span class="line">    params:</span><br><span class="line">        index = config[<span class="string">"salmon"</span>][<span class="string">"salmon_index"</span>],</span><br><span class="line">        samplename = <span class="string">"{sample}"</span>,</span><br><span class="line">        option = config[<span class="string">"salmon"</span>][<span class="string">"param"</span>],</span><br><span class="line">        fastqpath = <span class="keyword">lambda</span> wildcards: get_fastq_path(config[<span class="string">"mode"</span>], config[<span class="string">"inputfile"</span>][<span class="string">"groupfile"</span>], wildcards.sample)</span><br><span class="line">    log:</span><br><span class="line">        <span class="string">"logs/{sample}_salmon.log"</span></span><br><span class="line">    threads: config[<span class="string">"salmon"</span>][<span class="string">"threads"</span>]</span><br><span class="line">    shell:</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        if [ "{config[mode]}" == "single" ]; then</span></span><br><span class="line"><span class="string">            salmon quant -i {params.index} -l A -r &lt;(zcat {params.fastqpath}) -p {threads} {params.option} -o results/{params.samplename} &gt; {log} 2&gt;&amp;1</span></span><br><span class="line"><span class="string">        else</span></span><br><span class="line"><span class="string">            salmon quant -i {params.index} -l A -1 &lt;(zcat {params.fastqpath[0]}) -2 &lt;(zcat {params.fastqpath[1]}) -p {threads} {params.option} -o results/{params.samplename} &gt; {log} 2&gt;&amp;1</span></span><br><span class="line"><span class="string">        fi</span></span><br><span class="line"><span class="string">        """</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Snakefile</span></span><br><span class="line"><span class="comment"># Salmon quant</span></span><br><span class="line">include: <span class="string">"rules/03_salmon.smk"</span></span><br></pre></td></tr></tbody></table></figure><p>可以看到这里使用的通配符变为了 <code>{sample}</code>，并且使用了两个自行构造的函数 <code>get_fastq_list</code> 及 <code>get_fastq_path</code>，分别用于获取每个样本中所有 fastq 文件的列表和路径。这两个函数的具体实现在 <code>common.smk</code> 中进行：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_fastq_list</span>(<span class="params">mode, filepath, group</span>):</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Get fastq list for each group.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    group_fastq = {}</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filepath, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            info = line.strip().split()</span><br><span class="line">            <span class="keyword">if</span> info[<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> group_fastq:</span><br><span class="line">                group_fastq[info[<span class="number">1</span>]] = [info[<span class="number">0</span>]]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                group_fastq[info[<span class="number">1</span>]].append(info[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">"single"</span>:</span><br><span class="line">        fastq_path_list = [<span class="string">f'trimgalore_result/<span class="subst">{i}</span>_trimmed.fq.gz'</span> <span class="keyword">for</span> i <span class="keyword">in</span> group_fastq[group]]</span><br><span class="line">        <span class="keyword">return</span> fastq_path_list</span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">"paired"</span>:</span><br><span class="line">        fastq_path_list1 = [<span class="string">f'trimgalore_result/<span class="subst">{i}</span>_1_val_1.fq.gz'</span> <span class="keyword">for</span> i <span class="keyword">in</span> group_fastq[group]]</span><br><span class="line">        fastq_path_list2 = [<span class="string">f'trimgalore_result/<span class="subst">{i}</span>_2_val_2.fq.gz'</span> <span class="keyword">for</span> i <span class="keyword">in</span> group_fastq[group]]</span><br><span class="line">        fastq_path_list = fastq_path_list1 + fastq_path_list2</span><br><span class="line">        <span class="keyword">return</span> fastq_path_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_fastq_path</span>(<span class="params">mode, filepath, group</span>):</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Get fastq path for each group.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    group_fastq = {}</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filepath, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            info = line.strip().split()</span><br><span class="line">            <span class="keyword">if</span> info[<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> group_fastq:</span><br><span class="line">                group_fastq[info[<span class="number">1</span>]] = [info[<span class="number">0</span>]]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                group_fastq[info[<span class="number">1</span>]].append(info[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">"single"</span>:</span><br><span class="line">        fastq_path_list = [<span class="string">f'trimgalore_result/<span class="subst">{i}</span>_trimmed.fq.gz'</span> <span class="keyword">for</span> i <span class="keyword">in</span> group_fastq[group]]</span><br><span class="line">        <span class="keyword">return</span> <span class="string">' '</span>.join(fastq_path_list)</span><br><span class="line">    <span class="keyword">elif</span> mode == <span class="string">"paired"</span>:</span><br><span class="line">        fastq_path_list1 = [<span class="string">f'trimgalore_result/<span class="subst">{i}</span>_1_val_1.fq.gz'</span> <span class="keyword">for</span> i <span class="keyword">in</span> group_fastq[group]]</span><br><span class="line">        fastq_path_list2 = [<span class="string">f'trimgalore_result/<span class="subst">{i}</span>_2_val_2.fq.gz'</span> <span class="keyword">for</span> i <span class="keyword">in</span> group_fastq[group]]</span><br><span class="line">        <span class="keyword">return</span> [<span class="string">' '</span>.join(fastq_path_list1), <span class="string">' '</span>.join(fastq_path_list2)]</span><br></pre></td></tr></tbody></table></figure><p>这两个函数根据接收到的模式及 <code>group.txt</code> 内容，返回特定 sample 对应的 fastq 文件列表和路径，其中列表传输给 input 使其监视上游依赖 rule 的运行情况，而路径传输给特定参数以在 salmon 定量中对同一样本的测序数据进行合并。</p><p>这里涉及到的其他一些概念：</p><ul><li><strong>wildcards 是一个命名空间，在函数和 lambda 表达式中用于访问通配符。</strong><code>wildcards.sample</code> 只有在规则的输出、输入或其他字段中定义了 <code>{sample}</code> 占位符时才会存在。<strong>结合 lambda 和 wildcards 并通过自定义的处理函数可以获取需要动态规划的输入和输出。</strong>注意，直接在这些函数中给定 <code>{sample}</code> 是不可行的。</li><li>common.smk 同样需要在 Snakefile 中声明，此后该文件中定义的所有函数都可以被其他规则所识别。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Snakefile</span></span><br><span class="line">include: <span class="string">"rules/common.smk"</span></span><br></pre></td></tr></tbody></table></figure><p>到这里，Pipeline 的整体搭建就已完成。</p><h4 id="3、Pipeline-运行"><a href="#3、Pipeline-运行" class="headerlink" title="3、Pipeline 运行"></a>3、Pipeline 运行</h4><p>使用 snakemake 命令行运行 Pipeline：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $tutorial_path</span><br><span class="line">snakemake --core 16 --resources download_slots=4</span><br></pre></td></tr></tbody></table></figure><p>这里 <code>--core</code> 指定 snakemake 总共可以管理的 CPU 核数量，snakemake 将根据每个 rule 占用的 threads 自动分配任务，例如：</p><ul><li><p>如果一个 extract 要占用 8 个 threads，一个 salmon 要占用 4 个 threads。那么 snakemake 可能同时进行一个 extract 任务和两个 salmon 任务，<strong>确保提供的核被最大化利用（前提是这些任务的前置依赖都已经满足）</strong>。</p></li><li><p><code>--resources</code> 指定 snakemake 的其他分配资源，这些都是用户规定的。以上述命令为例，Snakemake 共有 4 个 download_slots 资源，而在需要 download_slots 资源运行的 rule 中，同时运行所需的资源总和将被限定在这个值以内。在该 Pipeline 中即最高只可同时并行四个下载任务。</p></li></ul><p>运行完成后，留意以下文件夹：</p><ul><li><code>log</code> 文件夹中包含各个环节运行时的输出日志文件。</li><li><code>rawfastq</code> 文件夹中为原始测序数据。</li><li><code>trimgalore_result  </code> 文件夹中为过滤后的测序数据。</li><li><code>results</code> 文件夹中为各样本的定量结果。</li></ul><p>实测以上 Pipeline 能够正确运行，如果存在问题请前往 github repository 页面查看完整 Pipeline 并确定出错点：</p><p><a href="https://github.com/JuseTiZ/Blog-Snakemake-pipeline/tree/main/Tutorial-Pipeline">https://github.com/JuseTiZ/Blog-Snakemake-pipeline/tree/main/Tutorial-Pipeline</a></p><h2 id="拓展-Pipeline"><a href="#拓展-Pipeline" class="headerlink" title="拓展 Pipeline"></a>拓展 Pipeline</h2><p>以下内容不再详细解释 Pipeline 中如何具体实现，但原理较简单且具有一定实用性，因此这里做一些简单介绍。</p><h3 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h3><p>每个 rule 在运行时都可以指定一个 conda 环境，例如：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rule download:</span><br><span class="line">......</span><br><span class="line">    conda:</span><br><span class="line">        <span class="string">"../envs/sratool.yaml"</span></span><br><span class="line">    ......</span><br></pre></td></tr></tbody></table></figure><p><strong>这里的相对路径是以 rule 所在 smk 文件开始寻找的</strong>，你可以在 <code>../envs/sratool.yaml</code> 中填写以下内容：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">sra</span></span><br><span class="line"><span class="attr">dependencies:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">bioconda::sra-tools==3.1.0</span></span><br></pre></td></tr></tbody></table></figure><p>在运行该规则时，Snakemake 会寻找名为 sra 的环境，如果不存在则新建该环境并安装指定依赖（sra-tools）。</p><p>请注意，Snakemake 所有环境操作都是默认使用 <code>mamba</code> 进行的，如果你想使用 <code>conda</code> 进行需要在命令行中指定 <code>--conda-frontend conda</code>（不推荐）。</p><p>另外你也可以在 snakefile 中指定运行这套 pipeline 所需的最低版本，例如：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> snakemake.utils <span class="keyword">import</span> min_version</span><br><span class="line">min_version(<span class="string">"6.0"</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="性能监测"><a href="#性能监测" class="headerlink" title="性能监测"></a>性能监测</h3><p>每个 rule 在运行时都可以指定一个 benchmark 文件，例如：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rule download:</span><br><span class="line">......</span><br><span class="line">    benchmark:</span><br><span class="line">        <span class="string">"logs/{srr}_download_prefetch.benchmark.txt"</span>,</span><br><span class="line">    ......</span><br></pre></td></tr></tbody></table></figure><p>Snakemake 会自动测量并记录该 rule 的执行时间、CPU 使用率、内存使用情况等信息并储存到 benchmark 文件中。<strong>这对于需要优化工作流和分析性能瓶颈的情况非常有用</strong>。</p><h2 id="再次改进的可能"><a href="#再次改进的可能" class="headerlink" title="再次改进的可能"></a>再次改进的可能</h2><p>不难看出，上述 Pipeline 依然存在很多可以改进的地方以增强 Pipeline 的可读性和可拓展性，但要做到这些可能会在一定程度上提升理解难度，因此如果你认为上述内容不算困难且想要进一步检验自己当前的能力，可以考虑对该 Pipeline 做以下改进：</p><ol><li>将 <code>group.txt</code> 换为 <code>sample.yaml</code>，在 <code>Snakefile</code> 中提取到 <code>config</code> 变量里，据此进行 rule all input 的指定（可通过动态函数进行），并在 salmon 规则中的 input 和 output 里使用更具效率的函数进行动态规划，<code>sample.yaml</code> 示例：</li></ol><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">samples:</span></span><br><span class="line">  <span class="attr">HeLa_Rep1:</span></span><br><span class="line">    <span class="attr">SRR:</span> <span class="string">"SRR25601734|SRR25601735"</span></span><br><span class="line">  <span class="attr">HeLa_Rep2:</span></span><br><span class="line">    <span class="attr">SRR:</span> <span class="string">"SRR25601736|SRR25601737"</span></span><br></pre></td></tr></tbody></table></figure><ol start="2"><li>将涉及单端双端判断的 rule 拆分成两个 rule（一个用于 single-end，一个用于 paired-end），并将 <code>mode</code> 参数从 <code>config.yaml</code> 中移除，使 Pipeline 能够同时处理单端和双端的数据。例如可以通过在上面提到的 <code>sample.yaml</code> 中添加每个样本的数据类型来进行单双端数据的混合处理：</li></ol><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">samples:</span></span><br><span class="line">  <span class="attr">HeLa_Rep1:</span></span><br><span class="line">    <span class="attr">SRR:</span> <span class="string">"SRR25601734|SRR25601735"</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">"paired"</span></span><br><span class="line">  <span class="attr">xxxx:</span></span><br><span class="line">    <span class="attr">SRR:</span> <span class="string">"SRRxxx"</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">"single"</span></span><br></pre></td></tr></tbody></table></figure><ol start="3"><li>添加下游分析部分，例如新建 <code>scripts</code> 文件夹存放自定义的用于提取表达矩阵的脚本，并在 Pipeline 中添加新的规则以对其进行实现（别忘了 rule all 的 input 部分也要进行对应更新）。</li></ol><p>前两者的具体实现可参考 repository 下的 <a href="https://github.com/JuseTiZ/Blog-Snakemake-pipeline/tree/main/ChIP-Pipeline">ChIP Pipeline</a>。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对 bedgraph 文件进行 lowess 平滑操作</title>
      <link href="/2024/06/29/%E5%AF%B9%20bedgraph%20%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%20lowess%20%E5%B9%B3%E6%BB%91%E6%93%8D%E4%BD%9C/"/>
      <url>/2024/06/29/%E5%AF%B9%20bedgraph%20%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%20lowess%20%E5%B9%B3%E6%BB%91%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>在进行一些特定的功能基因组学数据分析时，我们可能需要对 bedgraph 文件中每个 bin 的值进行一定的平滑操作，以降低随机噪声的影响并提供更好的可视化效果。例如：</p><ul><li>Repli-seq / BrdU-seq 中量化得到的 Replication Timing</li><li>OK-seq / Pu-seq 中量化得到的 Replication Fork Directionality</li></ul><p>以下是一个用于对 bedgraph 进行 lowess 平滑操作的 python script：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>():</span><br><span class="line"></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">'Perform lowess smooth on bedgraph.'</span>)</span><br><span class="line">    </span><br><span class="line">    parser.add_argument(<span class="string">'--input'</span>, <span class="string">'-i'</span>, <span class="built_in">help</span>=<span class="string">'Input bedgraph file.'</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--output'</span>, <span class="string">'-o'</span>, <span class="built_in">help</span>=<span class="string">'Output smoothed bedgraph file.'</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--span'</span>, <span class="built_in">help</span>=<span class="string">'Span size of loess smoothing.'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">"--chr"</span>, required=<span class="literal">True</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">"The chrom to input. e.g. 1-22,X,Y"</span>)</span><br><span class="line">    </span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_range</span>(<span class="params">value</span>):</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> part <span class="keyword">in</span> value.split(<span class="string">','</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'-'</span> <span class="keyword">in</span> part:</span><br><span class="line">            start, end = part.split(<span class="string">'-'</span>)</span><br><span class="line">            result.extend(<span class="built_in">range</span>(<span class="built_in">int</span>(start), <span class="built_in">int</span>(end) + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result.append(<span class="built_in">int</span>(part))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">    args = get_args()</span><br><span class="line"></span><br><span class="line">    data = pd.read_csv(args.<span class="built_in">input</span>, sep=<span class="string">'\t'</span>, header=<span class="literal">None</span>, names=[<span class="string">'chrom'</span>, <span class="string">'start'</span>, <span class="string">'end'</span>, <span class="string">'value'</span>])</span><br><span class="line">    data[<span class="string">'midpoint'</span>] = (data[<span class="string">'start'</span>] + data[<span class="string">'end'</span>]) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    span_size = args.span</span><br><span class="line">    smoothed_data = []</span><br><span class="line">    chr_list = [<span class="string">f'chr<span class="subst">{i}</span>'</span> <span class="keyword">for</span> i <span class="keyword">in</span> parse_range(args.<span class="built_in">chr</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> chrom <span class="keyword">in</span> data[<span class="string">'chrom'</span>].unique():</span><br><span class="line">        chrom_data = data[data[<span class="string">'chrom'</span>] == chrom]</span><br><span class="line">        <span class="keyword">if</span> chrom <span class="keyword">not</span> <span class="keyword">in</span> chr_list:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        chrom_length = chrom_data[<span class="string">'end'</span>].iloc[-<span class="number">1</span>] - chrom_data[<span class="string">'start'</span>].iloc[<span class="number">0</span>]</span><br><span class="line">        span_frac = span_size / chrom_length</span><br><span class="line"></span><br><span class="line">        lowess = sm.nonparametric.lowess(chrom_data[<span class="string">'value'</span>], chrom_data[<span class="string">'midpoint'</span>], frac=span_frac)</span><br><span class="line">        smoothed_df = pd.DataFrame(lowess, columns=[<span class="string">'midpoint'</span>, <span class="string">'smoothed_value'</span>])</span><br><span class="line">        chrom_data = chrom_data.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        chrom_data[<span class="string">'smoothed_value'</span>] = smoothed_df[<span class="string">'smoothed_value'</span>]</span><br><span class="line">        smoothed_data.append(chrom_data)</span><br><span class="line"></span><br><span class="line">    smoothed_data = pd.concat(smoothed_data)</span><br><span class="line">    smoothed_data[[<span class="string">'chrom'</span>, <span class="string">'start'</span>, <span class="string">'end'</span>, <span class="string">'smoothed_value'</span>]].to_csv(args.output, sep=<span class="string">'\t'</span>, header=<span class="literal">False</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></tbody></table></figure><p><strong>下载地址：</strong></p><p><a href="https://github.com/JuseTiZ/PyScript-for-CT/blob/main/bedgraph_lowess.py">https://github.com/JuseTiZ/PyScript-for-CT/blob/main/bedgraph_lowess.py</a></p><p><strong>依赖 module 安装：</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install pandas</span><br><span class="line">pip install statsmodels</span><br></pre></td></tr></tbody></table></figure><p><strong>参数详情：</strong></p><ul><li><code>--input</code> / <code>-i</code>，指定需要进行 lowess 平滑操作的 bedgraph 文件，该文件应当仅具有四列，且第一列染色体编号应以 <code>chr</code> 开头。</li><li><code>--output</code> / <code>-o</code>，指定输出的平滑后 bedgraph 文件，输出的新 bedgraph 中第四列为 LOWESS smooth 后的值。</li><li><code>--span</code>，指定平滑操作时使用的长度，脚本将根据每条染色体的总长确定用于平滑的数据比例。</li><li><code>--chr</code>，指定进行平滑操作的染色体编号，可使用 <code>-</code> 指定数字范围，也可使用逗号分隔，例如 <code>1-22,X,Y</code>。</li></ul><p><strong>应用示例：</strong></p><p>假设目前有一个通过 Repli-seq 计算得到的小鼠 RT(Replication Timing) bedgraph 文件 <code>RT.bedgraph</code>，通过以下命令进行 30w bp 的平滑：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python bedgraph_lowess.py -i RT.bedgraph -o RT.lowess.bedgraph --span 300000 --chr 1-19</span><br></pre></td></tr></tbody></table></figure><p>平滑前后 IGV track 示例：</p><p><img src="/pic2/bedgraphlowess.png"></p><p>请注意，平滑操作<strong>在减少噪音的同时，也损失了部分信息量</strong>，因此请根据自己当前使用的数据进行权衡，合理设置 <code>--span</code> 参数，一般情况下：</p><ul><li>数据的分辨率越高，该参数指定的值应当越低。反之亦然。</li><li>对信息精细程度的要求越高，该参数指定的值应当越低。反之亦然。</li></ul><p>例如对于某些 OK-seq 数据而言只需要 60kb 左右的 span size 即可。请根据研究需求或者数据来源文章指定恰当的值。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>获取基因组上 intron 区域及对应链信息的方法</title>
      <link href="/2024/06/09/%E8%8E%B7%E5%8F%96%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%8A%20intron%20%E5%8C%BA%E5%9F%9F%E5%8F%8A%E5%AF%B9%E5%BA%94%E9%93%BE%E4%BF%A1%E6%81%AF%E7%9A%84%E6%96%B9%E6%B3%95/"/>
      <url>/2024/06/09/%E8%8E%B7%E5%8F%96%E5%9F%BA%E5%9B%A0%E7%BB%84%E4%B8%8A%20intron%20%E5%8C%BA%E5%9F%9F%E5%8F%8A%E5%AF%B9%E5%BA%94%E9%93%BE%E4%BF%A1%E6%81%AF%E7%9A%84%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>前置条件：</p><ul><li>在环境变量中可调用的 <code>bedtools</code></li></ul><p>本文参考：</p><blockquote><p><strong>Get intronic and intergenic sequences based on gff file</strong> from Biostars</p><p><a href="https://www.biostars.org/p/112251/">https://www.biostars.org/p/112251/</a></p></blockquote><p>本文可满足的需求：</p><ul><li>得到特定区域的 bed 文件（例如 exon / intron 等）。</li><li>在得到区域信息的同时进行链信息的区分。</li></ul><h3 id="下载基因组注释文件（gtf）"><a href="#下载基因组注释文件（gtf）" class="headerlink" title="下载基因组注释文件（gtf）"></a>下载基因组注释文件（gtf）</h3><p>以人类最新版本的 gencode 注释为例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_46/gencode.v46.basic.annotation.gtf.gz</span><br></pre></td></tr></tbody></table></figure><p>也可以选择已有的 gtf 文件进行。</p><h3 id="得到-transcript-和-exon-区域信息"><a href="#得到-transcript-和-exon-区域信息" class="headerlink" title="得到 transcript 和 exon 区域信息"></a>得到 transcript 和 exon 区域信息</h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">GTF="/path/to/gencode.v46.basic.annotation.gtf.gz" # 改为自己实际的注释文件路径，建议使用压缩格式以兼容以下命令</span><br><span class="line">BASENAME=$(basename "$GTF" .gtf.gz)</span><br><span class="line"></span><br><span class="line">TRANSCRIPT_BED="${BASENAME}.transcript.bed"</span><br><span class="line">FORWARD_TRANS_BED="${BASENAME}.transcript.fors.bed"</span><br><span class="line">BACKWARD_TRANS_BED="${BASENAME}.transcript.bacs.bed"</span><br><span class="line">DOUBLE_TRANS_BED="${BASENAME}.transcript.doubletrans.bed"</span><br><span class="line">EXON_BED="${BASENAME}.exon.bed"</span><br><span class="line">INTRON_BED="${BASENAME}.intron.bed"</span><br><span class="line">CDS_BED="${BASENAME}.cds.bed"</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">得到 transcript 区域</span></span><br><span class="line">awk '$3=="transcript" {print $1, $4-1, $5, $7}' OFS='\t' &lt;(zcat $GTF) &gt; $TRANSCRIPT_BED</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">得到 exon 区域</span></span><br><span class="line">awk '$3=="exon" {print $1, $4-1, $5, $7}' OFS='\t' &lt;(zcat $GTF) &gt; $EXON_BED</span><br></pre></td></tr></tbody></table></figure><p>以上命令将得到 <code>.transcript.bed</code> 和 <code>.exon.bed</code> 结尾的文件，里面包含基因组上所有 transcript 和 exon 的信息。</p><h3 id="不关注链信息时"><a href="#不关注链信息时" class="headerlink" title="不关注链信息时"></a>不关注链信息时</h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">合并排序 transcript 区域</span></span><br><span class="line">bedtools sort -i $TRANSCRIPT_BED | bedtools merge -i - &gt; $TRANSCRIPT_BED.tmp </span><br><span class="line">mv $TRANSCRIPT_BED.tmp $TRANSCRIPT_BED</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">合并排序 exon 区域</span></span><br><span class="line">bedtools sort -i $EXON_BED | bedtools merge -i - &gt; $EXON_BED.tmp </span><br><span class="line">mv $EXON_BED.tmp $EXON_BED</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 transcript 中排除 exon 得到 intron</span></span><br><span class="line">bedtools subtract -a $TRANSCRIPT_BED -b $EXON_BED &gt; $INTRON_BED</span><br></pre></td></tr></tbody></table></figure><h3 id="关注链信息时"><a href="#关注链信息时" class="headerlink" title="关注链信息时"></a>关注链信息时</h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">得到正负链信息</span></span><br><span class="line">awk '$4=="+"' $TRANSCRIPT_BED | bedtools sort -i - | bedtools merge -i - | awk 'OFS="\t"{print $0, "+"}' &gt; $FORWARD_TRANS_BED</span><br><span class="line">awk '$4=="-"' $TRANSCRIPT_BED | bedtools sort -i - | bedtools merge -i - | awk 'OFS="\t"{print $0, "-"}' &gt; $BACKWARD_TRANS_BED</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找出冲突区域（正负链上都存在 transcript）</span></span><br><span class="line">bedtools intersect -a $FORWARD_TRANS_BED -b $BACKWARD_TRANS_BED &gt; $DOUBLE_TRANS_BED</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">排除 transcript 冲突区域</span></span><br><span class="line">bedtools subtract -a &lt;(cat $FORWARD_TRANS_BED $BACKWARD_TRANS_BED | bedtools sort -i -) -b $DOUBLE_TRANS_BED &gt; $TRANSCRIPT_BED</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">排除 exon 冲突区域</span></span><br><span class="line">awk '$3=="exon" {print $1, $4-1, $5, $7}' OFS='\t' &lt;(zcat $GTF) | bedtools sort -i - | bedtools merge -i - &gt; $EXON_BED</span><br><span class="line">bedtools intersect -a $TRANSCRIPT_BED -b $EXON_BED &gt; $EXON_BED.tmp</span><br><span class="line">mv $EXON_BED.tmp $EXON_BED</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">得到包含链信息的 intron</span></span><br><span class="line">bedtools subtract -a $TRANSCRIPT_BED -b $EXON_BED &gt; $INTRON_BED</span><br></pre></td></tr></tbody></table></figure><h3 id="相关的用途"><a href="#相关的用途" class="headerlink" title="相关的用途"></a>相关的用途</h3><p>通过上述命令，同理也可以获得例如 CDS 或 UTR 的 bed 文件。下游分析中，我们可以通过这些 bed 文件筛选在特定区域中的突变进行相关探索：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bedtools intersect -a input.vcf -b CDS.bed &gt; input.cds.vcf</span><br></pre></td></tr></tbody></table></figure><p>将 <code>input.vcf</code> 和 <code>CDS.bed</code> 请换为实际路径即可得到所有在 CDS 区域中的 variants。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 基因组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ensembl VEP plugins 的使用方法（Alphamissense、dbNSFP 等）</title>
      <link href="/2024/06/09/Ensembl%20VEP%20plugins%20%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%EF%BC%88Alphamissense%E3%80%81dbNSFP%20%E7%AD%89%EF%BC%89/"/>
      <url>/2024/06/09/Ensembl%20VEP%20plugins%20%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%EF%BC%88Alphamissense%E3%80%81dbNSFP%20%E7%AD%89%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>以下是相关的官网链接，如果想要得到除本文内容以外更全面深入的了解，建议跳转相关链接进行查阅：</p><blockquote><p>VEP plugins documentation:</p><p><a href="https://grch37.ensembl.org/info/docs/tools/vep/script/vep_plugins.html">https://grch37.ensembl.org/info/docs/tools/vep/script/vep_plugins.html</a></p><p>VEP install documentation:</p><p><a href="https://grch37.ensembl.org/info/docs/tools/vep/script/vep_download.html">https://grch37.ensembl.org/info/docs/tools/vep/script/vep_download.html</a></p></blockquote><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="安装-VEP"><a href="#安装-VEP" class="headerlink" title="安装 VEP"></a>安装 VEP</h3><p>此处强烈建议使用 Docker 或者 Singularity 直接拉取 VEP 镜像进行分析，因为在 VEP image 中已经内置好所有的 plugin，无需自己手动下载。</p><p>考虑到 Docker 对权限的要求更高，因此这里以普适性更强的 Singularity 为例（Docker 用户有需求可通过文章开头链接前往官网进行参考）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">拉取 VEP image</span></span><br><span class="line">singularity pull --name vep.sif docker://ensemblorg/ensembl-vep</span><br></pre></td></tr></tbody></table></figure><p>之后就可以通过 <code>singularity</code> 运行 VEP：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">singularity exec vep.sif vep --help</span><br></pre></td></tr></tbody></table></figure><p>直接安装的方法：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/Ensembl/ensembl-vep.git</span><br><span class="line">cd ensembl-vep</span><br><span class="line">perl INSTALL.pl</span><br></pre></td></tr></tbody></table></figure><p><code>INSTALL.pl</code> 可以通过指定一系列参数来进行自定义安装，这里介绍其中主要需要注意的几个：</p><ul><li><code>--CACHE_VERSION</code> 选择特定的 Ensembl 版本，目前最新为 112，请根据自己正在使用的注释版本确定。</li><li><code>--CACHEDIR</code> 下载数据库的存储路径，默认为 <code>$HOME/.vep</code>，可自行修改。</li><li><code>--PLUGINS</code> 指定下载的插件（plugins），通过逗号分隔。也可通过 <code>--PLUGINS all</code> 使其下载全部插件。</li></ul><p>由于 <code>INSTALL.pl</code> 需要一定的依赖项，因此遇到安装报错时可前往其 <a href="https://grch37.ensembl.org/info/docs/tools/vep/script/vep_download.html">documentation</a> 查看是否存在依赖项缺失，此外 API 和数据库版本不同时可能存在兼容问题。但目前我使用最新版本的 VEP 进行旧版本数据库的注释是不存在任何问题的。</p><h3 id="下载数据库"><a href="#下载数据库" class="headerlink" title="下载数据库"></a>下载数据库</h3><p>通过 <code>INSTALL.pl</code> 安装的另一个弊端就是可能下载速度非常慢，因此这里介绍一个自行安装数据库的方法，对于使用 <code>singularity</code> 或者已经配置好 <code>vep</code> 的情况，可以使用以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir vep_data</span><br><span class="line">cd vep_data</span><br><span class="line">wget -c ftp://ftp.ensembl.org/pub/release-112/variation/indexed_vep_cache/homo_sapiens_vep_112_GRCh38.tar.gz</span><br><span class="line">tar zxf homo_sapiens_vep_112_GRCh38.tar.gz</span><br></pre></td></tr></tbody></table></figure><p>使用其他版本时，可将上述网址中的 <code>112</code> 替换为其他版本号例如 <code>110</code> 等。</p><p>之后在运行 <code>vep</code> 时可以通过 <code>--cache_version</code> 指定需要使用的版本号。</p><h3 id="下载-plugins-需要的文件"><a href="#下载-plugins-需要的文件" class="headerlink" title="下载 plugins 需要的文件"></a>下载 plugins 需要的文件</h3><p>这里仅介绍 AlphaMissense 和 dbNSFP 两个插件的数据库构建方法，原因如下：</p><ul><li>AlphaMissense 对于非同义突变的影响预测具有目前最先进的性能。但由于其开发团队仅提供了 GENCODE V33（对应 Ensembl V98），因此很多更新版本注释中的突变可能没法找到其对应的 AlphaMissense 参数。且其 github 上仅提供模型架构而未提供训练后的权重信息，因此无法自行预测。但其结果依然是极具参考价值的。</li><li>dbNSFP 是一个集成数据库，里面包含了众多 Variant Effect Predictor 的结果，包括但不限于 CADD、LINSIGHT、ESM1b、EVE、AlphaMissense 等各种 score，安装了该插件的效果等同于安装许多其他插件，从效率上讲极具价值。如果选择安装该数据库则可以考虑跳过 AlphaMissense，注意该数据库文件较大请注意剩余存储。</li></ul><img src="/pic2/dbNSFP.png" style="zoom:80%;"><p>一些需要注意的事项：</p><ul><li>插件下载好不代表可以直接使用，因为它需要基于对应数据库才能运行。</li><li>AlphaMissense 是 vep 112 版本新发布的插件，不清楚旧版本 API 是否与其兼容。</li><li>dbNSFP 中<strong>仅包含非同义突变的注释信息</strong>，因此其仅会对那些存在 missense_variant 的位点进行注释。如果你还需要统计同义突变或者内含子突变的 score（例如 CADD 等软件包含其他类型突变的影响），那么使用 dbNSFP 可能不是最好的选择。</li><li>dbNSFP 本身使用的注释版本可能与 VEP 具有冲突，这可能导致相关的预测结果在不同版本间存在冲突，详见 <a href="https://github.com/Ensembl/VEP_plugins/issues/626">issue#626</a>。</li><li>建议将所有数据库下载到同一目录下的不同子目录中，方便进行管理和可能需要的路径绑定。</li></ul><h4 id="AlphaMissense-安装"><a href="#AlphaMissense-安装" class="headerlink" title="AlphaMissense 安装"></a>AlphaMissense 安装</h4><p>更多细节见：<a href="https://grch37.ensembl.org/info/docs/tools/vep/script/vep_plugins.html#alphamissense">https://grch37.ensembl.org/info/docs/tools/vep/script/vep_plugins.html#alphamissense</a></p><p>请自行选择安装该数据库的路径 <code>[PATH]</code>，然后运行以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd [PATH]</span><br><span class="line">gsutil -m cp \</span><br><span class="line">  "gs://dm_alphamissense/AlphaMissense_hg19.tsv.gz" \</span><br><span class="line">  "gs://dm_alphamissense/AlphaMissense_hg38.tsv.gz" \</span><br><span class="line">  .</span><br></pre></td></tr></tbody></table></figure><p>此后对数据库进行构建，以使用 hg38 版本为例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tabix -s 1 -b 2 -e 2 -f -S 1 AlphaMissense_hg38.tsv.gz</span><br></pre></td></tr></tbody></table></figure><p>建立好索引后，在运行 VEP 时可以通过以下命令进行 Alphamissense score 注释：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">singularity exec /path/to/vep.sif -i variations.vcf --plugin AlphaMissense,file=/full/path/to/AlphaMissense_hg38.tsv.gz</span><br></pre></td></tr></tbody></table></figure><p>将 <code>vep.sif</code> 和 <code>AlphaMissense_hg38.tsv.gz</code> 的路径替换为自己的路径（详细运行示例可见下文）。</p><h4 id="dbNSFP-安装"><a href="#dbNSFP-安装" class="headerlink" title="dbNSFP 安装"></a>dbNSFP 安装</h4><p>更多细节见：<a href="https://grch37.ensembl.org/info/docs/tools/vep/script/vep_plugins.html#dbnsfp">https://grch37.ensembl.org/info/docs/tools/vep/script/vep_plugins.html#dbnsfp</a></p><p>dbNSFP 每个版本分为 <code>a</code> <code>c</code> 两个类型，其中 <code>a</code> 适用于 academic use，<code>c</code> 适用于 <code>commercial use</code>。后者中不包含以下 effect score:</p><blockquote><p>Polyphen2, VEST, REVEL, ClinPred, CADD, LINSIGHT, GenoCanyon</p></blockquote><p>以下部分以 <code>a</code> 类型为例，该文章编写时 dbNSFP 的最新版本为 v4.8，若有变动请见其 <a href="https://sites.google.com/site/jpopgen/dbNSFP">documentation</a> 页面。</p><p>请自行选择安装该数据库的路径 <code>[PATH]</code>，然后运行以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd [PATH]</span><br><span class="line">wget https://dbnsfp.s3.amazonaws.com/dbNSFP4.8a.zip</span><br></pre></td></tr></tbody></table></figure><p>下载后，通过以下命令进行数据库的构建：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">version=4.8a</span><br><span class="line">unzip dbNSFP${version}.zip</span><br><span class="line">zcat dbNSFP${version}_variant.chr1.gz | head -n1 &gt; h</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">For hg38</span></span><br><span class="line">zgrep -h -v ^#chr dbNSFP${version}_variant.chr* | sort -k1,1 -k2,2n - | cat h - | bgzip -c &gt; dbNSFP${version}_grch38.gz</span><br><span class="line">tabix -s 1 -b 2 -e 2 dbNSFP${version}_grch38.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">For hg19</span></span><br><span class="line">zgrep -h -v ^#chr dbNSFP${version}_variant.chr* | awk '$8 != "." ' | sort -k8,8 -k9,9n - | cat h - | bgzip -c &gt; dbNSFP${version}_grch37.gz</span><br><span class="line">tabix -s 8 -b 9 -e 9 dbNSFP${version}_grch37.gz</span><br></pre></td></tr></tbody></table></figure><p>通过以下命令查看 dbNSFP 可以进行哪些 score 的注释：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat h | tr '\t' '\n'</span><br></pre></td></tr></tbody></table></figure><p>以上命令会打印出所有可以进行注释的列，通过在参数中指定这些列进行相应的注释，以 AlphaMissense 为例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> h | <span class="built_in">tr</span> <span class="string">'\t'</span> <span class="string">'\n'</span> | grep AlphaMissense</span></span><br><span class="line">AlphaMissense_score</span><br><span class="line">AlphaMissense_rankscore</span><br><span class="line">AlphaMissense_pred</span><br></pre></td></tr></tbody></table></figure><p>在运行 VEP 时可以通过以下命令进行 Alphamissense score 注释：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">singularity exec /path/to/vep.sif -i variations.vcf --plugin dbNSFP,file=/path/to/dbNSFP${version}_grch38.gz,AlphaMissense_score</span><br></pre></td></tr></tbody></table></figure><p>如果要进行其他注释，则将 <code>AlphaMissense_score</code> 替换为对应的列名（即文件 <code>h</code> 中包含的那些名称）。如果要使用所有列，则指定 <code>ALL</code> 即可。</p><p>将 <code>vep.sif</code> 和 <code>dbNSFP${version}_grch38.gz</code> 的路径替换为自己的路径。</p><h3 id="进行注释"><a href="#进行注释" class="headerlink" title="进行注释"></a>进行注释</h3><p>以下是一个 dbNSFP 注释的示例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">singularity exec -B /path/to/database:/path/to/database /path/to/vep.sif \</span><br><span class="line"> vep --dir /path/to/vep_data \</span><br><span class="line">    --cache --cache_version [version] --offline --format vcf --vcf --force_overwrite --assembly GRCh38 \</span><br><span class="line">    --input_file [input vcf] \</span><br><span class="line">    --output_file [output vcf] \</span><br><span class="line">    --plugin dbNSFP,/path/to/database/dbNSFP${version}_grch38.gz,AlphaMissense_score,CADD_raw,phyloP100way_vertebrate</span><br></pre></td></tr></tbody></table></figure><p>注意事项：</p><ul><li><code>-B</code>：该参数用于将目录挂载到 singularity 中，不是必选项。但是如果在运行中，各个插件文件的<u>路径指定正确却依然返回找不到文件</u>时，则需要通过 -B 将插件文件的目录挂载到 singularity 容器中进行访问。比如如果 dbNSFP 的目录在 <code>/database/dbNSFP</code> 中，则可以通过 <code>-B /database:/database</code> 将其目录挂载到容器的相同位置上，从而进行访问。</li><li>将 <code>/path/to/vep.sif</code> / <code>/path/to/vep_data</code> / <code>[input vcf]</code> / <code>[output vcf]</code> 更改为自己的实际路径。</li><li><code>[version]</code> 指定下载的注释版本，如 <code>112</code>。</li><li>dbNSFP 插件中的文件路径改为自己的实际路径。</li><li>要指定更多 dbNSFP 的列，只需要通过逗号作为分隔符添加即可。</li></ul><p>或者你仅想进行 AlphaMissense 的注释：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">singularity exec -B /path/to/database:/path/to/database /path/to/vep.sif \</span><br><span class="line"> vep --dir /path/to/vep_data \</span><br><span class="line">    --cache --cache_version [version] --offline --format vcf --vcf --force_overwrite --assembly GRCh38 \</span><br><span class="line">    --input_file [input vcf] \</span><br><span class="line">    --output_file [output vcf] \</span><br><span class="line">    --plugin AlphaMissense,file=/path/to/database/AlphaMissense_hg38.tsv.gz</span><br></pre></td></tr></tbody></table></figure><p>请根据自己的实际需求选择 <code>hg38</code> 或 <code>hg19</code> 版本。</p><h3 id="多进程并行"><a href="#多进程并行" class="headerlink" title="多进程并行"></a>多进程并行</h3><p>不难察觉到，VEP 的运行速度是非常慢的，如果想对基因组的所有 variants 进行注释可能需要花费大量的时间，因此可以通过以下几种方法降低所需时间：</p><ol><li>仅选择特定区域的 variants，例如只取出那些落在 CDS 区域的 variants 等。</li><li>通过多进程进行并行注释。</li></ol><p>关于如何选择仅在 CDS 区域的 variants 可见博客另一篇文章，这里仅提如何实现多进程并行。</p><p>首先，假设所有 variants 都在同一个文件里，那么一个简单的方法是将其拆分为不同染色体的 variants，然后对每一条染色体的 variants 进行并行注释：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">vcffile="example.vcf" # 请将该处的 vcf 替换为真实的 vcf 文件名称</span><br><span class="line">outname=$(basename "$vcffile" .vcf)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">保存 vcf header</span></span><br><span class="line">grep '^#' "$vcffile" &gt; header.vcf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">输出每条染色体的 vcf</span></span><br><span class="line">awk -v outname="$outname" 'BEGIN {OFS="\t"} !/^#/ {print &gt; outname"."$1".vcf.tmp"}' "$vcffile"</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">整合 header 和 vcf</span></span><br><span class="line">mkdir -p subvcf</span><br><span class="line">for i in *.vcf.tmp;</span><br><span class="line">do</span><br><span class="line">    cat header.vcf "$i" &gt; ./subvcf/"$(basename "$i" .tmp)"</span><br><span class="line">    rm "$i"</span><br><span class="line">done</span><br></pre></td></tr></tbody></table></figure><p>拆分步骤如上所示，并行请根据实际情况决定方案，例如通过 slurm 调度系统或者 parallel 命令等实现。此处以 parallel 为例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ls ./subvcf/*.vcf | parallel -j [num] \</span><br><span class="line">'singularity exec -B /path/to/database:/path/to/database /path/to/vep.sif \</span><br><span class="line"> vep --dir /path/to/vep_data \</span><br><span class="line">    --cache --cache_version [version] --offline --format vcf --vcf --force_overwrite --assembly GRCh38 \</span><br><span class="line">    --input_file {} \</span><br><span class="line">    --output_file {.}.anno.vcf \</span><br><span class="line">    --plugin AlphaMissense,file=/path/to/database/AlphaMissense_hg38.tsv.gz'</span><br></pre></td></tr></tbody></table></figure><p>请将 <code>-j</code> 后的 <code>[num]</code> 替换为希望的并行作业数，最终的注释 vcf 文件将在 <code>subvcf</code> 中以 <code>.anno.vcf</code> 结尾。</p><img src="/pic2/vep_example1.png" style="zoom:80%;"><p>以上方案依然存在两个问题：</p><p>①、不同染色体上的 variants 数量差异很大。</p><p>②、这样仅能做到最高同时并行 <code>染色体数</code> 个任务。</p><p>因此，也可以通过将文件拆分为 variants 数量相等的若干个文件进行并行，以下是一个示例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">vcffile="example.vcf"</span><br><span class="line">outname=$(basename "$vcffile" .vcf)</span><br><span class="line">num_splits=10  # 希望的拆分数量</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">保存 vcf header</span></span><br><span class="line">grep '^#' "$vcffile" &gt; header.vcf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算突变数量</span></span><br><span class="line">total_variants=$(grep -v '^#' "$vcffile" | wc -l)</span><br><span class="line">variants_per_file=$(( (total_variants + num_splits - 1) / num_splits ))</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">输出子 vcf 文件</span></span><br><span class="line">mkdir -p subvcf</span><br><span class="line">split_count=1</span><br><span class="line">variant_count=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用 awk 按突变数量进行拆分（By GPT4.0）</span></span><br><span class="line">awk -v header="header.vcf" -v outname="$outname" -v variants_per_file="$variants_per_file" -v split_count="$split_count" -v variant_count="$variant_count" '</span><br><span class="line">BEGIN {</span><br><span class="line">    while ((getline &lt; header) &gt; 0) {</span><br><span class="line">        header_lines[++header_line_count] = $0</span><br><span class="line">    }</span><br><span class="line">    close(header)</span><br><span class="line">}</span><br><span class="line">!/^#/ {</span><br><span class="line">    if (variant_count % variants_per_file == 0) {</span><br><span class="line">        if (split_count &gt; 1) close(output_file)</span><br><span class="line">        output_file = sprintf("./subvcf/%s.split%d.vcf", outname, split_count)</span><br><span class="line">        for (i = 1; i &lt;= header_line_count; i++) {</span><br><span class="line">            print header_lines[i] &gt; output_file</span><br><span class="line">        }</span><br><span class="line">        split_count++</span><br><span class="line">    }</span><br><span class="line">    print &gt;&gt; output_file</span><br><span class="line">    variant_count++</span><br><span class="line">}</span><br><span class="line">' "$vcffile"</span><br></pre></td></tr></tbody></table></figure><p>以上命令将把文件分为拆分为 10 个子 vcf 文件，并行的方法同之前所述。如果需要拆分为更多的子文件以设置更高的并行数量，仅需调整 <code>num_splits</code> 即可。</p><img src="/pic2/vep_example2.png" style="zoom:80%;"><h3 id="注释结果解释"><a href="#注释结果解释" class="headerlink" title="注释结果解释"></a>注释结果解释</h3><p>注释后，header 中会出现相应的说明字段，以 AlphaMissence 注释为例：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">##INFO=&lt;ID=CSQ,Number=.,Type=String,Description="Consequence annotations from Ensembl VEP. Format: Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|DISTANCE|STRAND|FLAGS|SYMBOL_SOURCE|HGNC_ID|am_class|am_pathogenicity"&gt;</span><br><span class="line">##am_class=The AlphaMissense thresholds are: 'Likely benign' if score &lt; 0.34, 'Likely pathogenic' if score &gt; 0.564, 'ambiguous' otherwise -- see doi.org/10.1126/science.adg7492 for details; column from /data/alphamissense/AlphaMissense_hg38.tsv.gz</span><br><span class="line">##am_pathogenicity=Continuous AlphaMissense score between 0 and 1 which can be interpreted as the predicted probability of the variant being pathogenic; column from /data/alphamissense/AlphaMissense_hg38.tsv.gz</span><br></pre></td></tr></tbody></table></figure><p>这里 <code>INFO</code> 中多出的 <code>CSQ</code> 为 Ensemble VEP 的注释结果，其中以 <code>|</code> 分隔所有注释信息，相应位置上对应的注释说明可见 header 说明。此外：</p><ul><li>一个 variant 可能落在多个转录本中，因此对应的 <code>CSQ</code> 会出现多条结果（以 <code>,</code> 分隔）。</li><li>也有可能该 variant 并不在某个 score 的注释区域内（例如 AlphaMissense 仅注释非同义突变），此时对应位置将为空。</li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>之前在 <a href="https://www.nature.com/articles/s41588-023-01465-0">esm1b</a> 的文章里看到他们用的就是 dbNSFP 来评估各个 VEP method 的表现，想一想先前我还傻楞地去一个一个下载，不禁感慨世界上有很多节省时间的方式，只是需要多花些时间、多长点见识才能了解到。</p><p>也希望这篇文章能帮其他人少走点弯路。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>fasterq-dump 下载 SRA 文件时报错的解决方法（err cmn_iter）</title>
      <link href="/2024/05/10/fasterq-dump%20%E4%B8%8B%E8%BD%BD%20SRA%20%E6%96%87%E4%BB%B6%E6%97%B6%E6%8A%A5%E9%94%99%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%88err%20cmn_iter%EF%BC%89/"/>
      <url>/2024/05/10/fasterq-dump%20%E4%B8%8B%E8%BD%BD%20SRA%20%E6%96%87%E4%BB%B6%E6%97%B6%E6%8A%A5%E9%94%99%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%88err%20cmn_iter%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>这几天下载 SRA，遇到的错误有：</p><ul><li><p><code>fasterq-dump.3.1.0 err: cmn_iter.c cmn_read_uint8_array</code></p></li><li><p><code>fasterq-dump.3.1.0 err: cmn_iter.c cmn_read_String</code></p></li></ul><p>以前使用 <code>fasterq-dump</code> 时只是偶然出现这些问题，重新下载也都能解决，但最近有些 SRA 一直下载失败，经过调查发现这种错误在大文件下载时出现异常频繁，且多次下载并没法有效解决问题，因此需要一个替代的方法。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="Prefetch"><a href="#Prefetch" class="headerlink" title="Prefetch"></a>Prefetch</h4><p>由于 <code>fasterq-dump</code> 直接通过 HTTP 下载得到 fastq 文件，该过程很可能由于一些问题中断从而导致下载失败。因此可以通过更稳定的 <code>prefetch</code> 先得到 sra 文件，再通过 <code>fasterq-dump</code> 提取 fastq 文件。</p><blockquote><p>fasterq-dump fetches SRR on the fly via HTTP and there could be fatal errors during the transfer.<br>prefetch eliminates transfer problems.</p></blockquote><p>具体操作：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">prefetch --max-size 100000000 [SRR <span class="built_in">id</span>]</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">fasterq-dump [SRR <span class="built_in">id</span>]/[SRR <span class="built_in">id</span>].sra --progress --details --split-files -v --threads [number of threads]</span></span><br></pre></td></tr></tbody></table></figure><p>使用 <code>prefetch</code> 下载的好处有两点：</p><ol><li>sra 文件占用的空间较小，因此下载速度更快。</li><li>下载如果因为某种原因中断，仍可以通过相同的命令进行断点重连。</li></ol><p>以下是一个使用 slurm 调度系统进行批量下载和读取的示例，没有调度系统的朋友也可以直接参考命令进行多下载任务并行：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#SBATCH -J download</span></span><br><span class="line"><span class="comment">#SBATCH -o download.out</span></span><br><span class="line"><span class="comment">#SBATCH -e download.err</span></span><br><span class="line"><span class="comment">#SBATCH -N 1</span></span><br><span class="line"><span class="comment">#SBATCH -n 4</span></span><br><span class="line"></span><br><span class="line">output_dir=<span class="string">"./rawfastq"</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$output_dir</span></span><br><span class="line"><span class="built_in">mkdir</span> -p tmp</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download</span></span><br><span class="line"><span class="built_in">cat</span> download.list | parallel -j 4 --tmpdir ./tmp <span class="string">"prefetch --max-size 100000000 --progress --output-directory <span class="variable">$output_dir</span> {} &gt;<span class="variable">$output_dir</span>/prefetch_{}.log 2&gt;&amp;1"</span></span><br></pre></td></tr></tbody></table></figure><p>其中 <code>download.list</code> 为一行一个 SRR id 的文件。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#SBATCH -J extract</span></span><br><span class="line"><span class="comment">#SBATCH -o extract.out</span></span><br><span class="line"><span class="comment">#SBATCH -e extract.err</span></span><br><span class="line"><span class="comment">#SBATCH -N 1</span></span><br><span class="line"><span class="comment">#SBATCH -n 16</span></span><br><span class="line"></span><br><span class="line">output_dir=<span class="string">"./rawfastq"</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$output_dir</span></span><br><span class="line"><span class="built_in">mkdir</span> -p tmp</span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract</span></span><br><span class="line"><span class="built_in">cat</span> download.list  | parallel -j 4 --tmpdir ./tmp <span class="string">"fasterq-dump <span class="variable">$output_dir</span>/{}/{}.sra* --progress --details --split-files -v --outdir <span class="variable">$output_dir</span> --threads 4 &gt;<span class="variable">$output_dir</span>/fasterq-dump_{}.log 2&gt;&amp;1"</span></span><br><span class="line"><span class="comment"># gzip Compress</span></span><br><span class="line"><span class="built_in">ls</span> <span class="variable">$output_dir</span>/*fastq | parallel -j 16 gzip {}</span><br></pre></td></tr></tbody></table></figure><p>这里使用 <code>.sra*</code> 作为后缀的原因是有时下载的 sra 文件其尾缀可能为 <code>.sralite</code>，具体差别可见 <a href="https://www.ncbi.nlm.nih.gov/sra/docs/sra-data-formats/">SRA Data Formats</a>。</p><p>若想加速提取过程，可以根据自身情况调整并行数量和 <code>fasterq-dump</code> 使用的线程数量。以上方法<strong>经实测非常稳定，对于大文件而言也不会出现报错</strong>。</p><h4 id="ascp"><a href="#ascp" class="headerlink" title="ascp"></a>ascp</h4><p>有时 <code>prefetch</code> 下载速度极缓慢，因此选择速度更快很多的 <code>ascp</code> 也是很好的替代方案。</p><p>conda 下载：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">有 mamba 则用 mamba</span></span><br><span class="line">conda install -c hcc aspera-cli -y</span><br></pre></td></tr></tbody></table></figure><p>在 <a href="https://www.ebi.ac.uk/ena/browser/home">ENA Browser</a> 搜索对应的 Accession Number，</p><img src="/pic2/ENAbroser.png" style="zoom:80%;"><p>勾选 <code>fastq_aspera</code> 后下载 TSV：</p><img src="/pic2/ENAbroser2.png" style="zoom:50%;"><p>根据 <code>fastq_ftp</code> 列，制成以下类似文件：</p><figure class="highlight txt"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/vol1/fastq/ERR418/003/ERR4181783/ERR4181783_1.fastq.gz</span><br><span class="line">/vol1/fastq/ERR418/003/ERR4181783/ERR4181783_2.fastq.gz</span><br></pre></td></tr></tbody></table></figure><p>假设其命名为 <code>download.list</code>，使用以下命令下载：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ascp -QT -k 1 -l 100m -P33001 -i /path/to/asperaweb_id_dsa.openssh --mode recv --user era-fasp --host fasp.sra.ebi.ac.uk --file-list ./download.list [output path]</span><br></pre></td></tr></tbody></table></figure><p>参数详解：</p><ul><li><code>-Q</code>：启用较少详细信息的输出模式（quiet mode）。</li><li><code>-T</code>：启用文件时间戳保留。文件传输完成后，目标文件的时间戳将与源文件相同。</li><li><code>-k 1</code>：断点续传。</li><li><code>-l 100m</code>：限制传输速率，最大传输速率为 100 Mbps。</li><li><code>-P 33001</code>：用于连接的端口号，<code>33001</code> 是 Aspera 使用的默认端口号。</li><li><code>-i /path/to/asperaweb_id_dsa.openssh</code>：指定私钥文件的路径，用于身份验证。位于<strong>安装 ascp 的环境</strong>目录中的 <strong>etc</strong> 下。</li></ul><img src="/pic2/ENAbroser3.png" style="zoom:80%;"><ul><li><code>--mode recv</code>：指定传输模式。<code>recv</code> 表示接收文件（下载）。</li><li><code>--user era-fasp</code>：指定连接使用的用户名。</li><li><code>--host fasp.sra.ebi.ac.uk</code>：指定连接的主机名或 IP 地址。</li><li><code>--file-list ./download.list</code>：指定包含待传输文件列表的文件。</li><li><code>[output path]</code>：存储下载文件的路径，改为自己的实际路径。</li></ul><p>不过需要注意，<code>ascp</code> 下载的数据有时会出现问题，进而导致下游分析如 <code>trim_galore</code> 在过滤 reads 时出错，以下是一些报错示例：</p><blockquote><p>cutadapt: error: Line xxx in FASTQ file is expected to start with ‘xxx’, but found ‘xxx’</p></blockquote><p>可以通过 <code>gunzip</code> 命令检查是否是由于 fastq 文件存在问题：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gunzip -t SRRxxx.fastq.gz</span></span><br><span class="line"></span><br><span class="line">gzip: SRRxxx.fastq.gz: invalid compressed data--crc error</span><br><span class="line"></span><br><span class="line">gzip: SRRxxx.fastq.gz: invalid compressed data--length error</span><br></pre></td></tr></tbody></table></figure><p>以上情况<strong>可能并不是因为下载过程中的网络问题</strong>，而是 <code>ascp</code> 下载的文件本身存在问题，经实测某些文件下载不存在问题的话，不管下载多少次都不会出错。而某些文件如果下载后存在问题，那么不管下载多少次都会存在问题，这同时也体现了 <code>prefetch</code> 的特点 —— 慢但稳定。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>本文解决方案皆来自 sra-tools Github issue:</p><blockquote><ul><li><p><a href="https://github.com/ncbi/sra-tools/issues/214">fasterq-dump err #214</a></p></li><li><p><a href="https://github.com/ncbi/sra-tools/issues/545">Fasterq-dump failing consistently #545</a></p></li></ul></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>提取 bwa 比对中唯一比对 reads（uniquely mapped reads）的方法</title>
      <link href="/2024/05/03/%E6%8F%90%E5%8F%96%20bwa%20%E6%AF%94%E5%AF%B9%E4%B8%AD%E5%94%AF%E4%B8%80%E6%AF%94%E5%AF%B9%20reads%EF%BC%88uniquely%20mapped%20reads%EF%BC%89%E7%9A%84%E6%96%B9%E6%B3%95/"/>
      <url>/2024/05/03/%E6%8F%90%E5%8F%96%20bwa%20%E6%AF%94%E5%AF%B9%E4%B8%AD%E5%94%AF%E4%B8%80%E6%AF%94%E5%AF%B9%20reads%EF%BC%88uniquely%20mapped%20reads%EF%BC%89%E7%9A%84%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>本文由 Juse 基于以下资料进行撰写：</p><blockquote><p><a href="https://www.seqanswers.com/forum/bioinformatics/bioinformatics-aa/49537-how-to-extract-uniquely-mapped-reads-from-bam-sam-produced-by-bwa-mem">How to extract uniquely mapped reads from bam/sam produced by bwa-mem?</a> from SEQanswers</p><p><a href="https://www.biostars.org/p/256448/">Obtaining uniquely mapped reads from BWA mem alignment (filtering by q score does not seem to do the trick in my case)</a> from Biostars</p><p><a href="https://bioinformatics.stackexchange.com/questions/508/obtaining-uniquely-mapped-reads-from-bwa-mem-alignment">Obtaining uniquely mapped reads from BWA mem alignment</a> from StackExchange</p></blockquote><p>在此感谢 community 中各位大佬的无私分享。</p><h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><p>在某些文章中，有时我们会看到作者提及到在后续分析中，ta 只考虑了 <u><strong>uniquely mapping reads</strong></u>（后文统称唯一比对）。从直觉上出发，使用唯一比对的思路不难理解 —— 这些比对更加精确，并使后续的分析具有更好的解释性。</p><p>目前来说，得到唯一比对的最主流方法是直接通过 MAPQ 进行过滤，但这并不能得到严格意义上的唯一比对，因为部分 reads 在经过该过滤后仍然具有多重比对。不过这里需要明确一点：通过 MAPQ 过滤后仍存在的多重比对数量其实已经很少，如 Biostars 中的帖主所示：</p><blockquote><p>For the one sample I am using to test out commands, I filtered my data so I only have properly paired reads and mapped reads (in the case of my unpaired reads) and also filtered by q score (I get nearly the same results at q of 10, 20, or 30, so it’s not an issue of changing the q score level), merged all my bam files, and obtained 193,998 reads total for that sample. When I open the bam file in Geneious and count the number of reads for each locus they add up to 194, 050. I realize the difference between these two numbers is an incredibly small number of reads.</p></blockquote><p>因此，<u><strong>仅使用 MAPQ 进行过滤看上去也是可行的</strong></u>（如果你能接受极小一部分 “可能具有多个比对” 的 reads）。并且严格意义上说，唯一比对这一概念本身就具有局限性 —— 比对时所使用的参数如果过于宽松，那么具有多重比对的 reads 数量也会大大增加。</p><p>不过，如果实在想要避免多重比对带来的影响，可以根据 bwa 比对中的一些 Alignment Tags 来进行过滤，在 bwa 中，拥有多重比对的 reads 会出现以下一些 Tag：</p><ul><li><code>XA</code>，该 flag 中描述了对应 read 的 Alternative hits。</li><li><code>SA</code>，该 flag 用于标识次要的比对结果（Supplementary Alignment）。</li></ul><p>这两个 flag 的格式非常相似，其中 XA 是 bwa 等一部分比对软件使用的 flag。</p><p>因此，如果要过滤出唯一比对，<u><strong>只需要对这两个 flag 进行筛选</strong></u>：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sambamba view -t 12 -h -f bam -F <span class="string">"mapping_quality &gt;= 1 and not (unmapped or secondary_alignment) and not ([XA] != null or [SA] != null)"</span> [input bam] -o [output bam]</span></span><br></pre></td></tr></tbody></table></figure><p>经过该过滤后，将仅剩下在基因组上有且仅有唯一比对位置的 alignment。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>bismark 分析 Bisulfite-Seq 数据的流程示例</title>
      <link href="/2024/04/20/bismark%20%E5%88%86%E6%9E%90%20Bisulfite-Seq%20%E6%95%B0%E6%8D%AE%E7%9A%84%E6%B5%81%E7%A8%8B%E7%A4%BA%E4%BE%8B/"/>
      <url>/2024/04/20/bismark%20%E5%88%86%E6%9E%90%20Bisulfite-Seq%20%E6%95%B0%E6%8D%AE%E7%9A%84%E6%B5%81%E7%A8%8B%E7%A4%BA%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>以下是相关的官网链接和参考资料，如果想要得到除本文内容以外更全面深入的了解，建议直接跳转相关链接进行查阅：</p><blockquote><p>Bismark github:</p><p><a href="https://github.com/FelixKrueger/Bismark">https://github.com/FelixKrueger/Bismark</a></p><p>Bismark documentation:</p><p><a href="https://felixkrueger.github.io/Bismark/">https://felixkrueger.github.io/Bismark/</a></p><p>本文比对及去重等流程均参考自 Bismark documentation</p></blockquote><p>此外，以下内容在本文中不会涉及到，有需要请自行探索：</p><ul><li>数据的质控</li><li>除 Bismark 以外其他软件的安装</li></ul><p>通过以下流程可以得到：</p><ul><li>基因组上 CpG 位点的甲基化信息</li></ul><p>请阅读完全文后再进行相关分析，建议先使用 bismark 的示例数据观察相关命令是否存在问题。</p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>下载最新版本的 bismark（至 2024/04/19）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/FelixKrueger/Bismark/archive/refs/tags/v0.24.2.tar.gz</span></span><br></pre></td></tr></tbody></table></figure><p>也可前往 github release 下载指定版本或可能已存在的更新版本：</p><p><a href="https://github.com/FelixKrueger/Bismark/releases">https://github.com/FelixKrueger/Bismark/releases</a></p><p>下载后解压并将对应文件夹置入环境变量：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar xzf Bismark-0.24.2.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">'export PATH="'</span>$(<span class="built_in">readlink</span> -f Bismark-0.24.2)<span class="string">':$PATH"'</span> &gt;&gt; ~/.bashrc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> ~/.bashrc</span></span><br></pre></td></tr></tbody></table></figure><p>由于 bismark 中比对等操作均由 bismark 本身调用比对软件进行，因此在运行后续代码前，请确保正确版本的 <code>Bowtie2</code> 或 <code>HISAT2</code> 已经被置入环境变量中，如果想自行指定，可在后续执行时添加以下参数：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--path_to_bowtie2 &lt;/../../bowtie2&gt; or</span><br><span class="line">--path_to_hisat2 &lt;/../../hisat2&gt;</span><br></pre></td></tr></tbody></table></figure><p>bismark 默认使用 bowtie2，除非特别指定 <code>--hisat2</code>。</p><h3 id="比对"><a href="#比对" class="headerlink" title="比对"></a>比对</h3><p>比对前，使用 bismark 构建基因组 <code>C&gt;T</code> <code>G&gt;A</code> 的索引：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bismark_genome_preparation --verbose --parallel [thread] [path]</span></span><br></pre></td></tr></tbody></table></figure><ul><li><code>path</code> 换为基因组序列文件储存的路径，bismark 将自动识别 <code>.fa</code> 及 <code>.fasta</code> 文件并建立索引（压缩格式 <code>.gz</code> 也能识别）。</li><li><code>thread</code> 处填入使用的线程数量，注意最终将会使用 <code>2 * thread</code> 个线程。</li></ul><p>在构建完索引后，就可以通过 bismark 对数据进行比对，在比对前，建议先记录版本信息：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bismark --version &gt; bismark.version 2&gt;&amp;1</span></span><br></pre></td></tr></tbody></table></figure><p>比对命令（单端）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bismark -L [seed length] -N [mismatch number] --genome [path] --parallel [thread] -o [output_dir] [fastq] &gt; [logfile] 2&gt;&amp;1</span></span><br></pre></td></tr></tbody></table></figure><p>比对命令（双端）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bismark -L [seed length] -N [mismatch number] --genome [path] --parallel [thread] -o [output_dir] -1 [fastq_R1] -2 [fastq_R2] &gt; [logfile] 2&gt;&amp;1</span></span><br></pre></td></tr></tbody></table></figure><p>相关参数解释：</p><ul><li><code>seed length</code> 指定比对过程中使用的基础片段的长度（默认为 20），最大可设置为 32，该值越小时比对越慢，但同时也增加了召回率。该选项只在 Bowtie2 可用。</li><li><code>mismatch number</code> 指定比对过程中基础片段允许的错配数量（默认为 0）。可设置为 1，设置为 1 时比对会减慢很多，但同样增加了召回率。该选项只在 Bowtie2 可用。</li><li><code>thread</code> 指定并行的实例，注意其不是单纯的线程数，由于一个 <code>bismark</code> 进程就已经使用了多个核，以小鼠基因组为例，该值设置为 4 时将会使用大约 20 个核以及 40GB 左右的 RAM。因此请根据基因组大小、空闲的内存及核数量对该参数进行调整。</li><li><code>path</code> 即构建索引时使用的 <code>path</code>。</li><li><code>output_dir</code> 为输出的目录，<code>fastq</code> 指定测序数据文件，<code>logfile</code> 记录比对过程中的屏幕输出。</li></ul><p><strong>注意！</strong>如果测序数据由 <a href="https://www.illumina.com/science/sequencing-method-explorer/kits-and-arrays/pbat.html">PBAT</a> 建库得到，需要添加 <code>--pbat</code> 参数。此外，bismark 也提供了 <code>--local</code> 参数，指定此参数可以提高该文库类型的 map 比率，但是在 documentation 中 bismark 团队并不推荐这么做。</p><p>比对完成后，请先检查比对情况，相关的比对报告将储存在 <code>output_dir</code> 中以 <code>_report.txt</code> 结尾的文件里，如果是单端数据且使用 Bowtie2 比对，则相关报告文件将以 <code>_bismark_bt2_SE_report.txt</code> 结尾。打开文件，检查其中 <u>Mapping efficiency</u> 一项：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Final Alignment report</span><br><span class="line">======================</span><br><span class="line">Sequences analysed in total:1157278848</span><br><span class="line">Number of alignments with a unique best hit from the different alignments:736261309</span><br><span class="line">Mapping efficiency:63.6%</span><br><span class="line">Sequences with no alignments under any condition:337204612</span><br><span class="line">Sequences did not map uniquely:83812927</span><br><span class="line">Sequences which were discarded because genomic sequence could not be extracted:29</span><br></pre></td></tr></tbody></table></figure><p>如果 Mapping efficiency 在可接受范围内，则可进行后续分析。若该值过低（例如不超过 30%），则需考虑更改过滤参数以提升该值。一个折中的选择是适当提升 <code>seed length</code> 并设置 <code>mismatch number</code> 为 1。</p><p>考虑到比对的用时都较长，因此在第一次比对时就应尽量根据实际情况决定一个好的参数起点，例如：</p><ul><li>测序数据的 reads 长度？是单端还是双端？</li><li>测序数据的质量如何？</li></ul><h3 id="去重"><a href="#去重" class="headerlink" title="去重"></a>去重</h3><p>基因组上相同位置的比对可能是由 PCR 扩增导致的，删除重复的 reads 有助于避免 PCR 引入的序列 bias 并提高后续相关分析的准确性。但请注意，<strong>不建议对目标富集型文库（target enrichment-type library）例如 RRBS 及 amplicon 等进行该操作</strong>，因为在这些类型的文库中，重复序列可能是有意义的。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">deduplicate_bismark --version &gt; deduplicate_bismark.version 2&gt;&amp;1</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">deduplicate_bismark --output_dir [output_dir] --outfile [prefix] [files] &gt; [logfile] 2&gt;&amp;1</span></span><br></pre></td></tr></tbody></table></figure><ul><li><code>output_dir</code> 填入去重后的文件输出目录。</li><li><code>prefix</code> 填入去重后的文件前缀名称。</li><li><code>files</code> 填入需要去重的文件。<code>logfile</code> 填入记录屏幕输出的日志文件。</li></ul><p>如果此处想要将多个比对结果放在一起进行去重，则需指定 <code>--multiple</code> 参数，此时 bismark 将会把所有的输入文件视为单个样本连接在一起并进行去重。</p><p>最后的去重结果将在以 <code>.deduplication_report.txt</code> 结尾的文件中，该文件里将展示共有多少比对被移除。</p><h3 id="统计甲基化信息"><a href="#统计甲基化信息" class="headerlink" title="统计甲基化信息"></a>统计甲基化信息</h3><p>该步使用的 <code>bismark_methylation_extractor</code> 命令具有非常多的可选参数，建议通过 <code>bismark_methylation_extractor --help</code> 查看详细信息，此处给出个人使用的命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bismark_methylation_extractor --version &gt; bismark_methylation_extractor.version 2&gt;&amp;1</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bismark_methylation_extractor --gzip --bedGraph [bamfile] --output_dir [output_dir] --parallel [thread] &gt; [logfile] 2&gt;&amp;1</span></span><br></pre></td></tr></tbody></table></figure><p><code>bamfile</code> 处填入经过上述处理后得到的最终 bam 文件。此处 <code>--gzip</code> 表示输出文件以 gzip 进行压缩，<code>--bedgraph</code> 使 bismark 输出 bedgraph 文件。也可不使用 <code>--bedgraph</code> 参数并通过结果文件自行处理生成。</p><p>通过上述命令将得到以下尾缀结尾的文件：</p><ul><li><code>.bismark.cov.gz</code> 该文件共六列，分别代表：染色体、起始位点（1 坐标）、终止位点、甲基化比例、甲基化的 read count、非甲基化的 read count。</li><li><code>.bedGraph.gz</code> 该文件共四列，分别代表：染色体、起始位点（0 坐标）、终止位点、甲基化比例。</li><li><code>.M-bias.txt</code> 该文件展示了 reads 中每个 position 的平均甲基化水平，可通过画图可视化，偏离水平线可能表示存在 bias [<a href="https://www.nature.com/articles/nrg3273#glossary">Bock 2012, Nat Rev Genet</a>]。</li><li><code>_splitting_report.txt</code> 相关信息的统计汇总。</li></ul><p>通过 <code>.bismark.cov.gz</code> 生成 <code>.bedGraph.gz</code> 的方式：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zcat xxx.bismark.cov.gz | awk -F<span class="string">'\t'</span> <span class="string">'OFS="\t" {print $1, $2-1, $3, $4}'</span> | gzip &gt; xxx.bedGraph.gz</span></span><br></pre></td></tr></tbody></table></figure><p>此后可以通过 bedgraph 文件生成 bigWig 文件，请注意，由于 <code>bedGraphToBigWig</code> 并没法输入压缩文件，因此你可能需要对上述文件进行解压，或者不使用 <code>gzip</code> 进行压缩：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bedGraphToBigWig xxx.bedGraph genome.chrom.sizes output.bw</span></span><br></pre></td></tr></tbody></table></figure><p>关于 <code>chrom.sizes</code> 文件的获取方式可参考之前的 <a href="https://biojuse.com/2024/04/16/%E9%80%9A%E8%BF%87%20bowtie2%20+%20macs3%20%E5%88%86%E6%9E%90%20ChIP-Seq%20%E6%95%B0%E6%8D%AE/#Signal-P-value-amp-Fold-change-over-control">ChIP-seq 文章</a>。</p><p>以下是 bismark documentation 中给出的示例 M-bias plot（仅为示例，并不代表这种属于正常情况）：</p><img src="https://felixkrueger.github.io/Bismark/images/PBAT_SE_M-bias.jpg"><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>bisulfite-seq 数据的分析也可以通过 <a href="https://github.com/heathsc/gemBS">gemBS</a> Pipeline 直接进行，请注意该 Pipeline 目前仅支持双端数据。</p><p>也不必过多担心参数的选择，大多数情况下可能仅有 <code>bismark</code> 的 <code>-L</code> 和 <code>-N</code> 需要进行调整，如果不知道应该设置多少为宜建议统一使用默认参数，再根据结果进行修改。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通过 bowtie2 + macs3 分析 ChIP-Seq 数据</title>
      <link href="/2024/04/16/%E9%80%9A%E8%BF%87%20bowtie2%20+%20macs3%20%E5%88%86%E6%9E%90%20ChIP-Seq%20%E6%95%B0%E6%8D%AE/"/>
      <url>/2024/04/16/%E9%80%9A%E8%BF%87%20bowtie2%20+%20macs3%20%E5%88%86%E6%9E%90%20ChIP-Seq%20%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>以下是相关的官网链接和参考资料，如果想要得到除本文内容以外更全面深入的了解，建议直接跳转相关链接进行查阅：</p><blockquote><p>MACS3 github:</p><p><a href="https://github.com/macs3-project/MACS">https://github.com/macs3-project/MACS</a></p><p>MACS3 documentation:</p><p><a href="https://macs3-project.github.io/MACS/">https://macs3-project.github.io/MACS/</a></p><p>本文比对及去重等流程参考自以下资料：</p><ul><li><a href="https://hbctraining.github.io/Intro-to-ChIPseq/lessons/03_align_and_filtering.html">Alignment and filtering</a> from Harvard Chan Bioinformatics Core (HBC)</li><li><a href="https://www.encodeproject.org/pipelines/ENCPL612HIG/">Histone ChIP-seq pipeline</a> from ENCODE project (<strong>Version 2.0</strong> with bowtie2)</li></ul><p>本文流程根据以下资料进行过优化：</p><ul><li><a href="https://github.com/biod/sambamba/issues/477">sambamba -F “not duplicate” processed bam still have duplicated</a> (sambamba issue#477) (Update 2024/4/24)</li><li><a href="https://www.nature.com/articles/s41598-019-45839-z">Encode blacklist</a> (Update 2024/4/24)</li></ul></blockquote><p>以下内容在本文中不会涉及到：</p><ul><li>数据的质控</li><li>除 macs3 以外其他软件的安装</li></ul><p>你可以考虑参考以下 github repository 安装用于 ChIP-seq 数据处理的 conda 环境，可补齐下文中需要的上游分析软件：</p><p><a href="https://github.com/JuseTiZ/Blog-Snakemake-pipeline/">https://github.com/JuseTiZ/Blog-Snakemake-pipeline/</a></p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>使用 pip 安装 macs3：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install macs3</span></span><br></pre></td></tr></tbody></table></figure><p>如果安装过程中无法安装依赖 <code>cykhash</code>，可以尝试使用 mamba 进行安装：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mamba install -c conda-forge cykhash</span></span><br></pre></td></tr></tbody></table></figure><p>安装后可以输入 <code>macs3 --version</code> 查看是否成功安装。</p><h3 id="比对"><a href="#比对" class="headerlink" title="比对"></a>比对</h3><p>比对前，使用 bowtie2 构建基因组的索引：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bowtie2-build genome.fa indexname</span></span><br></pre></td></tr></tbody></table></figure><p>将以上代码中的 <code>genome.fa</code> 替换为自己的基因组文件，<code>indexname</code> 替换为想要设定的索引名称，后续比对将用到 <code>indexname</code>。</p><p>构建后，对数据进行比对得到 sam 文件：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bowtie2 --threads 4 \</span></span><br><span class="line"><span class="language-bash">       -q -x indexname -U chip-seq.fastq.gz \</span></span><br><span class="line"><span class="language-bash">       -S output.sam &gt; bowtie2.log 2&gt;&amp;1</span></span><br></pre></td></tr></tbody></table></figure><ul><li><code>--threads</code> 使用的线程数量</li><li><code>-X</code> 指定索引</li><li><code>-U</code> 质控后的测序数据文件</li><li><code>-S</code> 输出的 sam 文件</li></ul><p>将 <code>indexname</code> 替换为之前建立的索引名称，将 <code>chip-seq.fastq.gz</code> 替换为 chip-seq 的数据，如果是双端则需进行一定修改，考虑到 chip-seq 数据一般都是单端数据此处不做拓展。该过程的屏幕输出将记录在 <code>bowtie2.log</code> 中（例如比对率等）。</p><p>以上命令在 slurm 调度系统下的一个并行示例：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#SBATCH -J alignment</span></span><br><span class="line"><span class="comment">#SBATCH -o alignment.out</span></span><br><span class="line"><span class="comment">#SBATCH -e alignment.err</span></span><br><span class="line"><span class="comment">#SBATCH -n 24</span></span><br><span class="line"></span><br><span class="line">input_dir=<span class="string">"./fastq"</span></span><br><span class="line">output_dir=<span class="string">"./bowtie2_alignment"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">"<span class="variable">${output_dir}</span>"</span></span><br><span class="line"></span><br><span class="line">bowtie2 --version &gt; bowtie2.version 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">align_fastq</span></span>() {</span><br><span class="line">    <span class="built_in">local</span> fastq_file=<span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">    <span class="built_in">local</span> sam_file=<span class="string">"<span class="variable">${output_dir}</span>/<span class="subst">$(basename <span class="string">"<span class="variable">${fastq_file}</span>"</span> .fq.gz)</span>.sam"</span></span><br><span class="line">    <span class="built_in">local</span> log_file=<span class="string">"<span class="variable">${output_dir}</span>/<span class="subst">$(basename <span class="string">"<span class="variable">${fastq_file}</span>"</span> .fq.gz)</span>.log"</span></span><br><span class="line"></span><br><span class="line">    bowtie2 --threads 4 -q -x indexname -U <span class="string">"<span class="variable">$fastq_file</span>"</span> -S <span class="string">"<span class="variable">$sam_file</span>"</span> &gt; <span class="string">"<span class="variable">$log_file</span>"</span> 2&gt;&amp;1</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> -f align_fastq</span><br><span class="line"><span class="built_in">export</span> input_dir</span><br><span class="line"><span class="built_in">export</span> output_dir</span><br><span class="line"></span><br><span class="line">parallel --<span class="built_in">jobs</span> 6 align_fastq ::: <span class="string">"<span class="variable">${input_dir}</span>"</span>/*.fq.gz</span><br></pre></td></tr></tbody></table></figure><p>上述脚本将从当前目录下的 <code>fastq</code> 文件夹里读取所有 <code>.fq.gz</code> 结尾的文件，并通过 <code>bowtie2</code> 进行比对，索引为 <code>indexname</code>。该过程将并行 6 个比对任务，每个比对任务使用 4 个线程，通过 slurm 使用 24 个 CPU。</p><p>请根据个人情况（如空闲内存、集群信息等）进行修改以保证正常运行。在比对结束后，请对相关 log 文件进行检查，确保比对率等信息未出现问题。</p><h3 id="排序及去重"><a href="#排序及去重" class="headerlink" title="排序及去重"></a>排序及去重</h3><p>由于 PCR 过程中可能部分片段有 bias（被过度扩增），将这些片段去重将有助于降低 call peak 时的假阳性。</p><p>单个运行时的示例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">samtools view -h -S -b -o [output_unsorted_bam] [input_sam_file] <span class="comment"># 转为 bam</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sambamba <span class="built_in">sort</span> -t 4 -o [output_sorted_bam] [input_unsorted_bam] <span class="comment"># 对 bam 排序</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sambamba markdup -t 4 [output_markdup_bam] [input_sorted_bam] <span class="comment"># 标记 duplicate</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sambamba view -h -t 4 -f bam -F <span class="string">"[XS] == null and not unmapped and not duplicate"</span> [input_markdup_bam] &gt; [output_filter_bam] <span class="comment"># 过滤及去重</span></span></span><br></pre></td></tr></tbody></table></figure><p>slurm 调度系统下的批量运行示例：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#SBATCH -J sam2bam</span></span><br><span class="line"><span class="comment">#SBATCH -o sam2bam.out</span></span><br><span class="line"><span class="comment">#SBATCH -e sam2bam.err</span></span><br><span class="line"><span class="comment">#SBATCH -n 24</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define directories</span></span><br><span class="line">input_dir=<span class="string">"./bowtie2_alignment"</span></span><br><span class="line">output_dir=<span class="string">"./bamfiles"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create output directory</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">"<span class="variable">${output_dir}</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Record versions</span></span><br><span class="line">samtools --version &gt; samtools.version 2&gt;&amp;1</span><br><span class="line">sambamba --version &gt; sambamba.version 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Function to process each SAM file into BAM format</span></span><br><span class="line"><span class="function"><span class="title">process_sam_to_bam</span></span>() {</span><br><span class="line">    <span class="built_in">local</span> sam_file=<span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">    <span class="built_in">local</span> base_name=<span class="string">"<span class="variable">${output_dir}</span>/<span class="subst">$(basename <span class="string">"<span class="variable">${sam_file}</span>"</span> .sam)</span>"</span></span><br><span class="line">    <span class="built_in">local</span> unsorted_bam=<span class="string">"<span class="variable">${base_name}</span>.unsorted.bam"</span></span><br><span class="line">    <span class="built_in">local</span> sorted_bam=<span class="string">"<span class="variable">${base_name}</span>.sorted.bam"</span></span><br><span class="line">    <span class="built_in">local</span> marked_bam=<span class="string">"<span class="variable">${base_name}</span>.marked.bam"</span></span><br><span class="line">    <span class="built_in">local</span> final_bam=<span class="string">"<span class="variable">${base_name}</span>.bam"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert SAM to BAM</span></span><br><span class="line">    samtools view -h -S -b -o <span class="string">"<span class="variable">${unsorted_bam}</span>"</span> <span class="string">"<span class="variable">${sam_file}</span>"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sort BAM file</span></span><br><span class="line">    sambamba <span class="built_in">sort</span> -t 4 -o <span class="string">"<span class="variable">${sorted_bam}</span>"</span> <span class="string">"<span class="variable">${unsorted_bam}</span>"</span></span><br><span class="line">    <span class="built_in">rm</span> <span class="string">"<span class="variable">${unsorted_bam}</span>"</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Mark duplicate</span></span><br><span class="line">    sambamba markdup -t 4 <span class="string">"<span class="variable">${sorted_bam}</span>"</span> <span class="string">"<span class="variable">${marked_bam}</span>"</span></span><br><span class="line">    <span class="built_in">rm</span> <span class="string">"<span class="variable">${sorted_bam}</span>"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Filter BAM file</span></span><br><span class="line">    sambamba view -h -t 4 -f bam -F <span class="string">"[XS] == null and not unmapped and not duplicate"</span> <span class="string">"<span class="variable">${marked_bam}</span>"</span> &gt; <span class="string">"<span class="variable">${final_bam}</span>"</span></span><br><span class="line">    <span class="built_in">rm</span> <span class="string">"<span class="variable">${marked_bam}</span>"</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment"># Export function and variables for parallel execution</span></span><br><span class="line"><span class="built_in">export</span> -f process_sam_to_bam</span><br><span class="line"><span class="built_in">export</span> input_dir</span><br><span class="line"><span class="built_in">export</span> output_dir</span><br><span class="line"></span><br><span class="line"><span class="comment"># Execute processing in parallel</span></span><br><span class="line">parallel --<span class="built_in">jobs</span> 6 process_sam_to_bam ::: <span class="string">"<span class="variable">${input_dir}</span>"</span>/*.sam</span><br></pre></td></tr></tbody></table></figure><p>以上注释均通过 ChatGPT 添加，请确保可以通过环境变量直接调用 <code>samtools</code> 和 <code>sambamba</code>。该脚本主要做了以下工作：</p><ul><li><code>samtools</code> 将 <code>sam</code> 转换为 <code>bam</code> 格式。</li><li><code>sambamba</code> 标记重复 reads。</li><li><code>sambamba</code> 对文件进行排序和索引，此后对其进行去重。</li></ul><p>以下是过滤规则：</p><ul><li><p><code>[XS] == null</code>：</p><ul><li>过滤掉具有 <code>XS</code> 标签的比对，选出比对位置唯一或最佳的比对（primary alignments），即没有其他次优的比对位置。</li></ul></li><li><p><code>not unmapped</code>：</p><ul><li>过滤未成功比对到参考基因组的序列。</li></ul></li><li><p><code>not duplicate</code>：</p><ul><li>过滤掉标记为重复的比对。在使用 PCR 方法扩增样本时，会产生重复的 reads。</li></ul></li></ul><p>通过上述命令，就能得到所有后续分析中 macs3 所需要使用到的 bam 文件。如果想要将不同 replicate 的数据放在一起获得最终 bedGraph 文件，可在该步后对同一处理下所有 bam 文件进行合并。</p><h3 id="Filtering-out-Blacklisted-Regions"><a href="#Filtering-out-Blacklisted-Regions" class="headerlink" title="Filtering out Blacklisted Regions"></a>Filtering out Blacklisted Regions</h3><p>详细可见：<a href="https://www.nature.com/articles/s41598-019-45839-z">The ENCODE Blacklist: Identification of Problematic Regions of the Genome</a></p><p>基因组中部分区域的序列高度重复，此外现有基因组版本也可能存在基因组组装错误所导致的 artifact。这些因素都可能导致 signal 出现异常，从而增加假阳性。解决这一问题的方法之一是过滤掉这些区域中的 alignment。</p><p>一些模式物种的 blacklist 文件可以在以下 github repositories 获得：</p><p><a href="https://github.com/Boyle-Lab/Blacklist/">https://github.com/Boyle-Lab/Blacklist/</a></p><p><a href="https://github.com/dozmorovlab/excluderanges">https://github.com/dozmorovlab/excluderanges</a></p><p>请注意选择正确的基因组版本，如果目标物种的 blacklist 文件并不存在于以上 repositories 中，可以自行通过 Encode Blacklist 软件识别。</p><p>以下是使用 deeptools <code>alignmentSieve</code> 过滤 blacklist 的方法：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">alignmentSieve --blackListFileName blacklist.bed.gz --filterMetrics filterMetricBlacklist.txt -p 8 -b input.bam -o output.bam</span></span><br></pre></td></tr></tbody></table></figure><ul><li><code>--blackListFileName</code> 指定 blacklist region file。</li><li><code>-p</code> 指定使用线程数，<code>-b</code> 和 <code>-o</code> 指定输入和输出 bam 文件。</li></ul><p>如果过滤的为 ATAC-seq 数据，则还需添加 <code>--ATACshift</code> 参数。在 <code>filterMetricBlacklist.txt</code> 中可以看到总 reads 数和过滤后留存的 reads 数。</p><p>由于该步骤并非必需，因此个人看需求选择是否加入到 <strong><u>排序及去重</u></strong> 部分的 Pipeline 中。</p><h3 id="macs3-call-peak"><a href="#macs3-call-peak" class="headerlink" title="macs3 call peak"></a>macs3 call peak</h3><p>一般而言，CHIP-seq（染色质免疫沉淀测序）实验中，通常包括 treat 组和 control 组，后者用于提供实验的背景信号，帮助区分特异性的信号和非特异性的背景噪音。通常有两种主要的对照方式：</p><ul><li><strong>Input control</strong>：在这种对照中，不进行抗体沉淀，直接使用同一样本的一部分进行 DNA 提取和测序。</li><li><strong>Mock IP control</strong>：这种对照使用不特异的抗体（如与目标蛋白无关的抗体或前清液）来进行免疫沉淀。</li></ul><p>因此，假设目前已经有了 treat 和 control 的 bam files，那么可以通过以下命令来进行 callpeak：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">macs3 callpeak -t [treat bam] -c [control bam] -f BAM -n [outname] --broad -g [species] -B --broad-cutoff 0.1</span></span><br></pre></td></tr></tbody></table></figure><p>以上命令适用于 <u>broad peak calling on Histone Mark ChIP-seq</u>，如果是其他 ChIP-seq 数据，请根据 github 上的 usage 示例进行相应修改。以 TF ChIP-seq 为例，示例命令如下：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">macs3 callpeak -t [treat bam] -c [control bam] -f BAM -g [species] -n [outname] -B -q 0.01</span></span><br></pre></td></tr></tbody></table></figure><p>由于 macs3 的 <code>bdgdiff</code> 只能处理一个重复下的情况，因此如果单个样本有多个重复，在 <code>callpeak</code> 步骤中可以一起输入（即 <code>-t</code> 和 <code>-c</code> 可以接多个 bam 文件）。或者也可以选择每个重复单独进行 <code>callpeak</code>，然后使用其他工具例如 <code>DESeq2</code> 或 <code>edgeR</code> 进行后续的比较分析。</p><p>这里将对应参数后的输入依据自己的实际情况和需求进行修改，着重提几个参数：</p><ul><li><p><code>-n</code> 输出文件的前缀（可包括输出路径）。</p></li><li><p><code>-g</code> 有效基因组大小，目前 macs3 内置有：</p></li></ul><blockquote><p>  hs for human (2,913,022,398)</p><p>  mm for mouse (2,652,783,500)</p><p>  ce for C. elegans (100,286,401)</p><p>  dm for fruitfly (142,573,017)</p><p>  Default:hs</p></blockquote><ul><li><code>-B</code> 生成 bedgraph 文件，该文件可用于后续计算得到 signal p-value 或 fold change over control 的 bigWig 文件。</li></ul><p>如果分析的物种有效基因组大小在 macs3 中没有内置，且在 deeptools 上也没给出，可以通过以下方法进行计算：</p><ul><li><p>下载 <code>faCount</code>：<code>wget https://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/faCount</code></p></li><li><p>统计物种非 N 碱基数量：<code>faCount genome.fa -summary &gt; genome.faCount.report</code></p></li><li><p>计算：<code>awk 'NR==2 {print $3+$4+$5+$6}' genome.faCount.report</code></p></li></ul><p>将 faCount 后的 <code>genome.fa</code> 替换为自己的基因组文件后，就能得到相应的信息，例如 rheMac10 基因组的非 N 碱基数量为 2936892725。此外也可以 <code>uniquely mappable regions</code> 确定。关于这两种方法的区别，可见 <a href="https://deeptools.readthedocs.io/en/develop/content/feature/effectiveGenomeSize.html">Effective Genome Size</a>。</p><p>由于 macs3 的默认值均根据非 N 碱基数量确定，因此这里只讨论 faCount。</p><p>确定相关参数后，<code>macs3 callpeak</code> 将产生相关的 peak 信息文件，若仅需要 peak 信息则进行到该步即完成任务。不添加 <code>-B</code> 参数时会生成的一些文件：</p><ul><li><code>*_peaks.narrowPeak</code>：包含了每个 peak 的详细信息，包括峰的起始和终止位置、峰的名称、峰的得分、以及峰顶相对于峰起始位置的偏移值。</li><li><code>*_summits.bed</code>：包含了每个 peak 的峰顶位置，即信号最强的点。每一行通常表示一个峰顶，包含染色体、峰顶的起始位置、终止位置（起始位置+1），以及峰的强度值。</li><li><code>*_peaks.xls</code>：详细结果文件，包含产生该文件所使用的命令，各参数的情况，以及峰的各个信息等。</li></ul><h3 id="Signal-P-value-amp-Fold-change-over-control"><a href="#Signal-P-value-amp-Fold-change-over-control" class="headerlink" title="Signal P-value &amp; Fold change over control"></a>Signal P-value &amp; Fold change over control</h3><p>如果在 call peak 步骤中添加了 <code>-B</code> 参数，那么此时应该就已经生成了 treat 组和 control 组的 bed 文件，通过比较这两个 bed 文件，可以得到基因组上不同位置中 peak 的 <code>signal p-value</code> 或者 <code>fold change over control</code>。</p><p>以下是一个运行示例，该例子将产生 Signal P-value 文件，其中第四列为 <code>-log10(pvalue)</code>，因此第四列越大，该处的 peak 越显著：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">macs3 bdgcmp -t treatment.bedGraph -c control.bedGraph -m ppois -p 1.0 -S 1.0 -o output.bedGraph</span></span><br></pre></td></tr></tbody></table></figure><p>各参数含义详细可见 <a href="https://github.com/macs3-project/MACS/blob/master/docs/bdgcmp.md">documentation</a>，这里提几个重要的：</p><ul><li><code>-m</code> 计算第四列 score 时所用的方法，<code>ppois</code> 即泊松 p 值，选择 <code>FE</code> 则能得到 <code>fold change over control</code> 信息。</li><li><code>-p</code> 为每个计数添加 x 个伪计数，尤其在对数转换时可以避免计数为 0 造成的计算问题，此外也有助于减少因样本稀疏导致的统计波动。</li><li><code>-S</code> 设置处理组（treatment）和对照组（control）数据的缩放因子，如果在 call peak 时未指定 <code>--SPMR</code> 参数，则该项设定为 1 即可。</li></ul><p>对于输出后的 bedgraph 文件，可以通过 <code>bedGraphToBigWig</code> 转为 bigWig 文件：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/bedGraphToBigWig <span class="comment"># 下载工具</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bedGraphToBigWig output.bedGraph genome.chrom.sizes output.bw</span></span><br></pre></td></tr></tbody></table></figure><p>每个物种的 <code>genome.chrom.sizes</code> 文件可在相应的 UCSC Genome Browser goldenpath 中得到，如果所分析物种尚未在基因组浏览器上记载，可自行通过 <code>samtools</code> 或 <code>Biopython</code> 得到。例：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">samtools faidx reference.fasta</span><br><span class="line"><span class="built_in">cut</span> -f1,2 reference.fasta.fai &gt; chrom.sizes</span><br></pre></td></tr></tbody></table></figure><p>如果此处存在一个样本下有多个重复的情况，并且已经对每个重复都单独计算得到了 bed 文件，你也可以通过 macs3 的 <code>cmbreps</code> 对不同的重复进行合并。例如以 <code>signal p-value</code> 为例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">macs3 cmbreps -i replicate1.bedGraph replicate2.bedGraph replicate3.bedGraph -o combined.bedGraph --method fisher</span></span><br></pre></td></tr></tbody></table></figure><p>其通过费舍尔联合概率检验合并 p 值并计算得到新 p 值。</p><p>对于 <code>fold change over control</code>，可将 <code>-m</code> 后的 <code>fisher</code> 换为 <code>mean</code> 进行。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>以上流程已被打包为一个完整的 Snakemake Pipeline，可在以下链接中获取：</p><p><a href="https://github.com/JuseTiZ/Blog-Snakemake-pipeline/tree/main/ChIP-Pipeline">https://github.com/JuseTiZ/Blog-Snakemake-pipeline/tree/main/ChIP-Pipeline</a></p><p>该 Pipeline 的理解和使用可能需要一定的 Snakemake 语法基础。</p><p>考虑到 ChIP-seq 下游分析能弄的东西五花八门，所以这篇文章就只介绍到如何产生结果，对于相关结果的解释和分析就各看需求了。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>远程服务器无 root 权限时 LightGBM GPU 版的安装方法</title>
      <link href="/2024/04/02/%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%97%A0%20root%20%E6%9D%83%E9%99%90%E6%97%B6%20LightGBM%20GPU%20%E7%89%88%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/"/>
      <url>/2024/04/02/%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%97%A0%20root%20%E6%9D%83%E9%99%90%E6%97%B6%20LightGBM%20GPU%20%E7%89%88%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>首先感谢 LightGBM 团队的帮助：</p><p><a href="https://github.com/microsoft/LightGBM/issues/6399">https://github.com/microsoft/LightGBM/issues/6399</a></p><h3 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h3><p>本文适用于在远程服务器（Linux）上安装 LightGBM 的情况。</p><p>不同的编译器版本在遇到报错时的解决方案可能略有不同，以下是我在编译时使用的相关版本：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- The C compiler identification is GNU 8.5.0</span><br><span class="line">-- The CXX compiler identification is GNU 4.8.5</span><br></pre></td></tr></tbody></table></figure><p>本文默认已在服务器上配置有 CUDA，如果 CUDA 另有路径请通过 <code>-DOpenCL_LIBRARY</code> 和 <code>-DOpenCL_INCLUDE_DIR</code> 指定。</p><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>下载 LightGBM，并进行 <code>CUDA</code> 版本的编译：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git clone --recursive https://github.com/microsoft/LightGBM</span><br><span class="line">cd LightGBM</span><br><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake -DUSE_CUDA=1 .. # 指定 CUDA version</span><br><span class="line">make -j4</span><br></pre></td></tr></tbody></table></figure><blockquote><p>注：</p><p>不知道是否属于个人原因，如果我使用 <code>-DUSE_GPU=1</code> 而非 <code>-DUSE_CUDA=1</code>（即安装 GPU version 而非 CUDA version），虽然最后能安装成功，但是在 Jupyter Notebook 中运行 LightGBM GPU 时会直接发生以下错误：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click [here](https://aka.ms/vscodeJupyterKernelCrash) for more info. View Jupyter [log](command:jupyter.viewOutput) for further details.</span><br></pre></td></tr></tbody></table></figure></blockquote><p>在上述 CUDA version 编译过程中，如果在 CMake 时发生以下错误：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x86_64-conda-linux-gnu-cc: error: unrecognized command-line option '-march'</span><br></pre></td></tr></tbody></table></figure><p>解决方案：打开 <code>build</code> 文件夹中的 <code>CMakeCache.txt</code>，搜索 <code>-march</code>，找到类似以下这段的内容：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//Flags used by the C compiler during all build types.</span><br><span class="line">CMAKE_C_FLAGS:STRING=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /public/home/xxxx/mambaforge/envs/kaggle/include -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /public/home/xxxx/mambaforge/envs/ncsvp/include -march</span><br></pre></td></tr></tbody></table></figure><p>将<strong>最后的</strong> <code>-march</code> 删除再重新运行 <code>cmake -DUSE_CUDA=1 ..</code>，如果成功则继续运行 <code>make -j4</code>。</p><p>如果与上述相关内容有所出入，则可自己根据具体情况尝试修改 <code>march</code> 相关内容。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>编译完成后，你已经可以使用 Linux 下的 LightGBM，如果要继续安装 Python LightGBM，则还需进行以下操作：</p><p>返回到 <code>LightGBM</code> 目录，并安装 Python 接口：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> ../</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sh ./build-python.sh install --precompile</span></span><br></pre></td></tr></tbody></table></figure><p>安装好 LightGBM Module 后，就可以使用 <code>device='CUDA'</code> 调用 GPU 进行加速。</p><p>关于以上流程，更详细内容可以移至文章开头的 github issue 查看。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>其实去年我也尝试过在服务器上安装 LightGBM GPU，但折腾了一段时间并没有搞成功，所以也就放弃了。</p><p>那么为什么现在又弄了呢？这个动机可以追溯到上个月在 Kaggle 上打 PlayGround 竞赛的时候。因为 LightGBM 没有 GPU 加速实在是跑的太慢，而我加入竞赛的时间又比较晚（只剩六七天就结束了），所以我选择了使用自己的电脑来做 XGBoost 和 LightGBM GPU 的 HPO。所幸最后的结果是不错的 —— 最好的结果可以排第八名，可惜选错了 submission<del>（盲目相信 public score 的代价）</del>。</p><p>离题了，如上所述，虽然拿着自己电脑的 2060 跑确实比 CPU 要快很多，但是每天拿着一个游戏本跑来跑去，还要早去课室为它霸占充电位以及忍受它狂躁的风扇声和令人发指的续航能力，实在是让人有些心力交瘁。看着服务器上三台 3090，我还是下定决心在服务器上也安装一个。</p><p>所幸最后安装成功，在这里记录下自己走的弯路，希望能帮助别人省些时间……</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>全基因组 CpG (or nonCpG) 位点 bed 文件的获取方式</title>
      <link href="/2024/03/18/%E5%85%A8%E5%9F%BA%E5%9B%A0%E7%BB%84%20CpG%20(or%20nonCpG)%20%E4%BD%8D%E7%82%B9%20bed%20%E6%96%87%E4%BB%B6%E7%9A%84%E8%8E%B7%E5%8F%96%E6%96%B9%E5%BC%8F/"/>
      <url>/2024/03/18/%E5%85%A8%E5%9F%BA%E5%9B%A0%E7%BB%84%20CpG%20(or%20nonCpG)%20%E4%BD%8D%E7%82%B9%20bed%20%E6%96%87%E4%BB%B6%E7%9A%84%E8%8E%B7%E5%8F%96%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p><a href="https://en.wikipedia.org/wiki/CpG_site">CpG 位点</a>是基因组上的一种特殊序列，它在 DNA 的结构和功能中起着重要作用。其组成和甲基化影响着基因组上各区域的调控，是表观遗传学领域中重要的研究目标。</p><p>本文中的脚本主要用于提取基因组中 CpG 位点的位置，以方便一些着重于 CpG 位点的下游分析进行。此外在部分场景下，我们可能希望排除 CpG 位点进行分析（因为其独特的性质例如高突变率等），因此该脚本也可产生 AT&amp;CG(nonCpG) 位点信息文件。</p><p>需要准备的文件和条件有：</p><ul><li>基因组序列文件</li><li>Biopython 库（<code>pip install biopython</code>）</li></ul><p>可能需要准备的前置条件：</p><ul><li>已被放置于 <code>$PATH</code> 环境变量中的 <code>bedtools</code></li></ul><p>脚本内容：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Bio <span class="keyword">import</span> SeqIO</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">"Use to extract AT/CG(nonCpG) &amp; CpG sites."</span>)</span><br><span class="line">    </span><br><span class="line">    input_group = parser.add_argument_group(<span class="string">"Input"</span>)</span><br><span class="line">    input_group.add_argument(<span class="string">"-g"</span>, <span class="string">"--genome"</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">"The path of genome sequence file."</span>)</span><br><span class="line">    input_group.add_argument(<span class="string">"-c"</span>, <span class="string">"--chr"</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">"The target chromosome to extract."</span>)</span><br><span class="line"></span><br><span class="line">    option_group = parser.add_argument_group(<span class="string">"Optional parameters"</span>)</span><br><span class="line">    option_group.add_argument(<span class="string">"--onlycpg"</span>, action=<span class="string">"store_true"</span>, <span class="built_in">help</span>=<span class="string">"Only extract CpG sites."</span>)</span><br><span class="line">    option_group.add_argument(<span class="string">"--merge"</span>, action=<span class="string">"store_true"</span>, <span class="built_in">help</span>=<span class="string">"Use bedtools to merge bed files."</span>)</span><br><span class="line">    option_group.add_argument(<span class="string">"--gzip"</span>, action=<span class="string">"store_true"</span>, <span class="built_in">help</span>=<span class="string">"Use gzip to compress output."</span>)</span><br><span class="line">    option_group.add_argument(<span class="string">"--nosoftmask"</span>, action=<span class="string">"store_true"</span>, <span class="built_in">help</span>=<span class="string">"Remove soft-masked where repeats are in lower-case text."</span>)</span><br><span class="line"></span><br><span class="line">    output_group = parser.add_argument_group(<span class="string">"Output"</span>)</span><br><span class="line">    output_group.add_argument(<span class="string">"-n"</span>, <span class="string">"--name"</span>, <span class="built_in">help</span>=<span class="string">"The name of output file."</span>)</span><br><span class="line">    output_group.add_argument(<span class="string">"-p"</span>, <span class="string">"--path"</span>, <span class="built_in">help</span>=<span class="string">"The path of output file."</span>, default=<span class="string">'./'</span>)</span><br><span class="line">    </span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> args.name:</span><br><span class="line">        args.name = os.path.splitext(os.path.basename(args.genome))[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_command</span>(<span class="params">command</span>):</span><br><span class="line">    result = subprocess.run(command, shell=<span class="literal">True</span>, stdout=subprocess.PIPE, stderr=subprocess.PIPE)</span><br><span class="line">    <span class="keyword">if</span> result.returncode != <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"Error when executing command: <span class="subst">{command}</span>\n<span class="subst">{result.stderr.decode()}</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    args = get_args()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> gzip.<span class="built_in">open</span>(args.genome, <span class="string">"rt"</span>) <span class="keyword">if</span> args.genome.endswith(<span class="string">".gz"</span>) <span class="keyword">else</span> <span class="built_in">open</span>(args.genome, <span class="string">"r"</span>) <span class="keyword">as</span> genome_file:</span><br><span class="line">        chr_num = <span class="string">"chr"</span> + args.<span class="built_in">chr</span>.replace(<span class="string">"chr"</span>, <span class="string">""</span>)</span><br><span class="line">        cpg_bed_name = os.path.join(args.path, <span class="string">f"<span class="subst">{args.name}</span>_<span class="subst">{chr_num}</span>_CpGsites.bed.tmp"</span>)</span><br><span class="line">        atcg_bed_name = os.path.join(args.path, <span class="string">f"<span class="subst">{args.name}</span>_<span class="subst">{chr_num}</span>_ATnonCpGsites.bed.tmp"</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(cpg_bed_name, <span class="string">"w"</span>) <span class="keyword">as</span> cpg_bed, <span class="built_in">open</span>(atcg_bed_name, <span class="string">"w"</span>) <span class="keyword">as</span> atcg_bed:</span><br><span class="line">            <span class="keyword">for</span> record <span class="keyword">in</span> SeqIO.parse(genome_file, <span class="string">"fasta"</span>):</span><br><span class="line">                <span class="keyword">if</span> record.<span class="built_in">id</span> != args.<span class="built_in">chr</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> args.nosoftmask:</span><br><span class="line">                    seq = <span class="built_in">str</span>(record.seq).upper()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    seq = <span class="built_in">str</span>(record.seq)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> i, nuc <span class="keyword">in</span> <span class="built_in">enumerate</span>(seq):</span><br><span class="line">                    <span class="keyword">if</span> nuc == <span class="string">"N"</span>:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    <span class="keyword">if</span> nuc <span class="keyword">in</span> [<span class="string">"A"</span>, <span class="string">"T"</span>] <span class="keyword">and</span> <span class="keyword">not</span> args.onlycpg:</span><br><span class="line">                        atcg_bed.write(<span class="string">f"<span class="subst">{chr_num}</span>\t<span class="subst">{i}</span>\t<span class="subst">{i+<span class="number">1</span>}</span>\n"</span>)</span><br><span class="line">                    <span class="keyword">elif</span> nuc <span class="keyword">in</span> [<span class="string">"C"</span>, <span class="string">"G"</span>]:</span><br><span class="line">                        <span class="keyword">if</span> (nuc == <span class="string">"C"</span> <span class="keyword">and</span> i + <span class="number">1</span> &lt; <span class="built_in">len</span>(seq) <span class="keyword">and</span> seq[i + <span class="number">1</span>] == <span class="string">"G"</span>) <span class="keyword">or</span> (nuc == <span class="string">"G"</span> <span class="keyword">and</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> seq[i - <span class="number">1</span>] == <span class="string">"C"</span>):</span><br><span class="line">                            cpg_bed.write(<span class="string">f"<span class="subst">{chr_num}</span>\t<span class="subst">{i}</span>\t<span class="subst">{i+<span class="number">1</span>}</span>\n"</span>)</span><br><span class="line">                        <span class="keyword">elif</span> <span class="keyword">not</span> args.onlycpg:</span><br><span class="line">                            atcg_bed.write(<span class="string">f"<span class="subst">{chr_num}</span>\t<span class="subst">{i}</span>\t<span class="subst">{i+<span class="number">1</span>}</span>\n"</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> bed_file <span class="keyword">in</span> [cpg_bed_name, atcg_bed_name] <span class="keyword">if</span> <span class="keyword">not</span> args.onlycpg <span class="keyword">else</span> [cpg_bed_name]:</span><br><span class="line">            outfile = bed_file.replace(<span class="string">".tmp"</span>, <span class="string">""</span>)</span><br><span class="line">            <span class="keyword">if</span> args.merge:</span><br><span class="line">                command = <span class="string">f"bedtools merge -i <span class="subst">{bed_file}</span> &gt; <span class="subst">{outfile}</span> &amp;&amp; rm <span class="subst">{bed_file}</span>"</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                command = <span class="string">f"mv <span class="subst">{bed_file}</span> <span class="subst">{outfile}</span>"</span></span><br><span class="line">            process_command(command)</span><br><span class="line">            <span class="keyword">if</span> args.gzip:</span><br><span class="line">                process_command(<span class="string">f"gzip -f <span class="subst">{outfile}</span>"</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> args.onlycpg:</span><br><span class="line">            os.remove(atcg_bed_name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></tbody></table></figure><p>将上述内容保存在一个名为 <code>get_sites.py</code> 的文件内，或者点击<a href="https://github.com/JuseTiZ/PyScript-for-CT/blob/main/get_sites.py">此处</a>下载。</p><p>运行示例（以 hg38 人类基因组为例，提取其在 21 号染色体上的 CpG 位点位置信息）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python get_sites.py -g hg38.fa -c chr21 --merge --gzip -n GRCh38</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">python get_sites.py -g [sequence file] -c [chr] --merge --gzip -n [outname]</span></span><br></pre></td></tr></tbody></table></figure><p>最后将会得到名为 <code>GRCh38_chr21_ATnonCpGsites.bed.gz</code> 和 <code>GRCh38_chr21_CpGsites.bed.gz</code> 的文件，以下是各参数说明：</p><ul><li><code>-g</code> 指定参考基因组序列文件，<code>.gz</code> 压缩格式可以被自动识别。</li><li><code>-c</code> 指定要提取位点信息的染色体，需和序列文件中的序列 id 一致。</li><li><code>--merge</code> 在提取完位点信息后，调用 <code>bedtools</code> 对输出文件进行合并，将每行 1bp 的 bed 文件合并为区间。该选项要求 <code>bedtools</code> 可以直接调用，否则会出现错误。bedtools 的安装可以直接通过 <code>conda install -c bioconda bedtools</code> 实现。</li><li><code>--gzip</code> 在提取完位点信息后（如果指定了 <code>--merge</code> 则在合并后），对输出文件进行压缩。</li><li><code>-n</code> 指定输出文件的前缀。如果命令中未给定，则默认为序列文件的前缀。</li><li><code>-p</code> 指定输出文件的路径。如果命令中未给定，则默认为运行脚本时所处的路径。</li></ul><p>此外，如果在运行脚本时指定了 <code>--onlycpg</code>，则仅产生 CpG 位点位置文件。如果在运行脚本时指定了 <code>--nosoftmask</code>，则跳过<a href="https://grch37.ensembl.org/info/genome/genebuild/assembly_repeats.html">软掩蔽区域</a>。</p><p>因为该脚本针对特定染色体进行，因此可以批量运行脚本以同时处理多条染色体，示例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span> {1..23};</span></span><br><span class="line">do</span><br><span class="line">python get_sites.py -g hg38.fa -c chr"$i" --merge --gzip -n GRCh38 &amp;</span><br><span class="line">done</span><br></pre></td></tr></tbody></table></figure><p>请保证计算机或服务器有足够的 CPU 和内存进行批量运行，此处更建议使用 <code>parallel</code> 来进行并行数量控制。如果在服务器上有作业调度系统，也可以合理利用，例如 slurm 的作业数组等，以下是一个 slurm 作业数组运行的示例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --job-name=getsites</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --nodelist=yournode</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --ntasks=1</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --array=1-23%10</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --mail-user=youremail</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --mail-type=END</span></span><br><span class="line"></span><br><span class="line">python get_sites.py -g hg38.fa -c chr"$SLURM_ARRAY_TASK_ID" --merge --gzip -n GRCh38</span><br></pre></td></tr></tbody></table></figure><p>产生结果示例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zcat GRCh38_chr21_CpGsites.bed.gz | <span class="built_in">head</span> -n 5</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chr21   5010008 5010010</span><br><span class="line">chr21   5010053 5010055</span><br><span class="line">chr21   5010215 5010217</span><br><span class="line">chr21   5010331 5010333</span><br><span class="line">chr21   5010335 5010337</span><br></pre></td></tr></tbody></table></figure><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>虽说这半年已经写了非常多的 script，但是翻来翻去感觉都属于针对性过强的类型，除了我大概率也没有人能用得上。因此最后只能选定本文中这个短小精悍<del>（没啥难度）</del>的脚本作为分享<del>（水文）</del>，或许能帮到有需要的人。</p><p>此外也还有一个和本文类似的脚本，主要用来提取全基因组上所有四倍简并位点的位置信息。之后如果有需要的话会补充在这篇文章里面。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Clash for windows 中让某些域名绕过代理</title>
      <link href="/2024/02/20/Clashforwindow/"/>
      <url>/2024/02/20/Clashforwindow/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>众所周知，Clash for windows 的作者已经删库跑路许久，而在使用这个软件到现在我也终于忍不住想要解决某些域名绕过代理的问题。我已经受够了每次进 web of science 查文献亦或是在 Science 官网上看文章都要关掉代理才能进去的痛楚了。</p><p>在搜索网上的解决方案时，部分文章说可以在 Settings&gt;System Proxy&gt;Bypass Domain/IPNet 中设置相应域名解决，但是我发现我新加域名进入后我的梯子就会直接整个没用。当然这发生在大约半年前的时候，那时的我选择了将这件事暂时搁置，直到现在。</p><p>这次再次寻找解决方法，终于找到个适用于我的，趁这个机会写在此处，希望能帮到其他有需求的朋友，当然也有可能某天这篇文章会因为不可抗力消失。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>首先点开 <code>Profiles</code>，选择自己的梯子右键，点开 <code>Parsers</code> 并选择 <code>Edit Parsers</code>。</p><p><img src="/pic2/cfw1.png"></p><p>将里面的内容处理成以下格式：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parsers: # array</span><br><span class="line">    - url: 梯子 url</span><br><span class="line">      yaml:</span><br><span class="line">        prepend-rules:</span><br><span class="line">        - DOMAIN-SUFFIX,www.science.org,DIRECT</span><br></pre></td></tr></tbody></table></figure><p><img src="/pic2/cfw2.png"></p><p>将 url 后的内容换成自己的梯子 url，注意<strong>不要破坏缩进，yaml 和 url 需要对齐才能正常发挥作用</strong>，后面可以通过以下格式在 prepend-rules 下添加域名：</p><ul><li>DOMAIN-SUFFIX,域名,DIRECT</li></ul><p>对于 Web of science，我填入以下几个规则后成功让 Web of science 绕过代理，但不清楚其中最关键的是哪些（亦或是都需要）：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- DOMAIN-SUFFIX,snowplow.apps.clarivate.com,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,access.clarivate.com,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,www.webofscience.com,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,snowplow-collector.userintel.prod.sp.aws.clarivate.net,DIRECT</span><br><span class="line">- DOMAIN-SUFFIX,www.webofknowledge.com,DIRECT</span><br></pre></td></tr></tbody></table></figure><p>有需求的朋友可以将上面这段复制到 <code>prepend-rules</code> 之后。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>通俗易懂的贝叶斯深度神经网络介绍及代码实现</title>
      <link href="/2024/01/20/%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
      <url>/2024/01/20/%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>最近在课题组里的一些任务涉及到了把模型的架构改成贝叶斯层，让模型输出的结果能够体现不确定性。恶补相关知识的同时正好也能记录下笔记发博客，一举两得。</p><p>这篇文章只做概念介绍，不做深入剖析，追求原理的话敬请走下文中相关链接前往原论文。</p><h2 id="贝叶斯神经网络是什么"><a href="#贝叶斯神经网络是什么" class="headerlink" title="贝叶斯神经网络是什么"></a>贝叶斯神经网络是什么</h2><p>或许你在很多其他的地方听过<strong>贝叶斯</strong>这个词汇。以下是一些生物学中的例子：</p><ul><li>系统发育学中的贝叶斯建树（Mrbayes、Phylobayes）。</li><li>群体遗传学（种群遗传学）中分析种群结构、估计种群历史等（Structure、ABC）。</li><li>在某些基因组比对的工具里也有用到贝叶斯方法（bwa）。</li></ul><p>贝叶斯方法的大致原理是结合先验知识和实验数据来估计参数或测试假设，这个过程涉及到随机采样，因此其他方法不同，应用贝叶斯法得到的结果往往不会是完全一致的，也就是说，可能每次跑出来的结果之间会相似，但不会完全相同。</p><p>这里就提及到了贝叶斯方法的一个宝贵性质 —— <strong>不确定性</strong>。</p><p>如果有模型搭建经验的话，你应该知道，对于传统的神经网络架构而言，在你训练好模型后，如果给它相同的输入，那么一般而言它都会产生一致的输出（因为模型内部的<strong>权重是确定的</strong>）。但是有些时候，我们可能想知道：</p><ul><li>我们模型输出的结果到底多可靠？它的不确定性有多大？波动范围大概是多少？</li></ul><p>这时候，贝叶斯神经网络就发挥了其优势。</p><h3 id="贝叶斯神经网络如何引入不确定性"><a href="#贝叶斯神经网络如何引入不确定性" class="headerlink" title="贝叶斯神经网络如何引入不确定性"></a>贝叶斯神经网络如何引入不确定性</h3><p>我深知过于详尽的数学公式和逻辑论证会让人头昏眼花（数学佬除外），所以我并不打算以过于专业的角度进行解释。如果你对本文涉及到的贝叶斯神经网络个中原理感兴趣，可以去观摩相关的文章：</p><p><a href="https://arxiv.org/abs/1505.05424">Weight Uncertainty in Neural Networks</a></p><p>简单来说，贝叶斯神经网络中，每个神经元（或者说节点）之间连接的<strong>权重</strong>并<strong>不是一个固定的值</strong>，而是一个<strong>分布</strong>。假设在一个传统的神经网络架构中，一个权重的值为 0.2，那么这个权重在贝叶斯神经网络中的对应值可能就变为了 0.1-0.3。</p><p>只要能够理解上述这点，那么其输出为什么具有不确定性也就不难理解了。在贝叶斯神经网络的前向传播中，权重将会从一个分布中进行采样，因此不同的运行里我们得到的结果会不同，以上面的权重为例，或许这一次模型采样的权重为 0.15，而下一次就变成了 0.25。</p><p>这里同样引申出另一个重要的点：贝叶斯神经网络如何得到<strong>结果的不确定性</strong>？不难看出，它引入不确定性是通过权重的随机采样实现的，但是它每次运行输出的结果依然是个确定的值而不是一个分布（因为权重在采样后都是确定的某个值）。不过正如上面所说，因为每次运行得到的结果都会不同，因此我们可以通过<strong>多次预测</strong>得到一组预测结果，<strong>这组预测结果</strong>的平均值和标准差等信息即我们所需要的。</p><h3 id="贝叶斯神经网络的优势和不足"><a href="#贝叶斯神经网络的优势和不足" class="headerlink" title="贝叶斯神经网络的优势和不足"></a>贝叶斯神经网络的优势和不足</h3><p>贝叶斯神经网络（BNNs）与传统神经网络相比，优势如下：</p><p><strong>不确定性估计</strong>：贝叶斯神经网络能够提供预测的不确定性估计。这是因为 BNNs 使用概率分布而非单一值来表示权重，从而能够在给出预测时同时给出关于这些预测的不确定性信息。</p><p>这一优势同时导致了其他方面的优势：</p><ul><li><strong>减少过拟合</strong>。这其实不难理解，正如被广泛使用的 dropout 一样，两者有一个共通之处 —— 随机性，dropout 体现在丢弃神经元的随机性上，而贝叶斯神经网络体现在权重取值的随机性上。</li><li><strong>自适应（鲁棒）性</strong>。通过对权重的不确定性进行建模，可以更好地适应数据分布的变化，从而在面对数据或环境变化时更加 robust。</li></ul><p>举一些实际例子：</p><ul><li><p>与传统神经网络相比，贝叶斯神经网络在处理对抗性攻击时表现出更高的鲁棒性 (Uchendu, Campoy, Menart &amp; Hildenbrandt, 2021)。</p></li><li><p>在经济领域，贝叶斯神经网络在预测任务中的表现优于传统神经网络。这在预测乳金融市场动态等方面得到了应用和验证 (Magris, Shabani &amp; Iosifidis, 2022)。</p></li></ul><p>当然，不确定性是一把双刃剑，并且它不一定会让模型表现得更加出色（免费午餐警告⚠），一些明显的缺点如下：</p><ul><li><strong>更高的计算成本和更长的训练时间</strong>。这一点在后文的代码实现中能够得到更清晰的解释。</li><li><strong>内存需求</strong>。需要存储权重的分布而不是单个权重值。</li><li><strong>可解释性问题</strong>。尽管贝叶斯神经网络提供预测的不确定性估计，但它们<strong>本身的结构和决策过程仍然是黑盒</strong>的。</li></ul><p>关于贝叶斯神经网络的介绍，我强烈推荐以下博客文章：</p><p><a href="https://towardsdatascience.com/a-gentle-introduction-to-bayesian-deep-learning-d298c7243fd6">A Gentle Introduction to Bayesian Deep Learning</a></p><p>这里面稍微涉及到了一些基础的数学知识，理解上并不困难，也是从更易于理解的角度出发进行介绍。</p><h2 id="贝叶斯神经网络的代码实现"><a href="#贝叶斯神经网络的代码实现" class="headerlink" title="贝叶斯神经网络的代码实现"></a>贝叶斯神经网络的代码实现</h2><p>在很久之前贝叶斯神经网络需要自己通过 coding 实现，但现在已经有造好的轮子，所以我们只需要搬过来用即可。</p><blockquote><p>2024/05/20</p><p>经与博后师兄讨论，确定了一个更好用的 module：</p><p><a href="https://github.com/IntelLabs/bayesian-torch">https://github.com/IntelLabs/bayesian-torch</a></p><p>该 module 中关于 KL divergence 的 loss 参数设定不需要自行调整，且支持直接将传统架构转为贝叶斯架构，并提供了不确定性量化的方法。</p><p>安装方法（使用 pip）：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install bayesian-torch</span><br></pre></td></tr></tbody></table></figure><p>使用方法：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> bayesian_torch.models.dnn_to_bnn <span class="keyword">import</span> dnn_to_bnn, get_kl_loss</span><br><span class="line"></span><br><span class="line">const_bnn_prior_parameters = {</span><br><span class="line">        <span class="string">"prior_mu"</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">"prior_sigma"</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">"posterior_mu_init"</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">"posterior_rho_init"</span>: -<span class="number">3.0</span>,</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"Reparameterization"</span>,  <span class="comment"># Flipout or Reparameterization</span></span><br><span class="line">        <span class="string">"moped_enable"</span>: <span class="literal">False</span>,  <span class="comment"># True to initialize mu/sigma from the pretrained dnn weights</span></span><br><span class="line">        <span class="string">"moped_delta"</span>: <span class="number">0.5</span>,</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">model = torchvision.models.resnet18()</span><br><span class="line">dnn_to_bnn(model, const_bnn_prior_parameters)</span><br></pre></td></tr></tbody></table></figure><p>以上方法将创造一个全新的贝叶斯神经网络模型。此外，如果你已经拥有了一个预训练好的模型，则可以通过将 <code>moped_enable</code> 改为 <code>True</code> 从而使贝叶斯神经网络基于该模型已有权重设置先验和初始化变分参数（该操作有利于大模型的收敛）：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">const_bnn_prior_parameters = {</span><br><span class="line">        <span class="string">"prior_mu"</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">"prior_sigma"</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">"posterior_mu_init"</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">"posterior_rho_init"</span>: -<span class="number">3.0</span>,</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"Reparameterization"</span>,  <span class="comment"># Flipout or Reparameterization</span></span><br><span class="line">        <span class="string">"moped_enable"</span>: <span class="literal">True</span>,  <span class="comment"># True to initialize mu/sigma from the pretrained dnn weights</span></span><br><span class="line">        <span class="string">"moped_delta"</span>: <span class="number">0.5</span>,</span><br><span class="line">}</span><br><span class="line">    </span><br><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">dnn_to_bnn(model, const_bnn_prior_parameters)</span><br></pre></td></tr></tbody></table></figure><p>训练、预测和不确定性量化的相关代码详情请见该 module 的 <a href="https://github.com/IntelLabs/bayesian-torch">github 页面</a>。与下文介绍的 blitz 相比，这里的 bayesian-torch 只需要更简单的命令就可以实现传统神经网络到贝叶斯神经网络的迁移，并且具有更全面的功能和参数设定。</p></blockquote><h3 id="blitz-安装"><a href="#blitz-安装" class="headerlink" title="blitz 安装"></a>blitz 安装</h3><p>这里会用到 Python 的 <code>blitz</code> module，其具体源码和 document 可见：</p><p><a href="https://github.com/piEsposito/blitz-bayesian-deep-learning">https://github.com/piEsposito/blitz-bayesian-deep-learning</a></p><p>pip 安装命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install blitz-bayesian-pytorch</span><br></pre></td></tr></tbody></table></figure><p>或者你可以使用 conda 完成:</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge blitz-bayesian-pytorch</span><br></pre></td></tr></tbody></table></figure><p>亦或者你可以通过 clone 其 GitHub 仓库完成：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda create -n blitz python=3.9</span><br><span class="line">conda activate blitz</span><br><span class="line">git clone https://github.com/piEsposito/blitz-bayesian-deep-learning.git</span><br><span class="line">cd blitz-bayesian-deep-learning</span><br><span class="line">pip install .</span><br></pre></td></tr></tbody></table></figure><h3 id="运行范例"><a href="#运行范例" class="headerlink" title="运行范例"></a>运行范例</h3><p>这里使用经典的 LeNet 和 MNIST 数据集进行贝叶斯神经网络和传统神经网络的比较，以下代码将根据 blitz github repository 中的示例代码进行补充和修改，原代码可见：</p><p><a href="https://github.com/piEsposito/blitz-bayesian-deep-learning/blob/master/blitz/examples/bayesian_LeNet_mnist.py">https://github.com/piEsposito/blitz-bayesian-deep-learning/blob/master/blitz/examples/bayesian_LeNet_mnist.py</a></p><p>首先 import 需要的库：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> dsets</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> blitz.modules <span class="keyword">import</span> BayesianLinear, BayesianConv2d</span><br><span class="line"><span class="keyword">from</span> blitz.losses <span class="keyword">import</span> kl_divergence_from_nn</span><br><span class="line"><span class="keyword">from</span> blitz.utils <span class="keyword">import</span> variational_estimator</span><br></pre></td></tr></tbody></table></figure><p>下载并加载数据：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = dsets.MNIST(root=<span class="string">"./data"</span>,</span><br><span class="line">                             train=<span class="literal">True</span>,</span><br><span class="line">                             transform=transforms.ToTensor(),</span><br><span class="line">                             download=<span class="literal">True</span></span><br><span class="line">                            )</span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset,</span><br><span class="line">                                           batch_size=<span class="number">64</span>,</span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_dataset = dsets.MNIST(root=<span class="string">"./data"</span>,</span><br><span class="line">                             train=<span class="literal">False</span>,</span><br><span class="line">                             transform=transforms.ToTensor(),</span><br><span class="line">                             download=<span class="literal">True</span></span><br><span class="line">                            )</span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset,</span><br><span class="line">                                           batch_size=<span class="number">64</span>,</span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure><p>构建贝叶斯神经网络和传统神经网络：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@variational_estimator</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BayesianCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = BayesianConv2d(<span class="number">1</span>, <span class="number">6</span>, (<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.conv2 = BayesianConv2d(<span class="number">6</span>, <span class="number">16</span>, (<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.fc1   = BayesianLinear(<span class="number">256</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2   = BayesianLinear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3   = BayesianLinear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.relu(self.conv1(x))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = F.relu(self.conv2(out))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = F.relu(self.fc1(out))</span><br><span class="line">        out = F.relu(self.fc2(out))</span><br><span class="line">        out = self.fc3(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">lenet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, (<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, (<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.fc1   = nn.Linear(<span class="number">256</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2   = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3   = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.relu(self.conv1(x))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = F.relu(self.conv2(out))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = F.relu(self.fc1(out))</span><br><span class="line">        out = F.relu(self.fc2(out))</span><br><span class="line">        out = self.fc3(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></tbody></table></figure><ul><li><code>BayesianCNN</code> 类前的 <code>@variational_estimator</code> 是一种装饰器，它用于拓展包含贝叶斯神经网络的类的功能（例如后面会提到的 <code>.sample_elbo</code>），同时与原先的 <code>nn.Module</code> 适配。</li><li><code>nn.Conv2d</code> 层对应 <code>BayesianConv2d</code>，<code>nn.Linear</code> 对应 <code>BayesianLinear</code>。</li></ul><p>贝叶斯神经网络训练及评估：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Bayesian train &amp; test</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">classifier = BayesianCNN().to(device)</span><br><span class="line">optimizer = optim.Adam(classifier.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">best_accuracy = <span class="number">0</span></span><br><span class="line">waiting = <span class="number">0</span></span><br><span class="line">iteration = <span class="number">0</span></span><br><span class="line">stop = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> stop:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i, (datapoints, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss = classifier.sample_elbo(</span><br><span class="line">            inputs=datapoints.to(device),</span><br><span class="line">            labels=labels.to(device),</span><br><span class="line">            criterion=criterion,</span><br><span class="line">            sample_nbr=<span class="number">3</span>,</span><br><span class="line">            complexity_cost_weight=<span class="number">1</span> / <span class="number">50000</span>,</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># print(loss)</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        iteration += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> iteration % <span class="number">250</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(loss)</span><br><span class="line">            correct = <span class="number">0</span></span><br><span class="line">            total = <span class="number">0</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">                    images, labels = data</span><br><span class="line">                    outputs = classifier(images.to(device))</span><br><span class="line">                    _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">                    total += labels.size(<span class="number">0</span>)</span><br><span class="line">                    correct += (predicted == labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">                accuracy = <span class="number">100</span> * correct / total</span><br><span class="line">                <span class="built_in">print</span>(</span><br><span class="line">                    <span class="string">"Iteration: {} | Accuracy of the network on the 10000 test images: {} %"</span>.<span class="built_in">format</span>(</span><br><span class="line">                        <span class="built_in">str</span>(iteration), <span class="built_in">str</span>(<span class="number">100</span> * correct / total)</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> accuracy &gt; best_accuracy + <span class="number">0.005</span>:</span><br><span class="line">                    best_accuracy = accuracy</span><br><span class="line">                    waiting = <span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    waiting += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> waiting &gt;= <span class="number">4</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f"The best accuracy is <span class="subst">{best_accuracy}</span> for bayesian nn."</span>)</span><br><span class="line">                    stop = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure><p>这里把一百个 epoch 全跑完太消时，所以我使用了简陋的早停策略提前终止训练，需要关注的参数主要为：</p><ul><li><code>.sample_elbo</code>：这是 blitz 中特有的计算 loss 的功能，这里的 <code>sample_nbr</code> 可以当作计算多少次来进行一次梯度更新（因为每次计算都会有不一样的结果），而 <code>complexity_cost_weight</code> 相当于对模型的复杂性进行惩罚，<strong>该值越大，惩罚的力度越高（根据权重的先验分布和后验分布）</strong> 。它的源码如下：</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sample_elbo</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                inputs,</span></span><br><span class="line"><span class="params">                labels,</span></span><br><span class="line"><span class="params">                criterion,</span></span><br><span class="line"><span class="params">                sample_nbr,</span></span><br><span class="line"><span class="params">                complexity_cost_weight=<span class="number">1</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">""" Samples the ELBO Loss for a batch of data, consisting of inputs and corresponding-by-index labels</span></span><br><span class="line"><span class="string">            The ELBO Loss consists of the sum of the KL Divergence of the model</span></span><br><span class="line"><span class="string">             (explained above, interpreted as a "complexity part" of the loss)</span></span><br><span class="line"><span class="string">             with the actual criterion - (loss function) of optimization of our model</span></span><br><span class="line"><span class="string">             (the performance part of the loss).</span></span><br><span class="line"><span class="string">            As we are using variational inference, it takes several (quantified by the parameter sample_nbr) Monte-Carlo</span></span><br><span class="line"><span class="string">             samples of the weights in order to gather a better approximation for the loss.</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            inputs: torch.tensor -&gt; the input data to the model</span></span><br><span class="line"><span class="string">            labels: torch.tensor -&gt; label data for the performance-part of the loss calculation</span></span><br><span class="line"><span class="string">                    The shape of the labels must match the label-parameter shape of the criterion (one hot encoded or as index, if needed)</span></span><br><span class="line"><span class="string">            criterion: torch.nn.Module, custom criterion (loss) function, torch.nn.functional function -&gt; criterion to gather</span></span><br><span class="line"><span class="string">                        the performance cost for the model</span></span><br><span class="line"><span class="string">            sample_nbr: int -&gt; The number of times of the weight-sampling and predictions done in our Monte-Carlo approach to</span></span><br><span class="line"><span class="string">                        gather the loss to be .backwarded in the optimization of the model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(sample_nbr):</span><br><span class="line">        outputs = self(inputs)</span><br><span class="line">        loss += criterion(outputs, labels)</span><br><span class="line">        loss += self.nn_kl_divergence() * complexity_cost_weight</span><br><span class="line">    <span class="keyword">return</span> loss / sample_nbr</span><br></pre></td></tr></tbody></table></figure><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">相关概念介绍（非必要内容）</summary><div class="toggle-content"><p>KL 散度是一种衡量两个概率分布差异的方法，关于该概念的理解，可参见：</p><p><a href="https://zhuanlan.zhihu.com/p/100676922?utm_id=0">Kullback-Leibler(KL)散度介绍 from 知乎</a></p><p>在贝叶斯神经网络中，使用 KL 散度作为损失函数的一部分是为了实现变分推断。在这个背景下，网络的权重被视为随机变量，遵循某种概率分布。变分推断的目标是寻找一个简单的分布（变分后验分布），以近似复杂的真实后验分布。</p><p>贝叶斯神经网络的损失函数通常包含两部分：</p><ol><li><strong>性能损失</strong>（Performance Loss）：这部分通常是传统神经网络中使用的损失函数（如上述代码中的交叉熵），用于衡量模型预测与实际情况之间的差距。</li><li><strong>复杂度损失</strong>（Complexity Loss）：这部分是 KL 散度，用于衡量变分后验分布与先验分布之间的差异。KL 散度越大，表示变分后验分布与先验分布差异越大，模型复杂度越高。</li></ol><p>那么为什么变分后验分布与先验分布差异越大，模型复杂度越高？</p><p>这与贝叶斯推断的本质有关，在贝叶斯方法中，先验分布代表模型权重的初始假设，这时我们通常选择较为简单或宽泛的分布（例如没有信息的均匀分布或分布较广的正态分布等）。在进行训练后，训练数据会对参数估计产生影响，从而导致权重的后验分布产生变化。</p><p>这个情况下，后验分布与先验分布相差显著时，模型可能捕捉到了数据中的复杂特征和模式，从而提高了其拟合能力。然而，这也可能意味着模型捕捉到了数据中的噪声，导致过拟合。因此，上述代码中引入了新的超参数 <code>complexity_cost_weight</code> 对这一点进行了限制，以起到一定的正则化作用，保证模型的泛化能力。同时也不难看出，<strong>错误的先验决定也会影响到模型的训练和泛化</strong>。</p><p>关于后验分布更新的示例，可以看以下文章：</p><p><a href="https://zhuanlan.zhihu.com/p/266563061">贝叶斯教你如何正确抛硬币 from 知乎</a></p><p>以抛硬币为例，<strong>正面向上的概率即</strong> <strong>P(正面向上)</strong> 的先验分布可能是 Beta(1,1)，即一个均匀分布（没有任何信息量），之后我们根据观测数据来更新这个分布得到后验概率分布：</p><ol><li>第一次抛出正面，后验分布变为 Beta(2,1)。</li><li>第二次抛出正面，后验分布变为 Beta(3,1)，此时的概率分布已变为向右倾斜（即正面向上的概率<strong>趋于</strong>更高）。</li><li>假设之后又抛了数次，总共出现正面 552 次，反面 539 次。</li><li>此时后验分布为 Beta(553, 540)，这个分布是轻微向右倾斜，但峰值很接近 0.5 且很窄。</li></ol><p><img src="/pic2/bata_distri.png"></p><p>关于贝塔分布的介绍，可见：<a href="https://zhuanlan.zhihu.com/p/69606875">深入理解Beta分布 from 知乎</a></p><p>你可以使用以下代码进行复现：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> beta</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">553</span>]</span><br><span class="line">b = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">540</span>]</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="built_in">len</span>(a), figsize=(<span class="built_in">len</span>(a)*<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, (suba, subb) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(a, b)):</span><br><span class="line"></span><br><span class="line">    x = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">    y = beta.pdf(x, suba, subb)</span><br><span class="line"></span><br><span class="line">    axes[i].plot(x, y, <span class="string">'r-'</span>, lw=<span class="number">2</span>, alpha=<span class="number">0.6</span>, label=<span class="string">'beta pdf'</span>)</span><br><span class="line">    axes[i].set_xlabel(<span class="string">'x'</span>)</span><br><span class="line">    axes[i].set_xlim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    axes[i].set_title(<span class="string">f'Beta(<span class="subst">{suba}</span>, <span class="subst">{subb}</span>)'</span>)</span><br></pre></td></tr></tbody></table></figure></div></details><p>需要注意的是，<code>complexity_cost_weight</code> 的值将对结果产生<strong>很大的</strong>影响，在 blitz 的其他示例代码中可以看到这个值一般设为 <code>1/batchsize</code>，但是在 MNIST 数据集中，它使用了 <code>1/50000</code> 作为该超参数的值。经过实测，如果使用 <code>1/batchsize</code>，模型的准确率将在 10% 上下浮动，说明惩罚过严重，导致权重的后验分布无法灵活适应数据。</p><p>针对该超参数的选择，blitz 的开发者没有给出 guideline<del>（很多相关 issue 发布多年都没有回复…..）</del>。但从该库源码里 KL 散度的计算中可以看出，模型越复杂（贝叶斯层越多或神经元越多），KL 散度越高，最后的计算复杂度惩罚项越大。因此<strong>对于复杂的模型而言，调低该值或许是一个不错的选择</strong>。</p><p>训练和预测结果：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor(4.0596, device='cuda:0', grad_fn=&lt;DivBackward0&gt;)</span><br><span class="line">Iteration: 250 | Accuracy of the network on the 10000 test images: 94.26 %</span><br><span class="line">......</span><br><span class="line">The best accuracy is 98.75 for bayesian nn.</span><br></pre></td></tr></tbody></table></figure><p>再换成传统的 Lenet 试试：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Lenet train &amp; test</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">classifier = lenet().to(device)</span><br><span class="line">optimizer = optim.Adam(classifier.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">best_accuracy = <span class="number">0</span></span><br><span class="line">waiting = <span class="number">0</span></span><br><span class="line">iteration = <span class="number">0</span></span><br><span class="line">stop = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> stop:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i, (datapoints, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        datapoints = datapoints.cuda()</span><br><span class="line">        labels = labels.cuda()</span><br><span class="line"></span><br><span class="line">        pred = classifier(datapoints)</span><br><span class="line">        loss = criterion(pred, labels)</span><br><span class="line">        <span class="comment"># print(loss)</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        iteration += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> iteration % <span class="number">250</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(loss)</span><br><span class="line">            correct = <span class="number">0</span></span><br><span class="line">            total = <span class="number">0</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">                    images, labels = data</span><br><span class="line">                    outputs = classifier(images.to(device))</span><br><span class="line">                    _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">                    total += labels.size(<span class="number">0</span>)</span><br><span class="line">                    correct += (predicted == labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">                accuracy = <span class="number">100</span> * correct / total</span><br><span class="line">                <span class="built_in">print</span>(</span><br><span class="line">                    <span class="string">"Iteration: {} | Accuracy of the network on the 10000 test images: {} %"</span>.<span class="built_in">format</span>(</span><br><span class="line">                        <span class="built_in">str</span>(iteration), <span class="built_in">str</span>(<span class="number">100</span> * correct / total)</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> accuracy &gt; best_accuracy + <span class="number">0.005</span>:</span><br><span class="line">                    best_accuracy = accuracy</span><br><span class="line">                    waiting = <span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    waiting += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> waiting &gt;= <span class="number">4</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f"The best accuracy is <span class="subst">{best_accuracy}</span> for lenet nn."</span>)</span><br><span class="line">                    stop = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor(0.2020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)</span><br><span class="line">Iteration: 250 | Accuracy of the network on the 10000 test images: 91.49 %</span><br><span class="line">......</span><br><span class="line">The best accuracy is 99.01 for lenet nn.</span><br></pre></td></tr></tbody></table></figure><p>从结果上看，贝叶斯神经网络并没有取得比传统神经网络更好的表现，但是两者仅相差几个千分点，也可能是训练的随机性造成的。不过也能看出，并不是越复杂的网络架构就一定会发挥的更好。</p><p>以上代码并没法看出预测的不确定性，接下来将以 blitz 的另一个示例展示其结果的波动：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> blitz.modules <span class="keyword">import</span> BayesianLinear</span><br><span class="line"><span class="keyword">from</span> blitz.utils <span class="keyword">import</span> variational_estimator</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X, y = fetch_california_housing(return_X_y=<span class="literal">True</span>)</span><br><span class="line">X = StandardScaler().fit_transform(X)</span><br><span class="line">y = StandardScaler().fit_transform(np.expand_dims(y, -<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X,</span><br><span class="line">                                                    y,</span><br><span class="line">                                                    test_size=<span class="number">.1</span>,</span><br><span class="line">                                                    random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X_train, y_train = torch.tensor(X_train).<span class="built_in">float</span>(), torch.tensor(y_train).<span class="built_in">float</span>()</span><br><span class="line">X_test, y_test = torch.tensor(X_test).<span class="built_in">float</span>(), torch.tensor(y_test).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line"><span class="meta">@variational_estimator</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BayesianRegressor</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment">#self.linear = nn.Linear(input_dim, output_dim)</span></span><br><span class="line">        self.blinear1 = BayesianLinear(input_dim, input_dim*<span class="number">2</span>)</span><br><span class="line">        self.blinear2 = BayesianLinear(input_dim*<span class="number">2</span>, output_dim)</span><br><span class="line">        <span class="comment"># self.blinear1 = nn.Linear(input_dim, input_dim*2)</span></span><br><span class="line">        <span class="comment"># self.blinear2 = nn.Linear(input_dim*2, output_dim)</span></span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x_ = self.blinear1(x)</span><br><span class="line">        x_ = F.relu(x_)</span><br><span class="line">        <span class="keyword">return</span> self.blinear2(x_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">regressor = BayesianRegressor(<span class="number">8</span>, <span class="number">1</span>)</span><br><span class="line">optimizer = optim.Adam(regressor.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">criterion = torch.nn.MSELoss()</span><br><span class="line"></span><br><span class="line">ds_train = torch.utils.data.TensorDataset(X_train, y_train)</span><br><span class="line">dataloader_train = torch.utils.data.DataLoader(ds_train, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ds_test = torch.utils.data.TensorDataset(X_test, y_test)</span><br><span class="line">dataloader_test = torch.utils.data.DataLoader(ds_test, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> i, (datapoints, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader_train):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        loss = regressor.sample_elbo(inputs=datapoints,</span><br><span class="line">                           labels=labels,</span><br><span class="line">                           criterion=criterion,</span><br><span class="line">                           sample_nbr=<span class="number">3</span>,</span><br><span class="line">                           complexity_cost_weight=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># loss = criterion(regressor(datapoints), labels)</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(loss.item(), end=<span class="string">'\r'</span>)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'Epoch <span class="subst">{epoch+<span class="number">1</span>}</span> finished!'</span>)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(regressor(X_test).detach().numpy()[<span class="number">0</span>:<span class="number">3</span>])</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[[-1.203408  ]</span><br><span class="line"> [-0.32957393]</span><br><span class="line"> [ 1.9057552 ]]</span><br><span class="line">[[-1.2015951 ]</span><br><span class="line"> [-0.32578745]</span><br><span class="line"> [ 1.9102848 ]]</span><br><span class="line">[[-1.2165544 ]</span><br><span class="line"> [-0.33425388]</span><br><span class="line"> [ 1.9049363 ]]</span><br></pre></td></tr></tbody></table></figure><p>可以看到，三次运行输出的结果都是不一致的，通过以下命令我们可以获得预测的均值和标准差：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">preds = [regressor(X_test) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>)]</span><br><span class="line">preds = torch.stack(preds)</span><br><span class="line">means = preds.mean(axis=<span class="number">0</span>).detach().numpy().squeeze()</span><br><span class="line">stds = preds.std(axis=<span class="number">0</span>).detach().numpy().squeeze()</span><br></pre></td></tr></tbody></table></figure><p>这里需要注意，<u>对于表格数据先需进行标准化，具体原因见注意事项</u>。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>以上就是使用 blitz 实现贝叶斯神经网络的整体流程，同样地，其他的网络架构可以通过将 nn 层替换为对应的贝叶斯层实现：</p><ul><li>BayesianLinear</li><li>BayesianConv1d</li><li>BayesianConv2d</li><li>BayesianConv3d</li><li>BayesianLSTM</li><li>BayesianGRU</li><li>BayesianEmbedding</li></ul><p>使用贝叶斯神经网络时，有几点需要注意：</p><ol><li>新增的超参数中，<code>complexity_cost_weight</code> 非常重要，<strong>该值的选择可能会极大影响模型的表现</strong>。当模型越复杂时，该值应当越低。</li><li>要获得结果的不确定性需多次运行模型，这<strong>对于模型过于复杂的任务来说可能极为耗时</strong>。因此需综合考虑自身需求和时间成本。</li><li>对于计算机视觉领域中的图片分类问题等，不需要对输入数据进行特别处理。但对于结构化数据（例如上述的 <code>fetch_california_housing</code> 数据集），需要注意特征的尺度是否一致，如果不一致则需要对其进行<strong>标准化处理</strong>。由于贝叶斯层在初始化时，对于每个权重的处理是一致的，因此特征的尺度不同将极大影响后续权重的更新，例如尺度更小的特征可能得到更大的权重，同时相应的复杂度惩罚也就越严重。对于图片分类，每个通道的尺度相同，因此不存在这方面的问题。</li></ol><h2 id="一些有趣的问题"><a href="#一些有趣的问题" class="headerlink" title="一些有趣的问题"></a>一些有趣的问题</h2><ul><li>问 ChatGPT 相同的问题时，它会给出不同的回答。这是为什么？是因为它的模型架构中引入了贝叶斯方法吗？</li><li>除了通过对权重进行采样引入正则化以外，贝叶斯神经网络还在其他哪些地方体现出了可以提升模型表现的性质？</li><li>你认为分类问题更需要贝叶斯神经网络还是回归问题更需要？为什么？</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>Robustness of Bayesian Neural Networks to White-Box Adversarial Attacks</li><li>Bayesian Bilinear Neural Network for Predicting the Mid-price Dynamics in Limit-Order Book Markets</li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>dN/dS 的计算及其核心理念</title>
      <link href="/2023/12/30/dNdS%20%E7%9A%84%E8%AE%A1%E7%AE%97%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%90%86%E5%BF%B5/"/>
      <url>/2023/12/30/dNdS%20%E7%9A%84%E8%AE%A1%E7%AE%97%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%90%86%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p><strong>dN/dS (ω)</strong> 是一个在进化生物学领域常出现的词，也是我最近分析的时候着重关注的一个对象。这几天翻了一些文献和书籍，对它的计算和设计理念有了一个全新的了解，所以有了这篇博客。</p><p>在阅读这篇文章前，你可能需要一定的相关知识基础，例如，你应该已经知道以下概念：</p><ul><li>密码子、简并位点、同义突变、非同义突变。</li><li>中性理论、正选择、纯化选择。</li></ul><h2 id="dN-dS-是什么"><a href="#dN-dS-是什么" class="headerlink" title="dN/dS 是什么"></a>dN/dS 是什么</h2><p>这里的 S 即 <strong>Synonymous</strong>，N 即 <strong>Nonsynonymous</strong>。</p><p>dN 指的是<strong>非同义替换率</strong>，dS 指的是<strong>同义替换率</strong>。但我认为另一个知乎博主文章里的说法会更加直观一些：</p><ul><li>dN: 每个<strong>非同义位点</strong>上发生的非同义突变的数量。</li><li>dS: 每个<strong>同义位点上</strong>发生的同义突变的数量。</li></ul><h3 id="计算原理"><a href="#计算原理" class="headerlink" title="计算原理"></a><strong>计算原理</strong></h3><p>首先，简单来说，dN 和 dS 的计算涉及到四个变量，分别为<strong>同义突变数量（S）、非同义突变数量（N）以及同义位点数量（Ssite）和非同义位点数量（Nsite）</strong>。</p><img src="/pic2/dndscalcu.png" height="100px"><p>前两个变量 N 和 S 非常好理解，所以这里需要重点关注的是后两个变量 Nsite 和 Ssite，即每种类型的位点数量是什么？它们是如何得到的？但在这之前，我们先简单回顾一下一些常见的突变类型。</p><h3 id="突变类型"><a href="#突变类型" class="headerlink" title="突变类型"></a>突变类型</h3><p>我们都知道，一个密码子在发生突变时，其性质可能发生以下几种变化，以密码子 TTT 为例（其编码苯丙氨酸 Phe）：</p><ul><li><strong>错义突变</strong>：由编码一个氨基酸变为编码另一个氨基酸，例如 TTT(苯丙氨酸)&gt;ATT(异亮氨酸)。</li><li><strong>同义突变</strong>：突变过后，仍编码相同氨基酸，例如 TTT(苯丙氨酸)&gt;TTC(苯丙氨酸)。同义突变通常发生在密码子的第三个碱基上（有时第一个碱基也可以，例如 AGA&gt;CGA 皆编码精氨酸），此时我们称这个位点具有简并性。需要注意的是，在某些情况下，<strong>终止密码子突变为终止密码子</strong>（例如 TAA&gt;TAG）<strong>也被视为一种同义突变</strong>。</li></ul><p>除了这一些可能的突变以外，还有一些其他的情况，例如，TAT(酪氨酸) 可能变为一个终止密码子（TAA），这时我们称其为<strong>无义突变</strong>，在某些情景下，这也可以被称为<strong>截断突变</strong> (protein-truncating variant，PTV)。</p><p>以上突变类型并不涵盖全部情况，但这些突变是大多 dN/dS 算法的关注对象。</p><p>部分情况下，错义突变和无义突变会<strong>被统一视为非同义突变</strong>，当然在一些算法中，无义突变并不被考虑。这也取决于具体的研究目的和需要。</p><img src="/pic2/maxresdefault.jpg" height="400px"><h3 id="位点类型"><a href="#位点类型" class="headerlink" title="位点类型"></a>位点类型</h3><p>现在我们知道，一个位点的突变可能带来的结果也不同，这也是计算 Ssite 和 Nsite 的关键所在。</p><p>首先对于任何情况下的 Nsite 和 Ssite 计算结果，我们都有：</p><img src="/pic2/cds_ns.png" height="100px"><p>例如，对于一个长度为 3 的密码子，它所计算出来的 Nsite 和 Ssite 总和也必定为 3。</p><p>接下来就是计算过程，最简单的计算即<strong>遍历每个位点的每种突变情况可能导致的突变类型</strong>，对于 TTT，我们可以列举出它的所有可能突变情况，这里直接用杨子恒《计算分子进化》中的一张图作为示例：</p><img src="/pic2/ttt.png" height="500px"><p>我们先仅考虑 <code>k=1</code> 一栏，<code>k=2</code> 在后文中我们会拓展讨论。</p><p>其中，对于一个密码子的每一个位点，它都可以突变成除它自身之外的碱基，因此每个位点都有三个 <code>Target codon</code>，其中同义突变的情况仅有 <code>TTT&gt;TTC</code>，而其他都为非同义突变。</p><p>因此，这里共有 9 个情况，其中同义突变占 1 个，非同义突变占 8 个。因此，同义位点数量为 <code>1/9 * 3</code>（3 即密码子长度），非同义位点数量为 <code>8/9 * 3</code>。最后则分别为表中的 1/3 和 8/3。</p><h3 id="突变计数及-dN-dS-计算"><a href="#突变计数及-dN-dS-计算" class="headerlink" title="突变计数及 dN/dS 计算"></a>突变计数及 dN/dS 计算</h3><p>知道位点数量后，我们就可以计算了，依然以一个最简单的情况作为示例，假设我们有一个包含九个 <code>TTT</code> 的 CDS：</p><ul><li>TTTTTTTTTTTTTTTTTTTTTTTTTTT</li></ul><p>通过计算我们可以知道，它具有 3 个同义位点和 24 个非同义位点，假设这里在两个密码子上我们观察到了一个同义突变和一个非同义突变：</p><ul><li>TT<strong>C</strong>TTTTTTTTTTTTTTTTTTTTTT<strong>A</strong>T</li></ul><p>那么此时，其 dN = 1/24，dS = 1/3，计算得到 dN/dS = 1/8。</p><p>当然，在突变计数步骤中也可能出现更加复杂的情况，例如同一个密码子上出现了两个突变，例如 TTT 变为了 TCA，这种情况就要考虑多条进化途径：</p><ul><li>TTT &gt; TTA &gt; TCA（苯丙氨酸 &gt; 亮氨酸 &gt; 丝氨酸），这条途径涉及到两个非同义突变。</li><li>TTT &gt; TCT &gt; TCA（苯丙氨酸 &gt; 丝氨酸 &gt; 丝氨酸），这条途径涉及到一个非同义突变和一个同义突变。</li></ul><p>对于这种情况，常见的做法有对不同的途径赋予合适的权重等，更多细节如果看客感兴趣可自行深入了解。</p><h3 id="dN-dS-应该是多少"><a href="#dN-dS-应该是多少" class="headerlink" title="dN/dS 应该是多少"></a>dN/dS 应该是多少</h3><p>在最简单的 dN/dS 计算中（前文中的 <code>k=1</code>），其中有一个隐性的假设：我们认为每一个位点上每一个突变情况发生的概率都是<strong>相等</strong>的。</p><p>那么，我们继续以 TTT 作为例子，如果每一个突变情况发生的概率都是<strong>相等</strong>的，理想情况下（<strong>无选择压力</strong>）我们会获得的 dN/dS 值会是多少？</p><p>很简单，发生同义突变的概率是 1/9，发生非同义突变的概率是 8/9，假设发生突变的数量为 x，则通过计算和约分后我们可以发现，<strong>dN/dS 值应该是 1</strong>。</p><p>当然，在现实条件中，每一个突变情况发生的概率并不一定相等，例如，转换（transition）发生的概率就要比颠换（transversion）更高，而很多同义突变都是转换事件，因此如果我们忽略转换和颠换之间的发生概率差异，就会导致 Ssite 低估和 Nsite 的高估，从而导致计算的 dN/dS 偏低。</p><p>对于上面这种情况，一种可行的方法就是在计算转换事件时，给它提供的位点数量进行相应加权，也就有了这个表格中 <code>k=2</code> 的情况：</p><img src="/pic2/ttt.png" height="500px"><p>相似的事情还发生在<strong>密码子偏好</strong>等因素上，而很多方法也针对这些点进行了改进。例如<a href="https://www.sciencedirect.com/science/article/pii/S0092867417311364">一篇 17 年的 cell 文章中</a>，作者使用 192 个 rate parameters (包括不同的替换类型和链属性，有些类似 3-mer 的突变率模型) 来计算 dN/dS，并发现其他方法要么高估要么低估了 dN/dS。</p><p>所以，dN/dS 有一个很关键的设计理念，就是<strong>在完全没有选择的情况下，这个值应当等于 1</strong>，即同义替代率和非同义替代率应当是相等的。这个概念对于后续的一系列引申也很重要。</p><h2 id="dN-dS-有什么用"><a href="#dN-dS-有什么用" class="headerlink" title="dN/dS 有什么用"></a>dN/dS 有什么用</h2><p>现在我们能够知道，如果完全考虑了不同替换发生概率的差异并针对它们矫正 Nsite 和 Ssite 的计算，那么 dN/dS 在没有选择的情况下应该是等于 1 的。</p><p>在很多地方我们也可以看到这么一个结论：</p><ul><li>dN/dS &lt; 1，表明存在<strong>纯化选择</strong>。</li><li>dN/dS = 1，表明处在<strong>中性选择</strong>下。</li><li>dN/dS &gt; 1，表明存在<strong>正选择</strong>。</li></ul><p>也就是说，dN/dS 还可以帮助我们确认一个基因所处的状态，并据此推断出其选择的机制，为我们理解其进化过程提供信息。</p><p>那么为什么说 dN/dS = 1 时，基因处于中性选择下呢？这里首先我们要明确一个概念，<strong>中性选择</strong>并不意味着不存在选择，只是它对生物体的适应性和生存几率没有正面或负面的影响，因此它并不因自然选择而频率增加或下降，在种群内的频率变化全由遗传漂变决定。当然为了方便理解，可以将其视为和 “没有选择” 等效。</p><p>同样，中性（neutral）的概念也是如此，一个中性突变就是对生物既无益处也无害处的突变（亦或是带来的益害相抵消）。</p><p>然后要明确一个概念，<code>dN/dS = 1</code> 推导出中性选择的前提假设是 —— <strong>同义突变都是中性的</strong>。</p><p>不妨设想一下，如果同义突变和非同义突变都受到相同强度的强纯化选择，导致其突变数量减少 50%，那么最后算出来的 dN/dS 依然等于 1。</p><p>那么这个假设到底成不成立呢？很显然不成立。这个假设主要的根基在于<strong>同义突变并不会改变蛋白质的组成和结构</strong>，因此从蛋白的角度出发它不会对生物体的表型产生影响。但是在转录翻译阶段，已经有很多研究发现，<strong>不同密码子就算编码同一氨基酸，也会存在效率和质量上的不同</strong>（这也是密码子偏好的原因之一），所以大多数同义突变其实归根结底是<strong>有害</strong>的（可见 <a href="https://www.nature.com/articles/s41586-022-04823-w">Shen et al. 2022, Nature</a>）。</p><p>但是这影不影响我们使用同义突变作为中性的 Proxy？其实这是个很有争议的问题，因为即使同义突变有害，也很难去量化同义突变到底 “多有害”。今年 4 月份，针对得出 “大多数同义突变都有害” 的文章有人产生了<a href="https://www.nature.com/articles/s41586-023-05865-4">质疑</a>。同样，很多其他的研究表明同义突变可能产生影响的概率比非同义小得多。</p><p>违反一个假设的严重性，一要看<strong>违反的程度</strong>，二要看<strong>理论对此的鲁棒性</strong>。就以我个人目前进行的分析来看，同义突变受到的影响应该较为轻微。从各种使用 dN/dS 进行选择推断的分析来看，似乎其结果都 “合乎情理”。当然，具体情况如何也有待更详尽的探讨。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实这篇博客最重要的点还是理清为什么会以 1 这个值作为 dN/dS 的 “分界线”，其实理解了 dN/dS 的计算目的，也就能明白这么做的理由。</p><p>这里再总结一下该文章中的一些重点：</p><p>①、计算 Nsite 和 Ssite 时，对于突变率高的突变类型，需要对其进行一定的加权以平衡其对 dN 和 dS 计算的贡献。以往的计算中，<code>转换-颠换比率</code> 和 <code>密码子偏好</code> 等都是基于该点考虑对计算进行修正。</p><p>②、基于突变发生概率矫正后计算的 dN/dS 可以作为选择情况的参考。如果同义突变的中性假设是正确的或者几近正确的，则当 dN/dS 等于 1 时我们可以认为该蛋白编码基因处于中性选择下。</p><p>如果你对代码更感兴趣，并且想知道具体的计算步骤，可以尝试看一看 Biopython 中相应脚本的源码：</p><p><a href="https://github.com/biopython/biopython/blob/master/Bio/codonalign/codonseq.py">https://github.com/biopython/biopython/blob/master/Bio/codonalign/codonseq.py</a></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>Ziheng Yang, Computational Molecular Evolution.</li><li>Martincorena et al., Universal Patterns of Selection in Cancer and Somatic Tissues.</li><li>Shen et al., Synonymous mutations in representative yeast genes are mostly strongly non-neutral.</li><li>Dhindsa et al., A minimal role for synonymous variation in human disease.</li></ol></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>slurm 作业数组的正确使用姿势</title>
      <link href="/2023/12/13/slurm%20%E4%BD%9C%E4%B8%9A%E6%95%B0%E7%BB%84%E7%9A%84%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%E5%A7%BF%E5%8A%BF/"/>
      <url>/2023/12/13/slurm%20%E4%BD%9C%E4%B8%9A%E6%95%B0%E7%BB%84%E7%9A%84%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%E5%A7%BF%E5%8A%BF/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>最近一次想要批量运行任务前试着运行了一个个例，发现占用的内存意外的比较多，所以一口气把所有提交到服务器上显然不太妥当。由于之前在服务器上用 slurm 仅限于 <code>srun</code> 而从来没有尝试过 <code>sbatch</code>，所以就对这方面的知识进行了一番恶补，正好也能补充十二月份的博客内容。</p><h3 id="如何确定内存是否充足"><a href="#如何确定内存是否充足" class="headerlink" title="如何确定内存是否充足"></a>如何确定内存是否充足</h3><p>对于当前节点，使用 <code>top</code> 和 <code>htop</code> 就能得到相关的信息，但对于其他节点，如果没有登录权限，那么这种实时监控的手段就没法派上用场了。</p><p>这时候，可以使用 <code>free -h</code>  命令将节点在该时间点的内存使用情况信息打印出来：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">srun -w nodexx free -h</span></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           487G        144G        2.7G        162M        340G        340G</span><br><span class="line">Swap:           49G        685M         49G</span><br></pre></td></tr></tbody></table></figure><p>重点关注 available 部分，可以看到当前该节点还是剩余了非常多可用内存的。不过并不是内存越多可以运行的命令就越多，这也跟剩余的空闲 CPU 数有关，关于剩余的 CPU 数可以直接使用 <code>scontrol show node nodexx </code> 来查看：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">scontrol show node nodexx | grep <span class="string">'CPUTot'</span></span></span><br><span class="line">   CPUAlloc=45 CPUTot=52 CPULoad=75.96</span><br></pre></td></tr></tbody></table></figure><p>可以看到已经分配的 CPU 有多少个（CPUAlloc）。</p><h3 id="如何确定任务要多少内存"><a href="#如何确定任务要多少内存" class="headerlink" title="如何确定任务要多少内存"></a>如何确定任务要多少内存</h3><p>可以先只投递单个任务，若该任务投递到当前终端所在节点，则直接使用 <code>top -u username</code> 就能进行查看。</p><p>如果该任务投递到其他节点上，那么可以使用 <code>ps</code> 命令查看相关情况：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">srun -w nodexx ps -u username -o pid,vsz,rss,<span class="built_in">comm</span></span></span><br><span class="line">   PID    VSZ   RSS COMMAND</span><br><span class="line">  6382 34042040 9706368 xxxx</span><br></pre></td></tr></tbody></table></figure><p>这里我们可以着重关注 RSS（常驻内存集大小，即进程实际使用的物理内存大小），该例子中这个命令占用了约 9.7 GB（9706368 KB） 的内存，以此为准，若我们剩余了 100 GB 的内存，那就还能支撑我们运行大约十个这样的命令（理想情况）。但实际情况肯定没那么简单，所以最好留出一些余量以避免性能下降或内存交换。</p><h3 id="使用-sbatch-提交作业"><a href="#使用-sbatch-提交作业" class="headerlink" title="使用 sbatch 提交作业"></a>使用 sbatch 提交作业</h3><p>确定了自己大约还能投多少任务后，就可以针对其编写相关的 shell 脚本了。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --job-name=xxx</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --output=xxx_%A_%a.out</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --error=xxx_%A_%a.err</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --partition=xxx</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --ntasks=1</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --array=1-10%5</span></span><br><span class="line"></span><br><span class="line">FILES=(*txt)</span><br><span class="line">INDEX=$(($SLURM_ARRAY_TASK_ID - 1))</span><br><span class="line">FILE=${FILES[$INDEX]}</span><br><span class="line"></span><br><span class="line">echo $FILE</span><br></pre></td></tr></tbody></table></figure><p>以上述例子为例，以下几个标头较为重要：</p><ul><li><p><code>#SBATCH --output=xxx_%A_%a.out</code> 这里的 <code>%A</code> 和 <code>%a</code> 分别表示作业数组的 ID 和数组中任务的索引，添加后不同作业的 out 和 err 会分开产生而不会混在一起。</p></li><li><p><code>#SBATCH --partition=xxx</code> 该处的填写可根据 <code>sinfo</code> 的信息进行，例如：</p></li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sinfo</span></span><br><span class="line">PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST</span><br><span class="line">all*         up   infinite      3    mix nodexx,nodexx,nodexx</span><br></pre></td></tr></tbody></table></figure><p>此时可填写 <code>all</code>，slurm 会根据该 partition 中 node 的使用情况自动分配任务。如果没有 partition 可以换成 <code>#SBATCH --nodelist=xxx</code> 填写想要投递的节点名称。</p><ul><li><code>#SBATCH --array=1-10%5</code> 这行定义了作业数组的范围（1-10，共十个）和同时运行的作业数量（%5），这里还有其他的设计技巧，例如：<ul><li><code>1-100:10</code> 表示从 1 到 100，每隔 10 个一个作业。</li><li><code>1,2,5-7</code> 表示作业 1, 2, 5, 6, 和 7。</li><li>slurm 为每个作业数组提供了特定的环境变量，如示例脚本中的 <code>$SLURM_ARRAY_TASK_ID</code></li></ul></li></ul><p>以上脚本会按照以下逻辑进行：</p><ol><li><code>FILE</code> 变量储存当前文件夹下所有 <code>txt</code> 结尾的文件。</li><li>通过 <code>$SLURM_ARRAY_TASK_ID</code> 定义索引变量 <code>INDEX</code> 并调取出 <code>FILE</code> 中对应索引的文件。</li><li>打印出对应文件的文件名（<code>echo</code>），结果将出现在 out 文件中。</li></ol><p>运行该脚本的方法（假设该脚本名字为 <code>test.sh</code>）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sbatch test.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sbatch --mail-user=xxx@xxx --mail-type=BEGIN,END test.sh <span class="comment"># 开始和结束后发邮件通知</span></span></span><br></pre></td></tr></tbody></table></figure><p>上述代码中，发邮件通知也可以通过在脚本中添加以下代码完成：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --mail-user=xxx@xxx</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">SBATCH --mail-type=BEGIN,END</span></span><br></pre></td></tr></tbody></table></figure><p>投递任务后，如果想要关注相关任务的状态，可以使用 <code>squeue -u username</code> 进行。</p><p>当然，如果需要提交的作业不能仅仅通过索引来区分，而是<strong>需要执行完全不同的命令</strong>时，使用作业数组可能不是最合适的选择。这时候对每个任务单独编写脚本并提交更能满足实际需求。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>DNA 语言模型 GPN 在突变效应预测中的应用及表现</title>
      <link href="/2023/11/24/DNA%20%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20GPN%20%E5%9C%A8%E7%AA%81%E5%8F%98%E6%95%88%E5%BA%94%E9%A2%84%E6%B5%8B%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E5%8F%8A%E8%A1%A8%E7%8E%B0/"/>
      <url>/2023/11/24/DNA%20%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%20GPN%20%E5%9C%A8%E7%AA%81%E5%8F%98%E6%95%88%E5%BA%94%E9%A2%84%E6%B5%8B%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E5%8F%8A%E8%A1%A8%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>众所周知，语言模型已经在诸多领域得到了广泛应用。受深度学习狂潮影响深远的生物学领域里，出色的语言模型应用不断涌出。以 DeepMind 为例，其所开发的 Alphafold、Alphamissense 等都是基于语言模型实现的。</p><p>这篇文章将分享一个最近发表的 DNA 语言模型（GPN，Genomic Pre-trained Network）和它的变体 GPN-MSA，该模型与之前的 DNABERT 等 DNA 语言模型不同，其使用<strong>单个碱基</strong>作为 token 进行训练，并在无监督的突变效应预测中取得了良好的成效。</p><p>相关论文链接见文章结尾，本文章将重点介绍两个模型的设计和它们之间的区别，并写出一些很值得学习的地方。</p><h3 id="GPN"><a href="#GPN" class="headerlink" title="GPN"></a>GPN</h3><p>GPN 是一种自监督训练的 DNA 语言模型，与 GPN-MSA 不同的地方在于，它可以仅依靠未经过比对的数个基因组序列而不使用多序列比对（MSA）进行训练，此外它使用的为单纯的 DNA 序列而未使用到任何功能基因组信息，因此可以说 GPN 的泛用性是非常强大的，因为对于很多类群中的生物来说，获得跨物种的 MSA 和全面的功能基因组数据并不是容易的事情。</p><p>GPN 的模型设计如下：</p><p><img src="/pic2/pnas.2311219120fig01.jpg"></p><p>该模型的训练架构类似于 Transformer，其中 DNA 的输入遵守如下规则：</p><ul><li>在基因组上使用 <code>512bp</code> 的窗口 &amp; <code>256bp</code> 的步长进行采样（类似于滑动窗口），并使用反向互补序列作为数据增强手段（DNA 语言模型中常见的方法）。</li><li>该采样并不针对全基因组，而是着重选择了特定区域（如外显子、启动子）以及和这些区域等量的其他随机窗口。</li><li>对于重复区域进行了损失权重的调整，以改善模型表现。</li></ul><p>对于输入的 DNA，其随机掩码 15% 的碱基，并传入给类 Transformer 模块。值得注意的是，与 Transformer 不同，这里用空洞卷积替代了多头注意力机制，文章的理由如下：</p><ul><li>卷积神经网络比用注意力机制收敛地更快。</li><li>对于该规模的 DNA 序列而言，卷积神经网络的局部模式识别可能较注意力机制的全局模式识别更加有用。</li><li>卷积的线性复杂度对于其向更长序列的推广是有益的。</li></ul><p>对于最后一点，具体来说，如果我们使用的为卷积神经网络，那么不论是处理 512 碱基还是 1k 个碱基，卷积层对每个碱基的计算成本是固定的。所以，处理后者大概需要的计算量是前者的两倍。</p><p>相比之下，注意力机制涉及到序列中所有元素之间的关系，其复杂度是<strong>序列长度的平方</strong>。在处理长序列时，这会导致计算成本急剧增加。为了处理长序列，模型可能需要将序列分成更小的块，并分别对它们进行处理，然后再将结果整合起来。这种分块处理通常需要在块之间有重叠部分，以捕捉块边界处的上下文信息，这使得整个处理过程变得复杂。</p><p><img src="/pic2/006C3FgEgy1gsqyd2q43kj60tj09iwlm02.jpg"></p><p>输入的掩码序列经过 25 个类 Transformer 块后被处理成包含上下文信息的 embedding，该 embedding 则被输入到后续的分类层中计算特定位置上四种碱基的概率，模型的损失函数为预测为正确碱基的概率的负 log 值。</p><p>此后，Benegas 等人利用该模型进行了一系列的分析工作，所得结果大致如下：</p><ul><li>在无监督情况下，模型也能有效识别部分基因组区域。使用 embedding 训练逻辑斯蒂回归分类模型后，在 CDS 上实现了高准确率（96%），但对于 ncRNA 和基因间区，模型的表现较为糟糕（51% 和 67%）。</li></ul><div class="hide-block"><button type="button" class="hide-button" style="">图 2    </button><div class="hide-content"><p><img src="/pic2/pnas.2311219120fig02.jpg"></p></div></div><ul><li>通过单独掩盖基因组上各个位置的碱基，模型鉴定出了一些可以在数据库中匹配到的基序和一些尚未匹配但在其他研究中有被提及或者序列特征较特殊的基序。</li></ul><div class="hide-block"><button type="button" class="hide-button" style="">图 3    </button><div class="hide-content"><p><img src="/pic2/pnas.2311219120fig03.jpg"></p></div></div><ul><li>通过以 <code>P(突变碱基)/P(参考碱基)</code> 的 <code>log</code> 值作为突变效应预测的分数，模型实现了良好的预测性能，对于那些因为与 functional variant 连锁的 neutral variants，模型也能实现有效的判别。</li></ul><div class="hide-block"><button type="button" class="hide-button" style="">图 4 5 6    </button><div class="hide-content"><p><img src="/pic2/fig456.png"></p></div></div><p>可以看出，GPN 的模型设计其实也并不复杂，但这里采取的一些方法令人较为受益。例如，不同于以往的研究，GPN 将注意力机制换为传统的卷积层并在单个基因组上取得了良好的学习效果。此外 GPN 使用了一种巧妙的无监督方法，将预测的不同碱基概率之比巧妙地转换为 variant effect 的 score。虽然这些想法来源自不同的研究，但具体的实现也要研究者巧妙地把它们组合起来。</p><h3 id="GPN-MSA"><a href="#GPN-MSA" class="headerlink" title="GPN-MSA"></a>GPN-MSA</h3><p>如果说 GPN 是一个轻巧的、适用于多数非模式物种的工具，那么 GPN-MSA 就是专门设计用于人类基因组的语言模型。与 GPN 不同，GPN-MSA 舍弃了卷积层重回正统的 Transformer 架构（RoFormer），同时它的输入数据也由单个基因组变成了九十种脊椎动物的 MSA。</p><p>不难看出，在这种情况下，更关注全局信息的 Transformer 会有更好的表现。这也告诉我们，对于不同的数据，灵活修改并使用合适的模型架构是非常重要的。</p><p><img src="/pic2/F1.large.jpg"></p><p>它的数据处理大致如下：</p><ul><li>MSA 处理，其首先下载了一百种脊椎动物的多序列比对，对其进行一定处理后，去除了与人类亲缘关系最接近的十种灵长类动物。</li><li>训练输入的数据为长度 <code>128bp</code> 步长 <code>64bp</code> 的窗口，与 GPN 相同，这里有选择性地对窗口进行了选择：①、专注于功能重要的区域，通过保守性分数 PhastCons 选择所有窗口中平均保守性分数最高的 5% 和剩余窗口随机选择 0.1%；②、降低了重复序列的权重并提高保守序列的权重（同样通过 PhastCons 进行）。</li><li>该模型同样使用反向互补序列作为数据增强手段，同样掩码 15% 的核苷酸进行训练。与 GPN 不同的是，该模型在数据增强中，还将非保守区域的参考碱基随机替换为其他碱基（在计算 loss 时），此外该模型使用 21 号染色体作为早停法的测试 loss 参考，且保留 22 号染色体作为进一步的测试（但在论文中并未使用到）。</li></ul><p>去除灵长类动物的原因文章并没有详细提及，但是可能原因也较好理解。首先这些生物与人类的基因组序列相似性可能很高，因此它们可能没法突出那些更广泛进化范围内保守的区域。此外，高度的相似性也意味着数据的冗余信息可能较多，因此去除将有利于模型更有效地提取特征。</p><p>另外，文章还进行了消融实验，以确定不同的模型架构对于最终模型表现的影响，具体的尝试可见论文的方法部分，此处贴出原文内容：</p><blockquote><ul><li>w/o MSA: the model is only trained on the human sequence, without access to other species.</li><li>MSA frequency: variants are scored using the log-likelihood ratio of observed frequencies in the MSA column, with a pseudocount of 1.</li><li>Train on 50% most conserved: expand the training region from the smaller 5% most conserved to a larger set with less overall conservation.</li><li>Include closest primates: do not filter out from the MSA the 10 primates closest to human.</li><li>Don’t upweight conserved: do not upweight the loss function on conserved elements.</li><li>Don’t replace non-conserved: do not replace the reference in non-conserved positions with random nucleotides when computing the loss function.</li></ul><p>Modeling the single human sequence instead of the MSA has by far the biggest impact. Using the column-wide MSA frequencies as predictor also shows a large decrease in performance. Including primate species close to human, or training on less conserved regions, have a moderate impact on performance. Finally, of relatively minor impact are removing the upweighting of conserved elements or removing the data augmentation procedure of replacing nucleotides in non-conserved positions.</p></blockquote><p>目前 Biorxiv 论文上研究人员仅将该模型在疾病预测中的表现进行了展示，在突变致病性预测中，GPN-MSA 超越了基于功能基因组数据的 CADD 以及保守性分数 PhyloP，在多个数据集（Clinvar、COSMIC）里取得了 SOTA。</p><p><img src="/pic2/F2.large.jpg"></p><p>当然，GPN-MSA 在利用多序列比对信息的同时，也失去了其在比对质量较差的非编码区上的表现机会，在文章的最后作者提到了一些未来的方向：</p><ul><li>整合群体遗传变异信息，而非依靠单个基因组。</li><li>整合 DNA 序列和功能基因组学信息。</li></ul><p>最后，我个人认为这个工作对我的启发还是非常大的，归根结底这个模型设计其实并不算非常复杂，但是很多思路缺一不可。此外这个架构还可以用在多个其他领域的下游分析中，它还有很多利用价值等待我们挖掘……</p><hr><p>文章链接如下：</p><blockquote><p>DNA language models are powerful predictors of genome-wide variant effects</p><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10622914/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10622914/</a></p><p>GPN-MSA: an alignment-based DNA language model for genome-wide variant effect prediction</p><p><a href="https://www.biorxiv.org/content/10.1101/2023.10.10.561776v1.full">https://www.biorxiv.org/content/10.1101/2023.10.10.561776v1.full</a></p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 文献阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献 </tag>
            
            <tag> 基因组学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习 loss 追踪器（用于追踪 loss 变化）</title>
      <link href="/2023/11/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20loss%20%E8%BF%BD%E8%B8%AA%E5%99%A8/"/>
      <url>/2023/11/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20loss%20%E8%BF%BD%E8%B8%AA%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>最近设计了一个深度神经网络，虽然使用 <code>logging</code> 模块记录 <code>Train loss</code> 和 <code>Valid loss</code> 也算方便，但作图观察 loss 的变动趋势还是要更加直观的，考虑到网上貌似没有这方面的方法，这里放一下自己的记录方式。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MaxNLocator</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">loss_tracer</span>():</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, outpath</span>):</span><br><span class="line"></span><br><span class="line">self.train_loss_list = []</span><br><span class="line">self.test_loss_list = []</span><br><span class="line">self.outpath = outpath</span><br><span class="line">timestamp = time.time()</span><br><span class="line">self.starttime = time.strftime(<span class="string">'%Y_%m_%d_%H_%M'</span>, time.localtime(timestamp))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, trainloss, testloss, plot=<span class="literal">False</span>, length=<span class="number">6</span>, width=<span class="number">3</span></span>):</span><br><span class="line"></span><br><span class="line">self.train_loss_list.append(trainloss)</span><br><span class="line">self.test_loss_list.append(testloss)</span><br><span class="line"><span class="keyword">if</span> plot:</span><br><span class="line">self.plot(length, width)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot</span>(<span class="params">self, length=<span class="number">6</span>, width=<span class="number">3</span></span>):</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(length,width))</span><br><span class="line">epoch_list = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(self.train_loss_list) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epoch_list, self.train_loss_list, color=<span class="string">'blue'</span>, label=<span class="string">'Train loss'</span>)</span><br><span class="line">plt.plot(epoch_list, self.test_loss_list, color=<span class="string">'red'</span>, label=<span class="string">'Valid loss'</span>)</span><br><span class="line">plt.gca().xaxis.set_major_locator(MaxNLocator(integer=<span class="literal">True</span>))</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">f'<span class="subst">{self.outpath}</span>/<span class="subst">{self.starttime}</span>_train_loss_valid_loss.png'</span>)</span><br><span class="line">plt.close()</span><br></pre></td></tr></tbody></table></figure><p>该方法要求已经安装 <code>matplotlib</code> 库，以下是一些具体的操作方式：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创造一个追踪器实例</span></span><br><span class="line">lt = loss_tracer(<span class="string">'./'</span>) <span class="comment"># 自行设置一个图片存放路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每次计算出 loss 后进行储存</span></span><br><span class="line">lt(train_loss, valid_loss) <span class="comment"># 不能传入张量哦</span></span><br><span class="line">lt(train_loss, valid_loss, plot=<span class="literal">True</span>) <span class="comment"># 储存后进行绘制</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用已储存的 loss 列表进行绘图</span></span><br><span class="line">lt.plot()</span><br></pre></td></tr></tbody></table></figure><p>需要注意的一些地方：</p><ul><li>频繁的进行绘制会导致性能开销过大，如果一个 epoch 用时并不长不建议设置 <code>plot=True</code> 。反之，如果一个 epoch 需要的时间较长，那么在每个 epoch 后储存新的 loss 图也是很好的选择。</li><li>该图的名称为 <code>年月日时分_train_loss_valid_loss.png</code>，如果有需求可自行修改。</li><li>该图默认长度为 <code>6</code> 宽度为 <code>3</code>，有需求可在参数中自行修改。</li></ul><p>简单的实战示例：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MaxNLocator</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">loss_tracer</span>():</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, outpath</span>):</span><br><span class="line"></span><br><span class="line">self.train_loss_list = []</span><br><span class="line">self.test_loss_list = []</span><br><span class="line">self.outpath = outpath</span><br><span class="line">timestamp = time.time()</span><br><span class="line">self.starttime = time.strftime(<span class="string">'%Y_%m_%d_%H_%M'</span>, time.localtime(timestamp))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, trainloss, testloss, plot=<span class="literal">False</span>, length=<span class="number">6</span>, width=<span class="number">3</span></span>):</span><br><span class="line"></span><br><span class="line">self.train_loss_list.append(trainloss)</span><br><span class="line">self.test_loss_list.append(testloss)</span><br><span class="line"><span class="keyword">if</span> plot:</span><br><span class="line">self.plot(length, width)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot</span>(<span class="params">self, length=<span class="number">6</span>, width=<span class="number">3</span></span>):</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(length,width))</span><br><span class="line">epoch_list = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(self.train_loss_list) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epoch_list, self.train_loss_list, color=<span class="string">'blue'</span>, label=<span class="string">'Train loss'</span>)</span><br><span class="line">plt.plot(epoch_list, self.test_loss_list, color=<span class="string">'red'</span>, label=<span class="string">'Valid loss'</span>)</span><br><span class="line">plt.gca().xaxis.set_major_locator(MaxNLocator(integer=<span class="literal">True</span>))</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">f'<span class="subst">{self.outpath}</span>/<span class="subst">{self.starttime}</span>_train_loss_valid_loss.png'</span>)</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">114514</span>)</span><br><span class="line">a_train = np.random.randn(<span class="number">400</span>)</span><br><span class="line">b_train = np.random.randn(<span class="number">400</span>)</span><br><span class="line">c_train = a_train*<span class="number">0.7</span> + b_train*<span class="number">0.6</span> + <span class="number">0.5</span> + np.random.rand(<span class="number">400</span>)</span><br><span class="line"></span><br><span class="line">a_valid = np.random.randn(<span class="number">100</span>)</span><br><span class="line">b_valid = np.random.randn(<span class="number">100</span>)</span><br><span class="line">c_valid = a_valid*<span class="number">0.7</span> + b_valid*<span class="number">0.6</span> + <span class="number">0.5</span> + np.random.rand(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">a_train = torch.from_numpy(a_train)</span><br><span class="line">b_train = torch.from_numpy(b_train)</span><br><span class="line">c_train = torch.from_numpy(c_train)</span><br><span class="line">a_valid = torch.from_numpy(a_valid)</span><br><span class="line">b_valid = torch.from_numpy(b_valid)</span><br><span class="line">c_valid = torch.from_numpy(c_valid)</span><br><span class="line"></span><br><span class="line">train_data = torch.stack((a_train, b_train), dim=<span class="number">1</span>)</span><br><span class="line">valid_data = torch.stack((a_valid, b_valid), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(nn.Linear(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">opt = torch.optim.SGD(net.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line">lf = nn.MSELoss()</span><br><span class="line">lt = loss_tracer(<span class="string">'./'</span>) <span class="comment"># 假设损失追踪图片在脚本运行目录下生成</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练 100 个 epoch</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line"></span><br><span class="line">    opt.zero_grad()</span><br><span class="line">    </span><br><span class="line">    train_outputs = net(train_data.<span class="built_in">float</span>())</span><br><span class="line">    train_loss = lf(train_outputs, c_train.<span class="built_in">float</span>().unsqueeze(<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    train_loss.backward()</span><br><span class="line">    opt.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        valid_outputs = net(valid_data.<span class="built_in">float</span>())</span><br><span class="line">    valid_loss = lf(valid_outputs, c_valid.<span class="built_in">float</span>().unsqueeze(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    lt(train_loss.item(), valid_loss.item())</span><br><span class="line"></span><br><span class="line">lt.plot()</span><br></pre></td></tr></tbody></table></figure><p>最后生成的图片实例：</p><p><img src="/pic2/train_loss_valid_loss.png"></p><p>事实证明，只要数据的模式足够简单且密集，想要过拟合其实也挺困难的。</p><p>最后提供一种上述函数的变体，可以实现每 x 个 epoch 绘图 1 次的功能：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MaxNLocator</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">loss_tracer</span>():</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, outpath, plotepoch=<span class="number">5</span></span>):</span><br><span class="line"></span><br><span class="line">self.train_loss_list = []</span><br><span class="line">self.test_loss_list = []</span><br><span class="line">self.plotepoch = plotepoch</span><br><span class="line">self.outpath = outpath</span><br><span class="line">timestamp = time.time()</span><br><span class="line">self.starttime = time.strftime(<span class="string">'%Y_%m_%d_%H_%M'</span>, time.localtime(timestamp))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, trainloss, testloss, plot=<span class="literal">True</span>, length=<span class="number">6</span>, width=<span class="number">3</span></span>):</span><br><span class="line"></span><br><span class="line">self.train_loss_list.append(trainloss)</span><br><span class="line">self.test_loss_list.append(testloss)</span><br><span class="line">        </span><br><span class="line">losslist_len = <span class="built_in">len</span>(self.train_loss_list)</span><br><span class="line"><span class="keyword">if</span> losslist_len % self.plotepoch == <span class="number">0</span> <span class="keyword">and</span> plot:</span><br><span class="line">self.plot(length, width)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot</span>(<span class="params">self, length=<span class="number">6</span>, width=<span class="number">3</span></span>):</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(length,width))</span><br><span class="line">epoch_list = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(self.train_loss_list) + <span class="number">1</span>)</span><br><span class="line">plt.plot(epoch_list, self.train_loss_list, color=<span class="string">'blue'</span>, label=<span class="string">'Train loss'</span>)</span><br><span class="line">plt.plot(epoch_list, self.test_loss_list, color=<span class="string">'red'</span>, label=<span class="string">'Valid loss'</span>)</span><br><span class="line">plt.gca().xaxis.set_major_locator(MaxNLocator(integer=<span class="literal">True</span>))</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">f'<span class="subst">{self.outpath}</span>/<span class="subst">{self.starttime}</span>_train_loss_valid_loss.png'</span>)</span><br><span class="line">plt.close()</span><br></pre></td></tr></tbody></table></figure><p>操作方法和之前一致，如果在新添 loss 的时候不需要绘图，则在调取实例时指定 <code>plot=False</code> 即可。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Python 循环太费时？让多进程解决这个问题（concurrent）</title>
      <link href="/2023/10/29/pythonconcurrent/"/>
      <url>/2023/10/29/pythonconcurrent/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>这篇文章主要分享如何使用 Python 的 concurrent 库进行多进程运行以加速分析。在约一年前我在跑多个物种的 <code>ABBA-BABA test</code> 时遇到过分析缓慢的问题，因为涉及到的物种有九十多种，所以在经过筛选以后四物种组合的数量依然高达数百万，但由于那个分析并不是很要紧所以也就没有多管（最后跑了一个多月）。</p><p>现在的状况与那时有些许不同，最近跑的分析大多涉及到大量计算，由于比较急迫地想看到最终结果，我不得不学习多进程方法来进行加速，很多时候进步都需要一些些小小的契机，now it comes。</p><hr><p>由于 Python 并不是从底层框架开始让人写代码，所以它在拥有友好入门门槛的同时也牺牲了一定的性能，特别是在处理计算密集型任务时，Python 比起 C 来说就显得有些捉襟见肘。</p><p>当然我肯定是不愿意写 C 的代码的，一是因为我只学了一些皮毛，二是因为相比之下 Python 实在太方便，俗话说性能不够进程来凑，既然我跑的不够快，那我就多跑一些，以量胜质。</p><p>在使用多进程前，建议先检查一下自己的<strong>代码是否可以进行优化</strong>，有时候换成合适的数据操作方式就可以让分析的速度有质的飞跃，使用多进程应该视为后备选择。</p><p>本文使用的为 Python 的 concurrent 库，官方网址：<a href="https://docs.python.org/zh-cn/3/library/concurrent.html">https://docs.python.org/zh-cn/3/library/concurrent.html</a></p><p>本文使用多进程，适用于计算密集型任务。如果是 I/O 密集型任务建议使用多线程。</p><p>俗话说实践出真知，这里以一个具体的任务作为例子来凸显多进程在处理计算密集型任务方面的优势。</p><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><h4 id="寻找一定范围内所有质数"><a href="#寻找一定范围内所有质数" class="headerlink" title="寻找一定范围内所有质数"></a>寻找一定范围内所有质数</h4><p>以下代码由 ChatGPT4.0 生成并由博主进行了补充矫正。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_prime</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="string">"""判断一个数是否是质数"""</span></span><br><span class="line">    <span class="keyword">if</span> n % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    sqrt_n = <span class="built_in">int</span>(math.floor(math.sqrt(n)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>, sqrt_n + <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">        <span class="keyword">if</span> n % i == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_primes</span>(<span class="params">n_start, n_end</span>):</span><br><span class="line">    <span class="string">"""在指定范围内找到所有的质数"""</span></span><br><span class="line">    primes = [n <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(n_start, n_end) <span class="keyword">if</span> is_prime(n)]</span><br><span class="line">    <span class="keyword">return</span> primes</span><br><span class="line"></span><br><span class="line"><span class="comment"># executor.map 不支持直接将多个参数应用于一个函数，因此这里需要一个包装函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_primes_range</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="keyword">return</span> compute_primes(*args)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multi_process_compute</span>(<span class="params">n_start, n_end</span>):</span><br><span class="line">    <span class="string">"""使用多进程在指定范围内计算质数"""</span></span><br><span class="line">    range_size = (n_end - n_start) // <span class="number">4</span></span><br><span class="line">    ranges = [(n_start + i*range_size, n_start + (i+<span class="number">1</span>)*range_size) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor(max_workers=<span class="number">4</span>) <span class="keyword">as</span> executor:</span><br><span class="line">        results = executor.<span class="built_in">map</span>(compute_primes_range, ranges)</span><br><span class="line"></span><br><span class="line">    primes = []</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        primes.extend(result)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> primes</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    n_start, n_end = <span class="number">10000000</span>, <span class="number">10100000</span></span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    primes = multi_process_compute(n_start, n_end)</span><br><span class="line">    mid = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"Multi-process duration: <span class="subst">{mid - start}</span>"</span>)</span><br><span class="line"></span><br><span class="line">    primes_single = compute_primes(n_start, n_end)</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"Single-threaded duration: <span class="subst">{end - mid}</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> primes == primes_single  <span class="comment"># 确保多进程和单线程计算的结果相同</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Multi-process duration: 0.3506944179534912</span><br><span class="line">Single-threaded duration: 0.7943074703216553</span><br></pre></td></tr></tbody></table></figure><p>能看到使用四个核计算时（max_workers=4）所需时间为单线程的一半左右。由于多进程本身就具有一定的性能开销（进程创建的开销、进程间通信的延迟，以及数据分割和再整合的额外成本等），因此在这种本身不需要太久时间的情况下使用多进程带来的收益并不明显，对于一些简单的计算问题而言，多进程所需要的时间甚至会多于单线程，因此多进程的使用需要考虑到具体情况。</p><p>以下是关于上述代码中重要的部分解析：</p><ul><li><code>with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:</code><ul><li>该部分相当于创造了一个进程池，允许并行执行四个进程（<code>max_workers</code>），进程池中的任务在 with 语句中完成，确保执行任务后正确关闭进程池。相应地，如果想要的是多线程则使用 <code>ThreadPoolExecutor</code> 进行初始化。</li></ul></li><li><code>results = executor.map(compute_primes_range, ranges)</code><ul><li>该步骤中 <code>executor.map</code> 将 <code>compute_primes_range</code> 并行映射到分割的 <code>ranges</code> 子列表上，每个进程处理一部分并在所有运行结束后汇总结果并关闭进程池。</li><li>此处的 <code>executor.map</code> 是 “阻塞” 且 “顺序” 的，它返回的结果列表会按照输入序列的顺序进行排列，即使某个任务早于其他任务完成，其也会等待所有的任务都完成后按照提交顺序统一返回结果。</li></ul></li></ul><p>以上设计适用于需要结果记录保留原有 “序列性” 的情况，但它不能立即获得结果，因此下面再介绍一种不需要按照提交顺序且能在任务完成后直接输出结果的方法。</p><h4 id="不要求返回结果有序"><a href="#不要求返回结果有序" class="headerlink" title="不要求返回结果有序"></a>不要求返回结果有序</h4><p>这个问题同上，不过将换一种方式处理：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_prime</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="string">"""判断一个数是否是质数"""</span></span><br><span class="line">    <span class="keyword">if</span> n % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    sqrt_n = <span class="built_in">int</span>(math.floor(math.sqrt(n)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>, sqrt_n + <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">        <span class="keyword">if</span> n % i == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_primes</span>(<span class="params">num</span>):</span><br><span class="line">    <span class="string">"""在指定范围内找到所有的质数"""</span></span><br><span class="line">    time.sleep(random.uniform(<span class="number">0.005</span>, <span class="number">0.01</span>))</span><br><span class="line">    attri = <span class="string">'质数'</span> <span class="keyword">if</span> is_prime(num) <span class="keyword">else</span> <span class="string">'非质数'</span></span><br><span class="line">    <span class="keyword">return</span> attri</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multi_process_compute</span>(<span class="params">n_start, n_end</span>):</span><br><span class="line">    <span class="string">"""使用多进程在指定范围内计算质数"""</span></span><br><span class="line">    lst = {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor(max_workers=<span class="number">4</span>) <span class="keyword">as</span> executor:</span><br><span class="line"></span><br><span class="line">        future_to_num = {executor.submit(compute_primes, num): num <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(n_start, n_end)}</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> future <span class="keyword">in</span> concurrent.futures.as_completed(future_to_num):</span><br><span class="line"></span><br><span class="line">            num = future_to_num[future]</span><br><span class="line">            res = future.result()</span><br><span class="line">            lst[num] = res</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> lst</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    n_start, n_end = <span class="number">10000000</span>, <span class="number">10000500</span></span><br><span class="line">    st_prime = {}</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    primes = multi_process_compute(n_start, n_end)</span><br><span class="line">    mid = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"Multi-process duration: <span class="subst">{mid - start}</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(n_start, n_end):</span><br><span class="line">        time.sleep(random.uniform(<span class="number">0.005</span>, <span class="number">0.01</span>))</span><br><span class="line">        st_prime[num] = <span class="string">'质数'</span> <span class="keyword">if</span> is_prime(num) <span class="keyword">else</span> <span class="string">'非质数'</span></span><br><span class="line"></span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"Single-threaded duration: <span class="subst">{end - mid}</span>"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">list</span>(primes) == <span class="built_in">list</span>(st_prime))</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Multi-process duration: 1.1387457847595215</span><br><span class="line">Single-threaded duration: 4.003631353378296</span><br><span class="line">False</span><br></pre></td></tr></tbody></table></figure><p>由于对单个数字进行质数判断并不是计算密集型，直接使用多进程带来的开销反而更大，因此为了凸显多进程的优势我对每一个循环引入了 <code>time.sleep(random.uniform(0.005, 0.01))</code> 作为平衡，引入后就相当于对每一个数进行计算都需要花费至少 <code>0.005s</code> 的时间。</p><p>以下是关于上述代码中重要的部分解析：</p><ul><li><p><code>future_to_num = {executor.submit(compute_primes, num): num for num in range(n_start, n_end)}</code></p><ul><li><code>executor.submit</code> 将 <code>compute_primes</code> 映射到 <code>num</code> 上提交给进程池，并返回一个 <code>Future</code> 对象，该对象代表异步执行的操作，这里将每一个 <code>Future</code> 都对应到其提交的数字 <code>num</code> 上方便后续调取。</li></ul></li><li><p><code>for future in concurrent.futures.as_completed(future_to_num):</code></p><ul><li><p><code>as_completed()</code> 在这里接受了一个 <code>Future</code> 对象的集合，一旦有 <code>Future</code> 对象完成，它就产生该 <code>Future</code> 并等待下一个完成（直到所有都完成）。这里的描述可能会有些模糊，可以自行查阅 <code>Python yield</code> 的相关知识。</p></li><li><p>当有 <code>Future</code> 完成，则通过后续代码得到对应数字及结果（<code>future.result()</code>），同时更新到字典 <code>lst</code> 中<del>（虽然 lst 是列表的意思但不用在意那么多细节）</del>。</p></li></ul></li></ul><p>最后结果表明，多进程花费的时间约为单线程的四分之一，可以看出来当涉及到的计算非常密集需要大量时间时，多进程带来的加速会更加明显。</p><p>需要注意的是，这种做法并没有考虑原有数字的序列性，当有一个 <code>Future</code> 完成时它就会即刻将结果保存到 <code>lst</code> 中，因此最后得到的字典顺序与直接使用 <code>For</code> 循环得到的并不相同，但相应地，性能方面也会有更高的提升（因为它不需要等待所有结果，而是可以一边得到结果一边对结果进行处理）。</p><h4 id="延申-——-异常处理"><a href="#延申-——-异常处理" class="headerlink" title="延申 —— 异常处理"></a>延申 —— 异常处理</h4><p>当然，有时我们不能确保所有传入给进程池中的任务都不发生错误，因此我们需要将这些错误记录下来：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_prime</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="string">"""判断一个数是否是质数"""</span></span><br><span class="line">    <span class="keyword">if</span> n % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    sqrt_n = <span class="built_in">int</span>(math.floor(math.sqrt(n)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>, sqrt_n + <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">        <span class="keyword">if</span> n % i == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_primes</span>(<span class="params">num</span>):</span><br><span class="line">    <span class="string">"""在指定范围内找到所有的质数"""</span></span><br><span class="line">    time.sleep(random.uniform(<span class="number">0.005</span>, <span class="number">0.01</span>))</span><br><span class="line">    attri = <span class="string">'质数'</span> <span class="keyword">if</span> is_prime(num) <span class="keyword">else</span> <span class="string">'非质数'</span></span><br><span class="line">    <span class="keyword">return</span> attri</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multi_process_compute</span>(<span class="params">n_start, n_end</span>):</span><br><span class="line">    <span class="string">"""使用多进程在指定范围内计算质数"""</span></span><br><span class="line">    lst = {}</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor(max_workers=<span class="number">4</span>) <span class="keyword">as</span> executor:</span><br><span class="line"></span><br><span class="line">        future_to_num = {executor.submit(compute_primes, num): num <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(n_start, n_end)}</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> future <span class="keyword">in</span> concurrent.futures.as_completed(future_to_num):</span><br><span class="line"></span><br><span class="line">            num = future_to_num[future]</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                res = future.result()</span><br><span class="line">                lst[num] = res</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f'<span class="subst">{num}</span> have error: <span class="subst">{e}</span>'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> lst</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    n_start, n_end = -<span class="number">1</span>, <span class="number">10</span></span><br><span class="line">    primes = multi_process_compute(n_start, n_end)</span><br><span class="line">    <span class="built_in">print</span>(primes)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-1 have error: math domain error</span><br><span class="line">{0: '非质数', 1: '质数', 3: '质数', 2: '非质数', 6: '非质数', 5: '质数', 7: '质数', 4: '非质数', 9: '非质数', 8: '非质数'}</span><br></pre></td></tr></tbody></table></figure><p>这里可以看到对于 <code>-1</code> 来说任务发生了错误，而该值也并未被记录进字典中，因此合适的异常处理也是很重要的，它可以帮助记录下那些出错的任务同时保证其他正常任务能够继续运行。</p><p><del>当然这里的 0 和 1 也算是异常情况。</del></p><p>看完了以上内容后再让我们来思考以下问题吧：</p><ol><li>什么情况下使用多进程会缩短分析时间？什么情况下反而会延长分析时间？是否能用代码复现出后一种情况？</li><li>在使用 <code>time.sleep</code> 时，使用<strong>多进程</strong>更快还是使用<strong>多线程</strong>更快？为什么？</li><li>如果小明想要使用爬虫爬取多个页面的内容，他应该使用多进程还是多线程？为什么？</li></ol></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Python seaborn 绘制复杂多变量图（hexbin + 拟合直线）</title>
      <link href="/2023/10/12/Python%20seaborn%20%E7%BB%98%E5%88%B6%E5%A4%8D%E6%9D%82%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%BE%EF%BC%88hexbin%20+%20%E6%8B%9F%E5%90%88%E7%9B%B4%E7%BA%BF%EF%BC%89/"/>
      <url>/2023/10/12/Python%20seaborn%20%E7%BB%98%E5%88%B6%E5%A4%8D%E6%9D%82%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%BE%EF%BC%88hexbin%20+%20%E6%8B%9F%E5%90%88%E7%9B%B4%E7%BA%BF%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>当初作图时想往 <code>sns.pairplot</code> 里加些内容，搜索了解到 <code>sns.PairGrid</code> 可以更灵活地绘制多因素（多变量）关系图，遂在网上找相关教程，最后发现 CSDN 上的内容竟然都要付费，无奈转向 ChatGPT 求助，最后在 C 老师帮助下成功完成了自己的想法。</p><p>以上既是这篇文章的来源也是动机，这篇文章就来分享一下如何使用 <code>sns.PairGrid</code> 绘制更加复杂的多变量图，本文示例将是 <code>hexbin</code> + 拟合直线，但只要知道如何将图架构起来那么绘制其他类型的图也不会有问题。</p><p><code>sns.pairplot</code> 的详尽用法：</p><p><a href="https://seaborn.pydata.org/generated/seaborn.pairplot.html#seaborn-pairplot">https://seaborn.pydata.org/generated/seaborn.pairplot.html#seaborn-pairplot</a></p><p>一般的多变量图绘制：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟三个变量</span></span><br><span class="line">np.random.seed(<span class="number">114514</span>)</span><br><span class="line">a = np.random.randn(<span class="number">100</span>)</span><br><span class="line">b = a*<span class="number">0.7</span>+<span class="number">0.5</span>+np.random.rand(<span class="number">100</span>)</span><br><span class="line">c = b**<span class="number">2</span>-<span class="number">0.1</span>+np.random.rand(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">data = {</span><br><span class="line">    <span class="string">'a'</span>: a,</span><br><span class="line">    <span class="string">'b'</span>: b,</span><br><span class="line">    <span class="string">'c'</span>: c</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line">sns.pairplot(df)</span><br></pre></td></tr></tbody></table></figure><p><img src="/pic2/sns1.png"></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加一些参数，使对角变成核密度图</span></span><br><span class="line">sns.pairplot(df, diag_kind=<span class="string">"kde"</span>)</span><br></pre></td></tr></tbody></table></figure><p><img src="/pic2/sns2.png"></p><p>虽然说这个功能确实非常方便，但是它有个不足就在于其框架已经是设置好的，也就是说图形的变化都只能在已设置好的范围里进行。如果我想要进行其他的操作比如拟合直线或者给每一个图添加相关性标注，这时就只能寻找一个更加 “泛用” 的框架了。</p><p><code>sns.PairGrid</code> 就是理想之选，它允许我们自定义绘图参数并应用于对角线下、对角线和对角线上的部分，因此假如这里我们想要拟合直线，那么可以自定义绘图函数：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> spearmanr</span><br><span class="line"><span class="keyword">from</span> statsmodels.nonparametric.smoothers_lowess <span class="keyword">import</span> lowess</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下方的图，此处计算了 spearman 相关系数并拟合了一次项的直线</span></span><br><span class="line"><span class="comment"># **kwargs 是为了让绘图函数能接受任意关键字参数避免 sns 传入其他参数时报错。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regres_scatter</span>(<span class="params">x, y, nhc=<span class="string">'black'</span>, **kwargs</span>):</span><br><span class="line"></span><br><span class="line">    m, b = np.polyfit(x, y, <span class="number">1</span>)</span><br><span class="line">    y_fit = m*x + b</span><br><span class="line">    rho, p_value = spearmanr(x, y)</span><br><span class="line"></span><br><span class="line">    plt.scatter(x, y, color=<span class="string">'#C9DCEB'</span>, edgecolors=<span class="string">'black'</span>)</span><br><span class="line">    plt.plot(x, y_fit, color=nhc, lw=<span class="number">2</span>)</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ax.text(<span class="number">1.5</span>*x.<span class="built_in">min</span>(), <span class="number">0.9</span>*y.<span class="built_in">max</span>(), </span><br><span class="line">            <span class="string">f"Spearman R: <span class="subst">{rho:<span class="number">.2</span>f}</span>\np-value: <span class="subst">{p_value:<span class="number">.3</span>f}</span>"</span>,</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上方的图，此处使用 hexbin 而非 scatter 并且拟合了 lowess 曲线</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lowess_scatter</span>(<span class="params">x, y, gridsize=<span class="number">30</span>, **kwargs</span>):</span><br><span class="line"></span><br><span class="line">    result = lowess(y, x)</span><br><span class="line">    x_fit = result[:, <span class="number">0</span>]</span><br><span class="line">    y_fit = result[:, <span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    plt.hexbin(x, y, gridsize=gridsize, cmap=<span class="string">'Blues'</span>)</span><br><span class="line">    plt.plot(x_fit, y_fit, color=<span class="string">'red'</span>, lw=<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure><p>自定义好函数以后，使用 <code>sns.PairGrid</code> 进行构造：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 传入数据</span></span><br><span class="line">pgp = sns.PairGrid(df, diag_sharey=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 对不同部分进行绘图，可以传入参数也可以选择不传入</span></span><br><span class="line">pgp.map_lower(<span class="keyword">lambda</span> x, y, **kwargs: regres_scatter(x, y, nhc=<span class="string">'red'</span>))</span><br><span class="line">pgp.map_diag(sns.kdeplot, shade=<span class="literal">True</span>, shade_lowest=<span class="literal">False</span>)</span><br><span class="line">pgp.map_upper(lowess_scatter)</span><br></pre></td></tr></tbody></table></figure><p><img src="/pic2/sns3.png"></p><p>能看到每一部分的图都依据自己定义或选择的绘图函数进行了绘制，可以看出在绘制多变量图时 <code>sns.PairGrid</code> 比 <code>sns.pairplot</code> 会更加灵活，上限也能拉的更高。</p><p>课后问题（bushi）：</p><ol><li>如何使用<strong>相对坐标</strong>放置标签（<code>ax.text</code>）？相较于绝对坐标使用相对坐标的好处是什么？</li><li>hexbin plot 中如何让<strong>没有数据点的位置</strong>不进行着色？如何让着色根据数据点数量的 <code>log</code> 值进行？</li><li>如何将 <code>spearman r</code> 换成 <code>pearson r</code>？两者有什么区别？文中的数据更适用于哪个（亦或是都适用）？</li></ol></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 绘图 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于人类基因组注释中起始和终止位点相同的现象</title>
      <link href="/2023/10/05/%E5%85%B3%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%9F%BA%E5%9B%A0%E7%BB%84%E6%B3%A8%E9%87%8A%E4%B8%AD%E8%B5%B7%E5%A7%8B%E5%92%8C%E7%BB%88%E6%AD%A2%E4%BD%8D%E7%82%B9%E7%9B%B8%E5%90%8C%E7%9A%84%E7%8E%B0%E8%B1%A1/"/>
      <url>/2023/10/05/%E5%85%B3%E4%BA%8E%E4%BA%BA%E7%B1%BB%E5%9F%BA%E5%9B%A0%E7%BB%84%E6%B3%A8%E9%87%8A%E4%B8%AD%E8%B5%B7%E5%A7%8B%E5%92%8C%E7%BB%88%E6%AD%A2%E4%BD%8D%E7%82%B9%E7%9B%B8%E5%90%8C%E7%9A%84%E7%8E%B0%E8%B1%A1/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>已经有一个月没有更新文章，之前在知乎看到过一段话，大体是说写博客最重要的不是怎么把博客做的好看，而是如何持之以恒地产出，这句话让我感触颇深，正值国庆期间放假，就记录一下这段时间在分析数据时候发现的东西，以后万一有其他朋友发现并疑惑也好快速找到答案。</p><p>这里进行一个简要的概括：</p><ol><li>长度为 1 并不代表该构成该基因的所有片段组合长度为 1，例如 1bp 的 exon 可能是微外显子，在剪切后与其他 exon 组合共同构成成熟 mRNA。</li><li>CDS 长度不为 3 的整数倍，说明该基因的 CDS 注释不完善，例如缺失 3’ 或 5’ 端。</li><li>出于第 2 点现象，建议在下载注释时，选择 basic 版本，因为该版本中所有的注释都是完善的。</li></ol><p><img src="/pic2/gencodeannotation.png"></p><h2 id="基因组注释中长度为-1-的现象解释"><a href="#基因组注释中长度为-1-的现象解释" class="headerlink" title="基因组注释中长度为 1 的现象解释"></a>基因组注释中长度为 1 的现象解释</h2><p>在使用基因组注释（版本：<a href="https://www.gencodegenes.org/human/release_19.html">https://www.gencodegenes.org/human/release_19.html</a> ）时，我发现了两个问题：</p><ol><li>有些 CDS 的长度为 1。</li><li>CDS 的长度不一定为 3 的倍数。</li></ol><p>由于我是先发现的第一个问题，此后才发现的第二个问题，因此顺序如上，首先看一看第一个问题：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">First, download the GENCODE v19 annotation file</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Next, extract and count the annotations with a length of 1bp</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zcat gencode.v19.annotation.gtf.gz | awk <span class="string">'$4==$5'</span> | <span class="built_in">cut</span> -f 3 | <span class="built_in">sort</span> | <span class="built_in">uniq</span> -c | awk <span class="string">'$1 &gt; 1'</span></span></span><br><span class="line">  516 CDS</span><br><span class="line">   19 exon</span><br><span class="line">  249 start_codon</span><br><span class="line">  377 stop_codon</span><br><span class="line"> 1058 UTR</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Optionally, view the full lines of annotations with a length of 1bp <span class="keyword">for</span> closer examination</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zcat gencode.v19.annotation.gtf.gz | awk <span class="string">'$4==$5'</span> | less</span></span><br></pre></td></tr></tbody></table></figure><p>能看到，不仅仅是 CDS，有许多其他的 annotation type 也仅有 1bp 的长度，甚至包括起始密码子和终止密码子，这个问题之后再讨论，首先说一说对于 CDS 而言为什么会有上面两个问题：</p><p>问题 ① 可能原因：</p><ul><li>长度为 1 有可能是<strong>微外显子</strong>（microexon），在剪切后它参与到蛋白翻译中。</li><li>注释信息并不完全，见下文。</li></ul><p>问题 ② 可能原因：</p><ul><li><p>对于一个基因，它可能具有多种剪切方式，<strong>对于每一种剪切方式</strong>，其<strong>涉及到的所有 CDS</strong> 的总长度为 3 的倍数，而一些外显子可能在多种剪切中出现，但在注释中它仅标明了一种。</p><ul><li><p>通过以下命令可以排除该点：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zcat gencode.v19.annotation.gtf.gz | awk <span class="string">'$3=="CDS" &amp;&amp; $1=="chr6"'</span> | grep <span class="string">"99999716"</span> | <span class="built_in">cut</span> -f 1-5</span></span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line">chr6    HAVANA  CDS     99999716        99999771</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">说明在不同剪切中重复出现的 CDS 会被记录</span></span><br></pre></td></tr></tbody></table></figure></li></ul></li><li><p>注释信息并不完全，例如 <code>tag "cds_start_NF"</code> <code>tag "cds_end_NF"</code> 表明对于该转录本而言，起始密码子和终止密码子没有在注释的 CDS 区域中找到。</p></li></ul><p>此外，另一些情况例如 <code>alternative_5_UTR</code> <code>nonsense_mediated_decay</code> 也可能有所影响。</p><p>如果你对具体的情况感兴趣，可以运行以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zcat gencode.v19.annotation.gtf.gz | awk <span class="string">'$3=="CDS"'</span> | awk -F <span class="string">'\t'</span> <span class="string">'{split($9, a, "gene_name \""); split(a[2], b, "\""); print b[1], ($5-$4+1)/3}'</span> | awk <span class="string">'{ a[$1] += $2 } END { for (i in a) print i, a[i] }'</span> | <span class="built_in">sort</span> &gt;&gt; cdsdevide3.txt</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zcat gencode.v19.annotation.gtf.gz | awk <span class="string">'$3=="CDS"'</span> | awk -F <span class="string">'\t'</span> <span class="string">'{split($9, a, "transcript_name \""); split(a[2], b, "\""); print b[1], ($5-$4+1)/3}'</span> | awk <span class="string">'{ a[$1] += $2 } END { for (i in a) print i, a[i] }'</span> &gt;&gt; transcriptdevide3.txt</span></span><br></pre></td></tr></tbody></table></figure><p>例子：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 长度/3</span><br><span class="line">A1BG-001 495</span><br><span class="line">A1BG-004 305.667</span><br><span class="line">A2ML1-001 1454</span><br><span class="line">A2ML1-003 1004</span><br><span class="line">A2ML1-004 963</span><br><span class="line">A2ML1-006 181.333</span><br><span class="line">A2ML1-008 81.3333</span><br><span class="line">A2ML1-009 183.667</span><br><span class="line"></span><br><span class="line"># 对应注释</span><br><span class="line">transcript_name "A1BG-004"; exon_number 1; exon_id "ENSE00003185372.1"; level 2; protein_id "ENSP00000470909.1"; tag "mRNA_start_NF"; tag "mRNA_end_NF"; tag "cds_start_NF"; tag "cds_end_NF"; havana_gene "OTTHUMG00000183507.1";</span><br><span class="line">transcript_name "A2ML1-008"; exon_number 1; exon_id "ENSE00002207222.1"; level 2; protein_id "ENSP00000440662.1"; tag "mRNA_end_NF"; tag "cds_end_NF"; havana_gene "OTTHUMG00000128499.7"; havana_transcript "OTTHUMT00000395958.1";</span><br><span class="line">transcript_name "A2ML1-009"; exon_number 2; exon_id "ENSE00001798845.1"; level 2; protein_id "ENSP00000440057.1"; tag "mRNA_end_NF"; tag "cds_end_NF"; havana_gene "OTTHUMG00000128499.7"; havana_transcript "OTTHUMT00000395959.1";</span><br><span class="line">transcript_name "A2ML1-006"; exon_number 6; exon_id "ENSE00001348621.1"; level 2; protein_id "ENSP00000445674.1"; tag "mRNA_start_NF"; tag "cds_start_NF"; havana_gene "OTTHUMG00000128499.7"; havana_transcript "OTTHUMT00000395963.1";</span><br><span class="line"></span><br><span class="line">上述例子中，其他能被整除的皆具有 tag "basic"</span><br></pre></td></tr></tbody></table></figure><hr><p>讲完了 CDS，再来看看起始密码子和终止密码子是怎么回事。</p><p>当然，真相很简单，直接打印出所有的长度-数量表就能知道是为什么了：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zcat gencode.v19.annotation.gtf.gz | awk <span class="string">'($3=="start_codon" || $3=="stop_codon") {print ($5-$4+1)}'</span> | <span class="built_in">sort</span> | <span class="built_in">uniq</span> -c</span></span><br><span class="line">    626 1</span><br><span class="line">    626 2</span><br><span class="line"> 159088 3</span><br></pre></td></tr></tbody></table></figure><p>如果想要更详细地了解具体情况可以输入以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">zcat gencode.v19.annotation.gtf.gz | awk <span class="string">'($3=="start_codon" || $3=="stop_codon") &amp;&amp; ($5-$4+1)!=3'</span> | less</span></span><br></pre></td></tr></tbody></table></figure><p>在输入了上述命令以后可以看到，有些密码子是跨越了两个外显子的，也就是说，它们在基因组上的位置并不连续，但在转录和剪切后它们则共同构成终止密码子。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>事实上探索这些问题时，我突然意识到它的情况如何对我的分析并没有影响，但是我依然狠狠地将时间荒废在了这问题上。</p><p>或许有些时候重要的不是结果而是过程，探索这些问题的时候注释文件的结构和各种 shell 命令在我脑子里刻的都更深了些，这也算是一种进步。</p><p>这次探索也让我意识到基因注释是一个非常具有挑战性的操作，虽然用软件可以轻轻松松得到结果，但是这些结果也需要仔细的审查和验证才能知道它到底是不是真实可靠的。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 基因组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JuseKit（八） —— 计算转录组组装指标</title>
      <link href="/2023/09/01/JuseKit%EF%BC%88%E5%85%AB%EF%BC%89%20%E2%80%94%E2%80%94%20%E8%AE%A1%E7%AE%97%E8%BD%AC%E5%BD%95%E7%BB%84%E7%BB%84%E8%A3%85%E6%8C%87%E6%A0%87/"/>
      <url>/2023/09/01/JuseKit%EF%BC%88%E5%85%AB%EF%BC%89%20%E2%80%94%E2%80%94%20%E8%AE%A1%E7%AE%97%E8%BD%AC%E5%BD%95%E7%BB%84%E7%BB%84%E8%A3%85%E6%8C%87%E6%A0%87/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><blockquote><div id="portalContainer"></div><script src="/js/jklink.js"></script><script> generatePortalLinks(8);</script></blockquote><h2 id="更新变动及进度"><a href="#更新变动及进度" class="headerlink" title="更新变动及进度"></a>更新变动及进度</h2><p>JuseKit 故事传之开学第一天，我在课题组实验室搞新功能。</p><p>已有功能的相关教程请见：<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">Juseの软件开发</a></p><p>本文所涉及功能借鉴了 Trinity 脚本的输出格式。</p><h3 id="本次更新变动"><a href="#本次更新变动" class="headerlink" title="本次更新变动"></a>本次更新变动</h3><ul><li>完善了部分报错提示。</li><li>完善了部分文本显示。</li><li>新增了转录组组装指标计算功能。</li></ul><h3 id="目前的功能进度"><a href="#目前的功能进度" class="headerlink" title="目前的功能进度"></a>目前的功能进度</h3><ul><li>提取最长转录本。</li><li>根据 id 提取序列。</li><li>对序列的 id 进行各种处理。</li><li>串联序列并得到分区信息。</li><li>批量进行序列格式转换。</li><li>批量提取 Orthofinder 的 orthogroup 对应的 CDS 序列。</li><li>批量进行序列的物种数和长度过滤。</li><li>火山图绘制。</li><li>气泡图绘制。</li><li>组装指标计算。</li></ul><p>叠盾警告⚠：本软件解释权归属 Juse 所有，本软件能走多远具体得看 Juse 能坚持多久。</p><p>下载地址：<a href="https://github.com/JuseTiZ/JuseKit/releases">https://github.com/JuseTiZ/JuseKit/releases</a></p><h2 id="转录组组装指标计算"><a href="#转录组组装指标计算" class="headerlink" title="转录组组装指标计算"></a>转录组组装指标计算</h2><p>本文主要着重于这次更新新增的功能，其他模块请走<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">这里</a>。</p><h3 id="要求的数据"><a href="#要求的数据" class="headerlink" title="要求的数据"></a>要求的数据</h3><p>需要输入的数据为 <code>fasta</code> 格式的序列文件。</p><p>可通过将文件拖拽至文本框或者点击右侧按钮读取文件路径。</p><p>操作示例：</p><p><img src="/pic2/qc1.png"></p><p>结果文件会产生在序列文件的同一路径下，文件名为 <code>assem_qc.txt</code>。</p><p>目前返回的信息包括：</p><ul><li>基因数量</li><li>最大长度、最小长度和平均长度</li><li>Nxx 值</li><li>GC 含量</li></ul><p>以后视情况会继续完善这一功能，例如补充其他可以反应转录组组装质量的指标。</p><h3 id="进阶应用"><a href="#进阶应用" class="headerlink" title="进阶应用"></a>进阶应用</h3><p>这一部分就相当于取最长转录本，关于该概念可见以往文章。</p><p>此处我将使用 <code>_seq</code> 作为基因标识进行（老版 Trinity 的序列格式）：</p><p><img src="/pic2/qc2.png"></p><p>在指定基因标识后 JuseKit 会将每个基因的最长 Contig 作为其代表序列进行各指标计算。</p><p>如果在使用前后指标没有变化则说明该标识并不存在或者输入错误。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>后记？这次啊，没有后记！</p><p>最后是复制黏贴：</p><p>我会争取将这些功能慢慢完善，让它成为一个具有更广适用性的软件，希望能够帮助到某些盆友，当然我个人认为最大的可能是自娱自乐。</p><p>如果这个软件帮助到您了，您可以给它一个小小的 Star 聊表支持，或者在您汇报的时候引一下 <a href="https://github.com/JuseTiZ/JuseKit/">https://github.com/JuseTiZ/JuseKit/</a> ，想必看着还是非常高端大气上档次的。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 软件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JuseKit </tag>
            
            <tag> 转录组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于 js 在系列文章开头设置文章传送门（hexo + butterfly）</title>
      <link href="/2023/08/11/%E5%9F%BA%E4%BA%8E%20js%20%E5%9C%A8%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E5%BC%80%E5%A4%B4%E8%AE%BE%E7%BD%AE%E6%96%87%E7%AB%A0%E4%BC%A0%E9%80%81%E9%97%A8/"/>
      <url>/2023/08/11/%E5%9F%BA%E4%BA%8E%20js%20%E5%9C%A8%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E5%BC%80%E5%A4%B4%E8%AE%BE%E7%BD%AE%E6%96%87%E7%AB%A0%E4%BC%A0%E9%80%81%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="示例效果"><a href="#示例效果" class="headerlink" title="示例效果"></a>示例效果</h2><blockquote><div id="portalContainer"></div><script src="/js/portallinks.js"></script><script> generatePortalLinks(3);</script></blockquote><p>注：以上超链接并没有任何指向，只作示例用！</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>事实上这个想法在很早以前就有了，但那时候我还不知道具体的实行方案（只知道最笨的方法是直接在每篇文章开头自己写传送门，不过每次更新一篇新的文章以后就要全部都补充一遍，非常麻烦）。在经过博客一系列的魔改以后，也算是储备了一小些基本的 <code>css</code> <code>js</code> 知识，所以就有了这篇文章。</p><h2 id="js-实现"><a href="#js-实现" class="headerlink" title="js 实现"></a>js 实现</h2><p>首先 <code>hexo-theme-butterfly\source\js</code>（请替换成自己的 <code>js</code> 文件存放路径）中新建一个 <code>portallinks.js</code> 文件，在里面填写以下内容：</p><figure class="highlight javascript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">generatePortalLinks</span>(<span class="params">currentArticleId</span>) {</span><br><span class="line">    <span class="keyword">var</span> links = [</span><br><span class="line">        <span class="comment">//填写 id 及对应的标题和链接</span></span><br><span class="line">        { <span class="attr">id</span>: <span class="number">1</span>, <span class="attr">title</span>: <span class="string">"这里填写标题 1"</span>, <span class="attr">url</span>: <span class="string">"这里填写链接 1"</span> },</span><br><span class="line">        { <span class="attr">id</span>: <span class="number">2</span>, <span class="attr">title</span>: <span class="string">"这里填写标题 2"</span>, <span class="attr">url</span>: <span class="string">"这里填写链接 2"</span> },</span><br><span class="line">        { <span class="attr">id</span>: <span class="number">3</span>, <span class="attr">title</span>: <span class="string">"这里填写标题 3"</span>, <span class="attr">url</span>: <span class="string">"这里填写链接 3"</span> },</span><br><span class="line">        { <span class="attr">id</span>: <span class="number">4</span>, <span class="attr">title</span>: <span class="string">"这里填写标题 4"</span>, <span class="attr">url</span>: <span class="string">"这里填写链接 4"</span> },</span><br><span class="line">        <span class="comment">//如果还有更多就继续依次填写</span></span><br><span class="line">    ];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> html = <span class="string">'&lt;div class="portal"&gt;'</span>;</span><br><span class="line">    <span class="comment">//看自己需要可以修改部分</span></span><br><span class="line">    html += <span class="string">'&lt;h3&gt;系列文章传送门&lt;/h3&gt;'</span>;</span><br><span class="line">    html += <span class="string">'&lt;ul&gt;'</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; links.<span class="property">length</span>; i++) {</span><br><span class="line">        html += <span class="string">'&lt;li&gt;'</span>;</span><br><span class="line">        <span class="keyword">if</span> (links[i].<span class="property">id</span> === currentArticleId) {</span><br><span class="line">            html += <span class="string">'&lt;strong&gt;'</span>;</span><br><span class="line">        }</span><br><span class="line">        html += <span class="string">'&lt;a href="'</span> + links[i].<span class="property">url</span> + <span class="string">'"&gt;'</span> + links[i].<span class="property">title</span> + <span class="string">'&lt;/a&gt;'</span>;</span><br><span class="line">        <span class="keyword">if</span> (links[i].<span class="property">id</span> === currentArticleId) {</span><br><span class="line">            html += <span class="string">'&lt;/strong&gt;  👈 您当前所处位置'</span>;</span><br><span class="line">        }</span><br><span class="line">        html += <span class="string">'&lt;/li&gt;'</span>;</span><br><span class="line">    }</span><br><span class="line">    html += <span class="string">'&lt;/ul&gt;&lt;/div&gt;'</span>;</span><br><span class="line"></span><br><span class="line">    <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">'portalContainer'</span>).<span class="property">innerHTML</span> = html;</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>填写完以后，在文章开头写入以下内容以引用该 js 文件（如果使用的是 Typora 等编辑器则需切换成源代码输入）并且通过指定 ID 确定当前所处位置：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; &lt;div id="portalContainer"&gt;&lt;/div&gt;</span><br><span class="line">&gt; &lt;script src="/js/portallinks.js"&gt;&lt;/script&gt;</span><br><span class="line">&gt; &lt;script&gt; generatePortalLinks(3);&lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure><p>以上示例代码的效果可见文章开头，实际应用中 <code>generatePortalLinks(3)</code> 中的数字请换成文章对应的 <code>id</code>。</p><p>这样做的好处在于，以后更新了新的系列文章后，只需要修改对应的 <code>js</code> 文件并部署就能让所有文章中的传送门发生相同的变化。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>部署传送门一方面让读者寻找对应内容变得更加便利，另一方面也能让阅读量高排名前的文章给其他文章引流。</p><p>不过需要注意的是，所有需要部署传送门的文章都要引入上述代码（并更换 <code>generatePortalLinks()</code> 中的数字），这对于已经更新了很多文章的人来说会比较累，此外 <code>js</code> 文件中的各项信息也需要进行相应的修正。</p><p>实际应用效果可见本博客的 <em><strong>比较转录组分析</strong></em> 和 <em><strong>JuseKit</strong></em> 系列文章。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 博客 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>JuseKit（七） —— 绘制 GO 富集分析气泡图</title>
      <link href="/2023/08/04/JuseKit%EF%BC%88%E4%B8%83%EF%BC%89%20%E2%80%94%E2%80%94%20%E7%BB%98%E5%88%B6%20GO%20%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90%E6%B0%94%E6%B3%A1%E5%9B%BE/"/>
      <url>/2023/08/04/JuseKit%EF%BC%88%E4%B8%83%EF%BC%89%20%E2%80%94%E2%80%94%20%E7%BB%98%E5%88%B6%20GO%20%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90%E6%B0%94%E6%B3%A1%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><blockquote><div id="portalContainer"></div><script src="/js/jklink.js"></script><script> generatePortalLinks(7);</script></blockquote><h2 id="更新变动及进度"><a href="#更新变动及进度" class="headerlink" title="更新变动及进度"></a>更新变动及进度</h2><p>和上次更新火山图功能正好相差一个月，也算是勉强符合一开始二至四周一更的预期？</p><p>这次更新说实话还是遇到了很多困难的，最直观的体验应该是用 R 画气泡图可比用 Python 方便多了。</p><p>不过既然已经引入了绘图的库，那么就理应尽善尽美，所以这一次的更新正式上线 —— 绘制富集分析气泡图。</p><p>已有功能的相关教程请见：<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">Juseの软件开发</a></p><p>使用 R 绘制气泡图的教程可见：<a href="https://biojuse.com/2022/12/19/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94%20GO%20%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/">比较转录组分析（六）—— GO 富集分析与可视化</a></p><h3 id="本次更新变动"><a href="#本次更新变动" class="headerlink" title="本次更新变动"></a>本次更新变动</h3><ul><li>修复了 ‘火山图绘制’ 模块中文件不能通过点击按钮读取的问题。</li><li>新增了气泡图绘制功能。</li><li>新增了 GO id 注释功能（23.8.27）。</li></ul><h3 id="目前的功能进度"><a href="#目前的功能进度" class="headerlink" title="目前的功能进度"></a>目前的功能进度</h3><ul><li>提取最长转录本。<em>（已实现）</em></li><li>根据 id 提取序列。<em>（已实现）</em></li><li>对序列的 id 进行各种处理。<em>（已实现）</em></li><li>串联序列并得到分区信息。<em>（已实现）</em></li><li>批量改后缀。<em>（已实现）</em></li><li>批量进行序列格式转换。<em>（已实现）</em></li><li>批量提取 Orthofinder 的 orthogroup 对应的 CDS 序列。<em>（已实现）</em></li><li>批量进行序列的物种数和长度过滤。<em>（已实现）</em></li><li>火山图绘制。<em>（已实现）</em></li><li>气泡图绘制。<em>（已实现）</em></li><li>通过 GO id 进行 Description 和 Ontology 注释。<em>（已实现）</em></li></ul><p>叠盾警告⚠：本软件解释权归属 Juse 所有，本软件能走多远具体得看 Juse 能坚持多久。</p><p>下载地址：<a href="https://github.com/JuseTiZ/JuseKit/releases">https://github.com/JuseTiZ/JuseKit/releases</a></p><h2 id="富集分析气泡图绘制"><a href="#富集分析气泡图绘制" class="headerlink" title="富集分析气泡图绘制"></a>富集分析气泡图绘制</h2><p>本文主要着重于这次更新新增的功能，其他模块请走<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">这里</a>。</p><h3 id="要求的数据"><a href="#要求的数据" class="headerlink" title="要求的数据"></a>要求的数据</h3><p>首先，输入的文件需为 <code>csv</code> 格式的表格，表格必须包含至少三列内容：</p><ul><li><code>GO id</code> 或 <code>Description</code> 中的一个（前者列名需设置为 <code>ID</code>，后者需设置为 <code>Description</code>）。</li><li>矫正 p 值（列名必须为 <code>qvalue</code>）。</li><li>每个 GO 对应的<strong>基因数量</strong>（列名必须为 <code>Count</code>）。</li></ul><p>可选列：</p><ul><li>GeneRatio，即每个 GO 所拥有的基因数量占所有注释基因数的比例（需以 <code>x/y</code> 形式表示）。</li><li>Ontology，即每个 GO 对应的大类，包括 <code>biological_process</code> <code>cellular_component</code> <code>molecular_function</code>。</li></ul><p>示例数据：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">IDDescriptionGeneRatioCountqvalueOntology</span><br><span class="line">GO:0035158regulation of tube diameter, open tracheal system53/651537.36E-58biological_process</span><br><span class="line">GO:0098533ATPase dependent transmembrane transport complex56/651561.84E-55cellular_component</span><br><span class="line">GO:0036376sodium ion export across plasma membrane54/651542.15E-55biological_process</span><br><span class="line">GO:0005890sodium:potassium-exchanging ATPase complex55/651552.34E-55cellular_component</span><br><span class="line">GO:0090533cation-transporting ATPase complex55/651552.75E-55cellular_component</span><br></pre></td></tr></tbody></table></figure><h3 id="绘图方法"><a href="#绘图方法" class="headerlink" title="绘图方法"></a>绘图方法</h3><p>打开软件，切换到绘图专区的 <code>富集气泡图</code> 模块，将会出现以下内容。</p><p><img src="/pic2/ep1.png"></p><p>通过拖拽文件或点击右侧按钮输入文件路径，输入文件以后可以先直接点击绘图查看是否有报错再调整各类参数。</p><p>参数设置区中：</p><ul><li>绘图设置中的展示数量表明展示 p 值最小的 <code>20</code> 个，展示顺序将以 <code>Count</code> 进行排序。</li><li>进阶设置中的 <code>Description</code> 和 <code>GeneRatio</code> 分别表示展示的纵轴和横轴标签。</li><li>进阶设置中的分类一旦勾选，则将以 Ontology 列作为标准进行分类，以默认参数为例：</li></ul><blockquote><p>默认参数下，软件将选取每个 Ontology 中 p 值最小的 <code>5</code> 个 GO 制成新表格，以 Ontology 作为优先排序指标，Count 作为次优排序指标进行绘图，每个 Ontology 将被分隔展示。</p></blockquote><ul><li>进阶设置中的下载 <code>GO term list 文件</code> 和 <code>对 GO 富集文件进行分类</code> 将在下个版本更新，敬请期待。</li></ul><p>不勾选分类时，点击运行会出现绘图窗口，所出图片如下所示：</p><p><img src="/pic2/ep2.png"></p><p>可以进行如下操作：</p><ul><li><p>通过拖动窗口调整图片的大小，或者通过上方菜单中从右边数第二个和第三个按钮调整图片。</p></li><li><p>待图片调整至满意状态，点击菜单最右方保存按钮进行保存。</p></li></ul><p>快速入门：</p><ol><li>首先想象一个合适的大小，将图片拖拽到该尺寸。</li><li>点击上方右侧第三个按钮，并点击弹出页面中的 Tight layout 将图片重新布局。</li><li>保存并输出为 <code>pdf</code> 格式（也可以输出为 <code>png</code> 等，但实测应该是 <code>pdf</code> 最清晰）。</li></ol><p>勾选分类时，点击运行得到的图片如下所示（该示例中数量选择为 <code>7</code>）：</p><p><img src="/pic2/ep3.png"></p><p>一些注意事项：</p><ul><li>如果有 Ontology 的数量未达到设定，则输出的图将存在错误。</li><li>输出的 pdf 文件中的字体为 Type 3 格式，WPS 无法处理，可能需要用到其他处理软件如 <code>Adobe Acrobat</code>。</li><li>pdf 文件是可编辑的，有部分内容不合意也可输出为 pdf 文件后调整（WPS 可以先擦除字体再插入，该字体与微软雅黑相同）。</li><li>如果觉得绘图功能还有可以改进的地方，可以直接对源码进行修改以满足要求，软件在 GitHub 上开源中。</li></ul><h3 id="添加-Description-和-Ontology-列"><a href="#添加-Description-和-Ontology-列" class="headerlink" title="添加 Description 和 Ontology 列"></a>添加 Description 和 Ontology 列</h3><p>考虑到可能存在表格中只有 GO id 而无其他 GO 信息的情况，在这里补充了两个功能可以向表格中加入 <code>Description</code> 和 <code>Ontology</code> 列。</p><p>以下是更新后界面（红框为启用的功能）：</p><p><img src="/pic2/ep4.png"></p><p>按钮功能：</p><ul><li>点击 <code>下载 GO term list 文件</code> 后会下载相关注释文件（该过程中程序可能无响应），下载完成（或失败）后会弹出提示窗口，若已经存在相关文件则会弹出窗口提示文件已存在。</li><li>点击 <code>对 GO 富集文件进行分类</code> 后会读取已选文件和注释文件，并根据其中的 <code>ID</code> 列向表格中添加 <code>Description</code> 和 <code>Ontology</code> 列（如果已有则会将其覆盖），最后的文件将输出在与已选文件相同路径的 <code>GOanno.csv</code> 中。</li></ul><p>相关示例（发现错别字，下个版本再改 😀）：</p><p><img src="/pic2/ep5.png"></p><p>一些注意事项：</p><ul><li>注释文件也可以自己下载（推荐）：<a href="http://current.geneontology.org/ontology/go-basic.obo">链接</a>，下载后将文件放置在 JuseKit 路径下即可（可以识别 <code>go-basic.obo</code> 和 <code>go_term.list</code> 两个命名）。</li><li>部分 GO id 可能已废弃，此时对应注释将为 <code>NA(Obsolete)</code> 而不是 <code>NA</code>，后续绘图可能需要将其修改以让 JuseKit 识别并过滤相应 GO。</li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>还是想说一句，如果不嫌安装 R 包有些麻烦的话，还是走开头传送门去使用 R 绘制气泡图吧。</p><p>我个人认为 JuseKit 中的绘图功能只有一个优势 —— 方便，但是从别的角度看，不管是绘图的上限还是专业性肯定都不及自己精心调配各种参数来的好。</p><p>不过从最后结果上来看，JuseKit 得到的气泡图也是具有一定美观性的，至少比在 R 里完全不调任何参数要更好看得多。</p><p>最后是复制黏贴：</p><p>我会争取将这些功能慢慢完善，让它成为一个具有更广适用性的软件，希望能够帮助到某些盆友，当然我个人认为最大的可能是自娱自乐。</p><p>如果这个软件帮助到您了，您可以给它一个小小的 Star 聊表支持，或者在您汇报的时候引一下 <a href="https://github.com/JuseTiZ/JuseKit/">https://github.com/JuseTiZ/JuseKit/</a> ，想必看着还是非常高端大气上档次的。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 软件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JuseKit </tag>
            
            <tag> 转录组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DiscoVista 可视化系统发育不一致</title>
      <link href="/2023/07/12/DiscoVista%20%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E4%B8%8D%E4%B8%80%E8%87%B4/"/>
      <url>/2023/07/12/DiscoVista%20%E5%8F%AF%E8%A7%86%E5%8C%96%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E4%B8%8D%E4%B8%80%E8%87%B4/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="关于系统发育不一致"><a href="#关于系统发育不一致" class="headerlink" title="关于系统发育不一致"></a>关于系统发育不一致</h2><p>基因树不一致是一个常见的问题，导致这个问题的原因有很多，如<a href="https://biojuse.com/2023/07/07/%E4%BD%BF%E7%94%A8%20IQTREE%20%E8%AE%A1%E7%AE%97%E4%B8%80%E8%87%B4%E6%80%A7%E5%9B%A0%E5%AD%90/">上一篇文章中</a>提到过的谱系不完全分选和渐渗，此外也可能是因为：</p><ul><li>水平基因转移（Horizontal Gene Transfer）。</li><li>基因遗传方式的差异（核基因和线粒体基因）。</li></ul><p>有时我们会想要找出物种树和基因树间的不一致在哪以及有多严重，因此我们需要一个可以可视化并且能够提供良好解释性的工具。</p><p>所以这篇文章将介绍 DiscoVista（Discordance Visualization Tool），它可以帮助我们可视化特定类群在不同树间的拓扑不一致情况。</p><h2 id="DiscoVista-的安装和使用"><a href="#DiscoVista-的安装和使用" class="headerlink" title="DiscoVista 的安装和使用"></a>DiscoVista 的安装和使用</h2><p>DiscoVista github：<a href="https://github.com/esayyari/DiscoVista/tree/master">https://github.com/esayyari/DiscoVista/tree/master</a></p><p>详细的示例教程：<a href="https://github.com/esayyari/DiscoVista/tree/master/example">https://github.com/esayyari/DiscoVista/tree/master/example</a></p><p>前排提示，该文所使用的 DiscoVista 经过了博主本人的一些修改以方便使用，如果想要使用和作者一样的版本请更改安装步骤为：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/JuseTiZ/DiscoVista.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">'export WS_HOME='</span>$(<span class="built_in">readlink</span> -f ./)<span class="string">''</span> &gt;&gt; ~/.bashrc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> ~/.bashrc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda activate DiscoVista</span></span><br></pre></td></tr></tbody></table></figure><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>DiscoVista 有两种安装方法，一种是通过 Docker 直接拉取镜像，另一种是通过配置依赖项及下载源码（更困难一些）。</p><p>如果已经安装了 Docker 可以通过以下命令使用：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker pull esayyari/discovista</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run -v &lt;absolute path to data folder&gt;:/data esayyari/discovista discoVista.py [OPTIONS]</span></span><br></pre></td></tr></tbody></table></figure><p>如果未安装的话这里提供一种相对于其 GitHub 指导而言更好的方式：</p><p>由于 DiscoVista 要求较多依赖项，且其源码编写是基于 <code>Python2</code> 进行的，因此为了避免和别的环境产生冲突，建议新建一个环境进行相关配置。</p><p>首先新建一个名为 <code>DiscoVista.yml</code> 的文件，在里面写入以下内容：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">name: DiscoVista</span><br><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">  - conda-forge</span><br><span class="line">  - r</span><br><span class="line">  - bioconda</span><br><span class="line">dependencies:</span><br><span class="line">  - python=2.7</span><br><span class="line">  - r=4.1</span><br><span class="line">  - r-reshape</span><br><span class="line">  - r-reshape2</span><br><span class="line">  - r-ggplot2</span><br><span class="line">  - r-plyr</span><br><span class="line">  - r-scales</span><br><span class="line">  - r-ape</span><br><span class="line">  - r-optparse</span><br><span class="line">  - dendropy</span><br></pre></td></tr></tbody></table></figure><p>此后运行（如果没有 mamba 的话可以尝试 conda，但成功率会比较低）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mamba <span class="built_in">env</span> create -f DiscoVista.yml</span></span><br></pre></td></tr></tbody></table></figure><p>环境安装成功后，DiscoVista 所需要的各项依赖项就已经配置完成，此后通过以下命令下载源码并激活环境：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/esayyari/DiscoVista.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">'export WS_HOME='</span>$(<span class="built_in">readlink</span> -f ./)<span class="string">''</span> &gt;&gt; ~/.bashrc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> ~/.bashrc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda activate DiscoVista</span></span><br></pre></td></tr></tbody></table></figure><p>现在你应该可以通过 <code>$WS_HOME/DiscoVista/src/utils/discoVista.py</code> 进行调用：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="variable">$WS_HOME</span>/DiscoVista/src/utils/discoVista.py</span></span><br><span class="line">Usage: discoVista.py [options]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  -a ANNOTATION, --annotation=ANNOTATION</span><br><span class="line">                        The annotation file</span><br><span class="line">  -c CLADES, --clades=CLADES</span><br><span class="line">                        The path to the clades definition file</span><br><span class="line">  -m MODE, --mode=MODE  summerize gene trees or estimated species tree. To</span><br><span class="line">                        summerize species tree use 0.  To summereize gene</span><br><span class="line">                        trees use 1 . For GC stat analysis use 2.</span><br><span class="line">  -p PATH, --path=PATH  path to the gene directory or species tree</span><br><span class="line">  -r ROOT, --rooting=ROOT</span><br><span class="line">                        The rooting file</span><br><span class="line">  -s STYLE, --style=STYLE</span><br><span class="line">                        The color style set</span><br><span class="line">  -t THRESH, --threshold=THRESH</span><br><span class="line">                        The bootstrap threshold</span><br><span class="line">  -x MODELCOND, --modelCond=MODELCOND</span><br><span class="line">                        The model condition that the occupancy map will be</span><br><span class="line">                        plotted for</span><br><span class="line">  -y NEWMODEL           The new order for model conditions</span><br><span class="line">  -w NEWORDER           The new order for clades</span><br><span class="line">  -k MISSING, --missing=MISSING</span><br><span class="line">                        The missing data handling flag. If this flag set to</span><br><span class="line">                        one, clades with partially missing taxa are considered</span><br><span class="line">                        as complete.</span><br><span class="line">please enter the path to the gene directory</span><br></pre></td></tr></tbody></table></figure><p>如果下载的是<strong>原作者</strong>的 <code>master</code> 分支，那么进行以上安装后还需进行如下修改：</p><p>打开 <code>DiscoVista/src/R</code>，修改其中的 <code>main_depict_clades.R</code>，在 <code>read.data</code> 函数下该部分添加 <code>as.is=F</code>：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"> read.data <span class="operator">&lt;-</span> <span class="keyword">function</span> <span class="punctuation">(</span>...<span class="punctuation">)</span> <span class="punctuation">{</span></span><br><span class="line">  raw.all <span class="operator">=</span> read.csv<span class="punctuation">(</span>file.all<span class="punctuation">,</span>sep<span class="operator">=</span><span class="string">"\t"</span><span class="punctuation">,</span> header<span class="operator">=</span><span class="built_in">T</span><span class="punctuation">,</span> as.is<span class="operator">=</span><span class="built_in">F</span><span class="punctuation">)</span> <span class="comment">#原先没有as.is=F</span></span><br><span class="line">  raw.highsupport <span class="operator">=</span> read.csv<span class="punctuation">(</span>file.hs<span class="punctuation">,</span>sep<span class="operator">=</span><span class="string">"\t"</span><span class="punctuation">,</span> header<span class="operator">=</span><span class="built_in">T</span><span class="punctuation">,</span> as.is<span class="operator">=</span><span class="built_in">F</span><span class="punctuation">)</span> <span class="comment">#原先没有as.is=F</span></span><br><span class="line">  ...</span><br></pre></td></tr></tbody></table></figure><p><code>as.is</code> 为 <code>TRUE</code> 时，R 不会将读取数据中的字符串转换成因子，因此部分函数会返回 <code>NULL</code> 导致画图异常，修改后就可以正常生成 <code>pdf</code> 和 <code>csv</code> 结果文件。</p><p>该选项在 <code>Rv4.0</code> 前默认为 <code>FALSE</code>，而在此之后的 R 则需要手动指定。</p><p>该问题我已向 DiscoVista 提交 PR，如果后续被接受则可跳过该修改部分，也可以在配置环境时指定更低的 R 版本避免该问题（但我没有尝试过）。</p><p>DiscoVista 的示例数据集比较复杂，为简化理解，我从 NCBI 上下载了来自于 <code>人</code> <code>鸡</code> <code>小鼠</code> <code>黑猩猩</code> <code>非洲爪蟾</code> <code>斑马鱼</code> 六种物种的蛋白序列并随机挑选其中五十个直系同源基因进行展示。</p><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>对示例数据集进行了以下操作：</p><ul><li>Mafft &amp; TrimAl 比对修剪。</li><li>使用 IQTREE 对每个基因进行了最大似然建树。</li><li>使用 IQTREE 对串联序列进行了分区建树。</li><li>使用 Astral 基于基因树推导了物种树。</li><li>为了对比效果人为编写了一个物种树。</li></ul><p>本文中所使用的示例数据集仅为更好地呈现 DiscoVista，因此并不具备绝对的严谨性。</p><p>需要提前注意的一些地方：</p><ul><li>有些树的支持率为后验概率等，其最大值为 1（与自展值不同），对这种树需要进行一定处理（后记中有相关脚本）或者调整 <code>-t</code> 参数。</li><li>本文的部分内容可能有所遗漏，如果想要更全面的理解软件运行请前往其 github 页面。</li><li>本文仅介绍 <em><strong>物种树的不一致分析</strong></em> 以及 <em><strong>基因树的不一致分析</strong></em> ，其他用例请见官网。</li></ul><h4 id="物种树的不一致分析"><a href="#物种树的不一致分析" class="headerlink" title="物种树的不一致分析"></a>物种树的不一致分析</h4><p>DiscoVista 的重点是关注某一特定分支在不同树中的拓扑情况，在文章中作者提到：</p><blockquote><p>In many analyses, not all branches in a phylogenetic tree are equally important because questions of interest typically concern several hypotheses surrounding the relationships between focal groups. Visualizing discordance with respect to only these focal relationships simplifies interpretation.</p></blockquote><p>因此这一部分的重点和难点就在于支定义文件的编写，需要有一定先验认识。</p><p>此次示例中进行了以下划分：</p><ul><li>将 <code>人</code> <code>黑猩猩</code> 划分成一个组（灵长类）。</li><li>将灵长类组与 <code>小鼠</code> 共同划分成一个组（哺乳类）。</li><li>将哺乳类组与 <code>鸡</code> 共同划分成一个组（陆生动物类）。</li></ul><p>支定义文件生成步骤：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">也可使用后记中的脚本进行替代，不过相应地需要使用 Juse 的 fork 版本</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="variable">$WS_HOME</span>/DiscoVista/src/utils/generate_clade-defs.py anno-1.txt anno.txt</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># anno-1.txt内容</span><br><span class="line">Xenopus_laevisAmphibia</span><br><span class="line">Danio_rerioAquatic</span><br><span class="line">Gallus_gallusTerrestrial</span><br><span class="line">Homo_sapiensPrimates</span><br><span class="line">Pan_troglodytesPrimates</span><br><span class="line">Mus_musculusMammal</span><br></pre></td></tr></tbody></table></figure><p>此后对 <code>anno.txt</code> 中的 <code>Terrestrial</code> <code>Mammal</code> 组进行补充，得到最终的支定义文件。</p><p>由于 IQTREE 和 Astral 得到的物种树结果一致，均为以下拓扑结构且支持率都达到最大：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(Pan_troglodytes,((Gallus_gallus,(Xenopus_laevis,Danio_rerio)100)100,Mus_musculus)100,Homo_sapiens);</span><br></pre></td></tr></tbody></table></figure><p>因此为了展现出不同的情况，我将黑猩猩与小鼠的位置互换并得到以下拓扑结构：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(Mus_musculus,((Gallus_gallus,(Xenopus_laevis,Danio_rerio)100)100,Pan_troglodytes)100,Homo_sapiens);</span><br></pre></td></tr></tbody></table></figure><p>每一个物种树文件都应该<strong>单独放置在一个文件夹</strong>内，并以 <code>estimated_species_tree.tree</code> 命名，文件夹名称命名格式为 <code>模型-序列类型</code>，例如：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- tree</span><br><span class="line"> - astral-pep</span><br><span class="line">   - estimated_species_tree.tree</span><br><span class="line"> - iqtree-pep</span><br><span class="line">   - estimated_species_tree.tree</span><br><span class="line"> - juse-pep</span><br><span class="line">   - estimated_species_tree.tree</span><br></pre></td></tr></tbody></table></figure><p>运行：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="variable">$WS_HOME</span>/DiscoVista/src/utils/discoVista.py -m 0 -c anno.txt -p tree -t 95 -m 0 -o results</span></span><br></pre></td></tr></tbody></table></figure><p><code>-m</code> 指定进行哪种分析，<code>-c</code> 指定支定义文件，<code>-p</code> 指定物种树存放文件夹，<code>-t</code> 为高度支持分支的支持率阈值，<code>-o</code> 为结果输出位置。</p><p>在该例中，<code>results</code> 文件夹里的 <code>pep.block.pdf</code> 等即为 DiscoVista 运行结果：</p><p><img src="/pic2/pep.block_00.png"></p><p>可以看到结果是符合预期的，即所有的树都支持之前划分的不同分支（除了人为编写的物种树）。</p><h4 id="基因树的不一致分析"><a href="#基因树的不一致分析" class="headerlink" title="基因树的不一致分析"></a>基因树的不一致分析</h4><p>和上述分析类似，不过本例中每一个基因树文件都应放置在<strong>单个文件夹中的单个文件夹内</strong>（相当于 <code>/不同基因/不同建树方法</code>）并以 <code>estimated_gene_trees.tree</code> 命名。本文示例中每个基因只采取了一个建树方法进行，因此可以运行以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">i=1</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> file <span class="keyword">in</span> genetree/*; <span class="keyword">do</span></span></span><br><span class="line">mkdir "genetree/$i"</span><br><span class="line">mkdir "genetree/$i/genetree"</span><br><span class="line">mv "$file" "genetree/$i/genetree/estimated_gene_trees.tree"</span><br><span class="line">i=$((i+1))</span><br><span class="line">done</span><br></pre></td></tr></tbody></table></figure><p>将 <code>genetree/</code> 换成自己的基因树存放文件夹，此后运行 DiscoVista：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="variable">$WS_HOME</span>/DiscoVista/src/utils/discoVista.py -c anno.txt -p genetree -t 75 -m 1 -o genetree_results</span></span><br></pre></td></tr></tbody></table></figure><p>运行后，文件夹 <code>genetree_results</code> 中的 <code>Monophyletic_Bargraphs.pdf</code> 等文件即为结果：</p><p><img src="/pic2/Monophyletic_Bargraphs_Porportion_00.png"></p><p>其中有部分基因并不支持我们所定义的支（例如哺乳类和陆生类有部分基因显示强拒绝），但大多数还是符合先验预期的。</p><h2 id="涉及到的其他脚本"><a href="#涉及到的其他脚本" class="headerlink" title="涉及到的其他脚本"></a>涉及到的其他脚本</h2><p>上述部分以一个简单的示例说明了 DiscoVista 如何使用，该部分将展示本文中使用的相关脚本。</p><p>自己编辑的支定义文件生成脚本：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate_clade-defs.py</span></span><br><span class="line"><span class="comment"># Author: Juse</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">header = <span class="string">"Clade Name\tClade Definition\tSection\tLetter\tComponents\tShow\tComments\n"</span></span><br><span class="line">annofile = <span class="built_in">open</span>(sys.argv[<span class="number">1</span>], <span class="string">'r'</span>)</span><br><span class="line">outpfile = <span class="built_in">open</span>(sys.argv[<span class="number">2</span>], <span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line">group_spe = {}</span><br><span class="line">all_spe = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> annofile:</span><br><span class="line"></span><br><span class="line">    spe = line.split()[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> spe <span class="keyword">not</span> <span class="keyword">in</span> all_spe:</span><br><span class="line">        all_spe.append(spe)</span><br><span class="line">    group = line.split()[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> group <span class="keyword">not</span> <span class="keyword">in</span> group_spe:</span><br><span class="line">        group_spe[group] = [spe]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        group_spe[group].append(spe)</span><br><span class="line"></span><br><span class="line">content = <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> group, spes <span class="keyword">in</span> group_spe.items():</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(spes) == <span class="number">1</span>:</span><br><span class="line">        content += <span class="string">f'<span class="subst">{group}</span>\t<span class="subst">{spes[<span class="number">0</span>]}</span>\tNone\t\t0\t\t\n'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        definition = <span class="string">'+'</span>.join(spes)</span><br><span class="line">        content += <span class="string">f'<span class="subst">{group}</span>\t<span class="subst">{definition}</span>\tNone\t\t1\t\t\n'</span></span><br><span class="line"></span><br><span class="line">species = <span class="string">'+'</span>.join(all_spe)</span><br><span class="line">content += <span class="string">f'All\t<span class="subst">{species}</span>\tNone\t\t0\t\t\n'</span></span><br><span class="line"></span><br><span class="line">outpfile.write(header)</span><br><span class="line">outpfile.write(content)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Done!'</span>)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python generate_clade-defs.py anno-1.txt anno.txt</span></span><br></pre></td></tr></tbody></table></figure><p>注意以下几点可能需要留意和自己修改：</p><ul><li>该脚本生成的支定义文件仅与 Juse 本人 fork 后编辑的 DiscoVista 兼容（见正文开头）。</li><li>该脚本自动将包含多个物种的类群编辑为<strong>显示</strong>（即第四列为 1）。</li><li>不支持复合类群的定义，请在生成支定义文件后自行添加。</li></ul><hr><p>将 RefSeq 格式的序列文件转变成以物种名为开头的序列格式：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ref2spename.py</span></span><br><span class="line"><span class="comment"># Author: Juse with ChatGPT</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Bio <span class="keyword">import</span> SeqIO</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">input_file = sys.argv[<span class="number">1</span>]</span><br><span class="line">output_file = sys.argv[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">modify_header</span>(<span class="params">record</span>):</span><br><span class="line"></span><br><span class="line">    new_id = record.description.replace(<span class="string">' '</span>, <span class="string">'_'</span>)</span><br><span class="line">    <span class="keyword">match</span> = re.search(<span class="string">r".*\[([^]]*)\]"</span>, new_id)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">match</span>:</span><br><span class="line">        species = <span class="keyword">match</span>.group(<span class="number">1</span>).replace(<span class="string">' '</span>, <span class="string">'_'</span>)</span><br><span class="line">        rest = new_id[:<span class="keyword">match</span>.start(<span class="number">1</span>)-<span class="number">1</span>]</span><br><span class="line">        new_id = species + <span class="string">'@'</span> + rest</span><br><span class="line"></span><br><span class="line">    record.<span class="built_in">id</span> = new_id.strip(<span class="string">'_'</span>)</span><br><span class="line">    record.description = <span class="string">""</span></span><br><span class="line">    <span class="keyword">return</span> record</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_fasta_file</span>(<span class="params">input_file, output_file</span>):</span><br><span class="line"></span><br><span class="line">    records = SeqIO.parse(input_file, <span class="string">"fasta"</span>)</span><br><span class="line">    new_records = (modify_header(record) <span class="keyword">for</span> record <span class="keyword">in</span> records)</span><br><span class="line">    SeqIO.write(new_records, output_file, <span class="string">"fasta"</span>)</span><br><span class="line"></span><br><span class="line">process_fasta_file(input_file, output_file)</span><br></pre></td></tr></tbody></table></figure><p>该脚本需要下载 Bio 包，运行例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python ref2spename.py ncbi_dataset/data/GCF_000001405.40/protein.faa human.fasta</span></span><br></pre></td></tr></tbody></table></figure><p>运行前（<code>protein.faa</code>）序列名格式 &amp; 运行后（<code>human.fasta</code>）：    </p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;NP_000005.3 alpha-2-macroglobulin isoform a precursor [Homo sapiens]</span><br><span class="line">&gt;Homo_sapiens@NP_000005.3_alpha-2-macroglobulin_isoform_a_precursor</span><br></pre></td></tr></tbody></table></figure><p>该脚本已上传至 github 中，可见：<a href="https://github.com/JuseTiZ/pythonscript">https://github.com/JuseTiZ/pythonscript</a></p><hr><p>将树文件中支持率变为 100 倍（<strong>注意该脚本直接覆盖原文件</strong>）：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pp2perc.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">spe_tree = <span class="built_in">open</span>(sys.argv[<span class="number">1</span>], <span class="string">'r'</span>)</span><br><span class="line"></span><br><span class="line">tree_con = spe_tree.read()</span><br><span class="line">new_species_tree = re.sub(<span class="string">r'\)(\d(\.\d*)?):'</span>,</span><br><span class="line">                          <span class="keyword">lambda</span> m: <span class="string">')'</span>+<span class="built_in">str</span>(<span class="built_in">int</span>(<span class="built_in">float</span>(m.group(<span class="number">1</span>))*<span class="number">100</span>))+<span class="string">':'</span>,</span><br><span class="line">                          tree_con)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(sys.argv[<span class="number">1</span>], <span class="string">'w'</span>) <span class="keyword">as</span> o:</span><br><span class="line">    o.write(new_species_tree)</span><br></pre></td></tr></tbody></table></figure><p>运行例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python pp2perc.py astral.treefile</span></span><br></pre></td></tr></tbody></table></figure></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 系统发育分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用 IQTREE 计算一致性因子</title>
      <link href="/2023/07/07/%E4%BD%BF%E7%94%A8%20IQTREE%20%E8%AE%A1%E7%AE%97%E4%B8%80%E8%87%B4%E6%80%A7%E5%9B%A0%E5%AD%90/"/>
      <url>/2023/07/07/%E4%BD%BF%E7%94%A8%20IQTREE%20%E8%AE%A1%E7%AE%97%E4%B8%80%E8%87%B4%E6%80%A7%E5%9B%A0%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="关于谱系不完全分选和渐渗"><a href="#关于谱系不完全分选和渐渗" class="headerlink" title="关于谱系不完全分选和渐渗"></a>关于谱系不完全分选和渐渗</h2><blockquote><p>注意：该前言部分使用 ChatGPT4.0 生成并由 Juse 纠正总结，图源自维基百科。</p><p>问题：请介绍一下谱系不完全分选（ILS）和渐渗（introgression）对推断系统发育关系的影响，随之引出基因一致性因子（gene concordance factor）和位点一致性因子（site concordance factor）的概念并介绍它们的作用。</p></blockquote><p>在生物学中，推断不同物种的系统发育关系是一个核心课题。然而，系统发育树的构建很复杂，可能受到多种因素的影响。这里我们着重介绍两个重要因素：谱系不完全分选（Incomplete Lineage Sorting，简称 ILS）和渐渗（Introgression）。</p><ul><li>谱系不完全分选 (ILS)： 谱系不完全分选发生在物种分化的过程中。当两个物种在很短的时间内分化时，一些基因座可能没有足够的时间来完全分化，因此这些基因座在不同物种之间可能会保留共同的祖先多态性。这意味着即使两个物种已经分化，它们的一些基因序列可能仍然相似。这在系统发育树的构建中会引入混乱，因为它可能导致基于这些基因的树与真实的物种树不一致。</li></ul><p><img src="/pic2/ILS.png"></p><ul><li>渐渗 (Introgression)： 渐渗是指一个物种的基因通过杂交和回交进入另一个物种的基因库的过程。这通常是通过自然的或人为的杂交事件发生的。渐渗的结果是，两个原本是独立进化的物种在其基因组中出现了相互混合的部分。这在系统发育分析中会引起问题，因为基于混合基因的树可能会误导我们认为两个物种比实际上更为接近。</li></ul><p><img src="/pic2/introgression.png"></p><p>为了解决这些问题，研究人员引入了 “基因一致性因子”（Gene Concordance Factor，简称 GCF）和 “位点一致性因子”（Site Concordance Factor，简称 SCF）这两个概念。</p><ol><li>基因一致性因子 (GCF)： GCF 用于测量不同基因的系统发育信号与某一特定的参考拓扑结构的一致性。它计算的是支持给定物种树拓扑结构的基因的百分比。如果 GCF 值接近 1，这意味着大多数基因支持该参考拓扑；而如果 GCF 值较低，这意味着基因之间在支持的物种树结构上存在较大差异。</li><li>位点一致性因子 (SCF)： 与 GCF 类似，SCF 用于测量单个位点的系统发育信号与参考拓扑的一致性，为支持分支的信息位点比例。</li></ol><p>通过使用 GCF 和 SCF，研究人员能够更准确地评估基因和位点数据对系统发育树的贡献，从而更有效地解决因谱系不完全分选和渐渗引起的问题。</p><h2 id="运行方法"><a href="#运行方法" class="headerlink" title="运行方法"></a>运行方法</h2><p>IQTREE 官方文档（重应用）：<a href="http://www.iqtree.org/doc/Concordance-Factor">http://www.iqtree.org/doc/Concordance-Factor</a></p><p>IQTREE 开发者亲自教学（重理解）：<a href="http://www.robertlanfear.com/blog/files/concordance_factors.html">http://www.robertlanfear.com/blog/files/concordance_factors.html</a></p><p>本文就其中重点进行阐述介绍。</p><p>由于新的基于最大似然法计算 sCF 的方法在 IQTREEv2.2.2 以上才提供，因此请确保自己的版本已经足够。</p><p>新版本的下载和安装可以前往：<a href="https://github.com/iqtree/iqtree2">https://github.com/iqtree/iqtree2</a></p><p>懒人版命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/iqtree/iqtree2/releases/download/v2.2.2.6/iqtree-2.2.2.6-Linux.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -zxf iqtree-2.2.2.6-Linux.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">'export PATH="'</span>$(<span class="built_in">readlink</span> -f iqtree-2.2.2.6-Linux/bin)<span class="string">':$PATH"'</span> &gt;&gt; ~/.bashrc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> ~/.bashrc</span></span><br></pre></td></tr></tbody></table></figure><p>完成所有命令以后，你应该就可以直接通过 <code>iqtree2</code> 命令调用软件了。</p><p>如果已经有了不同基因的比对序列文件（未串联）且存放在一个文件夹中，则可以使用以下命令计算 SCF GCG：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">infer a concatenation-based species tree with 1000 ultrafast bootstrap and an edge-linked partition model</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -p ALN_DIR --prefix concat -B 1000 -T AUTO</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ALN_DIR为比对序列文件所在的文件夹，第一步为建立一个串联树，已建树则可跳过该步。</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">infer the locus trees（推断基因树）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -S ALN_DIR --prefix loci -T AUTO</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">compute gene concordance factors（计算GCF）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -t concat.treefile --gcf loci.treefile --prefix concord</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">compute site concordance <span class="built_in">factor</span> using likelihood with v2.2.2（计算SCF）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -te concat.treefile -p ALN_DIR --scfl 100 --prefix concord2</span></span><br></pre></td></tr></tbody></table></figure><p>如果已经串联好了序列并且有分区文件，则可以使用以下命令计算 SCF GCG：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">infer a concatenation-based species tree with 1000 ultrafast bootstrap and an edge-linked partition model</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -s ALN_FILE -p PARTITION_FILE --prefix concat -B 1000 -T AUTO</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ALN_FILE为串联序列，PARTITION_FILE为分区文件，已建树则可跳过该步。</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">infer the locus trees（推断基因树）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -s ALN_FILE -S PARTITION_FILE --prefix loci -T AUTO</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">compute gene concordance factors（计算GCF）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -t concat.treefile --gcf loci.treefile --prefix concord</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">compute site concordance <span class="built_in">factor</span> using likelihood with v2.2.2（计算SCF）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -te concat.treefile -s ALN_FILE --scfl 100 --prefix concord2</span></span><br></pre></td></tr></tbody></table></figure><p>以上述命令为例，运行后将得到一系列文件，其中 <code>concord.cf.stat</code> 记录 GCF 信息，<code>concord2.cf.stat</code> 记录 SCF 信息。</p><p>如果想要可视化各个位点的信息，可以使用相应的树文件 <code>concord.cf.tree</code> 和 <code>concord2.cf.tree</code>。</p><p>此后的可视化等操作详细可看之前所提到的链接，这里将节选其中的某些重点：</p><ul><li>GCF 低的原因可能有：①、解析短序列和短分支的能力有限；②、许多基因中存在相互冲突的信号。此时 SCF 可以提供更多信息，如果导致 GCF 低的原因仅是基因树中的信号冲突，那么 GCF 和 SCF 应该是相近的。而如果 GCF 受到其他影响（有限数据的随机误差）那么它将比 SCF 低很多。</li><li>即使 GCF 和 SCF 低，可能也会得到一个非常高的自举值（支持率），因为 bootstrap 测量的是采样方差，而它们反映的是原始数据中的方差。有论文表明在一个长度为 137324 的比对中，17 个位点的差异（131 vs 114）就能让程序得到 99.999% 的支持率。因此这凸显了在大数据集中使用 GCF 和 SCF 进行补充的有效性。    </li><li>SCF 小于 33% 但该拓扑结构依然显示高支持率：可能是由于存在少数影响更显著的位点。</li></ul><p>以下提供相关原文：</p><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">原文部分</summary><div class="toggle-content"><blockquote><p>The gCF is probably low for two reasons: our ability to resolve single locus trees is limited because they’re short (and this is a short branch in the tree, which makes things worse), and many of the loci contain genuinely conflicting signal. The sCF helps us dig deeper here – the sCF for this node is ~37%, suggesting that the low gCF is a combination of both factors. Roughly speaking we expect the gCF and sCF to be similar if the only thing causing a low gCF is genuine discordant signal in the single locus trees. If the gCF values are affected by other processes (e.g. stochastic error from limited information), then gCF values can be a lot lower than sCF values. An sCF of 37% shows that there is not overwhelming support for any particular resolution of this branch. A sensible biological interpretation here would be that this resolution of the tree is a good best guess for the species tree, but that there is plenty of conflicting signal meaning that: even if this is the correct resolution, there’s probably a lot of conflicting signal in the gene trees from processes like incomplete lineage sorting.</p></blockquote><blockquote><p>We can see a number of things from this. First, the branch is very short, and that’s probably most of the reason for the low gCF (short branches are hard to resolve, particularly with short loci). This is confirmed by the fact that although 87 of the 88 single locus trees could have contained this branch (gN = 87 in the table, meaning that 87 of the 88 gene trees could have contained that branch; these gene trees are called decisive in the preprint), only 1 of them did (1.15% of 87 is 1). Three other single locus trees supported a second resolution of the four clades around that branch (gDF1 = 3.45%, corresponding to 3 trees), and none supported the third resolution (gDF2 = 0%). The remaining 83 out of the 87 gene trees had a topology that wasn’t any one of the three possible arrangements of the four clades around this branch, which is a typical signal of noisy single locus trees. This highlights another important point – the most common resolution of this branch in the gene trees is NOT the one we see in the ML concatenated tree. There are at least two reasons this might be the case – we might be in the <a href="http://www.robertlanfear.com/blog/files/%E2%80%9Chttps://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0020068%E2%80%9D">anomaly zone</a>, or it might be that the informative sites for this tree are scattered around in all the noisy genes, such that individual gene trees really aren’t giving us much useful information here. The sCF and sDF values suggest that the latter explanation is true (see below). In itself, this highlights a limitation of methods that look to build a species tree from pre-estimated gene trees: when the gene trees are noisy, these methods will struggle.</p></blockquote><blockquote><p>But how can the bootstrap be so high, when the sCF is so low? This is because bootstrap values are measuring sampling variance, while the sCF is measuring the observed variance in the original data. This difference is important, and highlights why in many cases (especially for large phylogenomic datasets) gCF and sCF values are a useful complement to bootstrap values. Specifically, it makes it explicit that a very low sampling variance (e.g. 100% bootstrap support) tells you very little about the underlying variation in your data. An analogy might be useful here: imagine you collect height data from 1 million individuals in a population. Let’s say your data show that individuals can range from 4 feet tall to 10 feet tall, and that the distribution is almost uniform. If you calculate the mean of this distribution, and then recalculate it again and again from bootstrapped samples of your dataset, you’ll see that your sampling variance on the mean is very low because you have such a big dataset. But if you were to measure the variance of your raw data, you’d see that this is very high. A low sampling variance on the mean is analogous to a high bootstrap value (which indicates a low sampling variance on a branch in tree), and a high observed variance is like a low sCF value (which indicates high variance in the support that sites give for the correct resolution of this branch).</p></blockquote><blockquote><p>Felsenstein’s <a href="http://www.robertlanfear.com/blog/files/%E2%80%9Chttps://onlinelibrary.wiley.com/doi/abs/10.1111/j.1558-5646.1985.tb00420.x%E2%80%9D">1985 bootstrap paper</a> gives us a formula which tells us that we should expect very high bootstrap support if we have 131 vs. 114 sites competing to resolve a single branch. Indeed, it says that the bootstrap support for a difference of 17 sites in an alignment of length 137324 should be 99.999% in favour of the resolution with the most supporting sites. Regardless, these sCF values tell us that despite a bootstrap support of 100%, the underlying data contain a lot of discordance (almost the maximum possible amount) around this one branch.</p></blockquote></div></details><p>关于使用卡方检验计算 p 值确定是否存在谱系不完全分选的部分可以作为一个参考，以下我贴出通过两个文件计算 p 值的代码部分：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">library<span class="punctuation">(</span>dplyr<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">gcf_file <span class="operator">=</span> read.delim<span class="punctuation">(</span><span class="string">'concord.cf.stat'</span><span class="punctuation">,</span> header <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> comment.char<span class="operator">=</span><span class="string">'#'</span><span class="punctuation">)</span></span><br><span class="line">scf_file <span class="operator">=</span> read.delim<span class="punctuation">(</span><span class="string">'concord2.cf.stat'</span><span class="punctuation">,</span> header <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">,</span> comment.char<span class="operator">=</span><span class="string">'#'</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">all_file <span class="operator">=</span> cbind<span class="punctuation">(</span>gcf_file<span class="punctuation">,</span> scf_file<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="operator">:</span><span class="number">8</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">chisq <span class="operator">=</span> <span class="keyword">function</span><span class="punctuation">(</span>DF1<span class="punctuation">,</span> DF2<span class="punctuation">,</span> N<span class="punctuation">)</span><span class="punctuation">{</span></span><br><span class="line">  tryCatch<span class="punctuation">(</span><span class="punctuation">{</span></span><br><span class="line">    <span class="comment"># converts percentages to counts, runs chisq, gets pvalue</span></span><br><span class="line">    chisq.test<span class="punctuation">(</span><span class="built_in">c</span><span class="punctuation">(</span><span class="built_in">round</span><span class="punctuation">(</span>DF1<span class="operator">*</span>N<span class="punctuation">)</span><span class="operator">/</span><span class="number">100</span><span class="punctuation">,</span> <span class="built_in">round</span><span class="punctuation">(</span>DF2<span class="operator">*</span>N<span class="punctuation">)</span><span class="operator">/</span><span class="number">100</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="operator">$</span>p.value</span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  error <span class="operator">=</span> <span class="keyword">function</span><span class="punctuation">(</span>err<span class="punctuation">)</span> <span class="punctuation">{</span></span><br><span class="line">    <span class="comment"># errors come if you give chisq two zeros</span></span><br><span class="line">    <span class="comment"># but here we're sure that there's no difference</span></span><br><span class="line">    <span class="built_in">return</span><span class="punctuation">(</span><span class="number">1.0</span><span class="punctuation">)</span></span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">}</span></span><br><span class="line"></span><br><span class="line">e <span class="operator">=</span> all_file <span class="operator">%&gt;%</span> </span><br><span class="line">  group_by<span class="punctuation">(</span>ID<span class="punctuation">)</span> <span class="operator">%&gt;%</span></span><br><span class="line">  mutate<span class="punctuation">(</span>gEF_p <span class="operator">=</span> chisq<span class="punctuation">(</span>gDF1<span class="punctuation">,</span> gDF2<span class="punctuation">,</span> gN<span class="punctuation">)</span><span class="punctuation">)</span> <span class="operator">%&gt;%</span></span><br><span class="line">  mutate<span class="punctuation">(</span>sEF_p <span class="operator">=</span> chisq<span class="punctuation">(</span>sDF1<span class="punctuation">,</span> sDF2<span class="punctuation">,</span> sN<span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">ILS_df_all <span class="operator">=</span> data.frame<span class="punctuation">(</span>e<span class="punctuation">)</span></span><br><span class="line">ILS_df_re <span class="operator">=</span> subset<span class="punctuation">(</span>data.frame<span class="punctuation">(</span>e<span class="punctuation">)</span><span class="punctuation">,</span> <span class="punctuation">(</span>gEF_p <span class="operator">&lt;</span> <span class="number">0.05</span> <span class="operator">|</span> sEF_p <span class="operator">&lt;</span> <span class="number">0.05</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">write.csv<span class="punctuation">(</span>ILS_df_all<span class="punctuation">,</span> <span class="string">'allcf.csv'</span><span class="punctuation">)</span></span><br><span class="line">write.csv<span class="punctuation">(</span>ILS_df_re<span class="punctuation">,</span> <span class="string">'cf.csv'</span><span class="punctuation">)</span></span><br></pre></td></tr></tbody></table></figure><p>其中 <code>allcf.csv</code> 为全部节点的一致性因子信息文件（最后两列为相关 p 值），<code>cf.csv</code> 则仅保留了经卡方检验两个 p 值中有至少一个小于 0.05 的节点。</p><p>注意：该 p 值的解释需要谨慎，因为它没有考虑到一些因素例如连锁不平衡等。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>进化学领域中，关于 ILS 和 Introgression 的讨论一直存在，检测它们的方法也随之出现，经典的有 <code>abba-baba test</code>，复杂的也有应用了隐马尔可夫模型的 <code>coalHMM</code> 等软件。</p><p>但事实上本文讲到的一致性因子和这两个现象<strong>并没有绝对的关联</strong>，对于一致性因子而言，其最重要的作用是量化系统发育数据集的一致性，有助于帮助我们识别数据中的问题并严谨地对待得到的系统发育关系。</p><p>话虽如此，这些因子同样也能作为 ILS 现象是否存在的一个参考，为后续进行具体的 ILS 检测提供一定的先验理解。</p><p>感兴趣的话还可以看一看最近关于 ILS 的一些文章：</p><blockquote><p><a href="https://www.science.org/doi/10.1126/science.abn4409">Pervasive incomplete lineage sorting illuminates speciation and selection in primates</a> from Science</p><p><a href="https://www.sciencedirect.com/science/article/pii/S0092867422003440">Incomplete lineage sorting and phenotypic evolution in marsupials</a> from Cell</p></blockquote><p>如果想对 GCF 和 SCF 有更充分的认识可以看以下文章：</p><blockquote><p><a href="https://academic.oup.com/mbe/article/37/9/2727/5828940?login=true">New Methods to Calculate Concordance Factors for Phylogenomic Datasets</a> from Mol. Bio. Evol.</p><p><a href="https://academic.oup.com/bioinformatics/article/39/1/btac741/6831093">Updated site concordance factors minimize effects of homoplasy and taxon sampling</a> from Bioinformatics</p></blockquote><p>最后用 R 的一个示例说明为什么基因数量的增加会提高支持率但是并不带动一致性因子的变化：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">library<span class="punctuation">(</span>boot<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数来计算平均值</span></span><br><span class="line">mean.fun <span class="operator">&lt;-</span> <span class="keyword">function</span><span class="punctuation">(</span>data<span class="punctuation">,</span> indices<span class="punctuation">)</span> <span class="punctuation">{</span></span><br><span class="line">  <span class="built_in">return</span><span class="punctuation">(</span>mean<span class="punctuation">(</span>data<span class="punctuation">[</span>indices<span class="punctuation">]</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">}</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机数种子</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">114514</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个空的向量来存储结果</span></span><br><span class="line">bootstrap_sd <span class="operator">&lt;-</span> numeric<span class="punctuation">(</span><span class="number">3</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置样本量</span></span><br><span class="line">sample_sizes <span class="operator">&lt;-</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">100</span><span class="punctuation">,</span> <span class="number">1000</span><span class="punctuation">,</span> <span class="number">10000</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个样本量进行处理</span></span><br><span class="line"><span class="keyword">for</span> <span class="punctuation">(</span>i <span class="keyword">in</span> <span class="number">1</span><span class="operator">:</span><span class="number">3</span><span class="punctuation">)</span> <span class="punctuation">{</span></span><br><span class="line">  <span class="comment"># 生成数据集</span></span><br><span class="line">  data <span class="operator">&lt;-</span> rnorm<span class="punctuation">(</span>sample_sizes<span class="punctuation">[</span>i<span class="punctuation">]</span><span class="punctuation">,</span> mean <span class="operator">=</span> <span class="number">10</span><span class="punctuation">,</span> sd <span class="operator">=</span> <span class="number">5</span><span class="punctuation">)</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 使用自助法进行抽样</span></span><br><span class="line">  boot_results <span class="operator">&lt;-</span> boot<span class="punctuation">(</span>data<span class="punctuation">,</span> mean.fun<span class="punctuation">,</span> R <span class="operator">=</span> <span class="number">1000</span><span class="punctuation">)</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 计算所有抽样均值的标准差</span></span><br><span class="line">  bootstrap_sd<span class="punctuation">[</span>i<span class="punctuation">]</span> <span class="operator">&lt;-</span> sd<span class="punctuation">(</span>boot_results<span class="operator">$</span>t<span class="punctuation">)</span></span><br><span class="line"><span class="punctuation">}</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">print<span class="punctuation">(</span>bootstrap_sd<span class="punctuation">)</span></span><br></pre></td></tr></tbody></table></figure><p>结果返回：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.49967844 0.14973480 0.05184815</span><br></pre></td></tr></tbody></table></figure><p>该代码通过 ChatGPT4.0 生成，其中三个数据均来自同一分布，但随着样本量的增加，采样均值的标准差明显减小。</p><p>但是一致性因子不同，可以理解为它关注的是<strong>原始数据集的分布</strong>，此时不管样本量多大它的分布性质依然是不变的。</p><p>接着我们再来举一个功效分析的例子：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">library<span class="punctuation">(</span>pwr<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设一个很低的效应值（t检验为标准化的均值差）</span></span><br><span class="line">d <span class="operator">&lt;-</span> <span class="punctuation">(</span><span class="number">5</span><span class="operator">-</span><span class="number">4</span><span class="punctuation">)</span><span class="operator">/</span><span class="number">25</span> <span class="comment"># 均值之差/标准差</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 取很严格的显著性水平和功效水平</span></span><br><span class="line">sig <span class="operator">&lt;-</span> 0.01</span><br><span class="line">pow <span class="operator">&lt;-</span> 0.99</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测到差异需要的样本数量</span></span><br><span class="line">pwr.t.test<span class="punctuation">(</span>d<span class="operator">=</span>d<span class="punctuation">,</span> sig.level<span class="operator">=</span>sig<span class="punctuation">,</span> power<span class="operator">=</span>pow<span class="punctuation">)</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">     Two-sample t test power calculation </span><br><span class="line"></span><br><span class="line">              n = 30040.84</span><br><span class="line">              d = 0.04</span><br><span class="line">      sig.level = 0.01</span><br><span class="line">          power = 0.99</span><br><span class="line">    alternative = two.sided</span><br><span class="line"></span><br><span class="line">NOTE: n is number in *each* group</span><br></pre></td></tr></tbody></table></figure><p>可以看到，只要样本量够大（每组 30040.84 个样本以上），就算是很微弱的差异，也能被检测到（而且是极显著的）。</p><p>以上例子只是简化对于之前问题的理解，实际上的计算过程会要复杂得多（我也不会）。从结果上来看，或许有时候支持率确实不能成为我们判断系统发育关系是否准确的唯一标准，但也不必因此过多重视 GCF 和 SCF 而忽视了支持率信息，正如文章中所提到：</p><blockquote><p>One measure is not better or worse than the other, rather, concordance factors provide useful information that bootstraps do not, and vice versa.</p><p>衡量标准没有好坏之分，一致性因子提供了一些自助法没有提供的信息，反之亦然。</p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> IQtree </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>贝叶斯建树之 Mrbayes 篇</title>
      <link href="/2023/07/06/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%BB%BA%E6%A0%91%E4%B9%8B%20Mrbayes%20%E7%AF%87/"/>
      <url>/2023/07/06/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%BB%BA%E6%A0%91%E4%B9%8B%20Mrbayes%20%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="贝叶斯建树原理及优缺点"><a href="#贝叶斯建树原理及优缺点" class="headerlink" title="贝叶斯建树原理及优缺点"></a>贝叶斯建树原理及优缺点</h2><blockquote><p>注意：该前言部分使用 ChatGPT4.0 生成并由 Juse 纠正总结。</p><p>问题：请介绍一下系统发育分析中的贝叶斯推断法（原理、优缺点等），并指出几个代表生信软件。</p></blockquote><p>在系统发育学中，贝叶斯推断是一种常用的统计方法，用于根据观测数据推断出物种间的系统发育关系。</p><p><strong>原理：</strong></p><p>贝叶斯推断的原理基于贝叶斯定理，该定理可以将先验概率和似然度结合起来，得到后验概率。</p><p>在系统发育分析中，贝叶斯推断法被用来估计种群或物种之间的演化关系。这种方法假设所有可能的树形图都存在某种先验概率，并使用蒙特卡洛马尔科夫链（MCMC）来在所有可能的树形图和其关联参数的空间中进行采样。每一步，系统会根据特定的概率提议一种新的树形图或参数，然后根据新的树形图或参数与当前状态的拟合度决定是否接受。</p><p><strong>优点：</strong></p><ol><li>贝叶斯推断提供了一种直观的方式来理解不确定性和证据的权重。因为后验概率可以直接解释为在给定数据下模型或参数的概率。</li><li>贝叶斯推断允许使用先验信息，有助于引导分析并提高准确性。</li></ol><p><strong>缺点：</strong></p><ol><li>计算复杂性高，尤其是对于大数据集。MCMC方法<strong>需要长时间的运行才能确保采样的充分性</strong>。</li><li>对先验概率的选择可能对结果有影响。不合理的先验可能会导致偏差的结果。</li></ol><p><strong>代表性生物信息学软件：</strong></p><ol><li>MrBayes：可能是最广泛使用的贝叶斯系统发育分析软件。它允许使用各种进化模型，并且可以并行处理以加快计算速度。</li><li>BEAST：通常用于分子时钟和历史进化的分析。它可以结合时间信息来推断系统发育树，并估计进化参数。</li><li>PhyloBayes：这是一个专门针对复杂模型的贝叶斯系统发育分析软件，常用于蛋白质序列的系统发育重建。</li></ol><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2023.07.17    完善了一些细节。</p><p>2023.10.07    补充了如何设定起始树以增快收敛速度。</p><p>2023.11.08    根据留言版内容添加了 slurm 运行 Mrbayes 的方法链接。</p><h2 id="Mrbayes-使用方法"><a href="#Mrbayes-使用方法" class="headerlink" title="Mrbayes 使用方法"></a>Mrbayes 使用方法</h2><p>关于 Mrbayes 的安装和运行原理介绍（最详尽版）：<a href="https://github.com/NBISweden/MrBayes/blob/develop/doc/manual/Manual_MrBayes_v3.2.pdf">Mrbayes Manual</a></p><p>该 manual 在 Mrbayes 的根目录下 <code>share/doc/mrbayes/Manual_MrBayes_v3.2.pdf</code> 也能找到。</p><p>很好很易懂的其他教程：<a href="http://www.chenlianfu.com/?p=1364">贝叶斯法构建进化树 from 陈连福</a></p><p>注意：请安装<strong>支持多线程的 MPI 版 Mrbayes</strong>。</p><p>本文将以<strong>尽量最简洁</strong>的方式介绍 Mrbayes 的运行及注意事项。</p><p>使用 slurm 运行 Mrbayes 的方法：<a href="https://github.com/NBISweden/MrBayes/issues/130">https://github.com/NBISweden/MrBayes/issues/130</a></p><h3 id="运行方法"><a href="#运行方法" class="headerlink" title="运行方法"></a>运行方法</h3><p>所需要准备的文件及可用信息：</p><ul><li><code>nex</code> 格式的序列文件（不是 <code>fasta</code>）。</li><li>分区信息及对应模型（可选）。</li></ul><p>Mrbayes 也支持其他类型（例如形态学）数据的输入，但本文将侧重于序列数据（<code>DNA</code> or <code>蛋白</code>）的处理。</p><p><strong>①、</strong>使用多核运行 Mrbayes：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mpirun -np 10 mb</span></span><br></pre></td></tr></tbody></table></figure><p>命令中的 <code>10</code> 表示使用十个核，使用的核数量越多，运行速度越快。需要注意的是，如果 Mrbayes 耗尽了内存，分析会变得更慢很多。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MrBayes &gt; log start filename = mrbayes.log;</span><br><span class="line">MrBayes &gt; execute xxx.nex</span><br></pre></td></tr></tbody></table></figure><p>建议先输入 <code>log start filename = mrbayes.log;</code> 命令将 Mrbayes 的所有屏幕输出储存到文件 <code>mrbayes.log</code> 中以便后续查阅（该命令会直接覆盖目标文件，因此在断点重续时注意更改文件名），确定有相关 log 记录后再通过 <code>execute xxx.nex</code> 读取序列文件。</p><p>此后的模型选择，如果没有相关的先验理解，那么可以先通过一些方法确定自己数据所适合的模型：</p><ul><li>Mrmodeltest2</li><li>IQTREE 的 ModelFinder</li><li>PartitionFinder2（仅适用于多基因串联超矩阵序列）</li></ul><p><strong>②、</strong>确定最佳模型后，输入相关参数，以 <code>GTR substitution model with gamma-distributed rate variation across sites and a proportion of invariable sites</code> 为例（多基因串联情况见后文）：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MrBayes &gt; lset nst=6 rates=invgamma</span><br></pre></td></tr></tbody></table></figure><p>接着设置运行参数，可以以下列参数<strong>作为参考</strong>：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MrBayes &gt; mcmcp append=no ngen=100000 printfreq=1000 samplefreq=1000 nchains=10 nruns=2 savebrlens=yes checkpoint=yes checkfreq=5000;</span><br></pre></td></tr></tbody></table></figure><p>各个参数的含义及设置参考：</p><ul><li><code>append=no</code>，表示<strong>新开始</strong>一个分析，如果之前已经运行过但因为某种原因中断，可以将其调整为 <code>append=yes</code> 从上一个检查点继续运行，需要搭配 <code>checkpoint=yes</code>。</li><li><code>ngen=100000</code>，表示分析总共迭代<strong>十万代</strong>，对于小数据集一般只需几万代就可以收敛，而大数据集可能则要至少数百万代才能收敛。可以根据自己的数据集调整，如果迭代完依旧未收敛可以再添加该值继续运行（Mrbayes 会询问）。</li><li><code>printfreq=1000</code>，表示<strong>每一千代</strong>打印一次链状况到屏幕输出上。</li><li><code>samplefreq=1000</code>，表示<strong>每一千代</strong>采一次样，对于需要长时间才能收敛的大数据集而言可以将该值调高以降低采样频率，避免最终文件包含的树和参数信息过多。采样量为 <code>ngen/samplefreq</code>。</li><li><code>nchains=10</code>，表示每个运行使用<strong>十条链</strong>，总链数为 <code>nchains*nruns</code>。</li><li><code>nruns=2</code>，表示进行<strong>两个</strong>独立的分析，用于判断收敛情况。有时，提升该值（例如到 3 或 4）会对有效样本大小（ESS）增加有奇效。</li></ul><blockquote><p>链数跟 <code>nchains</code> 和 <code>nruns</code> 有关，所有的链会<strong>被平均分</strong>到各个核中，当每个分析中链数量大于 1 时（<code>nchains &gt; 1</code>）会设置一条冷链（其他均为热链），热链的存在在某些情况下对于收敛来说是必要的。在一些大数据集中热链越多收敛越快。因此设置合理的链数和内核数对于分析来说也很重要。</p><p>在 Mrbayes 的屏幕输出中，以圆括号框起来的即为热链，方括号框起来的为冷链，星号分离不同的分析。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 -- [-8849.255] (-8762.724) (-8987.103) (-8764.951) * [-8802.317] ...</span><br></pre></td></tr></tbody></table></figure></blockquote><ul><li><p><code>savebrlens=yes</code>，表示<strong>记录分支长度</strong>。如果只关注树的拓扑结构且不需分支长度信息可以设置为 <code>no</code> 节省空间。</p></li><li><p><code>checkfreq=5000</code>，表示<strong>每五千代</strong>进行一次收敛诊断，输出 ASDSF，例：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Average standard deviation of split frequencies: 0.178972</span><br></pre></td></tr></tbody></table></figure></li></ul><p>设定好所有参数以后，输入 <code>mcmc;</code> 开始分析。</p><p>在运行中及结束以后，有几个判断分析收敛程度的指标：</p><ul><li><strong>平均标准分歧</strong>（ASDSF），低于 0.01 时表明收敛良好。</li><li><strong>潜在似然</strong>（PSRF），在 <code>sump</code> 输出中出现，理想情况应该接近 1，若不是则说明可能仍未收敛。</li><li><strong>有效样本大小</strong>（ESS），在 <code>sump</code> 输出中出现，通常情况下以大于 200 作为样本量足够的标准（PhyloBayes 则为 300）。</li></ul><p>一般来说，三个指标都达标时我们才有充分的信心相信贝叶斯推断的结果足够可靠，以下是得到后两种信息的方法：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MrBayes &gt; sump relburnin=yes burninfrac=0.25;</span><br></pre></td></tr></tbody></table></figure><p>其中 <code>relburnin=yes</code> 表示使用比例，此处意为丢弃冷链中前 25% 的样本。</p><p>输出的结果中，<code>min ESS</code> 和 <code>PSRF</code> 两列即为上述要关注的两个指标。</p><p><strong>③、</strong>确保分析收敛后，可使用以下命令得到贝叶斯推断树：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MrBayes &gt; sumt conformat=Simple contype=Halfcompat relburnin=yes burninfrac=0.25;</span><br></pre></td></tr></tbody></table></figure><p>其中 <code>conformat=Simple</code> 时输出的树较为整洁，能被大多数的软件识别接受，另一种选项为 <code>Figtree</code>，会输出一个适用于 FigTree 程序的更丰富的树格式。<code>contype=Halfcompat</code> 表示输出 <code>majority rule consensus tree</code>，该参数指定为 <code>Allcompat</code> 时输出 <code>strict consensus tree</code>。关于这两者的描述可见：<a href="https://csbf.stanford.edu/phylip/consense.html">Consensus tree program</a></p><p>输出的树文件以 <code>.con.tre</code> 结尾，建议使用 Figtree 打开并转换为其他所需格式。</p><p>分享多基因串联处理方法前的一些建议：</p><ul><li><p>官方 manual 中有更多细节，包括在收敛困难时可以用于改善收敛情况的手段以及让程序的运行效率变得更高的方法等，遇到这些问题的时候可以在里面寻找到相应的解决方案。</p><ul><li><p>Mrbayes 可以从一个已有的树开始进行分析，因此可以先使用最大似然法等其他方法完成建树后，再提交给 Mrbayes 进行分析（有助于收敛）。详情可见 Manual 的第 94 页，<code>TREE block</code> 格式见 77 页。</p><blockquote><p>假设此时你已经有一个使用其他方法得到的系统发育树，那么你可以将其添加到 <code>execute xxx.nex</code> 中 <code>xxx.nex</code> 的结尾：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">begin trees;</span><br><span class="line">tree usertree = 这里输入你的树</span><br><span class="line">end;</span><br></pre></td></tr></tbody></table></figure><p>需要注意的几点：</p><p>①、输入的树若为有根树，则需要在其前面加上 [&amp;R] 进行标记。</p><p>②、输入的树可以有枝长，但一定不能有 bootstrap 值，可以通过正则表达式将其替换掉。</p><p>之后在执行时需输入以下命令：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; mcmcp nperts=3 append=no ngen=100000 printfreq=1000 samplefreq=1000 nchains=xx nruns=x savebrlens=yes checkpoint=yes checkfreq=5000;</span><br><span class="line">&gt; startvals tau=usertree;</span><br><span class="line">&gt; mcmc;</span><br></pre></td></tr></tbody></table></figure><p>因为在设定起始树后再重新设置 <code>nruns</code> 和 <code>nchains</code> 会使其失效，因此在 mcmcp 设置参数后再设定起始树，mcmcp 中新增的 <code>nperts</code> 会对起始树进行扰动从而让不同的链起始树具有略微差异，避免不同运行难以检测收敛问题。</p></blockquote></li></ul></li><li><p>Mrbayes 有运行示例，可以跟着做一遍。</p></li><li><p>关于最终收敛的判断，还可以使用 <code>Tracer</code> <code>R</code> 等软件辅助进行。</p></li></ul><h3 id="多基因串联时的分区方法"><a href="#多基因串联时的分区方法" class="headerlink" title="多基因串联时的分区方法"></a>多基因串联时的分区方法</h3><p>需准备的软件：ModelFinder（IQTREE）。</p><p>首先通过下列命令寻找最佳的分区方案和对应进化模型：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -s concatenation_ortho.fasta \</span></span><br><span class="line"><span class="language-bash">-spp IQ_partition.txt \</span></span><br><span class="line"><span class="language-bash">-m TESTMERGEONLY -mset mrbayes \</span></span><br><span class="line"><span class="language-bash">-nt AUTO -pre mybayes_aa</span></span><br></pre></td></tr></tbody></table></figure><p>此处，<code>-s</code> 指定串联得到的序列文件，<code>-spp</code> 指定对应分区文件，<code>-m</code> 和 <code>-mset</code> 将模型寻找限制在 Mrbayes 所具有的模型中并仅寻找最佳模型不进行建树。如果已有多个基因的比对文件但不知道怎么串联可见之前的文章：</p><ul><li>软件解决：<a href="https://biojuse.com/2023/04/13/JuseKit%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20%E4%B8%B2%E8%81%94%E5%BA%8F%E5%88%97%E3%80%81%E6%A0%B9%E6%8D%AEid%E6%8F%90%E5%8F%96%E5%BA%8F%E5%88%97%E3%80%81%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%B0%BE%E7%BC%80/">JuseKit（三） —— 串联序列部分</a></li><li>脚本解决：<a href="https://biojuse.com/2023/01/29/%E7%94%A8%E4%BA%8E%20IQtree%20%E7%9A%84%E5%BA%8F%E5%88%97%E4%B8%B2%E8%81%94%E6%96%B9%E6%B3%95/">用于 IQtree 的序列串联方法</a></li></ul><p>运行结束后，最佳的分区方案和进化模型会出现在以 <code>.best_scheme.nex</code> 结尾的文件中，以上述代码示例为例即为 <code>mybayes_aa.best_scheme.nex</code>。</p><p>需要注意的是，该结果并没法直接套用于 Mrbayes 中，因此还需要进一步的转换，对此，我基于 Phylosuite 的源码（详情可见脚本中所给链接）编制了一个专门用于转换的脚本：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mf2mrbayes.py</span></span><br><span class="line"><span class="comment"># Author: Juse</span></span><br><span class="line"><span class="comment"># Transform result from modelfinder to format used in Mrbayes.</span></span><br><span class="line"><span class="comment"># Usage: python mf2mrbayes.py xxx.best_scheme.nex</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">mf_result = <span class="built_in">open</span>(sys.argv[<span class="number">1</span>],<span class="string">"r"</span>)</span><br><span class="line">abs_path = os.path.abspath(sys.argv[<span class="number">1</span>])</span><br><span class="line">op_path = os.path.dirname(abs_path)</span><br><span class="line"></span><br><span class="line">numPar = <span class="number">0</span></span><br><span class="line">numMol = <span class="number">0</span></span><br><span class="line">conPar = <span class="string">''</span></span><br><span class="line">conPar_set = []</span><br><span class="line">conMol = <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reference: https://github.com/dongzhang0725/PhyloSuite/blob/master/PhyloSuite/src/Lg_Mrbayes.py</span></span><br><span class="line"><span class="comment"># Line73 - Line124</span></span><br><span class="line">dict_models = {<span class="string">"JC"</span>: <span class="string">"1"</span>, <span class="string">"F81"</span>: <span class="string">"1"</span>, <span class="string">"K80"</span>: <span class="string">"2"</span>, <span class="string">"HKY"</span>: <span class="string">"2"</span>, <span class="string">"TrNef"</span>: <span class="string">"6"</span>, <span class="string">"TrN"</span>: <span class="string">"6"</span>, <span class="string">"K81"</span>: <span class="string">"6"</span>,</span><br><span class="line">               <span class="string">"K81uf"</span>: <span class="string">"6"</span>, <span class="string">"K2P"</span>: <span class="string">"2"</span>, <span class="string">"JC69"</span>: <span class="string">"1"</span>, <span class="string">"HKY85"</span>: <span class="string">"2"</span>, <span class="string">"K3P"</span>: <span class="string">"6"</span>,</span><br><span class="line">               <span class="string">"TIMef"</span>: <span class="string">"6"</span>, <span class="string">"TIM"</span>: <span class="string">"6"</span>, <span class="string">"TVMef"</span>: <span class="string">"6"</span>, <span class="string">"TVM"</span>: <span class="string">"6"</span>, <span class="string">"SYM"</span>: <span class="string">"6"</span>, <span class="string">"GTR"</span>: <span class="string">"6"</span>, <span class="string">"TPM2"</span>: <span class="string">"6"</span>,</span><br><span class="line">               <span class="string">"TPM2uf"</span>: <span class="string">"6"</span>, <span class="string">"TPM3"</span>: <span class="string">"6"</span>, <span class="string">"TPM3uf"</span>: <span class="string">"6"</span>, <span class="string">"TIM2ef"</span>: <span class="string">"6"</span>, <span class="string">"TIM2"</span>: <span class="string">"6"</span>, <span class="string">"TIM3ef"</span>: <span class="string">"6"</span>,</span><br><span class="line">               <span class="string">"TIM3"</span>: <span class="string">"6"</span>}</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> mf_result:</span><br><span class="line">    <span class="comment"># 处理分区集信息</span></span><br><span class="line">    <span class="keyword">if</span> line.strip().startswith(<span class="string">'charset'</span>):</span><br><span class="line">        numPar += <span class="number">1</span></span><br><span class="line">        ParPos = line.split(<span class="string">'='</span>)[<span class="number">1</span>].strip()</span><br><span class="line">        conPar += <span class="string">f'charset subset<span class="subst">{numPar}</span> = <span class="subst">{ParPos}</span>\n'</span></span><br><span class="line">        conPar_set.append(<span class="string">f'subset<span class="subst">{numPar}</span>'</span>)</span><br><span class="line">    <span class="comment"># 处理分区模型信息</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">':'</span> <span class="keyword">in</span> line:</span><br><span class="line">        model_name = line.split(<span class="string">':'</span>)[<span class="number">0</span>].strip()</span><br><span class="line">        numMol += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'+G'</span> <span class="keyword">in</span> model_name <span class="keyword">and</span> <span class="string">'+I'</span> <span class="keyword">in</span> model_name:</span><br><span class="line">            rates = <span class="string">" rates=invgamma"</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="string">'+G'</span> <span class="keyword">in</span> model_name:</span><br><span class="line">            rates = <span class="string">" rates=gamma"</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="string">'+I'</span> <span class="keyword">in</span> model_name:</span><br><span class="line">            rates = <span class="string">" rates=propinv"</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            rates = <span class="string">''</span></span><br><span class="line">        model_used = model_name.split(<span class="string">'+'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> model_used <span class="keyword">in</span> dict_models:</span><br><span class="line">            <span class="comment"># nt序列</span></span><br><span class="line">            conMol += <span class="string">f'lset applyto=(<span class="subst">{numMol}</span>) nst=<span class="subst">{dict_models[model_used]}</span><span class="subst">{rates}</span>;\n'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># aa序列</span></span><br><span class="line">            conMol += <span class="string">f"lset applyto=(<span class="subst">{numMol}</span>)<span class="subst">{rates}</span>;\n"</span></span><br><span class="line">            conMol += <span class="string">f"prset applyto=(<span class="subst">{numMol}</span>) aamodelpr=fixed(<span class="subst">{model_used.lower()}</span>);\n"</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">'+F'</span> <span class="keyword">in</span> model_name:</span><br><span class="line">                conMol += <span class="string">f"prset applyto=(<span class="subst">{numMol}</span>) statefreqpr=fixed(empirical);\n"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成分区名</span></span><br><span class="line">parnam = <span class="string">f'partition Names = <span class="subst">{<span class="built_in">len</span>(conPar_set)}</span>:<span class="subst">{<span class="string">", "</span>.join(conPar_set)}</span>;\n'</span> \</span><br><span class="line">         <span class="string">f'set partition=Names;\n'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 汇总输出</span></span><br><span class="line">total_output = conPar + parnam + conMol</span><br><span class="line">total_output = total_output.replace(<span class="string">"amodelpr=fixed(jtt)"</span>, <span class="string">"amodelpr=fixed(jones)"</span>)</span><br><span class="line">total_output = total_output.replace(<span class="string">"  "</span>, <span class="string">" "</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f'<span class="subst">{op_path}</span>/Mrbayes_par.txt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> t:</span><br><span class="line">    t.write(total_output)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Finished!'</span>)</span><br></pre></td></tr></tbody></table></figure><p>用法：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python mf2mrbayes.py mybayes_aa.best_scheme.nex</span></span><br></pre></td></tr></tbody></table></figure><p>请将脚本和最佳分区文件替换成自己的路径，脚本在 <a href="https://github.com/JuseTiZ/PyScript-for-CT">GitHub</a> 可下载。</p><blockquote><p>Juse 注：</p><p>注意！上述脚本中关于模型的选择不完全正确，例如 SYM 模型虽然与 GTR 模型基本相同，但它假设所有核苷酸的频率相等，而 GTR 模型则允许这些频率不等，因此事实上在选用纯粹的 SYM 模型时理应多加一项 <code>statefreqpr=fixed(equal)</code> 进行指定。</p><p>虽然说 GTR 相比之下更灵活更复杂，往往能更好的拟合数据，但是在一些情况下这也有可能导致过拟合问题，如果推测出来的最佳模型是 SYM 而不是 GTR，那么我们就有理由去怀疑以上述标准做的正确性。</p><p>幸运的是，这个问题仅在核苷酸数据集中出现，如果你使用的是蛋白序列数据，那么就不用担心模型选择的问题，因为这些已经在相对应的参数中直接进行了选择。</p></blockquote><p>运行后，在最佳分区文件的同一目录下会出现名为 <code>Mrbayes_par.txt</code> 的文件，里面记录了 Mrbayes 指定分区和进化模型所需键入的命令，将其替换 <em><strong>运行方法 ② 部分</strong></em> 中第一部分的代码即可。</p><h2 id="关于-Mrbayes-的使用体验"><a href="#关于-Mrbayes-的使用体验" class="headerlink" title="关于 Mrbayes 的使用体验"></a>关于 Mrbayes 的使用体验</h2><p>Mrbayes 是一个操作较为复杂的系统发育推断软件，此外贝叶斯法本身也需要消耗大量计算资源，所以资源有限的情况下可以有限考虑更高效同时功能强大的最大似然法或其他方法。</p><p>此外，对于不同的数据集 Mrbayes 也会存在不同的表现，以个人经验来讲：</p><ul><li>对于小数据集，Mrbayes 会以极快的速度收敛，但是相比最大似然法依旧需要消耗更多时间。</li><li>就算收敛速度很快（ASDSF 低于 0.01 且 PSRF 接近 1），有效样本大小可能依旧不达标（可能这时所得到的树已经基本正确）。如果追求所有指标的达成可能会不得不添加一定的迭代次数。</li><li>对于大数据集，Mrbayes 可能会收敛的非常慢，这种现象随着数据缺失（gap 比例）增多而更明显。</li></ul><p>所以后面可能还会出一篇关于 PhyloBayes 的文章，它相比之下就操作更简单许多并且也有一些独特的优势。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
          <category> 建树 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 系统发育分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JuseKit（六） —— 绘制火山图</title>
      <link href="/2023/07/04/JuseKit%EF%BC%88%E5%85%AD%EF%BC%89%20%E2%80%94%E2%80%94%20%E7%BB%98%E5%88%B6%E7%81%AB%E5%B1%B1%E5%9B%BE/"/>
      <url>/2023/07/04/JuseKit%EF%BC%88%E5%85%AD%EF%BC%89%20%E2%80%94%E2%80%94%20%E7%BB%98%E5%88%B6%E7%81%AB%E5%B1%B1%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><blockquote><div id="portalContainer"></div><script src="/js/jklink.js"></script><script> generatePortalLinks(6);</script></blockquote><h2 id="更新变动及进度"><a href="#更新变动及进度" class="headerlink" title="更新变动及进度"></a>更新变动及进度</h2><p>很久没更 JuseKit，这一段时间我也时不时在想我还能搞什么出来，或者说我最应该搞什么。很多其他有用的功能事实上在别的软件诸如 <code>BTtools</code> <code>Phylosuite</code> 中都有涵盖到，所以陷入了一段瓶颈期<del>（说到底是不够勤勉）</del>。</p><p>恰巧毕业以后已经没啥事，闲余之时就思考这些事情，想着既然已经把这个坑挖开来了，那就也不要想太多直接把最开始的设想全部完成一遍再说吧。</p><p>所以这一次的更新正式上线 —— 绘制火山图。</p><p>已有功能的相关教程请见：<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">Juseの软件开发</a></p><h3 id="本次更新变动"><a href="#本次更新变动" class="headerlink" title="本次更新变动"></a>本次更新变动</h3><ul><li>修复了 ‘序列过滤’ 模块中文件不能拖拽读取的问题。</li><li>新添了日志模块，报错后将有 <code>error.log</code> 出现在程序根目录。</li><li>新增了画图模块，并完成了火山图绘制的功能。</li><li>新增的模块导致软件大小的膨胀，对于不需要绘图且内存紧张的人来说可能不是好消息。</li></ul><h3 id="目前的功能进度"><a href="#目前的功能进度" class="headerlink" title="目前的功能进度"></a>目前的功能进度</h3><ul><li>提取最长转录本。<em>（已实现）</em></li><li>根据 id 提取序列。<em>（已实现）</em></li><li>对序列的 id 进行各种处理。<em>（已实现）</em></li><li>串联序列并得到分区信息。<em>（已实现）</em></li><li>批量改后缀。<em>（已实现）</em></li><li>批量进行序列格式转换。<em>（已实现）</em></li><li>批量提取 Orthofinder 的 orthogroup 对应的 CDS 序列。<em>（已实现）</em></li><li>批量进行序列的物种数和长度过滤。<em>（已实现）</em></li><li>火山图绘制。<em>（已实现）</em></li><li>气泡图绘制。<em>（拟下一次更新）</em></li></ul><p>叠盾警告⚠：本软件解释权归属 Juse 所有，本软件能走多远具体得看 Juse 能坚持多久。</p><p>下载地址：<a href="https://github.com/JuseTiZ/JuseKit/releases">https://github.com/JuseTiZ/JuseKit/releases</a></p><h2 id="火山图绘制"><a href="#火山图绘制" class="headerlink" title="火山图绘制"></a>火山图绘制</h2><p>本文主要着重于这次更新新增的功能，其他模块请走<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">这里</a>。</p><p>火山图是差异表达分析中常出现的图片类型之一，由于其形状酷似火山喷发而得名。虽然普通的火山图并未包含太多有用的信息，但很多时候大家都会顺手画一画这个图，而这也是我水这篇文章的动机之一。</p><h4 id="要求的数据"><a href="#要求的数据" class="headerlink" title="要求的数据"></a>要求的数据</h4><p>首先，输入的文件需为 <code>csv</code> 格式的表格，表格必须包含两列内容：</p><ul><li>差异倍数 Log2FoldChange（列名必须为 <code>logFC</code> 和 <code>log2FoldChange</code> 中的一个）。</li><li>矫正 p 值（列名必须为 <code>FDR</code> 和 <code>padj</code> 中的一个，<strong>该处的列名会影响 y 轴标题</strong>）。</li></ul><p>这样设置的原因是方便 <code>DESeq2</code> 和 <code>edgeR</code> 的输出表格在转换为 <code>csv</code> 格式后能直接输入软件进行作图。</p><h4 id="绘图方法"><a href="#绘图方法" class="headerlink" title="绘图方法"></a>绘图方法</h4><p>打开软件，切换到绘图专区的 <code>火山(volcano)图</code> 模块，将会出现以下内容。</p><p><img src="/pic2/vp1.png"></p><p>通过拖拽文件到输入区框中或点击右侧按钮输入文件路径。</p><p>参数设置区中：</p><ul><li><code>|log2FC|</code> 和 <code>adj-P</code> 为筛选差异表达基因的阈值，软件会根据设置的值区分点颜色并绘制辅助线。</li><li><code>上调色</code> 和 <code>下调色</code> 分别代表上调基因和下调基因的点颜色（不推荐选黄色）。</li><li>其他图形设置中涉及到的参数如其标签所示，会影响各个元素的尺寸。</li><li>你可以先尝试一下默认参数，此后再调整参数至满意为止。</li></ul><p>点击运行会出现绘图窗口，如下图所示：</p><p><img src="/pic2/vp2.png"></p><p>你可以进行如下操作：</p><ul><li><p>通过拖动窗口调整图片的大小，或者通过上方菜单中从右边数第二个和第三个按钮调整图片。</p></li><li><p>待图片调整至满意状态，点击菜单最右方保存按钮进行保存。</p></li></ul><p>快速入门：</p><ol><li>首先想象一个合适的大小，将图片拖拽到该尺寸。</li><li>点击上方右侧第三个按钮，并点击弹出页面中的 Tight layout 将图片重新布局。</li><li>保存并输出为 <code>pdf</code> 格式（也可以输出为 <code>png</code> 等，但实测应该是 <code>pdf</code> 最清晰）。</li></ol><p><img src="/pic2/vp3.png"></p><p>最后将 <code>pdf</code> 文件转换所得图片：</p><p><img src="/pic2/Volcano_00.png"></p><p>一些注意事项：</p><ul><li>为了美观，图片的横轴为对称形式，如果出现一边较空的情况请调整 x 轴取值范围。</li><li>图片标题为文件前缀，请尽量通过修改文件名来修改标题，因为在窗口中修改会导致标题大小变化。</li><li>输出的 pdf 文件中的字体为 Type 3 格式，WPS 无法处理，可能需要用到其他处理软件如 <code>Adobe Acrobat</code>。</li><li>标签设置在图的右上角外部，如若觉得不合适可以使用选项中的 <code>(Re-)Generate automatic legend</code>，但这同样会影响标题大小。</li><li>pdf 文件是可编辑的，有部分内容不合意也可输出为 pdf 文件后调整（WPS 可以先擦除字体再插入，该字体与微软雅黑相同）。</li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>事实上我不怎么用 Python 画图，但考虑到课题组文章里的图看上去像是用 Python 画的所以这一段时间也熟悉一下会更好。</p><p>不过 JuseKit 绘制的火山图事实上还有很多地方可以继续完善，比如说轴标题和标题的粗体亦或者更精细刻度的划分（像 Prism 那样），后面如果有机会的话我也会继续完善的。</p><p>新模块的增加导致 JuseKit 的大小迎来了一次巨变，但是后面更新新的绘图方法就不会再有什么变动了，从长远角度来看的话应该是利大于弊吧。之后所有版本的 JuseKit 我都将取消 <code>.exe</code> 格式的单文件上传（只上传压缩包），因为现在配置起来有些麻烦还要多指定一些隐模块。</p><p>最后是复制黏贴：</p><p>我会争取将这些功能慢慢完善，让它成为一个具有更广适用性的软件，希望能够帮助到某些盆友，当然我个人认为最大的可能是自娱自乐。</p><p>如果这个软件帮助到您了，您可以给它一个小小的 Star 聊表支持，或者在您汇报的时候引一下 <a href="https://github.com/JuseTiZ/JuseKit/">https://github.com/JuseTiZ/JuseKit/</a> ，想必看着还是非常高端大气上档次的。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 软件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JuseKit </tag>
            
            <tag> 转录组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Astral 建树指南</title>
      <link href="/2023/06/23/Astral%20%E5%BB%BA%E6%A0%91%E6%8C%87%E5%8D%97/"/>
      <url>/2023/06/23/Astral%20%E5%BB%BA%E6%A0%91%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="系统发育分析各类方法"><a href="#系统发育分析各类方法" class="headerlink" title="系统发育分析各类方法"></a>系统发育分析各类方法</h2><p>系统发育关系重建的方法是有很多的，耳熟能详的就有最大似然法（ML）、贝叶斯推断法（BI）、邻接法（NJ，距离法的一种代表性方法）、最大简约法（MP）等等，作为一个<del>伪</del> Phylotranscriptomics 学者，学会各种建树方法也是很有必要的 —— 事实上，在很多文章中也能看到作者会采用好几种不同的方法来进行物种树重建（甚至乎会采用不同的进化模型）。这篇文讲的就是一个在研究中经常出现的软件 Astral。</p><p>在讲之前需要先明确一个概念，Astral 是一种 <strong>Coalescent-based method</strong>，这也是一个经常会在文章里面出现的词，此外还有 <strong>Concatenated-based method</strong>，关于两者的概念 ChatGPT 的说法：</p><ol><li><strong>Coalescent-based method</strong>:  Coalescent-based 方法是一种模拟基因座的共同祖先的过程来构建进化树的方法。在这种方法中，每个基因座可能有自己独立的进化历史，而不是假设整个基因组有一个统一的历史。这种方法通常用于处理物种树和基因树的不一致性，比如基因水平转移、混合和不完全谱系分选。这是一种比较复杂的方法，通常在研究种群遗传学和进化过程时使用。</li><li><strong>Concatenated-based method</strong>:  Concatenated-based 方法是将多个基因或基因片段首尾连接起来，形成一个长的序列，并使用这个长序列来构建一个单一的进化树。这种方法基于这样的假设，即所有基因或基因片段在整个进化过程中遵循相同的历史（Juse 注：关于这一点我并不完全苟同，事实上很多软件例如 IQTREE 的分区模型都会将序列分成不同的区域并为它们应用不同的进化模型）。它是一种较为简单和直接的方法，通常用于较大的数据集。</li></ol><p>换一种更简洁直白的说法，在我狭隘的理解中，前者是一种基于<strong>基因树</strong>的方法，而后者是一种基于<strong>串联序列（超矩阵）</strong>的方法。</p><h2 id="Astral-运行方法"><a href="#Astral-运行方法" class="headerlink" title="Astral 运行方法"></a>Astral 运行方法</h2><p>关于 Astral 的安装，可以前往其 github ：<a href="https://github.com/smirarab/ASTRAL">Astral github</a></p><p>关于 Astral 的运行，在这里你或许能得到<strong>最全面</strong>的了解：<a href="https://github.com/smirarab/ASTRAL/blob/master/astral-tutorial.md">Astral tutorial</a></p><p>本文将以<strong>尽量最简洁</strong>的方式介绍 Astral 的运行及注意事项。</p><p>正如前文所说，Astral 是一种基于基因树的物种树重建方法，所以它是需要一组基因树作为输入来推断物种树的，原理大致如下：</p><p>汇总多个基因树的信息重建物种树，并使得这个物种树与这组基因树的 Quartet Score 最大化（在考虑四个物种时，一棵树可以有三种不同的拓扑结构，Astral 则会尝试寻找一个最能解释基因树数据的物种树拓扑结构）。</p><p>关于基因树，大部分文章都是使用 ML 方法（可选软件有 <code>IQTREE</code> or <code>RAxML</code>）推断得到的，假设我们现在已经有一组基因树并且它们以 <code>.treefile</code> 结尾，那么我们可以用这种方法将它们合并：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> *treefile &gt;&gt; all.treefile</span></span><br></pre></td></tr></tbody></table></figure><p>然后使用 Astral 进行物种树重建（将 <code>astral.5.7.8.jar</code> 替换成自己的版本及路径）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">java -jar astral.5.7.8.jar -i all.treefile -o astral.treefile 2&gt; astral.log</span></span><br></pre></td></tr></tbody></table></figure><p>最后生成的文件中，<code>astral.treefile</code> 为 Astral 的建树结果，<code>astral.log</code> 则包括各种信息。</p><p>在 <code>astral.log</code> 中有一行需要注意：</p><ul><li>Final normalized quartet score is: 0.xxxx</li></ul><p>这一行后的数字代表有多少基因树中的 quartet tree 出现在最终的物种树中，这一指标也可以作为物种树和基因树间一致性的衡量标准，如果其值过低，则可能表明了严重的 ILS/Introgression (不完全谱系分选 / 渐渗，皆为基因树不一致的重要成因) 现象。</p><p>也有方法可以改善 Quartet Score —— 修剪掉基因树中自展值低的分支，可以通过 <code>nw_ed</code> 完成该操作：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda install -c bioconda newick_utils</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nw_ed all.treefile <span class="string">'i &amp; b&lt;=10'</span> o &gt; all-BS10.treefile <span class="comment"># 自展值低于 10 则剪去</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">java -jar astral.5.7.8.jar -i all-BS10.treefile -o astral-BS10.treefile 2&gt; astral-BS10.<span class="built_in">log</span></span></span><br></pre></td></tr></tbody></table></figure><p>注：conda 安装不成功的也可前往<a href="https://github.com/tjunier/newick_utils">其 github 页面</a>并根据引导使用 <code>make</code> 安装。</p><h2 id="其他可能需要注意的地方"><a href="#其他可能需要注意的地方" class="headerlink" title="其他可能需要注意的地方"></a>其他可能需要注意的地方</h2><p>关于这一部分更详尽也请前往 Astral github tutorial 页面。</p><p>①、Astral 并不通过 bootstrapping 得到分支支持率，而是使用了一种称为局部后验概率的方法进行计算，这种计算方法得到的支持率描述了给定的 quartet tree 拓扑在基因树数据中的支持程度（可以简单地将其理解成物种树中这个分支的拓扑结构受基因树拓扑的支持程度）。当然我们也可以选择使用 bootstrapping 方法得到支持率（这个情况下我们也可以叫它自展值）：</p><p>指定 <code>-b</code> 和 <code>-r</code> 参数，其中 <code>-b</code> 指定某个文件，该文件中每一行都指定一个基因树自举文件的路径；<code>-r</code> 指定重复次数，默认为 100。</p><p>注：作者特意表明了在他们所探索的情况中，局部后验概率方法是比 bootstrapping 更可靠的。</p><p>②、关于内存的问题：如果数据集过大（包含非常多的物种或基因树），那么可能就需要给 Java 提供更多的可用内存确保 Astral 能正常运行：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">java -Xmx3000M -jar astral.5.7.8.jar -i in.tree</span></span><br></pre></td></tr></tbody></table></figure><p>其中 <code>-Xmx3000M</code> 指定了 3GB 的可用内存，也可以直接替换成  <code>-Xmx3G</code> 等。该值可视自身情况进行调整。其他一些基于 Java 开发的生信软件也可以通过该方法分配内存。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>Astral 本身的操作难度并不高，但大道至简，这并不妨碍它出现在各个文章之中并作为代表物种树使用。</p><p>如果数据集有着严重的 ILS 和 Introgression 现象，那么就需要谨慎地对待 Astral 的结果。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
          <category> 建树 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 系统发育分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JuseKit（五） —— 用于系统发育分析的序列过滤</title>
      <link href="/2023/05/14/JuseKit%EF%BC%88%E4%BA%94%EF%BC%89%20%E2%80%94%E2%80%94%20%E7%94%A8%E4%BA%8E%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E5%88%86%E6%9E%90%E7%9A%84%E5%BA%8F%E5%88%97%E8%BF%87%E6%BB%A4/"/>
      <url>/2023/05/14/JuseKit%EF%BC%88%E4%BA%94%EF%BC%89%20%E2%80%94%E2%80%94%20%E7%94%A8%E4%BA%8E%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E5%88%86%E6%9E%90%E7%9A%84%E5%BA%8F%E5%88%97%E8%BF%87%E6%BB%A4/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><blockquote><div id="portalContainer"></div><script src="/js/jklink.js"></script><script> generatePortalLinks(5);</script></blockquote><h2 id="更新变动及进度"><a href="#更新变动及进度" class="headerlink" title="更新变动及进度"></a>更新变动及进度</h2><p>貌似距离上次更新已经有一段时日了，这一段时间忙完了各种事儿，也算迎来了本科生涯的最后一段悠闲时光。正好趁着这股兴致，把新的 Jusekit 文章给肝出来。</p><p>已有功能的相关教程请见：<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">Juseの软件开发</a></p><p>Python 代码实现：<a href="https://biojuse.com/2023/02/17/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94%20%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E5%88%86%E6%9E%90/">比较转录组分析（七）—— 系统发育分析</a></p><h3 id="本次更新变动"><a href="#本次更新变动" class="headerlink" title="本次更新变动"></a>本次更新变动</h3><ul><li>新增序列过滤功能。</li><li>序列串联输出的 log 文件新增 gap 信息。</li><li>新增了部分按钮选择文件时的后缀选项。</li></ul><h3 id="目前的功能进度"><a href="#目前的功能进度" class="headerlink" title="目前的功能进度"></a>目前的功能进度</h3><ul><li>提取最长转录本。<em>（已实现）</em></li><li>根据 id 提取序列。<em>（已实现）</em></li><li>对序列的 id 进行各种处理。<em>（已实现）</em></li><li>串联序列并得到分区信息。<em>（已实现）</em></li><li>批量改后缀。<em>（已实现）</em></li><li>批量进行序列格式转换。<em>（已实现）</em></li><li>批量提取 Orthofinder 的 orthogroup 对应的 CDS 序列。<em>（已实现）</em></li><li>批量进行序列的物种数和长度过滤。<em>（已实现）</em></li></ul><p>叠盾警告⚠：本软件解释权归属 Juse 所有，本软件能走多远具体得看 Juse 能坚持多久。</p><p>下载地址：<a href="https://github.com/JuseTiZ/JuseKit/releases">https://github.com/JuseTiZ/JuseKit/releases</a></p><h2 id="序列过滤"><a href="#序列过滤" class="headerlink" title="序列过滤"></a>序列过滤</h2><p>本文主要着重于这次更新新增的功能，其他模块请走<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">这里</a>。</p><h3 id="序列过滤功能"><a href="#序列过滤功能" class="headerlink" title="序列过滤功能"></a>序列过滤功能</h3><p>为什么需要这个功能？多个基因的联合建树能够揭示出准确的系统发育关系，不过这个过程中也需要一定的筛选和过滤。</p><p>比如说，如果某个基因的比对太短，那么它可能根本无法提供什么有价值的信息。亦或者是某个比对所包含的物种数量过少，某条序列的 gap 占比过多等……</p><p>这些时候，舍弃某些不符合要求的比对和序列，保留下那些信息量足够的基因进行串联建树，一方面可以提高系统发育分析的分辨率，另一方面也可以提高后续相关软件的运行效率等。</p><p>基于此，Jusekit 中加入了 <code>序列过滤</code> 功能，以实现以上具体想法。</p><p>操作流程：</p><p><img src="/pic2/sf1.png"></p><p>各个过滤参数的含义：</p><ul><li>比对最短长度：默认为 <code>80</code>，若比对的长度小于 <code>80bp/aa</code> 则直接丢弃。</li><li>gap 符号：默认为 <code>-</code>，用于计算序列去除 gap 后的长度。</li><li>序列去除 gap 后最短长度：默认为 <code>80</code>，若比对中的序列去除 gap 后长度小于 <code>80bp/aa</code> 则丢弃。</li><li>物种标识：默认为 <code>@</code>，用于识别比对所包含的物种数量，物种标识的相关定义可看以往教程。</li><li>比对包含最少物种数量：默认为 <code>1</code>，当序列经过所有过滤后，所包含的物种低于该数时，丢弃该比对。该值可设置为 <code>研究中所包含的物种数 / 2</code> （常见的标准）。</li></ul><p>最后过滤的所有信息可以在输出文件夹的 <code>filter.log</code> 中查看。</p><h3 id="序列串联-log-新增-gap-率"><a href="#序列串联-log-新增-gap-率" class="headerlink" title="序列串联 log 新增 gap 率"></a>序列串联 log 新增 gap 率</h3><p>如题所示，在新更新的 Jusekit v0.6 中，序列串联后产生的 log 中将包含每个物种的 gap 率。</p><p><img src="/pic2/sf2.png"></p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>我会争取将这些功能慢慢完善，让它成为一个具有更广适用性的软件，希望能够帮助到某些盆友，当然我个人认为最大的可能是自娱自乐。</p><p>如果这个软件帮助到您了，您可以给它一个小小的 Star 聊表支持，或者在您汇报的时候引一下 <a href="https://github.com/JuseTiZ/JuseKit/">https://github.com/JuseTiZ/JuseKit/</a> ，想必看着还是非常高端大气上档次的。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 软件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JuseKit </tag>
            
            <tag> 转录组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于 PAML 的一二三事</title>
      <link href="/2023/05/04/%E5%85%B3%E4%BA%8E%20PAML%20%E7%9A%84%E4%B8%80%E4%BA%8C%E4%B8%89%E4%BA%8B/"/>
      <url>/2023/05/04/%E5%85%B3%E4%BA%8E%20PAML%20%E7%9A%84%E4%B8%80%E4%BA%8C%E4%B8%89%E4%BA%8B/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="PAML-简介"><a href="#PAML-简介" class="headerlink" title="PAML 简介"></a>PAML 简介</h2><p>PAML，全称 Phylogenetic Analysis by Maximum Likelihood，由国人大佬杨子恒教授开发，是一款用于进行各种系统发育分析的软件包。里面的诸多模型可以说是系统发育学文章里的常客，其所涵盖的功能包括但不限于：</p><ul><li>重建系统发育树。</li><li>检测选择压力。</li><li>估计进化速率。</li><li>估计物种或基因的分歧时间。</li></ul><p>想要最详细地了解这个软件，可直接下载官方 tutorial 进行啃读：</p><blockquote><p>PAML Manual：<a href="http://abacus.gene.ucl.ac.uk/software/pamlDOC.pdf">http://abacus.gene.ucl.ac.uk/software/pamlDOC.pdf</a></p><p>PAML FAQs：<a href="http://abacus.gene.ucl.ac.uk/software/pamlFAQs.pdf">http://abacus.gene.ucl.ac.uk/software/pamlFAQs.pdf</a></p></blockquote><p>也有其他博主写的精细介绍，详见：<a href="https://www.jianshu.com/p/152a6216c794">PAML-discussion-group from 简书</a></p><p>如果有些报错问题或者运行问题在网上找不到解释，也许可以看看 <a href="https://groups.google.com/g/pamlsoftware">PAML 的谷歌论坛</a>。</p><p>提示，本文将基于 <em><strong>linux</strong></em> 系统的操作进行讲解。</p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2023.05.20    补充了支位点模型的局限性。</p><p>2023.06.21    补充了自由比模型的相关内容。</p><p>2023.06.24    补充了自由比模型的批量运行方法。</p><p>2023.07.03    补充了 <code>mcmctree</code> 的运行介绍，精简部分内容。</p><p>2023.07.19    补充了 <code>mcmctree</code> 的相关内容，修改了后记内容。</p><p>2023.08.19    补充了正选择检测（支位点模型）的内容。</p><h2 id="正选择检测（支位点模型）"><a href="#正选择检测（支位点模型）" class="headerlink" title="正选择检测（支位点模型）"></a>正选择检测（支位点模型）</h2><p>如果想要系统地了解正选择检测的各种方法及其局限性等相关内容，可以参见官方出版论文教程：<a href="https://academic.oup.com/mbe/article/40/4/msad041/7140562?searchresult=1&amp;login=false#403497381">初学者的 PAML 正选择检测指南</a>。</p><p>该部分侧重于检测<strong>特定分支</strong>在<strong>特定位点</strong>上的正选择（因此被称作支位点模型 <strong>Branch-Site Model</strong>）。其他的还有：</p><ul><li>支模型（Branch model），检测作用于<strong>特定谱系</strong>的正选择，<code>m0 vs branch model</code>。</li><li>位点模型（Site model），检测作用于基因中<strong>位点</strong>的正选择，可选 <code>M0 vs M1a</code> <code>M1a vs M2a</code> 及 <code>M7 vs M8</code>。</li></ul><h3 id="原理及运行"><a href="#原理及运行" class="headerlink" title="原理及运行"></a>原理及运行</h3><p>这里首先详细讲一讲它的原理，<strong>PAML tutorial</strong> 中说法：</p><blockquote><p>The <em>branch-site</em> model A (see the section Codon substitution models above) is specified by using both variables model and NSsites. </p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Model A: model = 2, NSsites = 2, fix_omega = 0</span><br></pre></td></tr></tbody></table></figure><p>This is the alternative model for the branch-site test of positive selection. The null model is also the branch-site model A but with <em>ω</em>2 = 1 fixed, specified by </p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Model A1: model = 2, NSsites = 2, fix_omega = 1, omega = 1</span><br></pre></td></tr></tbody></table></figure></blockquote><p>简单来说，正选择检测的原理就是拿出两个模型（一个认为有正选择，一个认为没有）的最大似然对数值，通过似然比检验计算 p 值。</p><p>具体说法（可以跳过，无伤大雅）：</p><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">正选择检测原理</summary><div class="toggle-content"><p>支位点模型的基本原理是允许树的不同分支和序列的不同部位之间 ω 发生变化，该模型将树的分支分为前景分支（树文件中用特殊符号标记）和背景分支。</p><p>在前景分支上，某些位点可能发生正选择，而在背景分支上，这些位点可能没有受到正选择的影响。因此，支位点模型允许我们在指定的前景分支上检测正选择信号：</p><blockquote><p>The branch test (<a href="javascript:;">Yang 1998</a>) assigns two different <em>ω</em> parameters (<em>ω</em>F and <em>ω</em>B) to the foreground and background branches on the tree. The null hypothesis of the test is <em>H</em>0: <em>ω</em>F = 1, whereas the alternative is <em>H</em>1: <em>ω</em>F ≥ 1, with <em>ω</em>B to be a free parameter under both hypotheses.</p></blockquote><p>在实际应用中，支位点模型通常包含两个子模型：一个所有分支都中性进化（ω = 1）的零模型（A1）和一个认为前景枝存在正选择（ω &gt; 1）的备择模型（A2）。通过计算两个模型的最大似然值并进行似然比检验，评估正选择的统计显著性。</p><p>似然比检验的大致原理是：比较两个模型的最大似然值，从而确定哪个模型更能解释观测数据。步骤大致有：</p><ol><li>分别为零模型和备择模型计算最大似然值（给定模型下观测数据的最大概率）。</li><li>计算似然比统计量（两模型最大似然值之差的两倍）。</li><li>似然比统计量服从卡方分布，其自由度等于两个模型之间的参数差。根据卡方分布的临界值和实际计算得到的似然比统计量，确定拒绝还是接受零假设。</li></ol></div></details><p>对一个基因进行正选择检测需要运行两次 PAML，并根据输出文件中的最大似然值和自由度进行卡方检验，判断其是否存在显著正选择：</p><p>Model A1：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">seqfile = 这里要填你的序列文件路径</span><br><span class="line">treefile = 这里要填你的树文件路径，要检测是否有正选择的分支记得标记</span><br><span class="line">outfile = 这里要填你的输出文件，PAML会将结果输出到此处</span><br><span class="line">noisy = 9   </span><br><span class="line">verbose = 0   </span><br><span class="line">runmode = 0  </span><br><span class="line">seqtype = 1   </span><br><span class="line">CodonFreq = 2   </span><br><span class="line">clock = 0</span><br><span class="line">aaDist = 0</span><br><span class="line">model = 2</span><br><span class="line">NSsites = 2   </span><br><span class="line">icode = 0   </span><br><span class="line">Mgene = 0</span><br><span class="line">fix_kappa = 0   </span><br><span class="line">kappa = 2   </span><br><span class="line">fix_omega = 1   </span><br><span class="line">omega = 1   </span><br><span class="line">fix_alpha = 1   </span><br><span class="line">alpha = .0  </span><br><span class="line">Malpha = 0   </span><br><span class="line">ncatG = 3   </span><br><span class="line">getSE = 0   </span><br><span class="line">RateAncestor = 0 </span><br><span class="line">fix_blength = 0  </span><br><span class="line">method = 0   </span><br><span class="line">Small_Diff = .45e-6</span><br><span class="line">cleandata = 1</span><br></pre></td></tr></tbody></table></figure><p>这些参数的含义（可以跳过，无伤大雅）：</p><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">各参数具体含义</summary><div class="toggle-content"><p><code>noisy</code> ：信息打印级别。</p><p><code>verbose</code> ：输出信息详细程度。</p><p><code>runmode</code> ：设置为 0，PAML 将使用你提供的进化树。</p><p><code>seqtype</code> ：设置为 1，指定核苷酸序列。</p><p><code>CodonFreq</code> ：密码子频率模型，设置为 2 时可以捕获第三个密码子位置的碱基偏好，而这通常与选择压力较低的密码子部位有关。</p><p><code>clock</code> ：分子钟模型，支位点模型不接受其他选择。</p><p><code>aaDist </code>： 氨基酸替换模型，该处不使用。</p><p><code>model </code> 和 <code>NSsites</code>，设置为 2 代表支位点模型。</p><p><code>icode</code> ：遗传密码表，0 是标准密码表，需根据自身情况修改。</p><p><code>Mgene</code> ：多基因模型，0 表示使用单一模型。针对所有基因使用相同的模型。</p><p><code>fix_kappa</code>：是否固定kappa值，0 表示不固定。这允许程序自动估计转换/颠换比率。</p><p><code>kappa</code>：初始 kappa 值。程序会自动调整 kappa 值以找到最佳估计。</p><p><code>fix_omega</code>：是否固定 omega 值，1 表示固定。</p><p><code>omega</code>：初始 omega 值。</p><p><code>fix_alpha</code>：是否固定 alpha 值，1 表示固定。意味着不考虑不同位点之间的替换速率变异。</p><p><code>alpha</code>：初始 alpha 值。表示不使用 Gamma 分布模型</p><p><code>Malpha</code>：混合 Gamma 分布，0 表示不使用。</p><p><code>ncatG</code>：Gamma 分布类别数。没有使用 Gamma 分布模型，所以类别数设置为 1 即可。</p><p><code>getSE</code>：是否计算参数的标准误差，0 表示不计算。</p><p><code>RateAncestor</code>：是否计算祖先节点的替换速率，0 不计算，如果想顺便重建祖先序列的话也可以调 1，就是慢了一些。<strong>注：调 1 方便后续比较祖先序列确定平行替换</strong>。</p><p><code>fix_blength</code>：是否固定分支长度，0 表示不固定。这允许程序自动估计分支长度。</p><p><code>method</code>：计算最大似然值的方法，表示使用一阶梯度法。这是 codeml 中常用的方法，适用于大多数情况。</p><p><code>Small_Diff</code>：用于收敛判断的阈值。EasyCodeml 同款配置。</p><p><code>cleandata</code> ：是否删除缺失数据和停止密码子，1 表示要删除，具体如何选择看研究需求。</p></div></details><p>Model A2：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">seqfile = 这里要填你的序列文件路径</span><br><span class="line">treefile = 这里要填你的树文件路径，要检测是否有正选择的分支记得标记</span><br><span class="line">outfile = 这里要填你的输出文件，PAML 会将结果输出到此处</span><br><span class="line">noisy = 9   </span><br><span class="line">verbose = 0   </span><br><span class="line">runmode = 0  </span><br><span class="line">seqtype = 1   </span><br><span class="line">CodonFreq = 2   </span><br><span class="line">clock = 0</span><br><span class="line">aaDist = 0</span><br><span class="line">model = 2</span><br><span class="line">NSsites = 2   </span><br><span class="line">icode = 0   </span><br><span class="line">Mgene = 0</span><br><span class="line">fix_kappa = 0   </span><br><span class="line">kappa = 2   </span><br><span class="line">fix_omega = 0 </span><br><span class="line">omega = 1.5   </span><br><span class="line">fix_alpha = 1   </span><br><span class="line">alpha = .0  </span><br><span class="line">Malpha = 0   </span><br><span class="line">ncatG = 3   </span><br><span class="line">getSE = 0   </span><br><span class="line">RateAncestor = 0 </span><br><span class="line">fix_blength = 0  </span><br><span class="line">method = 0   </span><br><span class="line">Small_Diff = .45e-6</span><br><span class="line">cleandata = 1</span><br></pre></td></tr></tbody></table></figure><p>相较于 A1，它的变动有：</p><ul><li><code>fix_omega</code> 变成 0，这允许 ω 自由估计，这时 <code>omega</code> 的值将作为优化过程的起点。</li><li><code>omega</code> 变成 1.5，表示在优化过程开始时，ω 的初始值为 1.5。</li></ul><p>在不同的 paper 中或许会看到不同的 omega 值（常是 1.5 或 2），但这一般无关紧要，因为在后续的优化过程中，该值会变化以最大化似然。这个值只是一个起始点，并不代表最终 ω。选择一个合适的初始值只是有助于加速优化过程并提高收敛的稳定性。但大多数情况下，不同的初始值通常会收敛到相似的结果。</p><p>运行（上面两个模型分别操作，控制文件中就是上面两个模型的具体参数）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">codeml xxx(你的控制文件)</span></span><br></pre></td></tr></tbody></table></figure><p>不同模型跑出的结果（outfile）的似然值一般都是这种样子：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lnL(ntime:  7  np: 11):  -1225.318164</span><br></pre></td></tr></tbody></table></figure><p>查找 lnl 就能找到，两个文件里都有，记录下两个文件中的 <code>np</code> 和 <code>lnL</code> （上例中为 11 和 -1225.318164）。计算 D 和自由度：</p><ul><li>D = 2 | lnL1 - lnL0 |</li><li>df = np1 - np0</li></ul><blockquote><p>关于此处有个问题，从数学角度出发，使用似然比检验时更高的似然值意味着模型更能适应或描述数据，因此正选择模型（Model A2）的似然值显著高于中性模型（Model A1）时才应该能够成为数据中存在正选择的证据。</p><p>但是不管是网上的各个教程还是 EasyCodeml 中，对于似然值之差都取绝对值进行似然比检验，这导致有些时候正选择模型的似然值就算更低也能得到统计显著性（这种情况虽然少但确实会发生），这又给我带来了两个疑问：</p><ul><li>Model A2 包含更多的参数，这提供了更多的自由度来捕捉数据中的模式，因此它的似然值理应更高（或至少一样）。</li><li>为什么两个模型存在显著差异（不管哪个拟合的更好）就能说明存在显著正选择？</li></ul><p>目前我并不确定具体结论，现已在 PAML discussion group 上发贴求助，等得到具体回答以后会对文章内容进行修改。</p></blockquote><p>然后使用卡方检验，这里可以用 python scipy 包中的 <code>scipy.stats.chi2</code> 进行。</p><p>以上就是整个正选择检测的流程，接下来放一个脚本，该脚本可以用于批量进行正选择检测，该脚本原作者是一个<a href="">简书</a>博主，这里对他的脚本进行了一定的更改以适应合理的批量处理：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># callCodeml.py</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> chi2</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">help_info</span>() -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"This script is used to call codeML.\nUsage: python3 callCodeml.py Dir treeFile cpuNum\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>() -&gt; <span class="type">Tuple</span>[<span class="built_in">str</span>, <span class="type">List</span>[<span class="built_in">str</span>], <span class="built_in">str</span>, <span class="built_in">int</span>]:</span><br><span class="line">    args = sys.argv[<span class="number">1</span>:]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(args) &lt; <span class="number">3</span>:</span><br><span class="line">        help_info()</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    dir_path = os.path.abspath(args[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dir_path):</span><br><span class="line">        help_info()</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    tree_file = os.path.abspath(args[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cpu_num = <span class="built_in">int</span>(args[<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        help_info()</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    seqs = [x <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(dir_path) <span class="keyword">if</span> <span class="keyword">not</span> x.startswith(<span class="string">'.'</span>)]</span><br><span class="line">    <span class="keyword">return</span> dir_path, seqs, tree_file, cpu_num</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dir</span>(<span class="params">base_dir: <span class="built_in">str</span>, name: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    dirs = [</span><br><span class="line">        <span class="string">f'<span class="subst">{base_dir}</span>/'</span>,</span><br><span class="line">        <span class="string">f'<span class="subst">{base_dir}</span>/<span class="subst">{name}</span>'</span>,</span><br><span class="line">        <span class="string">f'<span class="subst">{base_dir}</span>/<span class="subst">{name}</span>/null'</span>,</span><br><span class="line">        <span class="string">f'<span class="subst">{base_dir}</span>/<span class="subst">{name}</span>/alte'</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">for</span> dir_path <span class="keyword">in</span> dirs:</span><br><span class="line">        os.makedirs(dir_path, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_ctl</span>(<span class="params">base_dir: <span class="built_in">str</span>, dir_path: <span class="built_in">str</span>, name: <span class="built_in">str</span>, tree_file: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    ctl_null = <span class="string">f'''</span></span><br><span class="line"><span class="string">    seqfile = <span class="subst">{dir_path}</span>/<span class="subst">{name}</span></span></span><br><span class="line"><span class="string">    treefile = <span class="subst">{tree_file}</span></span></span><br><span class="line"><span class="string">    outfile = <span class="subst">{base_dir}</span>/<span class="subst">{name}</span>/null/<span class="subst">{name}</span>_null.res</span></span><br><span class="line"><span class="string">    noisy = 9</span></span><br><span class="line"><span class="string">    verbose = 0</span></span><br><span class="line"><span class="string">    runmode = 0</span></span><br><span class="line"><span class="string">    seqtype = 1</span></span><br><span class="line"><span class="string">    CodonFreq = 2</span></span><br><span class="line"><span class="string">    clock = 0</span></span><br><span class="line"><span class="string">    aaDist = 0</span></span><br><span class="line"><span class="string">    model = 2</span></span><br><span class="line"><span class="string">    NSsites = 2</span></span><br><span class="line"><span class="string">    icode = 0</span></span><br><span class="line"><span class="string">    Mgene = 0</span></span><br><span class="line"><span class="string">    fix_kappa = 0</span></span><br><span class="line"><span class="string">    kappa = 2</span></span><br><span class="line"><span class="string">    fix_omega = 1</span></span><br><span class="line"><span class="string">    omega = 1</span></span><br><span class="line"><span class="string">    fix_alpha = 1</span></span><br><span class="line"><span class="string">    alpha = .0</span></span><br><span class="line"><span class="string">    Malpha = 0</span></span><br><span class="line"><span class="string">    ncatG = 3</span></span><br><span class="line"><span class="string">    getSE = 0</span></span><br><span class="line"><span class="string">    RateAncestor = 0</span></span><br><span class="line"><span class="string">    fix_blength = 0</span></span><br><span class="line"><span class="string">    method = 0</span></span><br><span class="line"><span class="string">    Small_Diff = .45e-6</span></span><br><span class="line"><span class="string">    cleandata = 1</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    ctl_alte = ctl_null.replace(<span class="string">f'<span class="subst">{base_dir}</span>/<span class="subst">{name}</span>/null/<span class="subst">{name}</span>_null.res'</span>, <span class="string">f'<span class="subst">{base_dir}</span>/<span class="subst">{name}</span>/alte/<span class="subst">{name}</span>_alte.res'</span>)\</span><br><span class="line">                       .replace(<span class="string">'fix_omega = 1'</span>, <span class="string">'fix_omega = 0'</span>)\</span><br><span class="line">                       .replace(<span class="string">'omega = 1'</span>, <span class="string">'omega = 1.5'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f'<span class="subst">{base_dir}</span>/<span class="subst">{name}</span>/null/null_profile.ctl'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(ctl_null)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f'<span class="subst">{base_dir}</span>/<span class="subst">{name}</span>/alte/alte_profile.ctl'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(ctl_alte)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_create</span>(<span class="params">base_dir: <span class="built_in">str</span>, dir_path: <span class="built_in">str</span>, seqs: <span class="type">List</span>[<span class="built_in">str</span>], tree_file: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> seqs:</span><br><span class="line">        create_dir(base_dir, name)</span><br><span class="line">        create_ctl(base_dir, dir_path, name, tree_file)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f'<span class="subst">{base_dir}</span>/codeml.sh'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(<span class="string">'''</span></span><br><span class="line"><span class="string">#!/bin/bash</span></span><br><span class="line"><span class="string">list=$(ls -1)</span></span><br><span class="line"><span class="string">count=$(ls -1 | wc -l)</span></span><br><span class="line"><span class="string">echo "Total number: $count"</span></span><br><span class="line"><span class="string">dir=$(pwd)</span></span><br><span class="line"><span class="string">echo "Start Now..."</span></span><br><span class="line"><span class="string">for i in $list</span></span><br><span class="line"><span class="string">do</span></span><br><span class="line"><span class="string">    {</span></span><br><span class="line"><span class="string">    echo "cd $dir/$i/null; codeml ./null_profile.ctl &gt; log.txt; cd $dir/$i/alte; codeml ./alte_profile.ctl &gt; log.txt" &gt;&gt; paml_command</span></span><br><span class="line"><span class="string">    }</span></span><br><span class="line"><span class="string">done</span></span><br><span class="line"><span class="string">wait</span></span><br><span class="line"><span class="string">'''</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"<span class="subst">{time.strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>)}</span> Files created.\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_codeml</span>(<span class="params">base_dir: <span class="built_in">str</span>, num: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    os.chdir(base_dir)</span><br><span class="line">    os.system(<span class="string">'bash codeml.sh'</span>)</span><br><span class="line">    os.system(<span class="string">f'cat paml_command | parallel --no-notice -j <span class="subst">{num}</span>'</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"\n<span class="subst">{time.strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>)}</span> Codeml Done...\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_res</span>(<span class="params">path: <span class="built_in">str</span></span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">int</span>, <span class="built_in">float</span>]:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        t = f.read()</span><br><span class="line">        kappa = <span class="built_in">float</span>(re.findall(<span class="string">r"kappa\s*=\s*([\d\.]+)"</span>, t)[<span class="number">0</span>])</span><br><span class="line">        lnL = <span class="built_in">float</span>(re.findall(<span class="string">r'lnL\s*\(.*\)\s*=\s*([-\d\.]+)'</span>, t)[<span class="number">0</span>])</span><br><span class="line">        np = <span class="built_in">int</span>(re.findall(<span class="string">r'lnL\s*\(.*\)\s*=\s*[-\d\.]+\s*\(\s*(\d+)'</span>, t)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> lnL, np, kappa</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_stat</span>(<span class="params">base_dir: <span class="built_in">str</span>, name: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        path_alte = <span class="string">f'<span class="subst">{base_dir}</span>/<span class="subst">{name}</span>/alte/<span class="subst">{name}</span>_alte.res'</span></span><br><span class="line">        path_null = <span class="string">f'<span class="subst">{base_dir}</span>/<span class="subst">{name}</span>/null/<span class="subst">{name}</span>_null.res'</span></span><br><span class="line">        </span><br><span class="line">        lnL0, np0, _ = get_res(path_null)</span><br><span class="line">        lnL1, np1, kappa = get_res(path_alte)</span><br><span class="line">        </span><br><span class="line">        lnl = <span class="built_in">abs</span>(lnL0 - lnL1) * <span class="number">2</span></span><br><span class="line">        np = <span class="built_in">abs</span>(np0 - np1)</span><br><span class="line">        pvalue = <span class="number">1</span> - chi2.cdf(lnl, np)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f'<span class="subst">{base_dir}</span>/result.tsv'</span>, <span class="string">'a'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">f"<span class="subst">{name}</span>\t<span class="subst">{lnL0}</span>\t<span class="subst">{lnL1}</span>\t<span class="subst">{np0}</span>\t<span class="subst">{np1}</span>\t<span class="subst">{kappa}</span>\t<span class="subst">{pvalue}</span>\n"</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"<span class="subst">{time.strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>)}</span> <span class="subst">{name}</span> failed to stats: <span class="subst">{e}</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>() -&gt; <span class="literal">None</span>:</span><br><span class="line">    start_time = time.strftime(<span class="string">'%Y%m%d-%H%M%S'</span>)</span><br><span class="line">    base_dir = <span class="string">f"<span class="subst">{os.getcwd()}</span>/WorkingDir_<span class="subst">{start_time}</span>"</span></span><br><span class="line">    </span><br><span class="line">    dir_path, seqs, tree_file, cpu_num = get_args()</span><br><span class="line">    run_create(base_dir, dir_path, seqs, tree_file)</span><br><span class="line">    run_codeml(base_dir, cpu_num)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> seqs:</span><br><span class="line">        run_stat(base_dir, name)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'Total time used: <span class="subst">{time.time() - start_time:<span class="number">.2</span>f}</span> seconds\n'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    t0 = time.time()</span><br><span class="line">    main()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'Total time used: <span class="subst">{time.time() - t0:<span class="number">.2</span>f}</span> seconds\n'</span>)</span><br></pre></td></tr></tbody></table></figure><p>相较于原来的版本，变动有：</p><ul><li>使用了 <code>parallel</code> 来控制并行命令的数量，因为一开始会对所有的序列文件同时开始处理，但如果用到了很多（比如几千个）序列的话这样做就会把 CPU 挤爆，所以加上一些控制的手段保证能几十个几十个来运行。</li><li>把文件名识别去除了（之前貌似有限制以特定字符开头或结尾啥的），过程中可能会有部分报错但不会影响结果。</li></ul><p>运行方式：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python callCodeml.py Dir treeFile numofcpu</span></span><br></pre></td></tr></tbody></table></figure><ul><li><code>Dir</code> 指定存放 PAML 格式序列文件的文件夹。</li><li><code>treefile</code> 指定物种树。</li><li><code>numofcpu</code> 指定预计使用的线程数。</li></ul><p>所有结果文件会输出在当前目录下以 <code>WorkingDir</code> 开头的文件夹中，所有结果的统计将出现在该文件夹下的 <code>result.tsv</code> 中。</p><p>运行前可能需要注意的事项：</p><ul><li>输入的树文件要为<strong>无根树</strong>，输入有根树会导致 PAML 估计错误。</li><li>输入的序列文件要是 PAML 需要的格式（非 fasta）。</li><li>确保前景枝已被标记，具体的标记方法可以看之前推荐的教程。</li></ul><p>你可能会感兴趣的问题：</p><ul><li>正选择检测时，应当输入<strong>每个基因的基因树</strong>作为树文件还是输入<strong>物种树</strong>作为树文件这一个问题，事实上在很多论文里都是有分歧的，两种方法都有人做，不过也有文章已经指出过，当基因树和物种树拓扑结构不一致时，将物种树作为输入树将会错误地估计枝长，导致更高的假阳性率。</li></ul><blockquote><p><a href="https://doi.org/10.1093/sysbio/syw018">Gene tree discordance causes apparent substitution rate variation.</a></p><p>from <em>Systematic Biology</em></p><p>Discussion group 里也有人提过这个问题，杨子恒教授的说法：</p><p>The best tree to use would be one that accurately describes the true evolutionary history of the aligned sequences.  </p><p>If the gene and species trees disagree, you’ll need to decide which is a better approximation of the true history.  </p><p> – a gene tree may be a poor indicator of true history simply because of limited sample size, or because of unusual patterns of sequence evolution (say, if there was strong convergent evolution) </p><p> – a species tree may be a poor indicator of true history if gene duplications occurred or if speciation events were tightly clustered (say, if there was incomplete lineage sorting)</p><p>Regardless of which tree you select, reviewers may ask that you conduct some/all of the analyses again on the other tree to ensure the results are robust. </p></blockquote><ul><li>经过卡方检验发现部分基因存在显著正选择，但是并没有正选择位点。这可能是因为整个基因表现出了正选择但是<strong>单独位点的信号</strong>太弱。</li></ul><blockquote><p><a href="https://groups.google.com/g/pamlsoftware/c/j8VKor3t7ws">Can we say a gene is under positve selcetion if the LRT tests results is significant but BEB detects no positively selective sites?</a></p></blockquote><ul><li>是否应当去除外群进行分析？杨子恒教授认为，如果外群离得不是很远，那么将其纳入正选择检测可能是有益的。</li></ul><blockquote><p><a href="https://groups.google.com/g/pamlsoftware/c/dNypX5VoOJ8/m/foPjr1wrAwAJ">Question on branch labeling with two species (multiple strains)</a></p></blockquote><ul><li>不同版本的 PAML 跑出来的结果可能会不同，请做好版本控制工作。</li><li>是否要删除比对中的 gap ？杨子恒团队建议删除主要是 gap 或难以对齐的区域之后，使用 <code>cleandata = 0</code> 保留数据中的信息。</li></ul><p>还有很多很好的问题有博主整理出来了，可见 <a href="https://www.jianshu.com/p/152a6216c794">PAML-discussion-group from 简书</a>。这里我就只放一些我在分析时遇到的几个问题还有对应的解释出来。</p><h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><p>虽然说支位点模型是最广为应用的正选择检测方法之一，但是它的很多假设也在一定程度上削弱了它的可靠性。</p><ul><li>支位点模型假设所有分支所有位点的进化是<strong>独立</strong>的，在很多情况下这并不成立（你可能想知道 <a href="https://zh.wikipedia.org/wiki/%E9%81%97%E4%BC%A0%E8%BF%9E%E9%94%81">遗传连锁</a> 或 <a href="https://zh.wikipedia.org/wiki/%E5%85%B1%E5%90%8C%E6%BC%94%E5%8C%96">协同进化</a>）。</li><li>支位点模型先验地将所有分支分为了存在正选择的前景枝和负选择或中性选择的背景枝两类，当背景枝的情况不符合这个假设时会导致非常高的假阳性率或假阴性率（<a href="https://academic.oup.com/mbe/article/28/11/3033/1044451">Sergei et al.</a>）。</li><li>支位点模型假设所有的分支在所有的位点中共享相同的 dS，在很多情况下这并不成立。</li></ul><p>此外，也要考虑到一些可能存在的客观不足，比如说：</p><ul><li>样本量过小（小样本偏差）。如果分析中涉及到的物种太少，那么物种的特异性就会被过度放大（考虑少数物种时以为存在正选择信号，但是加入更多物种后发现实际上并没有），而且参数估计可能会有很大的不确定性，导致结果偏向某一方向。</li><li>某些正选择信号可能是遗传漂变造成的（轻微有害突变被漂变固定），这在有效种群大小较低的物种中更有可能发生。</li></ul><p>所以，如果想要得到更准确的正选择结果，可以考虑使用 <code>Hyphy</code> 等其他生信软件（或模型）对结果进行补充，同时注意采取严格的假阳性控制手段（例如 BH 矫正等）。</p><p><code>Hyphy</code> 的模型有时候会表现得更好，现在越来越多的相关文章都是同时使用 <code>PAML</code> 和 <code>Hyphy</code> 进行分析，然后将两者的结果一起展示。</p><h2 id="dN-dS-计算（自由比模型）"><a href="#dN-dS-计算（自由比模型）" class="headerlink" title="dN / dS 计算（自由比模型）"></a>dN / dS 计算（自由比模型）</h2><h3 id="原理及运行-1"><a href="#原理及运行-1" class="headerlink" title="原理及运行"></a>原理及运行</h3><p>这一部分也可以叫做<em><strong>选择压力分析</strong></em>，使用的是 PAML Branch Model 中的 <code>free-ratio model</code>。</p><p>与之前讲到的支位点模型不同，自由比模型允许 ω(dN/dS) 在所有分支中变化，它对所有分支的 ω 进行独立统计（包括末端分支和祖先分支）。</p><p>PAML 的控制文件中，使用 <code>model = 1</code> 来指定自由比模型。</p><p>具体如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">seqfile = 这里要填你的序列文件路径</span><br><span class="line">treefile = 这里要填你的树文件路径，要检测是否有正选择的分支记得标记</span><br><span class="line">outfile = 这里要填你的输出文件，PAML 会将结果输出到此处</span><br><span class="line"></span><br><span class="line">noisy = 9</span><br><span class="line">verbose = 1</span><br><span class="line">runmode = 0</span><br><span class="line"></span><br><span class="line">seqtype = 1</span><br><span class="line">CodonFreq = 2</span><br><span class="line">model = 1</span><br><span class="line">NSsites = 0</span><br><span class="line">icode = 0</span><br><span class="line">Mgene = 0</span><br><span class="line"></span><br><span class="line">fix_kappa = 0</span><br><span class="line">kappa = 2</span><br><span class="line"></span><br><span class="line">fix_omega = 0</span><br><span class="line">omega = 1</span><br><span class="line"></span><br><span class="line">fix_alpha = 1</span><br><span class="line">ncatG = 8</span><br><span class="line"></span><br><span class="line">getSE = 0</span><br><span class="line">RateAncestor = 0</span><br><span class="line">Small_Diff = .5e-6</span><br><span class="line">cleandata = 1</span><br></pre></td></tr></tbody></table></figure><p>部分参数并没有详细指定，PAML 会选择默认选项（默认情况可以参见 <code>pamlDOC.pdf</code>）</p><p>然后直接运行即可：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">codeml xxx(你的控制文件)</span></span><br></pre></td></tr></tbody></table></figure><p>得到的结果可在 <code>outfile</code> 中查看，一般而言各个分支的 ω 值都在最后一行（以井号 <code>#</code> 作为标识），就像这样：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(A #0.1 , B #0.2 , C #0.3)</span><br></pre></td></tr></tbody></table></figure><p>和支位点模型相同，这里列出批量运行自由比模型的 Python 脚本：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># free-ratio-calcu</span></span><br><span class="line"><span class="comment"># Author: Juse</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">args = sys.argv[<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(args) == <span class="number">0</span>:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Usage: python free-ratio_calcu.py treefile seqdir outputDir"</span>)</span><br><span class="line">sys.exit()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">treefile = os.path.abspath(args[<span class="number">0</span>])</span><br><span class="line">seqdir = os.path.abspath(args[<span class="number">1</span>])</span><br><span class="line">outputDir = os.path.abspath(args[<span class="number">2</span>])</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Please check your command."</span>)</span><br><span class="line">sys.exit()</span><br><span class="line"></span><br><span class="line">paml_seq = []</span><br><span class="line"><span class="keyword">for</span> paml <span class="keyword">in</span> os.listdir(seqdir):</span><br><span class="line">paml_seq.append(<span class="string">f"<span class="subst">{seqdir}</span>/<span class="subst">{paml}</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> seqid <span class="keyword">in</span> paml_seq:</span><br><span class="line">outid = <span class="string">f"<span class="subst">{seqid.split(<span class="string">'/'</span>)[-<span class="number">1</span>]}</span>.mlc"</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">"codeml.ctl"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">f.write(<span class="string">f'''</span></span><br><span class="line"><span class="string">seqfile = <span class="subst">{seqid}</span></span></span><br><span class="line"><span class="string">treefile = <span class="subst">{treefile}</span></span></span><br><span class="line"><span class="string">outfile = <span class="subst">{outputDir}</span>/<span class="subst">{outid}</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">noisy = 9</span></span><br><span class="line"><span class="string">verbose = 1</span></span><br><span class="line"><span class="string">runmode = 0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">seqtype = 1</span></span><br><span class="line"><span class="string">CodonFreq = 2</span></span><br><span class="line"><span class="string">model = 1</span></span><br><span class="line"><span class="string">NSsites = 0</span></span><br><span class="line"><span class="string">icode = 0</span></span><br><span class="line"><span class="string">Mgene = 0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">fix_kappa = 0</span></span><br><span class="line"><span class="string">kappa = 2</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">fix_omega = 0</span></span><br><span class="line"><span class="string">omega = 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">fix_alpha = 1</span></span><br><span class="line"><span class="string">ncatG = 8</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">getSE = 0</span></span><br><span class="line"><span class="string">RateAncestor = 0</span></span><br><span class="line"><span class="string">Small_Diff = .5e-6</span></span><br><span class="line"><span class="string">cleandata = 1</span></span><br><span class="line"><span class="string">'''</span>)</span><br><span class="line">os.system(<span class="string">"codeml"</span>)</span><br></pre></td></tr></tbody></table></figure><p>具体脚本已经上传到 GitHub 上（<a href="https://github.com/JuseTiZ/PyScript-for-CT/blob/main/free-ratio-calcu.py">链接</a>），运行：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python free-ratio_calcu.py treefile seqdir outputDir</span></span><br></pre></td></tr></tbody></table></figure><ul><li><code>treefile</code> 指定物种树文件。</li><li><code>seqdir</code> 指定序列文件夹，应将所有要运行自由比模型的序列放置在其中<strong>并且不包括任何其他文件</strong>，序列应为 PAML 格式。</li><li><code>outputDir</code> 指定输出文件夹，所有的结果文件将在该处产生，建议指定一个空文件夹以衔接后续批量提取。</li></ul><p>在这里我并没有像支位点模型那个脚本一样设置多线程操作，所以如果数据较多的友友可以尝试自行修改脚本以提高效率。此外序列的格式要为 PAML 所需格式而非传统 fasta 格式，需要进行序列格式转换的可以使用 Phylosuite 或者 JuseKit。</p><h3 id="批量提取结果"><a href="#批量提取结果" class="headerlink" title="批量提取结果"></a>批量提取结果</h3><p>一般来说我们关注的都是末端分支 ω 值，然后取出进行统计比较，如果想要快捷提取出不同物种的 ω 值可以考虑使用 shell 的 <code>grep</code> 或者 Python 的 <code>re</code>。</p><p>在这里给出我的 Python 脚本实例（<a href="https://github.com/JuseTiZ/PyScript-for-CT/blob/main/free-ratio-omega.py">下载链接</a>）：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># free-ratio-omega</span></span><br><span class="line"><span class="comment"># Author: Juse</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">spefile = sys.argv[<span class="number">1</span>]</span><br><span class="line">mlcfiledir = sys.argv[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">species = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(spefile, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        <span class="keyword">if</span> line.strip() != <span class="string">''</span>:</span><br><span class="line">             species.append(line.strip())</span><br><span class="line">species[:] = <span class="built_in">sorted</span>(species)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">'free-ratio.result'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> op:</span><br><span class="line"></span><br><span class="line">    head = <span class="string">'\t'</span>.join(species)</span><br><span class="line">    op.write(<span class="string">f'File\t<span class="subst">{head}</span>\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> mlc <span class="keyword">in</span> os.listdir(mlcfiledir):</span><br><span class="line">        op.write(mlc+<span class="string">'\t'</span>)</span><br><span class="line">        mlcpath = <span class="string">f'<span class="subst">{mlcfiledir}</span>/<span class="subst">{mlc}</span>'</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(mlcpath, <span class="string">'r'</span>) <span class="keyword">as</span> m:</span><br><span class="line">            file_content = m.read()</span><br><span class="line">            <span class="keyword">for</span> spe <span class="keyword">in</span> species:</span><br><span class="line">                search = <span class="string">fr'<span class="subst">{spe}</span> #(\d+(?:\.\d+)?)'</span></span><br><span class="line">                omega = re.search(search, file_content).group(<span class="number">1</span>)</span><br><span class="line">                op.write(omega + <span class="string">'\t'</span>)</span><br><span class="line">        op.write(<span class="string">'\n'</span>)</span><br></pre></td></tr></tbody></table></figure><p>要求的输入有两个：</p><ul><li>物种名文件，格式如下（一行一个物种名，填需要统计 ω 值的物种）：</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SpeA</span><br><span class="line">SpeB</span><br><span class="line">SpeC</span><br></pre></td></tr></tbody></table></figure><ul><li>PAML 运行结果文件（也就是上面的 <code>outfile</code>）。</li></ul><p>脚本运行方式：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python free-ratio-omega.py spename_file path_of_outfile</span></span><br></pre></td></tr></tbody></table></figure><p>把 <code>spename_file</code> <code>path_of_outfile</code> 两项换成对应文件和路径即可。</p><p>统计结果会出现在运行命令的路径中（<code>free-ratio.result</code>），结果文件实例：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FileABC</span><br><span class="line">10.007334070.00010.00574998</span><br><span class="line">20.1191510.09177340.0648513</span><br><span class="line">30.06533320.02881580.0296085</span><br></pre></td></tr></tbody></table></figure><p>需要注意的点：</p><ul><li>在一些基因中，可能会存在有些分支几乎没有变化的情况，这时很容易出现极端值（<code>999</code> 或 <code>0.0001</code>），因此在分析之前最好排除这些基因。关于这一点，部分文献中也有讲到一定的过滤方法，例如根据 <code>N*dN</code>  <code>S*dS</code> 的大小进行过滤。</li><li>本文章提供的脚本仅支持获取末端分支的 ω 值，如有需要提取某一祖先分支 ω 值，可以结合 Python 的 <code>ete3</code> 包完善脚本进行。</li></ul><p>然后就可以使用 R 或其他软件根据得到的结果进行绘图：</p><p><img src="/pic2/paml1.png"></p><h2 id="估计物种分歧时间"><a href="#估计物种分歧时间" class="headerlink" title="估计物种分歧时间"></a>估计物种分歧时间</h2><p>这一功能通过 PAML 的 <code>mcmctree</code> 实现，虽然该方法较本文中已经描述的几种方法要更复杂得多（涉及到许多参数的设置），但是由于其拥有专门的 tutorial 教程，因此这里我只挑出其中一些我个人认为比较重要的地方进行展示。</p><p>首先，请过目 <a href="http://abacus.gene.ucl.ac.uk/software/MCMCtree.Tutorials.pdf">mcmctree 的 tutorial</a>，这对于理解程序的运行和各个参数而言还是非常重要的，其中还展示了相关示例和实践，可以跟着做一遍。此外，也可以看看简书博主总结的教程：<a href="https://www.jianshu.com/p/46b28829b078">mcmctree估算物种分歧时间</a>。</p><p>如果不嫌看英文麻烦，也可以看看这篇教程：<a href="https://fish-evol.org/mcmctreeExampleVert6/text1Eng.html">Example of mcmctree analysis</a></p><p>如果想系统地了解这部分的理论背景，可以看这篇综述文章：<a href="https://www.nature.com/articles/nrg.2015.8">https://www.nature.com/articles/nrg.2015.8</a></p><p>这里讲一些比较关键的点：</p><p>首先是估计物种分歧时间所需要的条件：一个<strong>有根树（无枝长信息）</strong>以及相关的<strong>化石矫准</strong>。也可以用其他文献中估计的分歧时间作为校准点（这种情况被称为二次校准），不过相对来说没那么严谨；或者说以某个地质历史事件发生时间作为校准点，例如某个岛屿分裂导致地理隔离并随之引起两物种的分化。在该分析中，校准信息越准确，分析结果越可靠。</p><p>参数设置的相关注意事项：</p><ul><li>在松弛钟模型（<code>clock = 2 or 3</code>）下，如果树根部没有校准点，那么就需要通过 <code>RootAge</code> 指定一个分歧时间上限（所有物种的最近共同祖先形成时间）。</li></ul><blockquote><p>Juse 注：松弛钟模型允许不同分支进化速率不同，这与严格钟模型相反。</p></blockquote><ul><li>选择时间单位时应使节点的分歧时间大致在 <code>0.01-10</code> 的范围内（超过 10 应该也没有关系但不要低于 0.01），比方说如果分歧时间在大约 100-1000MY，那么可以将 100MY 视作一个时间单位。此外，一些参数的设置需根据你对时间尺度的选择进行调整。</li></ul><blockquote><p>Juse 注：具体的例子在 mcmctree tutorial 的 11 页可见。</p><p>在 <code>clock = 2</code> 时，<strong>只有</strong> <code>rgene_gamma</code> 要随之变动。而 <code>clock = 3</code> 时，<code>sigma2_gamma</code> <strong>也要</strong>变化。</p></blockquote><ul><li>指定先验替换率，具体怎么设置取决于对替换率有多大的把握，如果并无太大把握就将 αμ 设置成 <code>1</code> <code>1.5</code> 或 <code>2</code>，然后调整 βμ 至其合理。</li></ul><blockquote><p>Juse 注：有些生物类群的替换率可能能从文献中得到，例如：<a href="https://pubmed.ncbi.nlm.nih.gov/26603774/">例子</a>。</p><p>虽然 PAML 现在使用的 Dirichlet 先验能一定程度上减小错误替代率带来的影响，但关于替换率的参数设定仍需要谨慎，因为该值会直接影响分歧时间的后验估计。</p><p>如果没有相关信息，可以通过指定 <code>clock=1</code> 运行 baseml 来获得大致的替换率估计并用于先验设定（详见之前提供的英文教程或后文补充部分）。</p></blockquote><ul><li>最好进行多次分析，确保结果相似（要使用不同的 <code>seed</code> 或直接将 <code>seed</code> 设置为 <code>-1</code>）。对于分析是否已经收敛，可以用 tutorial 中提到的方法去判断，也可以看一看<a href="https://link.springer.com/protocol/10.1007/978-1-0716-2691-7_1">这篇文章</a>中阐述的方法（基于 R 实现）。若结果不相似，说明分析可能还未收敛，此时可能需要对 <code>burnin</code> <code>sampfreq</code> <code>nsample</code> 三个参数进行一定的修改。</li><li>此处涉及了一个新的参数为 <code>ndata</code>，指定的是序列的分区数量，tutorial 中所涉及到的序列就为分区数据（分三个部分，分别是密码子的第一、第二和第三个碱基），如果没有分区的话指定 <code>ndata = 1</code> 即可。</li><li>关于选择软边界还是硬边界，文章指出使用软边界能够更加灵活并且减弱错误化石校准的影响。</li><li>关于出生率、死亡率和抽样分数的先验设置，文章发现其对于后验时间估计只有很小的影响，但依然建议尝试改变这些值以观察后验估计的鲁棒性。</li></ul><blockquote><p><a href="https://academic.oup.com/mbe/article/23/1/212/1193630"><strong>Bayesian Estimation of Species Divergence Times Under a Molecular Clock Using Multiple Fossil Calibrations with Soft Bounds</strong></a></p><p>from <em>Molecular Biology and Evolution</em></p></blockquote><ul><li>关于怎么选择模型，你可能会对以下信息感兴趣：</li></ul><blockquote><p>不同 Model 指定的具体模型：</p><p>0:JC69，1:K80，2:F81，3:F84，4:HKY85</p><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">ChatGPT3.5 的回答</summary><div class="toggle-content"><blockquote><p>在这些模型中，JC69（Jukes-Cantor 69）是最简单的模型，它假设所有碱基或氨基酸的变异率相等，并且没有考虑碱基或氨基酸之间的相似性。因此，JC69模型通常只用于较近的亲缘关系分析。</p><p>K80（Kimura 2参数）模型是比JC69更复杂的模型，它考虑了不同碱基或氨基酸之间的相似性，并引入了转换和转换/颠换的不同变异率。</p><p>F81（Felsenstein 81）模型是另一个比JC69更复杂的模型，它考虑了碱基或氨基酸之间的不同变异率，并假设平稳状态的分布是相等的。</p><p>F84（Felsenstein 84）模型是F81模型的改进版本，它引入了不同的碱基或氨基酸转换和转换/颠换的变异率。</p><p>而HKY85（Hasegawa-Kishino-Yano 85）模型是这些模型中最复杂的一个。它在F84模型的基础上引入了碱基或氨基酸的酶位点偏好，并考虑了碱基或氨基酸的相对频率。因此，HKY85模型在描述分子演化过程中更准确和灵活，具有更高的泛用性。</p></blockquote></div></details><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">ChatGPT4.0 的回答</summary><div class="toggle-content"><blockquote><ol><li>**JC69 (Jukes-Cantor 1969)**：是最简单的模型之一。它假定四种碱基（A, T, C, G）替换的概率是均等的，即任何两种碱基之间的替换率是相等的。</li><li>**K80 (Kimura 2-parameter)**：比JC69稍微复杂一些。它引入了两个参数，一个是转换的替换率（purine之间或pyrimidine之间的替换），另一个是转变的替换率（purine和pyrimidine之间的替换）。</li><li>**F81 (Felsenstein 1981)**：在JC69的基础上增加了考虑站点频率不均的特点，即每种碱基出现的概率可以不同。</li><li>**HKY85 (Hasegawa, Kishino and Yano 1985)**：这个模型进一步扩展了K80，允许碱基频率不等，并且区分了转换和转变的替换率。</li><li>**F84 (Felsenstein 1984)**：类似于HKY85，但在处理转换和转变的替换率上略有不同。</li></ol><p>综合来看，<strong>HKY85</strong>和<strong>F84</strong>是你所列举的模型中较为复杂的，它们在处理碱基替换时考虑了更多的参数。由于HKY85和F84在处理替换率和频率方面都较为灵活，因此它们通常具有较高的泛用性。在许多情况下，HKY85模型是一种非常受欢迎的选择。</p></blockquote></div></details><p>在文章的具体示例中，分别使用了 <code>JC</code> 模型和 <code>HKY+G</code> 模型进行对比，<code>JC</code> 在部分情况下会显得不可靠。</p><p>所以如果不缺计算资源和时间的话， <code>Model = 4</code> 或许会是一个万金油选择（同时设置 <code>alpha = 0.5</code> &amp; <code>ncatG = 5</code> 以使用 <code>HKY85+G5 Model</code>）。</p></blockquote><h3 id="实战演练"><a href="#实战演练" class="headerlink" title="实战演练"></a>实战演练</h3><p>由于该部分 tutorial 已经提供了相关的示例，因此这里为了我将直接示范其通过近似似然节省运行时间的方法。</p><p>首先，为什么要使用近似似然 —— 因为近似似然能大幅节约时间，这是 tutorial 的原文：</p><blockquote><p>For large alignments, calculation of the likelihood function during the MCMC is computationally expensive, and estimation of divergence times is very slow. Thorne et al.[8] suggested using an approximate method to calculate the likelihood that improves the speed of the MCMC dramatically.</p></blockquote><p>这是<a href="https://link.springer.com/protocol/10.1007/978-1-0716-2691-7_1">论文</a>片段：</p><blockquote><p>Because Bayesian molecular-clock dating relies on expensive MCMC sampling, the time savings obtained by using the approximation can be quite dramatic, up to 1000× depending on the dataset.</p></blockquote><p>本次示例使用的文件均在 PAML 根目录的 <code>examples/DatingSoftBound</code> 下，且均在 tutorial 中可见。</p><p>首先跳转到该文件夹，该文件夹中有一控制文件为 <code>mcmctree.ctl</code>，将其内容改为：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">        seed = -1</span><br><span class="line">     seqfile = mtCDNApri123.txt</span><br><span class="line">    treefile = mtCDNApri.trees</span><br><span class="line">    mcmcfile = mcmc.txt</span><br><span class="line">     outfile = out.txt</span><br><span class="line"></span><br><span class="line">       ndata = 3</span><br><span class="line">     seqtype = 0    * 0: nucleotides; 1:codons; 2:AAs</span><br><span class="line">     usedata = 3    * 0: no data; 1:seq like; 2:normal approximation; 3:out.BV (in.BV)</span><br><span class="line">       clock = 2    * 1: global clock; 2: independent rates; 3: correlated rates</span><br><span class="line">     RootAge = '&lt;1.0'  * safe constraint on root age, used if no fossil for root.</span><br><span class="line"></span><br><span class="line">       model = 4    * 0:JC69, 1:K80, 2:F81, 3:F84, 4:HKY85</span><br><span class="line">       alpha = 0.5    * alpha for gamma rates at sites</span><br><span class="line">       ncatG = 5    * No. categories in discrete gamma</span><br><span class="line"></span><br><span class="line">   cleandata = 0    * remove sites with ambiguity data (1:yes, 0:no)?</span><br><span class="line"></span><br><span class="line">     BDparas = 1 1 0.1  * birth, death, sampling</span><br><span class="line"> kappa_gamma = 6 2      * gamma prior for kappa</span><br><span class="line"> alpha_gamma = 1 1      * gamma prior for alpha</span><br><span class="line"></span><br><span class="line"> rgene_gamma = 2 20 1   * gammaDir prior for rate for genes</span><br><span class="line">sigma2_gamma = 1 10 1   * gammaDir prior for sigma^2     (for clock=2 or 3)</span><br><span class="line"></span><br><span class="line">    finetune = 1: .1 .1 .1 .1 .1 .1 * auto (0 or 1): times, musigma2, rates, mixing, paras, FossilErr</span><br><span class="line"></span><br><span class="line">       print = 1   * 0: no mcmc sample; 1: everything except branch rates 2: everything</span><br><span class="line">      burnin = 2000</span><br><span class="line">    sampfreq = 10</span><br><span class="line">     nsample = 20000</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mcmctree mcmctree.ctl</span></span><br></pre></td></tr></tbody></table></figure><p>可以在相关文件中查看详细的序列和物种树校准信息，运行上述命令后，文件夹中会出现一个名为 <code>out.BV</code> 的文件，将其重命名为 <code>in.BV</code>。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> out.BV in.BV</span></span><br></pre></td></tr></tbody></table></figure><p>随后修改控制文件，将 <code>usedata = 3</code> 换为 <code>usedata = 2</code> ，再次运行并得到结果。</p><p>比对一下结果，使用近似似然时（用时 10 s）：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">t_n8           0.1959 ( 0.1627,  0.2477) ( 0.1588,  0.2391)  0.0803  (Jnode 12)</span><br><span class="line">t_n9           0.1571 ( 0.1464,  0.1629) ( 0.1479,  0.1639)  0.0160  (Jnode 11)</span><br><span class="line">t_n10          0.0928 ( 0.0814,  0.1074) ( 0.0804,  0.1062)  0.0258  (Jnode 10)</span><br><span class="line">t_n11          0.0640 ( 0.0593,  0.0739) ( 0.0587,  0.0723)  0.0136  (Jnode  9)</span><br><span class="line">t_n12          0.0256 ( 0.0191,  0.0336) ( 0.0188,  0.0331)  0.0143  (Jnode  8)</span><br><span class="line">t_n13          0.0484 ( 0.0378,  0.0607) ( 0.0374,  0.0602)  0.0228  (Jnode  7)</span><br><span class="line">mu1            0.4790 ( 0.3951,  0.5705) ( 0.3933,  0.5675)  0.1742</span><br><span class="line">mu2            0.1643 ( 0.1270,  0.2092) ( 0.1262,  0.2078)  0.0816</span><br><span class="line">mu3            2.9379 ( 2.0577,  3.7933) ( 2.0485,  3.7801)  1.7316</span><br><span class="line">sigma2_1       0.0436 ( 0.0022,  0.1503) ( 0.0001,  0.1206)  0.1205</span><br><span class="line">sigma2_2       0.0941 ( 0.0103,  0.2748) ( 0.0001,  0.2292)  0.2291</span><br><span class="line">sigma2_3       0.2195 ( 0.0713,  0.5266) ( 0.0517,  0.4588)  0.4070</span><br><span class="line">lnL          -16.1493 (-24.6090, -9.3610) (-23.9400, -8.9710) 14.9690</span><br></pre></td></tr></tbody></table></figure><p>不使用近似似然时（<code>usedata = 1</code>，用时 24 min 38 s）：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">t_n8           0.1931 ( 0.1637,  0.2304) ( 0.1609,  0.2260)  0.0651  (Jnode 12)</span><br><span class="line">t_n9           0.1572 ( 0.1470,  0.1630) ( 0.1483,  0.1637)  0.0154  (Jnode 11)</span><br><span class="line">t_n10          0.0912 ( 0.0815,  0.1036) ( 0.0809,  0.1025)  0.0217  (Jnode 10)</span><br><span class="line">t_n11          0.0631 ( 0.0592,  0.0713) ( 0.0585,  0.0699)  0.0114  (Jnode  9)</span><br><span class="line">t_n12          0.0243 ( 0.0191,  0.0311) ( 0.0188,  0.0306)  0.0119  (Jnode  8)</span><br><span class="line">t_n13          0.0464 ( 0.0375,  0.0572) ( 0.0370,  0.0566)  0.0195  (Jnode  7)</span><br><span class="line">mu1            0.4824 ( 0.4064,  0.5676) ( 0.4033,  0.5633)  0.1600</span><br><span class="line">mu2            0.1677 ( 0.1323,  0.2090) ( 0.1300,  0.2061)  0.0761</span><br><span class="line">mu3            2.7935 ( 2.2004,  3.3122) ( 2.2439,  3.3458)  1.1019</span><br><span class="line">sigma2_1       0.0340 ( 0.0022,  0.1169) ( 0.0001,  0.0933)  0.0933</span><br><span class="line">sigma2_2       0.0712 ( 0.0049,  0.2187) ( 0.0001,  0.1797)  0.1796</span><br><span class="line">sigma2_3       0.0717 ( 0.0109,  0.2105) ( 0.0015,  0.1746)  0.1731</span><br><span class="line">kappa_1       12.3972 (10.4875, 14.6043) (10.3315, 14.4080)  4.0765</span><br><span class="line">kappa_2        9.3277 ( 7.2435, 11.8446) ( 7.1484, 11.6949)  4.5464</span><br><span class="line">kappa_3       33.8883 (30.1020, 38.0932) (30.0334, 37.9816)  7.9483</span><br><span class="line">alpha_1        0.2192 ( 0.1746,  0.2733) ( 0.1717,  0.2689)  0.0972</span><br><span class="line">alpha_2        0.0436 ( 0.0019,  0.1100) ( 0.0000,  0.0987)  0.0987</span><br><span class="line">alpha_3        3.9802 ( 2.7839,  5.7941) ( 2.6174,  5.5002)  2.8828</span><br><span class="line">lnL        -29997.5335 (-30011.0870, -29985.7710) (-30010.5710, -29985.3530) 25.2180</span><br></pre></td></tr></tbody></table></figure><p>对比不使用近似似然和使用近似似然时的结果可以发现，两次分析所得到的各节点分歧时间都是非常相近的，但是不使用近似似然分析所用的时间却花费了 140 倍以上。</p><p>此外，对于蛋白和密码子序列数据，若要使用近似似然方法节约时间可能需要进行额外的操作，详情可见 <em><strong>Tutorial 4: Approximate likelihood with protein data</strong></em>。</p><h3 id="要补充的一些话"><a href="#要补充的一些话" class="headerlink" title="要补充的一些话"></a>要补充的一些话</h3><p>本文中关于 <code>mcmctree</code> 的部分有很多相关的结果信息并没有详细说明，这主要是因为这一部分与之前讲的两个部分有个根本的不同 —— 它具有一个单独的 tutorial 并且 PAML DOC 中也有专门讲解，这些内容基本上涵盖了所有我未提及到的其他地方。</p><p>俗话说得好，好记性不如烂笔头。跟着看跟着学跟着做才是最好的学习方法，做出来了一遍还怕后面做不成吗？</p><h4 id="估计替换率的方法"><a href="#估计替换率的方法" class="headerlink" title="估计替换率的方法"></a>估计替换率的方法</h4><p>详尽版：<a href="http://abacus.gene.ucl.ac.uk/software/MCMCtreeStepByStepManual.pdf">A Step-by-Step Tutorial: Divergence Time Estimation with Approximate Likelihood Calculation Using MCMCTREE in PAML</a></p><p>创建一个 <code>baseml.ctl</code> 文件，写入以下内容：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">seqfile = xxx</span><br><span class="line">treefile = xxx</span><br><span class="line">outfile = mlb</span><br><span class="line"></span><br><span class="line">noisy = 3</span><br><span class="line">verbose = 1</span><br><span class="line">runmode = 0</span><br><span class="line"></span><br><span class="line">model = 7</span><br><span class="line">Mgene = 0</span><br><span class="line"></span><br><span class="line">fix_kappa = 0</span><br><span class="line">kappa = 2</span><br><span class="line"></span><br><span class="line">fix_alpha = 0</span><br><span class="line">alpha = 0.5</span><br><span class="line">Malpha = 0</span><br><span class="line">ncatG = 5</span><br><span class="line"></span><br><span class="line">fix_rho = 1</span><br><span class="line">rho = 0.</span><br><span class="line">nparK = 0</span><br><span class="line"></span><br><span class="line">clock = 1</span><br><span class="line">nhomo = 1</span><br><span class="line">getSE = 1</span><br><span class="line">RateAncestor = 0</span><br><span class="line">cleandata = 0</span><br></pre></td></tr></tbody></table></figure><p>其中 <code>seq</code> 为序列文件（PAML 或 Phy 格式），<code>treefile</code> 为根处有校准的有根树文件，例子：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">7  1</span><br><span class="line">((((human, (chimpanzee, bonobo)), gorilla), (orangutan, sumatran)), gibbon)'@1.0';</span><br></pre></td></tr></tbody></table></figure><p>在准备好相关文件后，运行以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">baseml baseml.ctl</span></span><br></pre></td></tr></tbody></table></figure><p>输出的 mlc 文件中存在以下内容：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Substitution rate is per time unit</span><br><span class="line"></span><br><span class="line">    0.090798 +- 0.006418</span><br></pre></td></tr></tbody></table></figure><p>根据该值，假设 <em>m</em> = <em>s</em> = 0.09，则：</p><ul><li><em>a</em> = (0.09/0.09)^2 = 1</li><li><em>b</em> = 0.09/0.09^2 = 11.1</li></ul><p>因此可在运行 mcmctree 时将 rgene_gamma 设置为：<code>rgene_gamma = 1 11.1</code></p><hr><p>除了已介绍的模型，还有一些模型例如 <code>Two-ratio model</code> 和 <code>Fixed ratio model</code> 等没有讲到，不过这些模型的运行只需改几个参数，包括它们之间的比较（比如说 <code>Two-ratio vs. Fixed</code>）同样是通过似然比检验，因此后面不会再特别补充，以后的变动可能主要是对现有的内容进行完善<del>（不过也说不定）</del>。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JuseKit（四） —— 序列格式转换以及 Orthogroup 的 cds 提取</title>
      <link href="/2023/04/26/JuseKit%EF%BC%88%E5%9B%9B%EF%BC%89%20%E2%80%94%E2%80%94%20%E5%BA%8F%E5%88%97%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2%E4%BB%A5%E5%8F%8A%20Orthogroup%20%E7%9A%84%20cds%20%E6%8F%90%E5%8F%96/"/>
      <url>/2023/04/26/JuseKit%EF%BC%88%E5%9B%9B%EF%BC%89%20%E2%80%94%E2%80%94%20%E5%BA%8F%E5%88%97%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2%E4%BB%A5%E5%8F%8A%20Orthogroup%20%E7%9A%84%20cds%20%E6%8F%90%E5%8F%96/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><blockquote><div id="portalContainer"></div><script src="/js/jklink.js"></script><script> generatePortalLinks(4);</script></blockquote><h2 id="更新变动及进度"><a href="#更新变动及进度" class="headerlink" title="更新变动及进度"></a>更新变动及进度</h2><p>已有功能的相关教程请见：<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">Juseの软件开发</a></p><h3 id="本次更新变动"><a href="#本次更新变动" class="headerlink" title="本次更新变动"></a>本次更新变动</h3><ul><li>多种序列格式的转换（包括一些常见的 <code>nex</code> <code>phylip</code> 等）。</li><li>将 PEP 序列转变成 CDS 序列。</li><li>新添了一个学习计时器。</li><li>修复了部分 Bug。</li></ul><h3 id="目前的功能进度"><a href="#目前的功能进度" class="headerlink" title="目前的功能进度"></a>目前的功能进度</h3><ul><li>提取最长转录本。<em>（已实现）</em></li><li>根据 id 提取序列。<em>（已实现）</em></li><li>对序列的 id 进行各种处理。<em>（已实现）</em></li><li>串联序列并得到分区信息。<em>（已实现）</em></li><li>批量改后缀。<em>（已实现）</em></li><li>批量进行序列格式转换。<em>（已实现）</em></li><li>批量提取 Orthofinder 的 orthogroup 对应的 CDS 序列。<em>（已实现）</em></li><li>批量进行序列的物种数和长度过滤。<strong>（拟下一次更新）</strong></li><li>增加自动绘图模块（例如火山图、富集图等）。（考虑中，新的模块将会大幅增加软件大小，Juse 正在权衡利弊）</li><li>增加各种系统发育分析辅助工具（例如批量计算 RF 值或进行 <code>ILS test</code> <code>Introgression detection</code> 等）。（考虑中，新的模块将会大幅增加软件大小，Juse 正在权衡利弊）</li></ul><p>叠盾警告⚠：不保证这些功能和想法一定会实现，本软件解释权归属 Juse 所有，本软件能走多远具体得看 Juse 能坚持多久。</p><p>下载地址：<a href="https://github.com/JuseTiZ/JuseKit/releases">https://github.com/JuseTiZ/JuseKit/releases</a></p><h2 id="序列格式转换及-CDS-提取"><a href="#序列格式转换及-CDS-提取" class="headerlink" title="序列格式转换及 CDS 提取"></a>序列格式转换及 CDS 提取</h2><p>本文主要着重于这次更新新增的功能，其他模块请走<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">这里</a>。</p><h3 id="序列格式转换"><a href="#序列格式转换" class="headerlink" title="序列格式转换"></a>序列格式转换</h3><p>目前支持转换的方式只有 fasta 到其他格式（如图），暂不支持其他格式间的相互转换。</p><p>操作如图：</p><p><img src="/pic2/sc1.png"></p><p>转换后的五种格式：</p><p><img src="/pic2/sc2.png"></p><p>重点如下：</p><ul><li><code>axt</code> 格式是用来给 <code>KaKs_Calculator</code> 计算的，一般来说只能含有两种物种。</li><li>判断序列是 <code>DNA</code> 还是 <code>Protein</code> 的逻辑是看<strong>属于哪种的序列数更多</strong>比如说有三条是 DNA 一条是 Protein 的话依然会判断成 DNA，如果既不是 DNA 又不是 Protein 又或者里面含有识别不了的字符的话那么 <code>nex</code> 文件中则会填写 <code>Unknown</code>。</li><li>默认 <code>gap</code> 是 <code>-</code>。</li><li>我并没有设置判断序列长度是否相同的函数，所以请务必检查输入的是否为<strong>比对后的序列</strong>。</li></ul><h3 id="PEP-转-CDS"><a href="#PEP-转-CDS" class="headerlink" title="PEP 转 CDS"></a>PEP 转 CDS</h3><p>正如这一功能下的注释所说，其实这一个功能只是根据 id 提取序列的高级版，本质上依然需要一个序列文件（里面为序列 id 和其对应的 cds 序列）。</p><p>应用场景：把 OrthoFinder 找出的 Orthogroup 对应的 cds 序列给提出来（现在 OrthoFinder 也支持输入核苷酸序列，但是由于比较核苷酸树和氨基酸树时最好使用一致的基因，所以这招依然有应用价值）。</p><p>操作方法如图：</p><p><img src="/pic2/sc3.png"></p><p>最上面一栏输入 cds，第二栏输入 pep 序列所在文件夹<strong>（只包含 pep 序列）</strong>，最下面设置输出路径（最好新建个文件夹输出）。</p><p>重点如下：</p><ul><li>cds 要包含所有的 cds，即所有物种的 cds 序列都在里面。</li><li>如果 cds 较大，那么进行提取前可能有较长的 cds 加载时间，不用着急。</li><li>如果想把 cds 转成 pep 序列也是可以的，也就是反过来操作，原理一致。</li></ul><h2 id="不太正经的小玩意"><a href="#不太正经的小玩意" class="headerlink" title="不太正经的小玩意"></a>不太正经的小玩意</h2><p>这次更新还带来了一个功能叫做 <code>学习计时小工具</code>（在菜单栏中的实用小工具中）。</p><p>它会对<strong>每天</strong>的学习时间进行独立的统计，也就是说它是分天来计算的，然后每天的学习时间会记录在与 <code>JuseKit.exe</code> 文件相同路径下的 <code>records.csv</code> 中。</p><p>大致操作如下：</p><ul><li>打开窗口时它会根据系统时间确定日期，如果本日已有学习记录则会进行续点计时，如果没有则从零开始。</li><li>点 <code>开始学习</code> 后时间开始积累，点 <code>暂停学习</code> 后时间停止积累并且更新学习记录。</li><li>点击 <code>学习记录</code> 后会读取 <code>records.csv</code> 并新开窗口展示，里面有具体的学习日期和学习时长。</li></ul><p><img src="/pic2/sc4.png"></p><p>自我尝试了几天，只能说这个功能食之无味弃之可惜，但兴许有人会需要它。</p><p>不过其优点在于可以独立运行，打开这个窗口以后关闭 JuseKit 主窗口不会影响其使用。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>序列格式转换是一个经常需要用到的功能，后续我可能会继续完善它。</p><p>复制黏贴：</p><p>我会争取将这些功能慢慢完善，让它成为一个具有更广适用性的软件，希望能够帮助到某些盆友，当然我个人认为最大的可能是自娱自乐。</p><p>如果这个软件帮助到您了，您可以给它一个小小的 Star 聊表支持，或者在您汇报的时候引一下 <a href="https://github.com/JuseTiZ/JuseKit/">https://github.com/JuseTiZ/JuseKit/</a> ，想必看着还是非常高端大气上档次的。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 软件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JuseKit </tag>
            
            <tag> 转录组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JuseKit（三） —— 串联序列、根据id提取序列、批量修改文件尾缀</title>
      <link href="/2023/04/13/JuseKit%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20%E4%B8%B2%E8%81%94%E5%BA%8F%E5%88%97%E3%80%81%E6%A0%B9%E6%8D%AEid%E6%8F%90%E5%8F%96%E5%BA%8F%E5%88%97%E3%80%81%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%B0%BE%E7%BC%80/"/>
      <url>/2023/04/13/JuseKit%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20%E4%B8%B2%E8%81%94%E5%BA%8F%E5%88%97%E3%80%81%E6%A0%B9%E6%8D%AEid%E6%8F%90%E5%8F%96%E5%BA%8F%E5%88%97%E3%80%81%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%B0%BE%E7%BC%80/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><blockquote><div id="portalContainer"></div><script src="/js/jklink.js"></script><script> generatePortalLinks(3);</script></blockquote><h2 id="更新变动及进度"><a href="#更新变动及进度" class="headerlink" title="更新变动及进度"></a>更新变动及进度</h2><p>已有功能的相关教程请见：<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">Juseの软件开发</a></p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2023.06.21    完善了输出的 log 信息。</p><h3 id="本次更新变动"><a href="#本次更新变动" class="headerlink" title="本次更新变动"></a>本次更新变动</h3><ul><li>对序列进行串联（支持 IQ-TREE 分区文件的生成）。</li><li>根据 id 提取序列。</li><li>批量修改文件的后缀（已经补充在第二篇的进阶应用中了）。</li><li>修复了部分 Bug。</li></ul><h3 id="目前的功能进度"><a href="#目前的功能进度" class="headerlink" title="目前的功能进度"></a>目前的功能进度</h3><ul><li>提取最长转录本。<em>（已实现）</em></li><li>根据 id 提取序列。<em>（已实现）</em></li><li>对序列的 id 进行各种处理。<em>（已实现）</em></li><li>串联序列并得到分区信息。<em>（已实现）</em></li><li>批量改后缀。<em>（已实现）</em></li><li>批量进行序列格式转换。<strong>（拟下一次更新）</strong></li><li>批量 RBH 得到一对一直系同源基因。（<strong>拟废弃</strong>，因为 diamond 的 windows 部署有些麻烦）</li><li>批量提取 Orthofinder 的 orthogroup 对应的 CDS 序列。<strong>（拟下下次更新）</strong></li><li>增加自动绘图模块（例如火山图、富集图等）。（考虑中，新的模块将会大幅增加软件大小，Juse 正在权衡利弊）</li></ul><p>叠盾警告⚠：不保证这些功能和想法一定会实现，本软件解释权归属 Juse 所有，本软件能走多远具体得看 Juse 能坚持多久。</p><p>下载地址：<a href="https://github.com/JuseTiZ/JuseKit/releases">https://github.com/JuseTiZ/JuseKit/releases</a></p><h2 id="提取序列及串联序列"><a href="#提取序列及串联序列" class="headerlink" title="提取序列及串联序列"></a>提取序列及串联序列</h2><p>本文主要着重于这次更新新增的功能，其他模块请走<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">这里</a>。</p><h3 id="根据-id-提取序列"><a href="#根据-id-提取序列" class="headerlink" title="根据 id 提取序列"></a>根据 id 提取序列</h3><p>可用到的场景应该比较少，但也是有些的，例如差异表达基因序列的提取等。</p><p>操作也很简单，如图：</p><p><img src="/pic2/eq1.png"></p><p>重点如下：</p><ul><li>当输入文件且同时文本框中有输入时，文件更优先执行。</li><li>输入的 id 应为一行一个。</li><li>当使用文本框进行提取时，文本框的内容会保存在 <code>.exe</code> 所在文件夹中，其中 id 保存在 <code>tmp_id.txt</code>，fasta 保存在 <code>tmp_fasta.txt</code>。输出的文件也在同一文件夹下。</li><li>当使用文件进行提取时，输出文件将和输入文件在同一路径。</li></ul><h3 id="串联序列"><a href="#串联序列" class="headerlink" title="串联序列"></a>串联序列</h3><p>这一功能在 <code>系统发育分析</code> 中的第一个板块。</p><p>首先介绍一下各个地方的功能：</p><p><img src="/pic2/eq2.png"></p><p>实例演示：</p><p><img src="/pic2/eq3.png"></p><p>一些例外的情况：</p><p><img src="/pic2/eq4.png"></p><p>一般而言，串联需要用到的序列数量不会过多，所以运行速度会非常快，但如果数量过多，所需要的时间也会随之增加。</p><p>运行中卡死是比较正常的，但一般不会一直卡死，一直卡死说明可能未使用物种标识，导致识别到的物种数异常庞大，从而增加了内存需要。所以运行前请务必检查好这一点。</p><p>运行结束后，会在结果路径中产生以下文件：</p><ul><li><code>concatenation_ortho.fasta</code> 串联结果。</li><li><code>IQ_partition.txt</code> 适用于 IQ-Tree 分区模型建树的分区信息。</li><li><code>sequence_con.log</code> 串联 log，展示了各物种信息（v0.6 新增了 gap 比例），其中最后一列应当全部为 <code>+</code>。</li><li><code>gene.log</code> 基因 log，展示了各个基因中所包含的物种（未出现的以 <code>-</code> 标识）及各物种的基因出现率。<ul><li><code>gene.log</code> 为 v0.62 新增，目的是为了<strong>更好地观察部分物种的高 gap 率是由于 missing gene 还是由于未修剪 gap</strong>。</li></ul></li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>我会争取将这些功能慢慢完善，让它成为一个具有更广适用性的软件，希望能够帮助到某些盆友，当然我个人认为最大的可能是自娱自乐。</p><p>如果这个软件帮助到您了，您可以给它一个小小的 Star 聊表支持，或者在您汇报的时候引一下 <a href="https://github.com/JuseTiZ/JuseKit/">https://github.com/JuseTiZ/JuseKit/</a> ，想必看着还是非常高端大气上档次的。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 软件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JuseKit </tag>
            
            <tag> 转录组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JuseKit（二） —— 序列id简化、加前缀尾缀或转变为物种名</title>
      <link href="/2023/04/09/JuseKit%EF%BC%88%E4%BA%8C%EF%BC%89%20%E2%80%94%E2%80%94%20%E5%BA%8F%E5%88%97id%E7%AE%80%E5%8C%96%E3%80%81%E5%8A%A0%E5%89%8D%E7%BC%80%E5%B0%BE%E7%BC%80%E6%88%96%E8%BD%AC%E5%8F%98%E4%B8%BA%E7%89%A9%E7%A7%8D%E5%90%8D/"/>
      <url>/2023/04/09/JuseKit%EF%BC%88%E4%BA%8C%EF%BC%89%20%E2%80%94%E2%80%94%20%E5%BA%8F%E5%88%97id%E7%AE%80%E5%8C%96%E3%80%81%E5%8A%A0%E5%89%8D%E7%BC%80%E5%B0%BE%E7%BC%80%E6%88%96%E8%BD%AC%E5%8F%98%E4%B8%BA%E7%89%A9%E7%A7%8D%E5%90%8D/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><blockquote><div id="portalContainer"></div><script src="/js/jklink.js"></script><script> generatePortalLinks(2);</script></blockquote><h2 id="更新变动及进度"><a href="#更新变动及进度" class="headerlink" title="更新变动及进度"></a>更新变动及进度</h2><p>本次更新变动有：</p><ul><li>对序列的 id 进行前缀或后缀（尾缀）添加。</li><li>对序列的 id 进行简化。</li><li>对序列的 id 进行转换（变为物种名）。</li></ul><p>部分功能的 Python 代码实现：<a href="https://biojuse.com/2022/11/21/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%84%E8%A3%85%E7%9A%84%E8%B4%A8%E9%87%8F%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8E%BB%E5%86%97%E4%BD%99/">比较转录组分析（三）—— 组装的质量检测与去冗余</a></p><h3 id="更新变动"><a href="#更新变动" class="headerlink" title="更新变动"></a>更新变动</h3><p>2023.04.13 新增了批量替换尾缀的功能，在进阶应用里进行了补充。</p><p>2023.04.24 处理组装 id 中的 <code>删除原有文件</code> 功能在什么时候都能使用了。</p><h3 id="目前的功能进度"><a href="#目前的功能进度" class="headerlink" title="目前的功能进度"></a>目前的功能进度</h3><ul><li>提取最长转录本。<em>（已实现）</em></li><li>根据 id 提取序列。<strong>（拟下一次更新）</strong></li><li>对序列的 id 进行各种处理。<em>（已实现）</em></li><li>串联序列并得到分区信息。<strong>（拟下一次更新）</strong></li><li>批量 RBH 得到一对一直系同源基因。</li></ul><h3 id="新的想法"><a href="#新的想法" class="headerlink" title="新的想法"></a>新的想法</h3><ul><li>批量提取 Orthofinder 的 orthogroup 对应的 CDS 序列。</li><li>批量进行序列格式转换。</li><li>批量改后缀。<strong>（拟下一次更新）</strong></li></ul><p>叠盾警告⚠：不保证这些功能和想法一定会实现，本软件解释权归属 Juse 所有，本软件能走多远具体得看 Juse 能坚持多久。</p><p>下载地址：<a href="https://github.com/JuseTiZ/JuseKit/releases">https://github.com/JuseTiZ/JuseKit/releases</a></p><h2 id="ID-处理"><a href="#ID-处理" class="headerlink" title="ID 处理"></a>ID 处理</h2><h3 id="基本应用"><a href="#基本应用" class="headerlink" title="基本应用"></a>基本应用</h3><p>本文主要着重于序列 id 的处理部分，其他模块请走<a href="https://biojuse.com/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/">这里</a>。</p><p>这个模块的样子：</p><p><img src="/pic2/ip1.png"></p><p>选项卡内是所有的功能，其余部分则为对应需要填写的信息以及批量处理等功能。</p><p>当你是在序列框中输入序列时，处理的序列会保留在 JuseKit.exe 所在文件夹中并被命名为 <code>JuseKit.fa</code>，生成的文件将是 <code>JuseKit.mod.fa</code>。当选择的选项不同时，所生成的文件尾缀也不同，前缀、尾缀、简化 id 以及转变物种名分别代表 <code>pre</code>、<code>suf</code>、<code>sim</code> 和 <code>spe</code>。</p><p>当选择文件进行处理时，处理的序列会保留在所选文件的文件夹中并被命名为 <code>所选文件名.mod.fa</code>，尾缀规则同上。</p><p>当选择前缀或后缀时，运行方式为：</p><p><img src="/pic2/ip2.png"></p><p>当选择物种标识时，运行方式为（以上面生成文件为例）：</p><p><img src="/pic2/ip3.png"></p><p>可以根据自己的序列名称自行定义物种标识，例如 <code>_</code> 或 <code>|</code> 等。</p><p>当选择简化 id 时，不需要填写任何东西，直接运行即可。</p><h3 id="进阶应用"><a href="#进阶应用" class="headerlink" title="进阶应用"></a>进阶应用</h3><p><em>批量处理是什么意思？它有什么用？</em></p><p>批量处理即将目标文件夹中所有的序列进行相同处理，从而便利于大规模的数据操作。</p><p><strong>将选项与删除原有文件绑定</strong>，即删除原有文件并不会在其他功能中发挥作用。</p><blockquote><p>2023.04.24 新版本中修复了部分闪退 bug，并且将删除原有文件选项与批量处理之间的绑定关系取消了。</p></blockquote><p>叠盾警告⚠：在未存有备份文件的情况下请勿使用 <code>删除原有文件</code> 选项，否则造成的问题 Juse 概不负责。</p><p>这个选项很大程度上是为了 <code>转变物种名</code> 选项服务的，以下将以实际例子进行演示：</p><p>假设我有很多个多序列比对文件，其中每条序列可能来自于不同的物种，并且这些序列 id 的开头已经有 <code>&gt;物种名@</code> 标识。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;Human@Contig1</span><br><span class="line">ZZSLZBC</span><br><span class="line">&gt;Mouse@Contig1</span><br><span class="line">ZZSLZBG</span><br><span class="line">&gt;Bat@Contig1</span><br><span class="line">ZADLZCG</span><br></pre></td></tr></tbody></table></figure><p>这时就可以使用批量处理，将这些序列的 id 转变成对应的物种名，方便之后的一系列分析。</p><p>操作示例：</p><p><img src="/pic2/ip4.png"></p><p>软件的进程会在批量处理工具卡下方的进度条显示，如果只想对特定文件处理，请在工具卡中指定文件尾缀，否则将对文件夹中的所有文件进行。</p><p><em><strong>v0.3 更新</strong></em></p><p><em>你的尾缀太憨憨了，我想要原来的样子！</em></p><p>v0.3 新增了批量替换尾缀的功能，在使用本文中的批量处理功能后，可以使用左上方工具栏中的第一个功能进行使用。</p><p>打开文件夹后，它会自动识别已有文件的尾缀并进行填充，直接运行就可以让它们变回去了。</p><p><img src="/pic2/ip5.png"></p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>我会争取将这些功能慢慢完善，让它成为一个具有更广适用性的软件，希望能够帮助到某些盆友，当然我个人认为最大的可能是自娱自乐。</p><p>如果这个软件帮助到您了，您可以给它一个小小的 Star 聊表支持，或者在您汇报的时候引一下 <a href="https://github.com/JuseTiZ/JuseKit/">https://github.com/JuseTiZ/JuseKit/</a> ，想必看着还是非常高端大气上档次的。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 软件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JuseKit </tag>
            
            <tag> 转录组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JuseKit（一） —— 提取最长转录本</title>
      <link href="/2023/04/08/JuseKit%EF%BC%88%E4%B8%80%EF%BC%89%20%E2%80%94%E2%80%94%20%E6%8F%90%E5%8F%96%E6%9C%80%E9%95%BF%E8%BD%AC%E5%BD%95%E6%9C%AC/"/>
      <url>/2023/04/08/JuseKit%EF%BC%88%E4%B8%80%EF%BC%89%20%E2%80%94%E2%80%94%20%E6%8F%90%E5%8F%96%E6%9C%80%E9%95%BF%E8%BD%AC%E5%BD%95%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><blockquote><div id="portalContainer"></div><script src="/js/jklink.js"></script><script> generatePortalLinks(1);</script></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>JU</strong>st a <strong>SE</strong>quence tool<strong>KI</strong>t for <strong>T</strong>ranscriptomics</p><p>不同于其他的生信软件，该软件将着重于一些非常基本的功能，并且以全中文进行编写。</p><blockquote><p>已有的生信软件一直以来只能用一个简单且粗暴的词来形容：高端大气上档次。如今，我将亲自定义简陋朴素接地气。</p><p>—— Juse</p></blockquote><p>这篇文分享第一个基本功能：提取最长转录本。</p><p>下载地址：<a href="https://github.com/JuseTiZ/JuseKit/releases">https://github.com/JuseTiZ/JuseKit/releases</a></p><p>Python 代码实现：<a href="https://biojuse.com/2022/11/21/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%84%E8%A3%85%E7%9A%84%E8%B4%A8%E9%87%8F%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8E%BB%E5%86%97%E4%BD%99/">比较转录组分析（三）—— 组装的质量检测与去冗余</a></p><h2 id="提取最长转录本"><a href="#提取最长转录本" class="headerlink" title="提取最长转录本"></a>提取最长转录本</h2><p>它目前只有那么一个简陋的页面：</p><p><img src="/pic2/jk1.png"></p><p>首先，默认情况下它提取 Trinity 组装中的最长转录本，因此基因标识锁定为 <code>_i</code>，后文将提到怎么活用基因标识。</p><p><img src="/pic2/jk2.png"></p><p>输入 fasta 的方法有两个，一个是通过文本框直接输入，一个是读取文件，后者优先级更高。</p><p>输出文件的名称默认是 <code>longest_contig.fasta</code> ，可以自定义修改。注意：</p><ul><li>文件的路径和输入文件一致。当通过文本框直接输入时，它将会在 <code>.exe</code> 所在文件夹下输出。</li><li>当通过文本框直接输入时，若存在报错则说明序列出现问题或者输出文件没填，此时输入的序列会存在于 <code>.exe</code> 所在文件夹的 <code>tmp.fa</code> 中。</li><li>如果是通过文本框直接输入，那么一定要留意最后一个序列结尾是否有换行符，如果没有要加上。</li></ul><p>准备好后点击运行，将会产生对应的输出文件，实际操作：</p><p><img src="/pic2/jk3.png"></p><h3 id="进阶应用"><a href="#进阶应用" class="headerlink" title="进阶应用"></a>进阶应用</h3><p><em>自定义基因标识是什么意思？它有什么用？</em></p><p>默认提取的文件中，不同的 isoform 是长这样的：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;TRINITY_DN16889_c0_g2_i1</span><br><span class="line">ABCDEF</span><br><span class="line">&gt;TRINITY_DN16889_c0_g2_i2</span><br><span class="line">ABCDEFG</span><br></pre></td></tr></tbody></table></figure><p>这里，它们的基因部分是 <code>TRINITY_DN16889_c0_g2</code> ，不同的 isoform 可以由 <code>_i</code> 标识。</p><p>如果要提取其他的 “最长”，例如古早的 Trinity 组装版本：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;TRI_1_20_2014_NORM_comp1_c0_seq1</span><br><span class="line">ABCDEF</span><br><span class="line">&gt;TRI_1_20_2014_NORM_comp1_c0_seq2</span><br><span class="line">ABCDEFG</span><br></pre></td></tr></tbody></table></figure><p>可以看到，基因部分由 <code>TRI_1_20_2014_NORM_comp1_c0</code> 标识，不同 isoform 由 <code>_seq</code> 标识。</p><p>这时可以通过自定义基因标识，提取这种形式的最长转录本。</p><p><img src="/pic2/jk4.png"></p><p>同理也适用于 Transdecoder 预测出来的最长蛋白（或 CDS）提取（<code>.p</code>）和 MitoFinder 跑出来的多条线粒体 contig（<code>_mtDNA_contig</code>）。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Contig 示例</span><br><span class="line">&gt;TRINITY_DN100033_c0_g2_i4.p1</span><br><span class="line">&gt;TRINITY_DN100033_c0_g2_i4.p2</span><br><span class="line">&gt;xxx_mtDNA_contig_1</span><br><span class="line">&gt;xxx_mtDNA_contig_2</span><br></pre></td></tr></tbody></table></figure><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>很显然，这个软件目前的大小根本没法匹配上它的功能，原因在于现在的大小主要来源于 PyQt5 的封装，也就是说现在框架已经搭好，但也仅有框架而没有内容。</p><p>我会争取将这些功能慢慢完善，让它成为一个具有更广适用性的软件，希望能够帮助到某些盆友，当然我个人认为最大的可能是自娱自乐。</p><p>如果这个软件帮助到您了，您可以给它一个小小的 Star 聊表支持，或者在您汇报的时候引一下 <a href="https://github.com/JuseTiZ/JuseKit/">https://github.com/JuseTiZ/JuseKit/</a> ，想必看着还是非常高端大气上档次的。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 软件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JuseKit </tag>
            
            <tag> 转录组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>系统发育转录组学是否靠谱？</title>
      <link href="/2023/04/06/%E6%96%87%E7%8C%AE%E5%88%86%E4%BA%AB%E7%AF%87%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%20%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E8%BD%AC%E5%BD%95%E7%BB%84%E5%AD%A6%E6%98%AF%E5%90%A6%E9%9D%A0%E8%B0%B1%EF%BC%9F/"/>
      <url>/2023/04/06/%E6%96%87%E7%8C%AE%E5%88%86%E4%BA%AB%E7%AF%87%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%20%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E8%BD%AC%E5%BD%95%E7%BB%84%E5%AD%A6%E6%98%AF%E5%90%A6%E9%9D%A0%E8%B0%B1%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我一直认为，阅读文献应该是带着明确的目的去读，要么是想要从中学习到什么东西，要么是想通过它解答一些问题。</p><p>作为开篇，我先来分享一下对我正在研究的东西有支持性的文章：</p><blockquote><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7743905/#:~:text=However%2C%20whether%20phylotranscriptomics%20is%20as%20reliable%20as%20phylogenomics,sequences%20of%20all%20genes%20encoded%20by%20a%20genome.">Is Phylotranscriptomics as Reliable as Phylogenomics?</a></p><p>from <em>Mol Biol Evol</em></p></blockquote><p>事实上，很久之前我认为用转录组找出来的 ortholog 并不可靠，里面有太多的不确定因素会干扰结果的准确性，这也是它和基因组最大的区别所在。所以我有一段时间一度在怀疑自己这么做到底是不是对的<del>（菜鸟就是年轻气盛啊！）</del>。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>首先，研究者肯定了基因组在系统发育分析中的优越性，但也指出其成本依然昂贵，相比之下相当便宜的转录组已经成为更多研究者的选择，不过转录组依然具有以下缺点：</p><ul><li>基因表达在组织间具有差异性（例如脑组织和肌肉组织所表达的基因可能有所不同）。</li><li>基因表达在物种间具有差异性（例如不同物种的同一基因可能具有不同的表达）。</li><li>高表达基因往往进化较为缓慢，而这一类基因在转录组中是大量出现的（也有其他观点认为相较于整个基因组背景而言这些编码序列进化速度更快，因为可能包括正在快速进化如经历正选择的基因）。</li></ul><p>文章提到的这三个缺点：①、导致不知道使用哪一种组织会有更好的系统发育分析性能；②、会阻碍直系同源基因的鉴定；③、数据不完整，有很多的基因并没有被挖掘；④、进化缓慢的基因对于研究系统发育关系近的物种而言分辨率低。</p><p>考虑到这些问题，为了评估系统发育转录组的性能，研究者选择了 22 种哺乳动物和 15 种植物的转录组数据进行分析，通过比较 PT (Phylotranscriptomics) 树和 PG (Phylogenomics) 树的拓扑结构，结果表明<strong>只要直系同源基因的鉴定足够严谨</strong>，那么 PT 树和 PG 树基本一致。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>PG 树的构建方法：使用 OrthoMCL 从基因组序列中寻找一对一直系同源基因，比对修剪串联后使用 RAxML 推断 ML 树。</p><p>PT 树的构建方法：分成三种，分别是</p><ul><li>使用 HaMStR 构建核心直系同源基因并寻找目标物种的直系同源基因，然后挑选那些含有至少 50% 物种的一对一直系同源基因。</li><li>基于基因树的直系同源基因推理方法。本文使用了两种方法，一种是由 Yang &amp; Smith 提出的经验性方法（YS），一种是 PhyloPypruner。</li><li>Orthograph 寻找（相当于是 pHMMs 的最优双向命中）。</li></ul><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>在哺乳动物中，HaMStR 和 YS 方法得到了不同的树，其中后者在拓扑结构上与 PG 树高度相似，前者就有较多的错误。基于拓扑距离得到的结论一致。</p><p>这可能是因为直系同源基因的错误识别，其中 PG 方法中错误识别的比例最小（1.9%），YS 方法的较高（5.5%），HaMStR 方法最高（28.0%）。</p><p>此外，HaMStR 鉴定得到的直系同源基因比对之后具有更高的碱基位点比例。</p><p><img src="/pic/msaa181f1.jpg"></p><center>PG 树</center><p><img src="/pic/msaa181f2.jpg"></p><center>AB 是 HaMStR 结果，CD 是 YS 结果</center><p>此外研究也发现使用不同的组织并不会显著降低 Phylotranscriptomics 的准确性。</p><p>为了验证这些结论的普适性，继续对植物进行了相同的操作。这次 YS 方法得到的树拓扑结构与 PG 树一致，HaMStR 树中有一个物种的位置出错。</p><p><img src="/pic/msaa181f4.jpg"></p><center>从上到下依次是 PG、HaMStR、YS</center><p>此后，为了验证结果的稳健性，使用 PhyloPypruner 和 Orthograph 进行了 PT 树构建，并且将上述操作中 OrthoMCL 进行的部分替换成 Orthofinder 又进行了一次。结果有：</p><ul><li>PhyloPypruner 得到了与 YS 方法几乎相同的结果（都和 PG 树很像）。Orthograph 的表现则不佳，甚至表现的还不如 HaMStR。</li><li>使用 Orthofinder 得到的结果和 OrthoMCL 没有太大出入。</li><li>不同的建树方法似乎能让某些情况下 PT 树和 PG 树的差异变小（将 RAxML 替换成 IQ-TREE 后有三个组织的 PT 树和 PG 树更像了）。</li><li>推断物种树的方法变换后结果依旧是相似的（串联建树 and ASTRAL-III）。</li></ul><h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><p>总之，本研究发现 Phylotranscriptomics 和 Phylogenomics 是一样可靠的，这有望解决以下问题：</p><p>尽管基因组数据越来越多，但是一些基于基因组的研究却也得出了相互矛盾的结果，这时更广泛的物种采样可能会有所帮助。采用 Phylotranscriptomics 时，每个物种成本的降低有助于更大规模采样的进行，这可以帮助解释一些比较有争议的树。</p><p>但是有以下那么些点需要注意：</p><ul><li>Phylotranscriptomics 的结果可靠性非常依赖于严格精确的直系同源基因鉴定，虽然 YS 方法鉴定的直系同源基因比 HaMStR 少一个数量级，但是显然前者的结果要可靠许多。</li><li>可用于系统发育推断的直系同源基因数量将随着物种数的增加而减少，这也会影响到结果的精准性。例如研究分析了 22 种哺乳动物的两个子集，它们分别包含了 14 和 7 个物种，最后得到的直系同源基因数量则依次为 235 个、705 个和 1991 个，而与 PG 树的拓扑距离则分别为 4、6 和 0。</li><li>HaMStR 的直系同源基因识别受到所用核心直系同源基因的影响，因此使用与目标物种匹配的核心直系同源基因可能更有利于精确的系统发育推断。</li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>最后再做一些补充吧：</p><ul><li>HaMStR 是 RBH (reciprocal best blast hit) 方法的改进版，它的大体操作是先从核心物种中提取直系同源基因并构建隐马尔可夫模型，然后据此搜索目标物种，如果目标物种有序列能够被搜索到，那么该序列会被用来进行验证，验证的方法就是通过 RBH 看它的最佳 blast 命中是否为该直系同源基因家族中的成员，如此就能整合出包含多个物种的直系同源基因集。当然它的准确率也比单纯的 RBH 要高。</li><li>如果用的是 <code>Orthofinder + PhyloPypruner</code> 的话，就算物种数很大只要跑的时间够长也是能凑出几百个直系同源基因的，不过有可能部分物种的 gap 率会比较高。</li><li>PhyloPypruner 性能和 YS 方法差不多，但是操作上要更简单。</li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 文献阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献 </tag>
            
            <tag> 比较转录组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于 mamba install 时会出现的两个错误解决方案</title>
      <link href="/2023/03/27/%E5%85%B3%E4%BA%8E%20mamba%20install%20%E6%97%B6%E4%BC%9A%E5%87%BA%E7%8E%B0%E7%9A%84%E4%B8%A4%E4%B8%AA%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/2023/03/27/%E5%85%B3%E4%BA%8E%20mamba%20install%20%E6%97%B6%E4%BC%9A%E5%87%BA%E7%8E%B0%E7%9A%84%E4%B8%A4%E4%B8%AA%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>工欲善其事必先利其器篇堂堂连载！这篇文分享一下使用 mamba 进行安装时遇到报错该怎么解决。</p><p>一般来说错误有这么两个：</p><ul><li>File not valid: file size doesn’t match expectation</li><li>RuntimeError: Multi-download failed.</li></ul><p>这两错误在 mamba github 上已经有人提出来了，并且指出了明确的报错原因：源有问题。</p><p><code>File not valid: file size doesn't match expectation</code> 时说明源网站没有正确识别 mamba 并返回了错误的信息，例如清华的镜像源会把 mamba 当成手机设备因此会先返回一个 “用移动设备下载会消耗过多流量建议改用计算机” 的劝告信息。</p><p><code>RuntimeError: Multi-download failed.</code> 时说明源可能已经不可用，例如中科大的 conda 镜像源已经废弃。此外也有可能是因为配置的源拼写有问题，例如将 <code>conda</code> 误拼成 <code>condo</code>。</p><p>因此解决办法也是很简单的，那就是把出现问题的镜像源删了，或者是修改成可以使用的不会报错的镜像源。</p><p>以下展示如何移除镜像源：</p><p>慢一些的可以用 conda 自带的命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda config --remove channels xxxx</span></span><br></pre></td></tr></tbody></table></figure><p>快一些的可以直接编辑源的文件然后在里面操作：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nano ~/.condarc</span></span><br></pre></td></tr></tbody></table></figure><p>然后剩下这么几个就行了：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - bioconda</span><br><span class="line">  - conda-forge</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: true</span><br><span class="line">channel_priority: flexible</span><br></pre></td></tr></tbody></table></figure><p>如果后续依旧要使用 conda 的话移除镜像源可能会有些麻烦，可以视自身需求选择如何纠错。</p><blockquote><p>Reference site:</p><p><a href="https://github.com/mamba-org/mamba/issues/1641">https://github.com/mamba-org/mamba/issues/1641</a></p><p><a href="https://github.com/mamba-org/mamba/issues/1169">https://github.com/mamba-org/mamba/issues/1169</a></p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>单基因 dN、dS 和 ω 的滑动窗口绘制方法</title>
      <link href="/2023/03/13/%E5%8D%95%E5%9F%BA%E5%9B%A0-dN%E3%80%81dS-%E5%92%8C-%CF%89-%E7%9A%84%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%BB%98%E5%88%B6%E6%96%B9%E6%B3%95/"/>
      <url>/2023/03/13/%E5%8D%95%E5%9F%BA%E5%9B%A0-dN%E3%80%81dS-%E5%92%8C-%CF%89-%E7%9A%84%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%BB%98%E5%88%B6%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="需要准备的文件和软件"><a href="#需要准备的文件和软件" class="headerlink" title="需要准备的文件和软件"></a>需要准备的文件和软件</h2><p>需要提前准备好的：</p><ul><li>用于进行滑动窗口绘制的基因比对文件（<strong>核苷酸、密码子比对格式</strong>）</li><li>KaKs_Calculator 3.0</li><li>Python</li><li>R</li></ul><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2023.07.03    解封文章，简化了部分内容。</p><h2 id="滑动窗口绘制过程"><a href="#滑动窗口绘制过程" class="headerlink" title="滑动窗口绘制过程"></a>滑动窗口绘制过程</h2><h3 id="计算滑动窗口"><a href="#计算滑动窗口" class="headerlink" title="计算滑动窗口"></a>计算滑动窗口</h3><p>将需要进行滑动窗口计算的 fasta 文件放置于某个特定文件夹中。</p><p>然后使用下述 Python 脚本：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">og_file = <span class="built_in">open</span>(sys.argv[<span class="number">1</span>],<span class="string">"r"</span>)</span><br><span class="line">fa_dir = os.path.abspath(sys.argv[<span class="number">2</span>])</span><br><span class="line">sli_len = <span class="built_in">int</span>(sys.argv[<span class="number">3</span>])</span><br><span class="line">gap_len = <span class="built_in">int</span>(sys.argv[<span class="number">4</span>])</span><br><span class="line">cpu_num = sys.argv[<span class="number">5</span>]</span><br><span class="line">code_model = sys.argv[<span class="number">6</span>]</span><br><span class="line"><span class="comment">###code model:</span></span><br><span class="line"><span class="comment">#1-Standard Code                         2-Vertebrate Mitochondrial Code</span></span><br><span class="line"><span class="comment">#3-Yeast Mitochondrial Code                      4-Mold, Protozoan, and Coelenterate Mitochondrial Code and the Mycoplasma/Spiroplasma Code</span></span><br><span class="line"><span class="comment">#5-Invertebrate Mitochondrial Code                       6-Ciliate, Dasycladacean and Hexamita Nuclear Code</span></span><br><span class="line"><span class="comment">#9-Echinoderm and Flatworm Mitochondrial Code                    10-Euplotid Nuclear Code</span></span><br><span class="line"><span class="comment">#11-Bacterial, Archaeal and Plant Plastid Code                   12-Alternative Yeast Nuclear Code</span></span><br><span class="line"><span class="comment">#13-Ascidian Mitochondrial Code                          14-Alternative Flatworm Mitochondrial Code</span></span><br><span class="line"><span class="comment">#16-Chlorophycean Mitochondrial Code                     21-Trematode Mitochondrial Code</span></span><br><span class="line"><span class="comment">#22-Scenedesmus obliquus Mitochondrial Code                      23-Thraustochytrium Mitochondrial Code</span></span><br><span class="line"><span class="comment">#24-Rhabdopleuridae Mitochondrial Code                   25-Candidate Division SR1 and Gracilibacteria Code</span></span><br><span class="line"><span class="comment">#26-Pachysolen tannophilus Nuclear Code                          27-Karyorelict Nuclear Code</span></span><br><span class="line"><span class="comment">#28-Condylostoma Nuclear Code                    29-Mesodinium Nuclear Code</span></span><br><span class="line"><span class="comment">#30-Peritrich Nuclear Code                       31-Blastocrithidia Nuclear Code</span></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"></span><br><span class="line">time_start = time.strftime(<span class="string">'%Y%m%d-%H%M%S'</span>)</span><br><span class="line">os.mkdir(<span class="string">f'SWworkdir_<span class="subst">{time_start}</span>'</span>)</span><br><span class="line"></span><br><span class="line">ogall = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> og_file:</span><br><span class="line">oglist = [line.split(<span class="string">'\t'</span>)[<span class="number">0</span>], line.split(<span class="string">'\t'</span>)[<span class="number">1</span>].strip()]</span><br><span class="line">ogall.append(oglist)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">readfa</span>(<span class="params">fasta</span>):</span><br><span class="line"></span><br><span class="line">id_seq = {}</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(fasta, <span class="string">'r'</span>) <span class="keyword">as</span> fa:</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fa:</span><br><span class="line"><span class="keyword">if</span> line.startswith(<span class="string">"&gt;"</span>):</span><br><span class="line">idofseq = line.split()[<span class="number">0</span>][<span class="number">1</span>:]</span><br><span class="line">id_seq[idofseq] = <span class="string">''</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">id_seq[idofseq] += line.strip()</span><br><span class="line"><span class="keyword">return</span> id_seq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fa2axt</span>(<span class="params">oglist, fasta, name</span>):</span><br><span class="line"></span><br><span class="line">axtname = <span class="string">'-'</span>.join(oglist)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f'<span class="subst">{name}</span>'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> axt:</span><br><span class="line">axt.write(<span class="string">f"<span class="subst">{axtname}</span>\n"</span>)</span><br><span class="line"><span class="keyword">for</span> spe <span class="keyword">in</span> oglist:</span><br><span class="line">axt.write(fasta[spe] + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sliding</span>(<span class="params">fasta, oglist, sli_len, gap_len, dire</span>):</span><br><span class="line"></span><br><span class="line">fa = readfa(fasta)</span><br><span class="line">fa_len = <span class="built_in">len</span>(<span class="built_in">list</span>(fa.values())[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">posi = <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> (posi-<span class="number">1</span>)*gap_len + sli_len &lt;= fa_len-<span class="number">1</span>:</span><br><span class="line">os.mkdir(<span class="string">f"<span class="subst">{dire}</span>/posi_<span class="subst">{posi}</span>"</span>)</span><br><span class="line">ini_fa = {}</span><br><span class="line">sta_po = (posi-<span class="number">1</span>)*gap_len</span><br><span class="line">end_po = sta_po + sli_len</span><br><span class="line"><span class="keyword">for</span> spe <span class="keyword">in</span> oglist:</span><br><span class="line">ini_fa[spe] = fa[spe][sta_po:end_po]</span><br><span class="line">fa2axt(oglist, ini_fa, <span class="string">f"<span class="subst">{dire}</span>/posi_<span class="subst">{posi}</span>/sliding_<span class="subst">{posi}</span>.axt"</span>)</span><br><span class="line">posi += <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> (posi-<span class="number">1</span>)*<span class="number">3</span> + sli_len &gt; fa_len-<span class="number">1</span>:</span><br><span class="line">os.mkdir(<span class="string">f"<span class="subst">{dire}</span>/posi_<span class="subst">{posi}</span>"</span>)</span><br><span class="line">ini_fa = {}</span><br><span class="line">sta_po = (posi-<span class="number">1</span>)*gap_len</span><br><span class="line">end_po = sta_po + sli_len</span><br><span class="line"><span class="keyword">for</span> spe <span class="keyword">in</span> oglist:</span><br><span class="line">ini_fa[spe] = fa[spe][sta_po:]</span><br><span class="line">fa2axt(oglist, ini_fa, <span class="string">f"<span class="subst">{dire}</span>/posi_<span class="subst">{posi}</span>/sliding_<span class="subst">{posi}</span>.axt"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> oglist <span class="keyword">in</span> ogall:</span><br><span class="line"></span><br><span class="line">ogname = <span class="string">'-'</span>.join(oglist)</span><br><span class="line">outputdir = <span class="string">f'SWworkdir_<span class="subst">{time_start}</span>/<span class="subst">{ogname}</span>'</span></span><br><span class="line">os.mkdir(outputdir)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> gene <span class="keyword">in</span> os.listdir(fa_dir):</span><br><span class="line"></span><br><span class="line">genename = gene.split(<span class="string">'.'</span>)[<span class="number">0</span>]</span><br><span class="line">os.mkdir(<span class="string">f'<span class="subst">{outputdir}</span>/<span class="subst">{genename}</span>'</span>)</span><br><span class="line">sliding(<span class="string">f'<span class="subst">{fa_dir}</span>/<span class="subst">{gene}</span>'</span>, oglist, sli_len, gap_len, <span class="string">f'<span class="subst">{outputdir}</span>/<span class="subst">{genename}</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Sliding window completed...\nRunning Kaks_cal..."</span>)</span><br><span class="line"></span><br><span class="line">os.system(<span class="string">f'for i in `ls SWworkdir_<span class="subst">{time_start}</span>/*/*/*/*axt`;do echo "KaKs -i $i -o $i.kaks -c <span class="subst">{code_model}</span>" &gt;&gt; sliding_window.command; done'</span>)</span><br><span class="line">os.system(<span class="string">f'cat sliding_window.command | parallel --no-notice -j <span class="subst">{cpu_num}</span>'</span>)</span><br><span class="line">os.system(<span class="string">'rm sliding_window.command'</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Kaks_cal done\nMerging result..."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">readkaks</span>(<span class="params">kaksfile</span>):</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(kaksfile, <span class="string">'r'</span>) <span class="keyword">as</span> kf:</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> kf:</span><br><span class="line"><span class="keyword">if</span> line.startswith(<span class="string">"Sequence"</span>):</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">dN = line.split(<span class="string">'\t'</span>)[<span class="number">2</span>]</span><br><span class="line">dS = line.split(<span class="string">'\t'</span>)[<span class="number">3</span>]</span><br><span class="line">omega = line.split(<span class="string">'\t'</span>)[<span class="number">4</span>]</span><br><span class="line"><span class="keyword">return</span> {<span class="string">"dN"</span>: dN, <span class="string">"dS"</span>: dS, <span class="string">"omega"</span>: omega}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> oglist <span class="keyword">in</span> ogall:</span><br><span class="line"></span><br><span class="line">ogname = <span class="string">'-'</span>.join(oglist)</span><br><span class="line">outputdir = <span class="string">f'SWworkdir_<span class="subst">{time_start}</span>/<span class="subst">{ogname}</span>'</span></span><br><span class="line">sf_res = <span class="built_in">open</span>(<span class="string">f'<span class="subst">{outputdir}</span>/sliding_window_<span class="subst">{ogname}</span>.res'</span>, <span class="string">'w'</span>)</span><br><span class="line">sf_res.write(<span class="string">'Gene\tPosition\tType\tvalue\n'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> gene <span class="keyword">in</span> os.listdir(outputdir):</span><br><span class="line"></span><br><span class="line">genesf = <span class="string">f'<span class="subst">{outputdir}</span>/<span class="subst">{gene}</span>'</span></span><br><span class="line"><span class="keyword">if</span> os.path.isdir(genesf):</span><br><span class="line">total_num = <span class="built_in">len</span>(os.listdir(genesf))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, total_num + <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">kaksinfo = readkaks(<span class="string">f'<span class="subst">{genesf}</span>/posi_<span class="subst">{i}</span>/sliding_<span class="subst">{i}</span>.axt.kaks'</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> kaksinfo:</span><br><span class="line">sf_res.write(<span class="string">f'<span class="subst">{gene}</span>\t<span class="subst">{i}</span>\t<span class="subst">{v}</span>\t<span class="subst">{kaksinfo[v]}</span>\n'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Finished."</span>)</span><br></pre></td></tr></tbody></table></figure><p>运行前需要保证 KaKs 所在路径已经放置在环境变量中。</p><p>此后进行计算：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python sliding_window.py ogfile fa_dir sli_len gap_len cpu_num code_model</span></span><br></pre></td></tr></tbody></table></figure><p><code>ogfile</code> 为一个制表符分隔的文本文件，每一行为一个滑动窗口要计算的物种对。例：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tax1tax2</span><br><span class="line">tax3tax4</span><br></pre></td></tr></tbody></table></figure><p>该情况会计算 tax1-tax2 和 tax3-tax4 的滑动窗口结果。</p><p><code>fa_dir</code> 为比对好的 fasta 文件所在文件夹路径。</p><p><code>sli_len</code> 为滑动窗口的长度。<code>gap_len</code> 为每个滑动窗口的间隔。</p><p><code>cpu_num</code> 为使用 KaKs 计算时调用的内核数。<code>code_model</code> 为计算时使用的密码子翻译模式。</p><p>运行例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python sliding_window.py ogfile fa_dir 57 6 20 1</span></span><br></pre></td></tr></tbody></table></figure><p>该情况下滑动窗口大小为 57 bp，间隔为 6 bp，使用 20 个内核计算，并使用标准密码子表。</p><p>计算结束后，会在<strong>当前所在路径</strong>中，出现一个工作文件夹，每个物种对的结果储存在相应文件夹中以 <code>.res</code> 结尾的文件里。</p><p>该文件可用于后续 R 进行可视化。</p><h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><p>使用 R 进行，本来这一步我也想用脚本一步到位地解决，但发现最后要调整的东西很多，所以贴出参考代码然后依照需求修改可能会更好些。</p><p>R 代码大致如下：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">library<span class="punctuation">(</span>ggplot2<span class="punctuation">)</span></span><br><span class="line">library<span class="punctuation">(</span>ggpubr<span class="punctuation">)</span></span><br><span class="line">library<span class="punctuation">(</span>ggprism<span class="punctuation">)</span></span><br><span class="line">library<span class="punctuation">(</span>readxl<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">barplot <span class="operator">=</span> read.delim<span class="punctuation">(</span><span class="string">"xxx.res"</span><span class="punctuation">)</span></span><br><span class="line">color <span class="operator">=</span> <span class="built_in">rep</span><span class="punctuation">(</span><span class="string">"black"</span><span class="punctuation">,</span> times <span class="operator">=</span> <span class="built_in">length</span><span class="punctuation">(</span>barplot<span class="operator">$</span>Type<span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">color<span class="punctuation">[</span>barplot<span class="operator">$</span>value <span class="operator">&gt;</span> <span class="number">1</span> <span class="operator">&amp;</span> barplot<span class="operator">$</span>Type <span class="operator">==</span> <span class="string">"omega"</span><span class="punctuation">]</span> <span class="operator">=</span> <span class="string">"red"</span></span><br><span class="line">barplot <span class="operator">=</span> cbind<span class="punctuation">(</span>barplot<span class="punctuation">,</span> color<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">pdf<span class="punctuation">(</span><span class="string">"slwd.pdf"</span><span class="punctuation">,</span>width <span class="operator">=</span> <span class="number">10</span><span class="punctuation">,</span>height <span class="operator">=</span> <span class="number">8</span><span class="punctuation">)</span></span><br><span class="line">ggplot<span class="punctuation">(</span>barplot<span class="punctuation">,</span>aes<span class="punctuation">(</span>Position<span class="punctuation">,</span> value<span class="punctuation">,</span> fill <span class="operator">=</span> color<span class="punctuation">)</span><span class="punctuation">)</span> <span class="operator">+</span> </span><br><span class="line">  geom_bar<span class="punctuation">(</span>stat <span class="operator">=</span> <span class="string">"identity"</span><span class="punctuation">,</span>width <span class="operator">=</span> <span class="number">0.9</span><span class="punctuation">)</span> <span class="operator">+</span> </span><br><span class="line">  theme_prism<span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">+</span> </span><br><span class="line">  theme<span class="punctuation">(</span>axis.line.y<span class="operator">=</span>element_line<span class="punctuation">(</span>linetype<span class="operator">=</span><span class="number">1</span><span class="punctuation">,</span>color<span class="operator">=</span><span class="string">"black"</span><span class="punctuation">,</span>size<span class="operator">=</span><span class="number">1</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">        axis.line.x<span class="operator">=</span>element_line<span class="punctuation">(</span>linetype<span class="operator">=</span><span class="number">1</span><span class="punctuation">,</span>color<span class="operator">=</span><span class="string">"black"</span><span class="punctuation">,</span>size<span class="operator">=</span><span class="number">1</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">        axis.ticks.x<span class="operator">=</span>element_line<span class="punctuation">(</span>color<span class="operator">=</span><span class="string">"black"</span><span class="punctuation">,</span>size<span class="operator">=</span><span class="number">1</span><span class="punctuation">,</span>lineend <span class="operator">=</span> <span class="number">1</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">        axis.ticks.y<span class="operator">=</span>element_line<span class="punctuation">(</span>color<span class="operator">=</span><span class="string">"black"</span><span class="punctuation">,</span>size<span class="operator">=</span><span class="number">1</span><span class="punctuation">,</span>lineend <span class="operator">=</span> <span class="number">1</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">        axis.text.x <span class="operator">=</span> element_text<span class="punctuation">(</span>angle <span class="operator">=</span> <span class="number">90</span><span class="punctuation">,</span> size <span class="operator">=</span> <span class="number">12</span><span class="punctuation">,</span>face <span class="operator">=</span> <span class="string">"plain"</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">        axis.text.y <span class="operator">=</span> element_text<span class="punctuation">(</span>size <span class="operator">=</span> <span class="number">12</span><span class="punctuation">,</span>face <span class="operator">=</span> <span class="string">"plain"</span><span class="punctuation">)</span><span class="punctuation">,</span> </span><br><span class="line">        axis.title<span class="operator">=</span>element_text<span class="punctuation">(</span>size<span class="operator">=</span><span class="number">18</span><span class="punctuation">,</span>face<span class="operator">=</span><span class="string">"plain"</span><span class="punctuation">)</span><span class="punctuation">,</span> </span><br><span class="line">        legend.position <span class="operator">=</span> <span class="string">"none"</span><span class="punctuation">)</span> <span class="operator">+</span> </span><br><span class="line">  xlab<span class="punctuation">(</span><span class="string">"Sliding windows starting positions (bp)"</span><span class="punctuation">)</span> <span class="operator">+</span></span><br><span class="line">  facet_grid<span class="punctuation">(</span>Type <span class="operator">~</span> Gene<span class="punctuation">,</span> scales<span class="operator">=</span><span class="string">"free"</span><span class="punctuation">,</span>space<span class="operator">=</span><span class="string">"free_x"</span><span class="punctuation">)</span> <span class="operator">+</span> </span><br><span class="line">  scale_x_continuous<span class="punctuation">(</span>breaks <span class="operator">=</span> seq<span class="punctuation">(</span><span class="number">0</span><span class="punctuation">,</span> <span class="number">300</span><span class="punctuation">,</span> by <span class="operator">=</span> <span class="number">100</span><span class="punctuation">)</span><span class="punctuation">,</span>labels <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">"0"</span><span class="punctuation">,</span> <span class="string">"600"</span><span class="punctuation">,</span> <span class="string">"1200"</span><span class="punctuation">,</span> <span class="string">"1800"</span><span class="punctuation">)</span><span class="punctuation">)</span> <span class="operator">+</span> </span><br><span class="line">  scale_fill_manual<span class="punctuation">(</span>values<span class="operator">=</span><span class="built_in">c</span><span class="punctuation">(</span><span class="string">"#666666"</span><span class="punctuation">,</span><span class="string">"red"</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">dev.off<span class="punctuation">(</span><span class="punctuation">)</span></span><br></pre></td></tr></tbody></table></figure><p>输出图片文件的宽高需根据实际情况修改，随后再调整一下各个标签的位置并给基因名打上斜体，最后的结果就出来了：</p><p><img src="/pic/slwd.png"></p><p>其中，ω 标红的区域代表该窗口中 ω 大于 1。</p><h2 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h2><p>从作用上来讲，画滑动窗口图，可以了解一个特定的基因内不同区域的选择情况。</p><p>从博客经营角度出发，这个又让我能写一篇文，补足前几个月摸鱼的空缺。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 绘图 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当 cmake 遇上 permission denied</title>
      <link href="/2023/03/09/%E5%BD%93%20cmake%20%E9%81%87%E4%B8%8A%20permission%20denied/"/>
      <url>/2023/03/09/%E5%BD%93%20cmake%20%E9%81%87%E4%B8%8A%20permission%20denied/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>工欲善其事必先利其器，软件就是生信人的武器，这篇文就是分享使用 cmake 配置遇到 permission denied 时应该怎么解决。</p><h2 id="一般错误出现的情况"><a href="#一般错误出现的情况" class="headerlink" title="一般错误出现的情况"></a>一般错误出现的情况</h2><p>一般来说，cmake 安装软件的流程都是大致如下：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> xxx <span class="comment"># 下载某个软件</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> xxx <span class="comment"># 进入下载的文件夹中</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cmake . <span class="comment"># cmake 进行编译配置</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make install <span class="comment"># make 进行安装</span></span></span><br></pre></td></tr></tbody></table></figure><p>在最后一步 make install 的时候，有时会出现 permission denied。</p><h2 id="如果具有-sudo-权限"><a href="#如果具有-sudo-权限" class="headerlink" title="如果具有 sudo 权限"></a>如果具有 sudo 权限</h2><p>这种情况一般发生在自己的电脑上（root 用户），又或者拥有 sudo 权限，加一个 <code>sudo</code> 即可。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo make install</span></span><br></pre></td></tr></tbody></table></figure><h2 id="如果不具有-sudo-权限"><a href="#如果不具有-sudo-权限" class="headerlink" title="如果不具有 sudo 权限"></a>如果不具有 sudo 权限</h2><p>本篇文章的重心，permission denied 的原因是自己没有在 <code>/usr/local</code> 配置文件的权限而又无法通过 <code>sudo</code> 解决，这个路径是很多软件默认的安装路径，但同样也是可选的，所以解决方法就是把安装路径改到<strong>自己有权限</strong>的路径即可。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cmake 时指定其他安装路径</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cmake -DCMAKE_INSTALL_PREFIX:PATH=/xxx/xxx .</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make install</span></span><br></pre></td></tr></tbody></table></figure><p>这里需要更改的即 <code>/xxx/xxx</code>（调整为要安装的路径），最后的 <code>.</code> <strong>并不是错打而是必需的</strong>！</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>如果使用 make 安装发生这种问题也不用慌，解决方法是相近的：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./configure --prefix=/xxx/xxx</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make install</span></span><br></pre></td></tr></tbody></table></figure><p>如果没有 configure 配置文件可以按照下面的方法进行：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">make prefix=/xxx/xxx install</span></span><br></pre></td></tr></tbody></table></figure><p>记得把安装路径配置进 PATH 变量里，以后方便调用 :)</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>基于 Cytoscape 的富集网络图绘制</title>
      <link href="/2023/03/02/%E5%9F%BA%E4%BA%8E%20Cytoscape%20%E7%9A%84%E5%AF%8C%E9%9B%86%E7%BD%91%E7%BB%9C%E5%9B%BE%E7%BB%98%E5%88%B6/"/>
      <url>/2023/03/02/%E5%9F%BA%E4%BA%8E%20Cytoscape%20%E7%9A%84%E5%AF%8C%E9%9B%86%E7%BD%91%E7%BB%9C%E5%9B%BE%E7%BB%98%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="所需文件"><a href="#所需文件" class="headerlink" title="所需文件"></a>所需文件</h2><p>需要准备的文件：通过 <strong>David</strong> 得到的富集分析结果表格。</p><p>软件的下载方式请自寻，请支持正版。</p><p>注意，本文着重的是无参转录组富集分析结果的网络图绘制，如果是有参基因组请移步它处。</p><h2 id="绘图过程"><a href="#绘图过程" class="headerlink" title="绘图过程"></a>绘图过程</h2><p>首先我们需要通过 David 分析得到富集分析结果文件。</p><p>DAVID 富集分析教程可见：<a href="https://biojuse.com/2022/12/19/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94%20GO%20%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/">比较转录组分析（六）</a>。</p><p>注意，这里对我来说仅选择 GO 的结果是不够的，因为这样会导致富集网络图中的节点数量过少（因为富集的 GO term 过少），因此我选择了更多的项（DAVID 的所有默认项）来进行富集结果的输出，可以根据个人的情况进行相应的调整。</p><p>得到表格以后可以直接输入 Cytoscape 进行绘制。</p><p>首先在 <code>Apps</code> 一栏中选择 <code>App Manager</code> 并下载以下两个插件：</p><ul><li>Enrichment Map</li><li>WordCloud</li></ul><p><img src="/pic/cyto2.png"></p><p>此后打开 <code>Apps</code> 中的 <code>Enrichment Map</code> ，会跳出一个窗口，操作步骤如下图所示：</p><p><img src="/pic/cyto3.png"></p><p>在这里可以输入多个表格（例如分别输入上调基因和下调基因的富集分析表格）。此外，在输入了表达量文件后左下角部分还可对基因进行表达量过滤，右下角可以通过调整参数来调节节点的聚集程度和连接程度等。勾选 Show advanced options 后还可进行更加细节的调整（例如设置 p 值和 FDR 值阈值、调整节点间距离计算方式等），这些都可以看个人的需要和偏好进行尝试和更改。</p><p>这里我输入了两份文件（一个是上调基因的富集分析结果，另一个是下调基因的富集分析结果），然后略微调整了下下面的参数等。</p><p><img src="/pic/cyto4.png"></p><p><img src="/pic/cyto5.png"></p><p>也可以多尝试几个参数看一看哪一种情况最好，然后选择觉得最不错的用于后续处理。</p><p>此后的一些操作网络的基本方式：</p><ul><li>左 <code>Ctrl</code> 键 + 长按鼠标左键选择要拖动的节点进行布局。</li><li>选中节点后可以用右键进行各种编辑（删除、绑定成组、甚至乎寻找对应的 GO 描述或通路描述等）。</li></ul><p>如果想要给一块聚在一起的基因集进行注释以说明它们代表着哪些功能，方式有以下两种：</p><p>①、选中目标节点，然后右键选择 <code>Apps</code> 中的 <code>AutoAnnotate</code>。</p><p><img src="/pic/cyto6.png"></p><p><img src="/pic/cyto7.png"></p><p>但上述方法从效果上来说显然是不太好的，因此为了追求更好的效果可以选择下一种方式：</p><p>②、选中目标节点，然后右键选择 <code>Apps</code> 中的 <code>Create Cloud</code>。此时会出来一个词云图，展示了各种词的词频大小等。</p><p><img src="/pic/cyto8.png"></p><p>知道关键词 Hsp 以后，选择左侧栏中的 Annotation ，选择栏目中上方第三个图案，拖拽至指定位置并作调整，此后用第一个添加文字注释，效果如下：</p><p><img src="/pic/cyto9.png"></p><p>通过这种方法，划分不同区块基因集，同时利用注释图案的颜色分别标注出上调和下调基因，同时拖拽节点到合适位置，就能造出一个有模有样的富集网络图了：</p><p><img src="/pic/cyto10.png"></p><p>另外如果觉得这种点的样式太丑也可以自己在左侧的 style 中进行详细的修改等。</p><p><img src="/pic/cyto11.png"></p><p>更多进阶的知识可以查看 Enrichment Map 的官方 tutorial ：<a href="https://enrichmentmap.readthedocs.io/en/latest/">EnrichmentMap Cytoscape App 3.5 — EnrichmentMap 3.5 documentation</a></p><h2 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h2><p>Cytoscape 的功能很强大，里面还有许多的插件可以用来做富集网络图，比如说 ClueGO 就是一个很好的选择。</p><p>此外它还可以绘制共表达网络图等类型的图，只需要下载相应的插件即可。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 绘图 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 富集网络图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>比较转录组分析（七）—— 系统发育分析</title>
      <link href="/2023/02/17/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94%20%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E5%88%86%E6%9E%90/"/>
      <url>/2023/02/17/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94%20%E7%B3%BB%E7%BB%9F%E5%8F%91%E8%82%B2%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><blockquote><div id="portalContainer"></div><script src="/js/ctlink.js"></script><script> generatePortalLinks(7);</script></blockquote><h2 id="关于分类学和系统发育分析"><a href="#关于分类学和系统发育分析" class="headerlink" title="关于分类学和系统发育分析"></a>关于分类学和系统发育分析</h2><p>分类学，这个学科虽然听起来很简单，但从整个生物史的尺度出发都能算的上是一个非常具有深度且一直以来都争议颇多的学问。从几个世纪前，分类学家就已经致力于通过各种形态学差异或者生活史差异来描述不同物种之间的亲缘关系并且把它们分门别类成不同的类群。在那个时候，不同的学者也会根据 “个人之见” 进行颇具主观性的划分（而且某些近缘物种之间的形态学差异确实可以迥然不同），因此许多分类单元并不统一且一直以来都在不停变动，这一些现象在达尔文先生的《物种起源》中表现得淋漓尽致。</p><p>即使古早的分类方法并不完全准确，分类学家依然完成了非常瞩目的成就，就拿现在的物种分类情况来说，很多框架依然与以前一致，并且新的分类单元也是基于已有的框架延申出来的。</p><p>测序手段的发展算得上是分类学的一个里程碑，从分子层面的观察让我们对于物种的分类关系有了更为准确的把握，这催生了大量分类错误的纠正以及新物种的发现，并且由此诞生出来了分子系统发育学这一学科。目前很多生信软件都能帮助我们探讨不同物种间的系统发育关系。</p><p>这篇文将分享如何通过一些软件来进行系统发育分析。</p><h3 id="出现的一些词"><a href="#出现的一些词" class="headerlink" title="出现的一些词"></a>出现的一些词</h3><p><strong>直系同源物和旁系同源物</strong>：见 <a href="https://www.jianshu.com/p/4d29d24883d2">生信基因功能分析工具：Orthofinder 使用教程</a>，更多详细信息见文章末尾题外话知识点。</p><p><strong>异同源（xenolog）</strong>：指通过基因水平转移，来源于共生或病毒侵染所产生的相似基因。也是一个进化学上比较热门的问题，在微生物、病毒及与这些类群密切相关的生物（如昆虫等）中较为常见。</p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2023.06.24    解封文章，完善了关于 Phylopypruner 的说明，补充了各种信息。</p><p>2023.07.16    删去了部分内容，进行了一些补充。</p><p>2023.09.02    优化了脚本，所需要的时间大大降低了。</p><h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><h3 id="所需文件和软件"><a href="#所需文件和软件" class="headerlink" title="所需文件和软件"></a>所需文件和软件</h3><ul><li>不同物种的 pep 序列。</li><li>软件（相关的安装请自主查阅）：<ul><li>orthofinder</li><li>mafft</li><li>trimAl</li><li>iqtree (建议使用 v2 以上的版本，模型寻找更快)</li><li>phylopypruner</li></ul></li></ul><h3 id="使用-Orthofinder-寻找同源序列"><a href="#使用-Orthofinder-寻找同源序列" class="headerlink" title="使用 Orthofinder 寻找同源序列"></a>使用 Orthofinder 寻找同源序列</h3><p>其他可选的软件也有 OrthoMCL 等，不过从 Orthofinder 具有更突出的优势（见后记题外话）, 此外它涵盖了更多且更全面的功能，使用非常便捷，并不需要花过多的时间学习。</p><p>安装方法和使用教程见：<a href="https://www.jianshu.com/p/16e0bbb2ba19">「基因组学」使用 OrthoFinder 进行直系同源基因分析</a>。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">orthofinder -f ./ -t 16</span></span><br></pre></td></tr></tbody></table></figure><p>这里讲一些需要注意的点：</p><ul><li>最好指定合适的线程数（因为 orthofinder 默认使用的线程数是 128，不足 128 则使用最大的线程数）。</li><li>也可以输入 DNA 序列，需要使用参数 <code>-d</code>。</li><li>无需指定 <code>-M msa</code> ，这些工作可以自己做并且更具可控性。</li><li>Orhofinder 在找完同源群后还会为每个同源群进行建树，这会消耗更多的时间，而且它并不会计算自展值，因此如果想省时间在最开始运行命令时指定 <code>-og</code>。</li><li>跑前请一定确保所有的 pep 序列都已经打上了物种标识！不然在后续的分析中你将很难区分每条序列来自哪个物种。</li></ul><p>其他的参数使用默认值即可。理解输出的文件比运行软件更重要，因此这里着重分享 Orthofinder 得到的结果是什么以及有什么用：</p><p>有最详尽解释的 orthofinder 官网 <a href="https://github.com/davidemms/OrthoFinder%E3%80%82">https://github.com/davidemms/OrthoFinder。</a></p><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">Comparative_Genomics_Statistics</summary><div class="toggle-content"><p>这个文件夹对于基于转录组分析的结果来说应该是没太大用处的。</p><p>它里面包括了一些基因复制事件的信息以及同源群的相关信息（比如说同源群的共享情况、同源群的大小信息等）。</p><p>Gene_Duplication_Events 同理，不过里面记录着更详细的基因复制事件信息。</p></div></details><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">Gene_Trees</summary><div class="toggle-content"><p>里面是关于同源群所对应的基因树。</p></div></details><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">Orthogroups &amp; Orthologues</summary><div class="toggle-content"><p>更详尽的同源群信息，比如每个同源群中包括了哪些物种的哪些基因。</p></div></details><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">Orthogroup_Sequences</summary><div class="toggle-content"><p>重要的文件夹，里面包括了所有同源群对应的序列信息，也就是每个 orthogroup 的 fasta 文件。</p></div></details><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">Single_Copy_Orthologue_Sequences</summary><div class="toggle-content"><p>在同源群中，<strong>每个物种只有一个基因</strong>的 orthogroup 序列，并不是严格意义上的单拷贝基因（而是推定得到的），如果数量足够可用于序列串联和建树。</p></div></details><details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">Species_Tree</summary><div class="toggle-content"><p>为一份 orthofinder 推断的物种树，默认的方法为 STAG，原理是把包含了所有物种的 orthogroup 对应基因树挑出来，并计算两物种间最近的距离，最后根据每个 orthogroup 的距离矩阵计算得到最后的共识物种树，节点的支持率由这 orthogroup 中的真实情况进行统计计算。</p></div></details><p>另外一些文件涉及到异同源、HOG 等信息，详细可以前往官网查看。</p><h3 id="直接使用-Single-Copy-Orthologue-Sequences-中的序列（情况-①）"><a href="#直接使用-Single-Copy-Orthologue-Sequences-中的序列（情况-①）" class="headerlink" title="直接使用 Single_Copy_Orthologue_Sequences 中的序列（情况 ①）"></a>直接使用 Single_Copy_Orthologue_Sequences 中的序列（情况 ①）</h3><p>这种方法适用于 orthofinder 找到了很多 ‘single copy ortholog’ 的情况，不过这种一般只在分析的物种数较少时发生。</p><h3 id="对-Orthogroup（OG）-进行挑选分类（情况-②）"><a href="#对-Orthogroup（OG）-进行挑选分类（情况-②）" class="headerlink" title="对 Orthogroup（OG） 进行挑选分类（情况 ②）"></a>对 Orthogroup（OG） 进行挑选分类（情况 ②）</h3><p>进行分类的原因很简单，一些很大的 orthogroup 里肯定包含了很多 paralog，虽然网上对于 orthogroup 的翻译是直系同源群，但显然里面并不都是 ortholog。很多 Phylotranscriptomics 文章中，研究者也会首先挑选出那些较小且包含物种数较多的 orthogroup 进行后续分析。</p><p>此外，部分 OG 中包含的物种数量很少，这种 OG 我们也应当剔除分析之外，具体的挑选通过 Python 实现：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># ortho_select</span></span><br><span class="line"><span class="comment"># Verson: 1.0</span></span><br><span class="line"><span class="comment"># This is used to select orthogroup from output of orthofinder.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>():</span><br><span class="line"></span><br><span class="line"><span class="keyword">global</span> args</span><br><span class="line">parser = argparse.ArgumentParser(description = <span class="string">"This is used to select orthogroup from output of orthofinder."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-l"</span>, <span class="string">"--least"</span>, <span class="built_in">type</span> = <span class="built_in">int</span>, <span class="built_in">help</span> = <span class="string">"Least number of species concluding."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-b"</span>, <span class="string">"--big"</span>, default = <span class="number">20</span>, <span class="built_in">type</span> = <span class="built_in">int</span>, <span class="built_in">help</span> = <span class="string">"Orthogroup considered as a big ortho when a species have more than xx sequences. default = 20"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-f"</span>, <span class="string">"--file"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The path to the orthofinder og file."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-o"</span>, <span class="string">"--output"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The output path of dir."</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mkdir</span>():</span><br><span class="line"></span><br><span class="line"><span class="keyword">global</span> outputDir</span><br><span class="line">outputDir = os.path.abspath(args.output)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">os.mkdir(<span class="string">f'<span class="subst">{outputDir}</span>/orthogroup_small'</span>)</span><br><span class="line">os.mkdir(<span class="string">f'<span class="subst">{outputDir}</span>/orthogroup_big'</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Please check the outputdir."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_seq</span>(<span class="params">seq</span>):</span><br><span class="line"></span><br><span class="line">species_seq = {}</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(seq, <span class="string">"r"</span>) <span class="keyword">as</span> s:</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> s:</span><br><span class="line"><span class="keyword">if</span> line.startswith(<span class="string">"&gt;"</span>):</span><br><span class="line">species = line.split(<span class="string">"@"</span>)[<span class="number">0</span>][<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">if</span> species <span class="keyword">in</span> species_seq.keys():</span><br><span class="line">species_seq[species] += <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">species_seq[species] = <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(species_seq.keys()) &lt; args.least:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"<span class="subst">{seq}</span>'s num of species is less than <span class="subst">{args.least}</span> and so abondoned."</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">all</span>(i &lt;= args.big <span class="keyword">for</span> i <span class="keyword">in</span> species_seq.values()):</span><br><span class="line">os.system(<span class="string">f"cp <span class="subst">{seq}</span> <span class="subst">{outputDir}</span>/orthogroup_small/"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">os.system(<span class="string">f"cp <span class="subst">{seq}</span> <span class="subst">{outputDir}</span>/orthogroup_big/"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_select</span>():</span><br><span class="line"></span><br><span class="line">inputdir = os.path.abspath(args.file)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(inputdir):</span><br><span class="line">select_seq(<span class="string">f"<span class="subst">{inputdir}</span>/<span class="subst">{i}</span>"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">arges = get_args()</span><br><span class="line">mkdir()</span><br><span class="line">run_select()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">t0 = time.time()</span><br><span class="line">main()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'Total time used: <span class="subst">{time.time() - t0}</span>s\nFinished! See output at <span class="subst">{outputDir}</span>'</span>)</span><br></pre></td></tr></tbody></table></figure><p>如果物种标识以下划线区分则将脚本中的 <code>@</code> 改为 <code>_</code>，用法例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> ortho_seq</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python ortho_select.py -l 30 -b 20 -f /pathto/OrthoFinder/Results_xxx/Orthogroup_Sequences -o ortho_seq</span></span><br></pre></td></tr></tbody></table></figure><p>其中：</p><ul><li><p><code>-l</code> 指定最少物种数</p></li><li><p><code>-b</code> 为当有物种序列数大于多少时该 OG 会被视为大 OG</p></li><li><p><code>-f</code> 为 orthofinder 跑出来的 Orthogroup_Sequences 路径</p></li><li><p><code>-o</code> 为输出的文件夹</p></li></ul><p>上述用例中，该命令将得到叫做 <code>ortho_seq</code> 的文件夹，其中包含 <code>orthogroup_big</code> 和 <code>orthogroup_small</code> 两个文件夹。</p><p>之后的操作将在 <code>orthogroup_small</code> 中进行（如果该文件夹处理后依然没得到足够的 msa 则需要对 <code>orthogroup_big</code> 中的序列再跑一次 orthofinder 以进行补充）。</p><h3 id="比对以及修剪"><a href="#比对以及修剪" class="headerlink" title="比对以及修剪"></a>比对以及修剪</h3><p>在对应的文件夹中输入以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span> *.fa;</span></span><br><span class="line">do</span><br><span class="line">id=${i%%.fa}</span><br><span class="line">mafft --thread 4 --auto $i &gt; $id.mafft.fasta</span><br><span class="line">done</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span> *mafft.fasta;</span></span><br><span class="line">do</span><br><span class="line">id=${i%%.mafft.fasta}</span><br><span class="line">trimal -in $i -out $id.trimal.fasta -gappyout</span><br><span class="line">done</span><br></pre></td></tr></tbody></table></figure><p><strong>mafft：</strong></p><p>mafft 的 <code>--thread</code> 对应使用的线程数。</p><p>此外 mafft 有多种比对模式以适用于不同的序列情况，<code>--auto</code> 开启后则是让 mafft 根据序列情况自动寻找适合的比对策略。</p><p><strong>trimal：</strong></p><p>trimal 也有很多种修剪策略，不同的修剪策略会选择不同的修剪阈值，目前的 trimal 主要包括三种策略 <em><code>gappyout</code><em>、</em><code>strict</code></em> 以及 *<code>strictplus</code>*。</p><p>第一种<strong>只考虑到比对的 gap 部分</strong>，会修剪掉比对中的 most gappy fraction。</p><p>后两种相较于第一种<strong>还考虑到了 gap 部分的相似性分数</strong>，其中 <em>strictplus</em> 比 <em>strict</em> 更加严格。</p><p>另外还有一种 <code>automated</code> 的方法，它会考虑到一些比对的信息比如说序列数量、序列间的一致性分数等然后基于此选择使用 <code>gappyout</code> or <code>strictplus</code>。</p><h3 id="二次筛选"><a href="#二次筛选" class="headerlink" title="二次筛选"></a>二次筛选</h3><p>在比对及修剪后部分 msa 的序列长度变短（可能修剪掉太多也有可能是 gap 太多），这些 msa 包含的信息量比较少，因此可以把它们筛掉选择其他那些 “合格” 的 msa 进行下一步的分析。</p><p>筛选的思路：选出长度高于一定阈值的 msa，其次删掉里面 gap 过多的序列，然后再根据删除后的物种数情况选择是否保留该 msa。</p><p>Python 实现：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># trim_filter</span></span><br><span class="line"><span class="comment"># Verson: 1.0</span></span><br><span class="line"><span class="comment"># This is used to filter alignment to build genetree.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>():</span><br><span class="line"></span><br><span class="line"><span class="keyword">global</span> args</span><br><span class="line">parser = argparse.ArgumentParser(description = <span class="string">"This is used to filter alignment to build genetree, run in the directory."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-s"</span>, <span class="string">"--seq"</span>, default = <span class="number">80</span>, <span class="built_in">type</span> = <span class="built_in">int</span>, <span class="built_in">help</span> = <span class="string">"Deletes original seqs shorter than this length, default = 80."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-a"</span>, <span class="string">"--align"</span>, default = <span class="number">80</span>, <span class="built_in">type</span> = <span class="built_in">int</span>, <span class="built_in">help</span> = <span class="string">"Minimum length of a trimmed alignment in amino acids, default = 80."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-t"</span>, <span class="string">"--tax"</span>, <span class="built_in">type</span> = <span class="built_in">int</span>, <span class="built_in">help</span> = <span class="string">"Specify minimum number of taxa, namely Minimum number of OTUs to keep an OG. Required!"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">remove_n</span>(<span class="params">string, char</span>):</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">len</span>(re.sub(char, <span class="string">''</span>, string))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">filter</span>():</span><br><span class="line"></span><br><span class="line">min_tax_num = args.tax</span><br><span class="line">min_len_file = args.seq</span><br><span class="line">min_len_alig = args.align</span><br><span class="line"><span class="keyword">for</span> trims <span class="keyword">in</span> os.listdir(<span class="string">"./"</span>):</span><br><span class="line">os.system(<span class="string">f'echo "Processing file <span class="subst">{trims}</span>......" &gt;&gt; trim_filter.log'</span>)</span><br><span class="line"><span class="comment"># 得到该比对的各个信息</span></span><br><span class="line">id_seq = {}</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(trims, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line"><span class="keyword">if</span> line.startswith(<span class="string">"&gt;"</span>):</span><br><span class="line">seq_name = line.strip()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment"># 制作映射字典</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">id_seq[seq_name] += line</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">id_seq[seq_name] = line</span><br><span class="line"></span><br><span class="line">os.system(<span class="string">f'rm <span class="subst">{trims}</span>'</span>)</span><br><span class="line"><span class="comment"># 判断序列原始长度是否达标</span></span><br><span class="line"><span class="keyword">if</span> remove_n(<span class="built_in">list</span>(id_seq.values())[<span class="number">0</span>], <span class="string">'\n'</span>) &lt; min_len_file:</span><br><span class="line">os.system(<span class="string">f'echo "<span class="subst">{trims}</span> length is less than <span class="subst">{min_len_file}</span>AA and be removed." &gt;&gt; trim_filter.log'</span>)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">os.system(<span class="string">f'echo "<span class="subst">{trims}</span> length is enough for next filter." &gt;&gt; trim_filter.log'</span>)</span><br><span class="line"><span class="comment"># 筛选合格序列</span></span><br><span class="line">newid_seq = {}</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> id_seq.keys():</span><br><span class="line"><span class="keyword">if</span> remove_n(id_seq[i], <span class="string">'[-\n]'</span>) &gt;= min_len_alig:</span><br><span class="line">newid_seq[i] = id_seq[i]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">os.system(<span class="string">f'echo "<span class="subst">{trims}</span> <span class="subst">{i[<span class="number">1</span>:]}</span> is shorter than <span class="subst">{min_len_alig}</span>AA and be removed." &gt;&gt; trim_filter.log'</span>)</span><br><span class="line"><span class="comment"># 判断物种数量是否合格</span></span><br><span class="line">species_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> newid_seq.keys():</span><br><span class="line">species = i.split(<span class="string">'@'</span>)[<span class="number">0</span>][<span class="number">1</span>:]</span><br><span class="line"><span class="comment"># 统计物种名单</span></span><br><span class="line"><span class="keyword">if</span> species <span class="keyword">not</span> <span class="keyword">in</span> species_list:</span><br><span class="line">species_list.append(species)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(species_list) &lt; min_tax_num:</span><br><span class="line">os.system(<span class="string">f'echo "<span class="subst">{trims}</span> tax is less than <span class="subst">{min_tax_num}</span> and be removed." &gt;&gt; trim_filter.log'</span>)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"><span class="comment"># 重新再建比对</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(trims, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> newid_seq.keys():</span><br><span class="line">f.write(i + <span class="string">'\n'</span>)</span><br><span class="line">f.write(newid_seq[i])</span><br><span class="line">os.system(<span class="string">f'echo "<span class="subst">{trims}</span> has been saved and filtered." &gt;&gt; trim_filter.log'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">get_args()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="built_in">filter</span>()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Please check the path."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Running..."</span>)</span><br><span class="line">main()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'Finished! See running log in trim_filter.log'</span>)</span><br></pre></td></tr></tbody></table></figure><p>如果物种标识以下划线区分则将脚本中的 <code>@</code> 改为 <code>_</code>，用法例：</p><p>把修剪后的序列复制一份到新的文件夹中：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> orthogroup_trim</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> orthogroup_small/*trimal.fasta orthogroup_trim/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> orthogroup_trim</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python /pathto/trim_filter.py -t 30</span></span><br></pre></td></tr></tbody></table></figure><p>具体的参数含义可见脚本。</p><p>在这之后如果一开始使用的是 <code>Single_Copy_Orthologue_Sequences</code> 的序列，那么可以直接跳到序列串联一部分。</p><h3 id="构建基因树（情况-②）"><a href="#构建基因树（情况-②）" class="headerlink" title="构建基因树（情况 ②）"></a>构建基因树（情况 ②）</h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">ls</span> *.trimal.fasta`;</span></span><br><span class="line">do</span><br><span class="line">id=${i%%.fasta}</span><br><span class="line">echo "iqtree2 -s $i -pre $id -bb 1000 -nt 4" &gt;&gt; iqtree_command</span><br><span class="line">done</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> iqtree_command | parallel --no-notice -j 10</span></span><br></pre></td></tr></tbody></table></figure><p>并行命令使用 IQTREE 进行批量的基因树构建，请根据实际情况修改 <code>-nt</code> 及 <code>-j</code> 参数。</p><p>也可以先从小的 Orthogroup sequence 开始建树（更快）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">ls</span> -r *.trimal.fasta`;</span></span><br><span class="line">do</span><br><span class="line">id=${i%%.fasta}</span><br><span class="line">echo "iqtree2 -s $i -pre $id -bb 1000 -nt 3" &gt;&gt; iqtree_command</span><br><span class="line">done</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> iqtree_command | parallel --no-notice -j 20</span></span><br></pre></td></tr></tbody></table></figure><h3 id="运行-Phylopypruner（情况-②）"><a href="#运行-Phylopypruner（情况-②）" class="headerlink" title="运行 Phylopypruner（情况 ②）"></a>运行 Phylopypruner（情况 ②）</h3><p>Phylopypruner 是实现多对多到一对一的关键步骤，它的原理是根据基因树所提供的信息进行一系列过滤修剪从而得到最准确的一对一直系同源物（虽然这仍是推定 [putative] 的）。详尽的原理以及各个参数含义可见其 <a href="https://gitlab.com/fethalen/phylopypruner/-/wikis/Home">gitlab</a>。</p><p><img src="/pic/proteomes2orthologs.png"></p><p>首先需要一个前置脚本 <code>OTU_replace.py</code> 用于替换基因树中的序列 id（iqtree 进行建树时会将 @ 替换成 _，但 Phylopypruner 只识别 @，当然也可以改源码让 Phylopypruner 可以识别 _）。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># OTU_replace</span></span><br><span class="line"><span class="comment"># Verson: 1.2</span></span><br><span class="line"><span class="comment"># This is used to replace OTU_ to OTU@ in fasta or treefile.</span></span><br><span class="line"><span class="comment"># Usage: python3 OTU_replace.py dir species_list</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">help_info</span>():</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"This is used to replace OTU_ to OTU@ in fasta or treefile.\n\tUsage: python3 OTU_replace.py dir species_list\n\tThe file can be indentified includes .fa .fasta .fas .tre .treefile"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getArgs</span>():</span><br><span class="line"></span><br><span class="line"><span class="keyword">global</span> inputfiledir</span><br><span class="line"><span class="keyword">global</span> species_list</span><br><span class="line"></span><br><span class="line">args = sys.argv[<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(args) == <span class="number">0</span>:</span><br><span class="line">help_info()</span><br><span class="line">sys.exit()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">inputfiledir = os.path.abspath(args[<span class="number">0</span>])</span><br><span class="line">species_list = os.path.abspath(args[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Please check the dirpath."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">spe_list_get</span>():</span><br><span class="line"></span><br><span class="line">spe_list = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(species_list, <span class="string">'r'</span>) <span class="keyword">as</span> s:</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> s:</span><br><span class="line">spe_list.append(line.strip())</span><br><span class="line"><span class="keyword">return</span> spe_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_replace</span>(<span class="params">dir_path, spe_list</span>):</span><br><span class="line"></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r'('</span> + <span class="string">'|'</span>.join(spe_list) + <span class="string">')_'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(dir_path):</span><br><span class="line">        <span class="keyword">if</span> filename.endswith((<span class="string">'.fa'</span>, <span class="string">'.fasta'</span>, <span class="string">'.fas'</span>, <span class="string">'.tre'</span>, <span class="string">'.treefile'</span>)):</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(dir_path, filename), <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                content = f.read()</span><br><span class="line"></span><br><span class="line">            new_content = pattern.sub(<span class="string">r'\1@'</span>, content)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(dir_path, filename), <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(new_content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">getArgs()</span><br><span class="line">spe_list = spe_list_get()</span><br><span class="line">run_replace(inputfiledir, spe_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">t0 = time.time()</span><br><span class="line">main()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'Total time used: <span class="subst">{time.time() - t0}</span>s\nFinished!'</span>)</span><br></pre></td></tr></tbody></table></figure><p>species_list 文件中应当包含所有物种的对应物种标识：</p><p>例如如果 fasta 中的序列名为这样，则 species_list 应为其下的格式，其中一行对应一个物种名。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;Human@xxxxxx</span><br><span class="line">&gt;Mouse@xxxxxxx</span><br><span class="line">&gt;Fish@xxxxxxxxx</span><br></pre></td></tr></tbody></table></figure><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Human</span><br><span class="line">Mouse</span><br><span class="line">Fish</span><br></pre></td></tr></tbody></table></figure><p>此后使用 Phylopypruner 推定不同物种的一对一同源物。如果运行所用的数据集过大，在运行的过程中极有可能发生递归错误，因此可以考虑在 Phylopypruner 的 <code>__main__.py</code> 中设置更大的递归深度：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">phylopypruner --<span class="built_in">dir</span> ./ --min-len 100 --trim-lb 5 --threads 6 \</span></span><br><span class="line"><span class="language-bash">--min-support 0.75 --prune MI --min-taxa 6 --min-otu-occupancy 0.1 \</span></span><br><span class="line"><span class="language-bash">--min-gene-occupancy 0.1 --trim-freq-paralogs 4 --trim-divergent 1.25 \</span></span><br><span class="line"><span class="language-bash">--jackknife --min-pdist 1e-8</span></span><br></pre></td></tr></tbody></table></figure><p>上述各参数设置是直接照搬 Phylopypruner gitlab 官网所给的<strong>过滤标准最严格</strong>的示例参数，但是实际的参数使用应该视自身需求及已有数据集情况而定！</p><blockquote><p>PhyloPyPruner, when compared to pre-existing orthology inference programs, have many more parameters that you could potentially tweak so finding a good starting point might be difficult. These are some suggested settings to get you started, but don’t forget to adjust the settings according to your own needs and the overall structure of the dataset that you are working with.</p></blockquote><p>这里附上 Phylopypruner 各参数含义：</p><ul><li><code>--dir</code> 多序列比对和树文件所在文件夹。</li><li><code>--min-len</code> 比对的最小长度，可以根据之前选择的过滤阈值修改。</li><li><code>--trim-lb</code> 删除长度超过所有分支标准差 n 倍的分支。</li><li><code>--threads</code> 使用的线程数。</li><li><code>--min-support</code> 将支持率低于 n 的节点归并成多分枝。</li><li><code>--prune</code> 使用 xx 方法进行剪枝。</li><li><code>--min-taxa</code> 不输出物种数小于 n 的比对，可以根据之前选择的过滤阈值修改。</li><li><code>--min-otu-occupancy</code> 如果某个物种的比对出现率在 n 以下，则删除该物种。</li><li><code>--min-gene-occupancy</code> 删除包含 1-n 以上 gap 的序列。</li><li><code>--trim-freq-paralogs</code> &amp; <code>--trim-divergent</code> &amp; <code>--min-pdist</code>：控制旁系同源过滤和直系同源质量的参数。</li></ul><blockquote><p><code>--trim-freq-paralogs 4</code> will get rid of taxa with more than 4 times the standard deviation of the total number of paralogs divided by the number of alignments in which each taxon is present in</p><p><code>--trim-divergent 1.25</code> will remove all sequences from a taxon on a per-alignment-basis, if the relative distance from the taxons own sequences, when compared to all other sequences, is than 125%</p><p><code>--min-pdist 1e-8</code> will remove any sequence pair which belong to two different species and have a distance that is less than 1e-8</p></blockquote><ul><li><code>--jackknife</code> 逐个删除物种，返回 <em><strong>删除某个物种后将恢复多少序列和比对</strong></em> 的信息。</li></ul><p>如果运行终止并返回 <code>RecursionError</code> 错误，那么你可以在 Phylopypruner 根目录下的 <code>phylopypruner/__main__.py</code> 中对 <code>main()</code> 部分进行修改：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sys.setrecursionlimit(<span class="number">100000</span>) <span class="comment"># 添加该行，如果还不行就将该值提高为更高的值，例如 200000</span></span><br></pre></td></tr></tbody></table></figure><p>对于已安装 conda 并使用 pip 安装的情况，该文件将位于 <code>anaconda3/lib/pythonx.x/site-packages/phylopypruner</code> 中。</p><p>最后所得到的伪一对一直系同源基因序列就可以在 <code>phylopypruner_output/output_alignments</code> 中查看，其中每个物种最多存在一条序列，需要注意的是，某些 orthogroup 可能会分离得到多个 <code>xxx_pruned_x.fasta</code>：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">OGxxxxxxx.trimal_pruned_1.fasta</span><br><span class="line">OGxxxxxxx.trimal_pruned_2.fasta</span><br></pre></td></tr></tbody></table></figure><h3 id="串联序列，Iqtree-建树"><a href="#串联序列，Iqtree-建树" class="headerlink" title="串联序列，Iqtree 建树"></a>串联序列，Iqtree 建树</h3><p><strong>此处以最大似然法建树软件 IQTREE 为例</strong>，当然也可以视自身要求选择其他方法和对应软件。</p><p>串联序列这一部分已在之前的文章中提到过，请走：<a href="https://biojuse.com/2023/01/29/%E7%94%A8%E4%BA%8E%20IQtree%20%E7%9A%84%E5%BA%8F%E5%88%97%E4%B8%B2%E8%81%94%E6%96%B9%E6%B3%95/">传送门</a>。</p><p>串联后运行下面的命令进行建树：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iqtree2 -s concatenation_ortho.fasta \</span></span><br><span class="line"><span class="language-bash">-spp IQ_partition.txt \</span></span><br><span class="line"><span class="language-bash">-m MFP+MERGE -bb 1000 -quiet -nt 20 -pre allOG</span></span><br></pre></td></tr></tbody></table></figure><p>各个参数的含义：</p><p><code>-s</code> 是输入的串联序列文件，<code>-spp</code> 则对应前者的分区信息，<code>-nt</code> 是使用的线程数（可以使用 <code>-nt AUTO</code> 让 iqtree 自己选择合适的线程数）。</p><p><code>-m</code> 是 iqtree 的运行模式，选定 <code>MFP+MERGE</code> 时 iqtree 会自动寻找最佳分区方案和替换模型。</p><p><code>-bb</code> 是 iqtree 的一种自展值计算方法 <em>ultrafast bootstrap</em> 的重复次数，一般设置 1000 次。</p><p>注意，<em>ultrafast bootstrap</em> 虽然相较于传统的计算方法只要求更低的计算资源，但是仅当支持率超过 95 时才能说明这个分支是可信的。</p><p><code>-quiet</code> 开启静默模式，此时 iqtree 不会有任何的屏幕输出。</p><p>更多相关的信息请见 iqtree 的 <a href="http://www.iqtree.org/doc/">documentation</a>。</p><p>建完树以后会得到一系列文件，以下一些文件比较关键：</p><p><code>xxx.treefile</code> 树文件，为多序列联合建树的结果。</p><p><code>xxx.best_scheme.nex</code> 和 <code>xxx.best_model.nex</code> 中有具体的分区信息和模型选择。</p><p>而这次得到的树文件，我们就可以把它当作一个揭示了物种间系统发育关系的<strong>物种树</strong>。</p><h3 id="其他方法建树"><a href="#其他方法建树" class="headerlink" title="其他方法建树"></a>其他方法建树</h3><p>可见其他文章，例：</p><p><a href="https://biojuse.com/2023/07/06/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%BB%BA%E6%A0%91%E4%B9%8B%20Mrbayes%20%E7%AF%87/">贝叶斯建树之 Mrbayes 篇</a></p><p><a href="https://biojuse.com/2023/06/23/Astral%20%E5%BB%BA%E6%A0%91%E6%8C%87%E5%8D%97/">Astral 建树指南</a></p><h2 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h2><p>提及到的所有脚本都放在了 <a href="https://github.com/JuseTiZ/pythonscript">github</a> 上，要搬去自用的话需要根据自身情况进行一定的修改等。</p><p>本文提出的仅是系统发育转录组学中一种可行的方法套路，请谨慎参考。<strong>所有相关脚本及代码的<em>具体参数选择</em>都<em>应依据实际需求进行更正</em>。</strong></p><p>如果搞不明白脚本怎么运行想省时间，可以试着看一看博客中的 <em><strong>JuseKit</strong></em> 系列，下载软件并根据教程进行操作（当然更建议学一学 Python）。</p><h3 id="Orthofinder-相比之-OrthoMCL-优势在哪"><a href="#Orthofinder-相比之-OrthoMCL-优势在哪" class="headerlink" title="Orthofinder 相比之 OrthoMCL 优势在哪"></a>Orthofinder 相比之 OrthoMCL 优势在哪</h3><p>简单来说，OrthoMCL 划分同源群时使用的是 <code>reciprocal BLAST best-hit method（RBH）</code>，这种方法有个坏处在于它会受到序列长度的干扰。</p><p>基于此，Orthofinder 使用了序列长度进行矫正，提高了同源群划分的精度，这种矫正后的方法叫做 <code>reciprocal best normalised hit（RBNH）</code>。</p><p><img src="/pic/ortho.png"></p><blockquote><p>OrthoFinder: solving fundamental biases in whole genome comparisons dramatically improves orthogroup inference accuracy</p><p>from <em>Genome Biology</em></p></blockquote><p>不过这并不代表绝对准确，某些 Orthogroup 中可能仍带有许多的 Paralog。</p><h3 id="准确推出-Ortholog-与-Paralog-的必要性"><a href="#准确推出-Ortholog-与-Paralog-的必要性" class="headerlink" title="准确推出 Ortholog 与 Paralog 的必要性"></a>准确推出 Ortholog 与 Paralog 的必要性</h3><p>这个问题很简单，以下图为例：</p><p><img src="/pic/ortho2.png"></p><p>当我们使用直系同源基因进行推断时，不管使用 α 还是 β 都能得到正确的结论，即这三个物种中鼠和人具有更近的亲缘关系。</p><p>但如果选错了基因，比如说挑选了青蛙和人的 α 基因，以及鼠的 β 基因，虽然挑取的都为同源基因，但是直系同源和旁系同源的区别会使得我们推断出青蛙和人的亲缘关系更近这一错误结论。</p><p>因此，<strong>直系同源的正确划分是推断系统发育关系的重点</strong>。</p><h3 id="蛋白序列建树和核苷酸序列建树"><a href="#蛋白序列建树和核苷酸序列建树" class="headerlink" title="蛋白序列建树和核苷酸序列建树"></a>蛋白序列建树和核苷酸序列建树</h3><p>使用核苷酸序列和蛋白序列建树得到的结果大多时候都是一致的，但也有可能存在不同。</p><p>原因是核苷酸实际上是一种更 “精” 的序列，它相较蛋白序列而言包含更多的信息，比如说某些同义替换等。</p><p>因此当存在出入时一般需要再进行考证，大多数情况下蛋白序列和核苷酸序列建树结果的不一致是出现在某些支持率较低的 node 上，这时再添加一些 Ortholog 分析可能可以解决问题。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 系统发育分析 </tag>
            
            <tag> 比较转录组学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用于 IQtree 的序列串联方法</title>
      <link href="/2023/01/29/%E7%94%A8%E4%BA%8E%20IQtree%20%E7%9A%84%E5%BA%8F%E5%88%97%E4%B8%B2%E8%81%94%E6%96%B9%E6%B3%95/"/>
      <url>/2023/01/29/%E7%94%A8%E4%BA%8E%20IQtree%20%E7%9A%84%E5%BA%8F%E5%88%97%E4%B8%B2%E8%81%94%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>因为这一段时间很懒而且现实生活的事情又多，所以系统发育分析的正式文章教程可能要搁置一会，但是想着总得更新些东西出来，所以就以这篇文章作为正餐开始前的一叠小菜分享分享。</p><p>事实上序列串联对于刚涉及到这一块的新手来说确实也会有些迷糊，比如说串联是怎么个串联法，需要准备什么文件，文件的内容格式应该是怎样等等问题都会存在，这篇文里就针对这一点讲一讲。</p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2023-04-07    简化了脚本，并完善了脚本的注释。</p><p>2023-07-04    完善了脚本，并添加了部分内容。</p><h3 id="需要知道的知识"><a href="#需要知道的知识" class="headerlink" title="需要知道的知识"></a>需要知道的知识</h3><p>一些系统发育分析中的概念是最基础的，如果未作了解或了解不深可以看一下这篇文章：<a href="https://www.biodiversity-science.net/CN/10.3724/SP.J.1003.2014.13170">生命之树及其应用</a> 。写的非常全面和具体，里面涉及到的各种术语也很专业，同时也介绍了很多常用的软件等。本文涉及到的地方就是这篇文章展望部分中第一点讲的 “超大树构建方法的革新” 中的超矩阵方法。</p><h2 id="序列串联方法"><a href="#序列串联方法" class="headerlink" title="序列串联方法"></a>序列串联方法</h2><h3 id="需要准备的文件"><a href="#需要准备的文件" class="headerlink" title="需要准备的文件"></a>需要准备的文件</h3><p>首先按照惯例推出几个能够实现的软件：<code>Phylosuite</code>、<code>FASconCAT-G</code>。前者用起来非常方便但是我只下了 windows 的版本，虽然它有 linux 的版本但我也没去调查怎么用，索性就自己写了个脚本进行序列串联。</p><p>先说明需要的文件内容格式：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;tax1@seq1</span><br><span class="line">ABCDEFG</span><br><span class="line">&gt;tax2@seq1</span><br><span class="line">ABCDEEG</span><br><span class="line">&gt;tax3@seq1</span><br><span class="line">ACCDEEG</span><br></pre></td></tr></tbody></table></figure><p>这是一个由不同物种的同源基因组成的多序列比对，其中不同 tax 代表不同的物种，以 @ 作为分隔符，其后对应不同物种的同源序列名称。对应的序列是已经经过比对修剪的序列，允许 gap 存在。<strong>每个物种至多存在一条序列</strong>。例（我随便编的）：</p><p>这是一个同源序列（蛋白）：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;Human@human_1215</span><br><span class="line">AAABKISPLM</span><br><span class="line">&gt;Mouse@mouse_98455</span><br><span class="line">AAXBKISPLM</span><br><span class="line">&gt;Fish@fish_1561</span><br><span class="line">AAABKISPNM</span><br></pre></td></tr></tbody></table></figure><p>这是另一个同源序列（蛋白）：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;Human@human_5372</span><br><span class="line">CJBSODNONVOIAA</span><br><span class="line">&gt;Mouse@mouse_12389</span><br><span class="line">CJBSODNNNVOIAS</span><br><span class="line">&gt;Fish@fish_1001</span><br><span class="line">DJBSODNBNVOIAS</span><br></pre></td></tr></tbody></table></figure><p>串联的意思是把它们串成这样（<strong>一个比对中不一定包含所有物种，串联以后该比对不存在的物种会全部以 gap 代替</strong>）：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;Human</span><br><span class="line">AAABKISPLMCJBSODNONVOIAA</span><br><span class="line">&gt;Mouse</span><br><span class="line">AAXBKISPLMCJBSODNNNVOIAS</span><br><span class="line">&gt;Fish</span><br><span class="line">AAABKISPNMDJBSODNBNVOIAS</span><br></pre></td></tr></tbody></table></figure><p>串成这样以后，也要有对应的 partition 信息以供软件进行超矩阵算法。</p><p>对我而言，实现上述操作的方法有两种：</p><ol><li><p>①、简化 ID 成物种编号（就是把 @ 以及后面的序列编号全删了）。</p><p>②、将处理后的序列输入 Phylosuite 处理。</p></li><li><p>编写脚本一步到位。</p></li></ol><p>对于第一种方法如果序列比较少是没什么问题，因为下载到 windows 不用多久（当然如果会 phylosuite 的 Linux 端操作也会变得非常方便），但是如果涉及到的序列很多且很大那就只能自己动手丰衣足食了。</p><h3 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h3><blockquote><p>2023-07-04 引流补充：</p><p>如果是 Windows 系统：不嫌麻烦的话可以下载我基于 PyQt5 编写的 <a href="https://biojuse.com/2023/04/13/JuseKit%EF%BC%88%E4%B8%89%EF%BC%89%20%E2%80%94%E2%80%94%20%E4%B8%B2%E8%81%94%E5%BA%8F%E5%88%97%E3%80%81%E6%A0%B9%E6%8D%AEid%E6%8F%90%E5%8F%96%E5%BA%8F%E5%88%97%E3%80%81%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%B0%BE%E7%BC%80/">JuseKit</a>，其中包含序列串联功能且输出信息更完善。</p></blockquote><p>如果是 Linux 系统，以下是我编写的序列串联脚本：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># sequence_con</span></span><br><span class="line"><span class="comment"># Verson: 1.1</span></span><br><span class="line"><span class="comment"># Date: 2023.1.14</span></span><br><span class="line"><span class="comment"># This script concatenates sequences and generates an IQ-TREE2 partition file.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">IQpartition = <span class="string">'#nexus\nbegin sets;\n'</span></span><br><span class="line">total_length = <span class="number">0</span></span><br><span class="line">total_spe_seq = {}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">total_num = <span class="built_in">len</span>(os.listdir(<span class="string">'./'</span>))</span><br><span class="line">compl_num = <span class="number">0</span></span><br><span class="line">aligns = os.listdir(<span class="string">'./'</span>)</span><br><span class="line">aligns.sort()</span><br><span class="line"></span><br><span class="line"><span class="comment">#对当前文件夹里所有文件逐个读取</span></span><br><span class="line"><span class="keyword">for</span> align <span class="keyword">in</span> aligns:</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(align, <span class="string">'r'</span>) <span class="keyword">as</span> ali:</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化当前文件信息</span></span><br><span class="line">tmp_len = <span class="number">0</span></span><br><span class="line">tmp_species = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> ali:</span><br><span class="line"><span class="keyword">if</span> line.startswith(<span class="string">'&gt;'</span>) <span class="keyword">and</span> line.strip() != <span class="string">'&gt;'</span>:</span><br><span class="line"><span class="comment">#如果物种名以下划线分割则替换为_</span></span><br><span class="line">spe_name = line.split(<span class="string">'@'</span>)[<span class="number">0</span>].strip()</span><br><span class="line"></span><br><span class="line">tmp_species.append(spe_name)</span><br><span class="line"></span><br><span class="line"><span class="comment">#到当前比对才出现的物种之前的序列都以gap表示</span></span><br><span class="line"><span class="keyword">if</span> spe_name <span class="keyword">not</span> <span class="keyword">in</span> total_spe_seq.keys():</span><br><span class="line">total_spe_seq[spe_name] = <span class="string">'-'</span>*total_length</span><br><span class="line"></span><br><span class="line"><span class="comment">#跳过空序列</span></span><br><span class="line"><span class="keyword">elif</span> line.strip() == <span class="string">'&gt;'</span> <span class="keyword">or</span> line.strip() == <span class="string">''</span>:</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将第一个序列的长度读取以作为该多序列比对的长度</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(tmp_species) == <span class="number">1</span>:</span><br><span class="line">tmp_len += <span class="built_in">len</span>(line.strip())</span><br><span class="line"></span><br><span class="line">total_spe_seq[spe_name] += line.strip(<span class="string">'&gt;'</span>).strip()</span><br><span class="line"></span><br><span class="line"><span class="comment">#对不在该文件出现但在之前出现过的物种以gap作为其序列进行补充</span></span><br><span class="line"><span class="keyword">for</span> spe <span class="keyword">in</span> total_spe_seq.keys():</span><br><span class="line"><span class="keyword">if</span> spe <span class="keyword">not</span> <span class="keyword">in</span> tmp_species:</span><br><span class="line">total_spe_seq[spe] += <span class="string">'-'</span>*tmp_len</span><br><span class="line"><span class="comment">#添加分区信息</span></span><br><span class="line">charsetid = align.split(<span class="string">'.'</span>)[<span class="number">0</span>]</span><br><span class="line">IQpartition += <span class="string">f"\tcharset <span class="subst">{charsetid}</span>=<span class="subst">{total_length+<span class="number">1</span>}</span>-<span class="subst">{total_length+tmp_len}</span>;\n"</span></span><br><span class="line"></span><br><span class="line">total_length += tmp_len</span><br><span class="line">compl_num += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"The progress is <span class="subst">{compl_num}</span>/<span class="subst">{total_num}</span>..."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">os.mkdir(<span class="string">"con_res"</span>)</span><br><span class="line"><span class="comment">#生成物种log</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">"con_res/sequence_con.log"</span>, <span class="string">'w'</span>) <span class="keyword">as</span> log:</span><br><span class="line"></span><br><span class="line">log.write(<span class="string">"Species\tLength\n"</span>)</span><br><span class="line"><span class="keyword">for</span> spe <span class="keyword">in</span> total_spe_seq.keys():</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(total_spe_seq[spe]) == total_length:</span><br><span class="line">log.write(<span class="string">f"<span class="subst">{spe[<span class="number">1</span>:]}</span>\t<span class="subst">{<span class="built_in">len</span>(total_spe_seq[spe])}</span>AA\t+\n"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">log.write(<span class="string">f"<span class="subst">{spe[<span class="number">1</span>:]}</span>\t<span class="subst">{<span class="built_in">len</span>(total_spe_seq[spe])}</span>AA\t-\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"See running log in con_res/sequence_con.log"</span>)</span><br><span class="line"><span class="comment">#生成串联文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">"con_res/concatenation_ortho.fasta"</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> spe <span class="keyword">in</span> total_spe_seq:</span><br><span class="line">f.write(spe + <span class="string">'\n'</span> + total_spe_seq[spe] + <span class="string">'\n'</span>)</span><br><span class="line"><span class="comment">#生成分区文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">"con_res/IQ_partition.txt"</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line"></span><br><span class="line">f.write(IQpartition)</span><br><span class="line">f.write(<span class="string">"end;"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Finished, see output at con_res.'</span>)</span><br></pre></td></tr></tbody></table></figure><p>原理比较简单，不过相对于其他软件的处理而言，这个脚本还可以解决 “空序列” 的问题。</p><p>运行也很简单，在存放多序列比对文件的文件夹中输入 <code>python /path/sequence_con.py</code> 即可（<strong>脚本不要放里面，也不要存在其他类型的文件</strong>，因为我没有加尾缀识别的判断语句）。</p><p>运行结束后会多出一个 <code>con_res</code> 的文件夹，里面有合并后的序列 <code>concatenation_ortho.fasta</code> 以及用于 <strong>IQtree</strong> 建树的分区信息（IQ_partition.txt），此外也有一个运行日志 <code>sequence_con.log</code>，里面记录了每个物种的序列长度信息，最后一列为 <code>+</code> 则表示与第一个长度一致，理应上所有的物种都应该为 <code>+</code> ，如果出现 <code>-</code> 号则说明该物种的某些比对存在错误，长度与其他物种不一致。</p><p><img src="/pic/iq.png"></p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>这一段时间完全放飞自我，正事没咋干摸鱼摸一堆，一方面是身不由己另一方面确实打不起什么劲，说明环境对于人的影响还是非常显著的。</p><p>相关的 python 脚本同以前一样放在了 github 里，感兴趣可以自取，若是不嫌麻烦事实上 phylosuite 也是个不错的选择（国人软件，能多引一个是一个）。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 系统发育分析 </tag>
            
            <tag> IQtree </tag>
            
            <tag> 序列串联 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于 GraphPad Prism 的火山图绘制</title>
      <link href="/2022/12/23/%E5%9F%BA%E4%BA%8E%20GraphPad%20Prism%20%E7%9A%84%E7%81%AB%E5%B1%B1%E5%9B%BE%E7%BB%98%E5%88%B6/"/>
      <url>/2022/12/23/%E5%9F%BA%E4%BA%8E%20GraphPad%20Prism%20%E7%9A%84%E7%81%AB%E5%B1%B1%E5%9B%BE%E7%BB%98%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="软件信息"><a href="#软件信息" class="headerlink" title="软件信息"></a>软件信息</h2><p>此文中使用的 GraphPad Prism 版本为 9.4.1，获取方式请自寻，请支持正版。</p><p>需要准备的文件：差异表达分析结果表格。</p><p>9.0 以上版本的 GraphPad Prism 已经支持火山图绘制，但是绘图效果并没有利用散点图绘制来的好，因此这篇文还是通过散点图的方式来实现火山图绘制，如果想要试试 Prism 自带的火山图可以在点开 Prism 时选择 Graph Portfolio 里的 Volcano Plot 进行：</p><p><img src="/pic/prism1.png"></p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2023.07.07    精简了内容，增加了题外话。</p><h2 id="绘图过程"><a href="#绘图过程" class="headerlink" title="绘图过程"></a>绘图过程</h2><p>在进行绘图之前，需要先筛选出 <code>|log2FC| &gt; 1</code> 以及 <code>adjustp &lt; 0.05</code> 的点（可以选用不同的阈值），然后将它们的 <code>log2FC</code> 放在新的一列，最后效果应该如下所示：</p><p><img src="/pic/prism3.png"></p><p>具体的实现过程可以通过 Python 脚本或者 R 进行，处理以后的表格用来绘制火山图。</p><p>点进 GraphPad Prism 后，选择最上方的 XY，各项选择如图：</p><p><img src="/pic/prism2.png"></p><p>生成表格后，导入差异表达分析结果（复制黏贴整个表格即可），此后删掉除了所需要的数据以外的列，最后如下图：</p><p><img src="/pic/prism4.png"></p><p>其中第一列为基因的 ID，第二列即 X 为各个基因的 <code>log2FoldChange</code> 值，后面三列 Y 为 <code>adjust.p</code> 值。此后选中三列 p 值，并点击箭头所指地方的 Analyze 选项：</p><p><img src="/pic/prism5.png"></p><p>选择 Transform 并点击 OK，此后选择转变 Y 值，选择 <strong>y = -1*Log(Y)</strong> ：</p><p><img src="/pic/prism6.png"></p><p><img src="/pic/prism7.png"></p><p>上述步骤也可以在 R 或 Python 的处理中完成，这里就展示下如何用 Prism 进行数据转换。</p><p>此后就能看见生成了一个新的表格和对应的图，点进图中可以看到它是这个样子：</p><p><img src="/pic/prism8.png"></p><p>到这里，一个初步的火山图雏形就已经产生，点击上方的 <code>Format axes</code> 进行进一步的润色：</p><p><img src="/pic/prism9.png"></p><p>在这里我就直接展示我在各个部分修改的参数：</p><p><img src="/pic/prism10.png"></p><p><img src="/pic/prism11.png"></p><p><img src="/pic/prism12.png"></p><p>y 轴设范围 -0.2 是因为避免等一下修改点大小后点挤出框外，更改完后整体效果应该如下：</p><p><img src="/pic/prism13.png"></p><p>此后我们在对点进行一些润色，同样直接以图的形式展现步骤：</p><p><img src="/pic/prism14.png"></p><p>点的大小可以选 2 也可以选 3，看个人的喜好而定。</p><p><img src="/pic/prism15.png"></p><p><img src="/pic/prism16.png"></p><p>最后，再修改下标签的名称和各标题，火山图诞生：</p><p><img src="/pic/prism17.png"></p><p>到这里使用 GraphPad Prism 绘制火山图的分享就结束了，还可以基于这些功能进行进阶应用。</p><p>例如可以用 Prism 展示各类基因的差异表达情况：</p><p><img src="/pic/prism18.png"></p><h2 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h2><p>Prism 除了火山图以外还有非常多的图形可以绘制，其本身也自带了许多相关的统计算法。</p><p>此外我个人感觉 Prism 画出的图很有科研风格，这可能也是它经常出现在各个文章的原因之一。</p><p>如果想在 R 中画出相似风格的图片，可以安装 <code>ggprism</code> 包，该包是一款主题，可以将 ggplot2 的图变成类似 Prism 的样式。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 绘图 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 转录组 </tag>
            
            <tag> 比较转录组学 </tag>
            
            <tag> 差异表达分析 </tag>
            
            <tag> 火山图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>比较转录组分析（六）—— GO 富集分析与可视化</title>
      <link href="/2022/12/19/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94%20GO%20%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
      <url>/2022/12/19/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94%20GO%20%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><blockquote><div id="portalContainer"></div><script src="/js/ctlink.js"></script><script> generatePortalLinks(6);</script></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>GO 富集分析的用处非常广泛，在这里我们将用来做差异表达基因的分析，在其他情况下也有可能是做例如正选择基因的富集分析、高突变率基因的富集分析、基因家族的富集分析等等一系列基因群的功能分析，不过着重点不同。</p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2022.12.22    更改了绘图脚本，新的气泡图以 GeneRatio 作为 x 轴标签（更改版本在 github 可见，文中未修改）。</p><p>2023.06.26    解封文章，简化了部分内容。</p><h3 id="出现的一些词"><a href="#出现的一些词" class="headerlink" title="出现的一些词"></a>出现的一些词</h3><p><strong>DAVID</strong>：全称 <strong>D</strong>atabase for <strong>A</strong>nnotation, <strong>V</strong>isualization and <strong>I</strong>ntegrated <strong>D</strong>iscovery，是一个广泛使用的富集分析平台，此外还可以在这里进行诸多 id 的转换。</p><p>链接：<a href="https://david.ncifcrf.gov/">https://david.ncifcrf.gov/</a></p><h2 id="富集分析过程"><a href="#富集分析过程" class="headerlink" title="富集分析过程"></a>富集分析过程</h2><h3 id="需要明白的概念"><a href="#需要明白的概念" class="headerlink" title="需要明白的概念"></a>需要明白的概念</h3><p>什么是富集分析？关于这一点在网上的诸多文章中都有解释，但我想要以一个更为通俗易懂的说法去进行解释。</p><p>打个比方，我们调查了 5000 个人的兴趣爱好，其中有 200 个人都很喜欢玩电脑。</p><p>然后我们挑出了一个我们所感兴趣的人群，比方说我们从这 5000 个人中挑出来 100 个宅。</p><p>然后我们发现在这 100 个宅中，竟然有高达 50 个人喜欢玩电脑。</p><p>于是乎，在我们的调查的所有人（即背景集）中，喜欢玩电脑的只有 200/5000 = 1/25 = 4%。</p><p>但在我们所感兴趣的人群（即前景集）中，喜欢玩电脑的就已经达到 50/100 = 1/2 = 50%。</p><p>所以我们可以认为，我们感兴趣的人群 —— 宅，他们相较于所有人群普遍而言，会更喜欢玩电脑。</p><h3 id="需要准备的文件"><a href="#需要准备的文件" class="headerlink" title="需要准备的文件"></a>需要准备的文件</h3><p>无参转录组需要的文件有：</p><ul><li>前景基因集（在这里是<strong>差异表达基因列表</strong>）</li><li>背景基因注释集（在这里是<strong>组装的注释</strong>）</li></ul><p>如果后续需要使用 R 进行则还需要（本文的教程源自 <a href="https://zhuanlan.zhihu.com/p/196761601">【生信小课堂】非模式物种或无参转录组GO注释与富集 from 知乎</a>）：</p><ul><li>GO term 的信息（下载地址：<a href="http://geneontology.org/docs/download-ontology/#subsets">http://geneontology.org/docs/download-ontology/#subsets</a> 里的 <a href="http://geneontology.org/docs/download-ontology/#go_basic">go-basic.obo</a>）</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget http://current.geneontology.org/ontology/go-basic.obo</span></span><br></pre></td></tr></tbody></table></figure><p>然后使用脚本将其转化为 GO term list：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#get_go_term.py</span></span><br><span class="line"><span class="keyword">import</span> sys </span><br><span class="line">raw_file = <span class="built_in">open</span>(sys.argv[<span class="number">1</span>]).read()  </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">"go_term.list"</span>,<span class="string">"w"</span>) <span class="keyword">as</span> output:</span><br><span class="line">     <span class="keyword">for</span> go_term <span class="keyword">in</span> raw_file.split(<span class="string">"[Term]"</span>):</span><br><span class="line">         go_id = <span class="string">''</span></span><br><span class="line">         name = <span class="string">''</span> </span><br><span class="line">         namespace = <span class="string">''</span></span><br><span class="line">         <span class="keyword">for</span> line <span class="keyword">in</span> go_term.split(<span class="string">"\n"</span>):</span><br><span class="line">             <span class="keyword">if</span> <span class="built_in">str</span>(line).startswith(<span class="string">"id"</span>) <span class="keyword">and</span> <span class="string">"GO:"</span> <span class="keyword">in</span> line:</span><br><span class="line">                 go_id = line.rstrip().split(<span class="string">" "</span>)[<span class="number">1</span>]</span><br><span class="line">             <span class="keyword">if</span> <span class="built_in">str</span>(line).startswith(<span class="string">"name:"</span>):</span><br><span class="line">                 name = line.rstrip().split(<span class="string">": "</span>)[<span class="number">1</span>]</span><br><span class="line">             <span class="keyword">if</span> <span class="built_in">str</span>(line).startswith(<span class="string">"namespace"</span>):</span><br><span class="line">                 namespace = line.rstrip().split(<span class="string">" "</span>)[<span class="number">1</span>]</span><br><span class="line">         term = go_id + <span class="string">'\t'</span> + name + <span class="string">'\t'</span> + namespace + <span class="string">'\n'</span></span><br><span class="line">         <span class="keyword">if</span> <span class="string">''</span> != go_id:</span><br><span class="line">             output.write(term)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python get_go_term.py go-basic.obo</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">会输出一个叫做 go_term.list 的文件</span></span><br></pre></td></tr></tbody></table></figure><p>然后就能得到 GO term list，或者你可以在我的 github 上直接下载（版本不是最新，慎重考虑），传送门点<a href="https://github.com/JuseTiZ/PyScript-for-CT/blob/main/go_term.list">这里</a>。</p><p>此后我们可以通过 R 或者 DAVID 进行富集分析。</p><h3 id="通过-R-实现-——-clusterProfiler"><a href="#通过-R-实现-——-clusterProfiler" class="headerlink" title="通过 R 实现 —— clusterProfiler"></a>通过 R 实现 —— clusterProfiler</h3><p>主要是通过 R 的 ClusterProfiler 包进行，因此在进行分析前需要把这个包装好：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># R version 3.5以上版本:</span></span><br><span class="line">BiocManager<span class="operator">::</span>install<span class="punctuation">(</span><span class="string">"clusterProfiler"</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment"># R version 3.5以下版本:</span></span><br><span class="line">source<span class="punctuation">(</span><span class="string">"http://bioconductor.org/biocLite.R"</span><span class="punctuation">)</span></span><br><span class="line">biocLite<span class="punctuation">(</span><span class="string">"clusterProfiler"</span><span class="punctuation">)</span></span><br></pre></td></tr></tbody></table></figure><p>具体的安装教程可以 Bing 搜索，安装好后就可以在 R 上进行后续的分析，也可以在装了 R 的服务器上进行。</p><p>用自己电脑的 R 画图是完全可以的，但如果涉及到的要分析的物种比较多时就会显得比较麻烦，所以在这里我制作了一个 python pipeline 在服务器上运行直接得到想要的结果：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># enrichment_plot.py</span></span><br><span class="line"><span class="comment"># Verson: 1.1</span></span><br><span class="line"><span class="comment"># Author: Juse</span></span><br><span class="line"><span class="comment"># Use R to plot enrichment dotplot.</span></span><br><span class="line"><span class="comment"># Usage: See github.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>():</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description = <span class="string">"This is used to plot enrichment dotplot."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-gef"</span>, <span class="string">"--genefore"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The gene list as foregroud."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-geb"</span>, <span class="string">"--geneback"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The gene list and annotation as backgroud."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-go"</span>, <span class="string">"--golist"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The go_term.list file."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-w"</span>, <span class="string">"--width"</span>, default = <span class="string">'8'</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"Width of plot, default = 8."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-l"</span>, <span class="string">"--height"</span>, default = <span class="string">'8'</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"Height of plot, default = 8."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-y"</span>, <span class="string">"--yaxis"</span>, default = <span class="string">"Description"</span>, choices = [<span class="string">'Description'</span>,<span class="string">'ID'</span>], <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The yaxis of plot, use GO Description as default."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-o"</span>, <span class="string">"--output"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, required = <span class="literal">True</span>, <span class="built_in">help</span> = <span class="string">"The output directory, required."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-t"</span>, <span class="string">"--title"</span>, default = <span class="string">'NULL'</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The title of plot, default = NULL."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-c"</span>, <span class="string">"--csv"</span>, default = <span class="string">'NULL'</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"Just plot with file given."</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_path</span>(<span class="params">args</span>):</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.csv == <span class="string">'NULL'</span>:</span><br><span class="line">paths = {</span><br><span class="line"><span class="string">'fore_gene'</span>: os.path.abspath(args.genefore),</span><br><span class="line"><span class="string">'back_gene'</span>: os.path.abspath(args.geneback),</span><br><span class="line"><span class="string">'go_list'</span>: os.path.abspath(args.golist),</span><br><span class="line"><span class="string">'output_dir'</span>: os.path.abspath(args.output),</span><br><span class="line">}</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">paths = {</span><br><span class="line"><span class="string">'output_dir'</span>: os.path.abspath(args.output),</span><br><span class="line"><span class="string">'csv_dir'</span>: os.path.abspath(args.csv)</span><br><span class="line">}</span><br><span class="line">     </span><br><span class="line"><span class="keyword">return</span> paths</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">R_code</span>(<span class="params">args, paths, run_time</span>):</span><br><span class="line"></span><br><span class="line">rcode = <span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 加载包</span></span><br><span class="line"><span class="string">library("clusterProfiler")</span></span><br><span class="line"><span class="string">library("ggplot2")</span></span><br><span class="line"><span class="string">library("DOSE")</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 加载各个参数</span></span><br><span class="line"><span class="string">goterm = "%juse%1"</span></span><br><span class="line"><span class="string">backgene = "%juse%2"</span></span><br><span class="line"><span class="string">foregene = "%juse%3"</span></span><br><span class="line"><span class="string">wid = %juse%4</span></span><br><span class="line"><span class="string">hei = %juse%5</span></span><br><span class="line"><span class="string">title = "%juse%7"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 生成背景注释集</span></span><br><span class="line"><span class="string">go_class &lt;- read.delim(goterm, header=FALSE, stringsAsFactors =FALSE) </span></span><br><span class="line"><span class="string">names(go_class) &lt;- c('ID','Description','Ontology')  </span></span><br><span class="line"><span class="string">go_anno &lt;- read.delim(backgene, header=FALSE, stringsAsFactors =FALSE)</span></span><br><span class="line"><span class="string">names(go_anno) &lt;- c('gene_id','ID')</span></span><br><span class="line"><span class="string">go_anno &lt;-merge(go_anno, go_class, by = 'ID', all.x = TRUE)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 生成前景基因集</span></span><br><span class="line"><span class="string">gene_list &lt;- read.delim(foregene,header=FALSE) </span></span><br><span class="line"><span class="string">names(gene_list) &lt;- c('gene_id') </span></span><br><span class="line"><span class="string">gene_select &lt;- gene_list$gene_id  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 进行富集分析</span></span><br><span class="line"><span class="string">go_rich &lt;- enricher(gene = gene_select,</span></span><br><span class="line"><span class="string">TERM2GENE = go_anno[c('ID','gene_id')],</span></span><br><span class="line"><span class="string">TERM2NAME = go_anno[c('ID','Description')],</span></span><br><span class="line"><span class="string">pvalueCutoff = 0.05,</span></span><br><span class="line"><span class="string">pAdjustMethod = 'BH',</span></span><br><span class="line"><span class="string">qvalueCutoff = 0.05,</span></span><br><span class="line"><span class="string">maxGSSize = 200) </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 提取富集分析结果制成表格</span></span><br><span class="line"><span class="string">plot_data = cbind(go_rich$ID, go_rich$Description, go_rich$GeneRatio, go_rich$BgRatio, go_rich$Count, go_rich$p.adjust, go_rich$ID, go_rich$geneID)</span></span><br><span class="line"><span class="string">colnames(plot_data) = c("ID", "Description", "GeneRatio", "BgRatio", "Count","qvalue", "Ontology", "GeneID")</span></span><br><span class="line"><span class="string">plot_data = data.frame(plot_data)</span></span><br><span class="line"><span class="string">for(i in 1:length(plot_data$Ontology)){</span></span><br><span class="line"><span class="string">  if(is.na(plot_data$Description[i])){</span></span><br><span class="line"><span class="string">plot_data$Ontology[i] = 'NA'</span></span><br><span class="line"><span class="string">  }else{</span></span><br><span class="line"><span class="string">plot_data$Ontology[i] = go_class$Ontology[go_class$ID == plot_data$ID[i]]</span></span><br><span class="line"><span class="string">  }</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 处理数据</span></span><br><span class="line"><span class="string">plot_data_noNA = plot_data[complete.cases(plot_data$Description),]</span></span><br><span class="line"><span class="string">plot_data_noNA = transform(plot_data_noNA, Count = as.numeric(Count),</span></span><br><span class="line"><span class="string">   qvalue = as.numeric(qvalue))</span></span><br><span class="line"><span class="string">plot_data_noNA = plot_data_noNA[order(plot_data_noNA$qvalue,-plot_data_noNA$Count),]</span></span><br><span class="line"><span class="string">plot_data_noNA$Ontology[plot_data_noNA$Ontology == "cellular_component"] = "Cellular Component"</span></span><br><span class="line"><span class="string">plot_data_noNA$Ontology[plot_data_noNA$Ontology == "biological_process"] = "Biological Process"</span></span><br><span class="line"><span class="string">plot_data_noNA$Ontology[plot_data_noNA$Ontology == "molecular_function"] = "Molecular Function"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Top15 = c()</span></span><br><span class="line"><span class="string">CC = 0</span></span><br><span class="line"><span class="string">BP = 0</span></span><br><span class="line"><span class="string">MF = 0</span></span><br><span class="line"><span class="string">for(i in 1:length(plot_data_noNA$Ontology)){</span></span><br><span class="line"><span class="string">  if(plot_data_noNA$Ontology[i] == "Cellular Component"){</span></span><br><span class="line"><span class="string">CC = CC + 1</span></span><br><span class="line"><span class="string">if(CC &lt;= 5){</span></span><br><span class="line"><span class="string">  Top15 = append(Top15,(i))</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string">  }</span></span><br><span class="line"><span class="string">  if(plot_data_noNA$Ontology[i] == "Biological Process"){</span></span><br><span class="line"><span class="string">BP = BP + 1</span></span><br><span class="line"><span class="string">if(BP &lt;= 5){</span></span><br><span class="line"><span class="string">  Top15 = append(Top15,(i))</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string">  }</span></span><br><span class="line"><span class="string">  if(plot_data_noNA$Ontology[i] == "Molecular Function"){</span></span><br><span class="line"><span class="string">MF = MF + 1</span></span><br><span class="line"><span class="string">if(MF &lt;= 5){</span></span><br><span class="line"><span class="string">  Top15 = append(Top15,(i))</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string">  }</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 进行气泡图绘制</span></span><br><span class="line"><span class="string">enrichment_plot = ggplot(plot_data_noNA[Top15,],aes(x = parse_ratio(GeneRatio),y = reorder(%juse%6, Count))) + geom_point(aes(size=Count,color=qvalue,)) +</span></span><br><span class="line"><span class="string">  scale_color_gradient(low = "red", high = "blue") + theme_bw() + ylab(NULL) + xlab("GeneRatio") + </span></span><br><span class="line"><span class="string">  facet_wrap(~Ontology, scale="free",ncol = 1,strip.position = "right") + </span></span><br><span class="line"><span class="string">  theme(text = element_text(size = 15))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">enrichment_plot_top10 = ggplot(plot_data_noNA[1:10,],aes(x = parse_ratio(GeneRatio),y = reorder(%juse%6, Count))) + geom_point(aes(size=Count,color=qvalue,)) +</span></span><br><span class="line"><span class="string">  scale_color_gradient(low = "red", high = "blue") + theme_bw() + ylab(NULL) + xlab("GeneRatio") + </span></span><br><span class="line"><span class="string">  theme(text = element_text(size = 15))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">if(title != "NULL"){</span></span><br><span class="line"><span class="string">  enrichment_plot = enrichment_plot + ggtitle(title)</span></span><br><span class="line"><span class="string">  enrichment_plot_top10 = enrichment_plot_top10 + ggtitle(title)</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 保存图及富集分析表格</span></span><br><span class="line"><span class="string">pdf("output%1%",width = wid,height = hei)</span></span><br><span class="line"><span class="string">enrichment_plot</span></span><br><span class="line"><span class="string">dev.off()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">pdf("output%2%",width = wid,height = hei)</span></span><br><span class="line"><span class="string">enrichment_plot_top10</span></span><br><span class="line"><span class="string">dev.off()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">write.csv(plot_data,file="output%3%")</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line">r_code_use = rcode.replace(<span class="string">"%juse%1"</span>, paths[<span class="string">'go_list'</span>])\</span><br><span class="line">.replace(<span class="string">"%juse%2"</span>, paths[<span class="string">'back_gene'</span>])\</span><br><span class="line">.replace(<span class="string">"%juse%3"</span>, paths[<span class="string">'fore_gene'</span>])\</span><br><span class="line">.replace(<span class="string">"%juse%4"</span>, args.width)\</span><br><span class="line">.replace(<span class="string">"%juse%5"</span>, args.height)\</span><br><span class="line">.replace(<span class="string">"%juse%6"</span>, args.yaxis)\</span><br><span class="line">.replace(<span class="string">"%juse%7"</span>, args.title)\</span><br><span class="line">.replace(<span class="string">"output%1%"</span>, <span class="string">f"<span class="subst">{paths[<span class="string">'output_dir'</span>]}</span>/<span class="subst">{run_time}</span>/enrichment_plot.pdf"</span>)\</span><br><span class="line">.replace(<span class="string">"output%2%"</span>, <span class="string">f"<span class="subst">{paths[<span class="string">'output_dir'</span>]}</span>/<span class="subst">{run_time}</span>/enrichment_plot_top10.pdf"</span>)\</span><br><span class="line">.replace(<span class="string">"output%3%"</span>, <span class="string">f"<span class="subst">{paths[<span class="string">'output_dir'</span>]}</span>/<span class="subst">{run_time}</span>/enrichment_analysis.csv"</span>)\</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> r_code_use</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_R</span>(<span class="params">args, paths, run_time</span>):</span><br><span class="line"></span><br><span class="line">rcode = <span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 加载包</span></span><br><span class="line"><span class="string">library("DOSE")</span></span><br><span class="line"><span class="string">library("ggplot2")</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 加载数据集</span></span><br><span class="line"><span class="string">plot_data_noNA = read.csv("%juse%1", header=TRUE)</span></span><br><span class="line"><span class="string">wid = %juse%4</span></span><br><span class="line"><span class="string">hei = %juse%5</span></span><br><span class="line"><span class="string">title = "%juse%7"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 处理数据</span></span><br><span class="line"><span class="string">plot_data_noNA = plot_data_noNA[complete.cases(plot_data_noNA$Description),]</span></span><br><span class="line"><span class="string">plot_data_noNA = transform(plot_data_noNA, Count = as.numeric(Count),</span></span><br><span class="line"><span class="string">   qvalue = as.numeric(qvalue))</span></span><br><span class="line"><span class="string">plot_data_noNA = plot_data_noNA[order(plot_data_noNA$qvalue,-plot_data_noNA$Count),]</span></span><br><span class="line"><span class="string">plot_data_noNA$Ontology[plot_data_noNA$Ontology == "cellular_component"] = "Cellular Component"</span></span><br><span class="line"><span class="string">plot_data_noNA$Ontology[plot_data_noNA$Ontology == "biological_process"] = "Biological Process"</span></span><br><span class="line"><span class="string">plot_data_noNA$Ontology[plot_data_noNA$Ontology == "molecular_function"] = "Molecular Function"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Top15 = c()</span></span><br><span class="line"><span class="string">CC = 0</span></span><br><span class="line"><span class="string">BP = 0</span></span><br><span class="line"><span class="string">MF = 0</span></span><br><span class="line"><span class="string">for(i in 1:length(plot_data_noNA$Ontology)){</span></span><br><span class="line"><span class="string">  if(plot_data_noNA$Ontology[i] == "Cellular Component"){</span></span><br><span class="line"><span class="string">CC = CC + 1</span></span><br><span class="line"><span class="string">if(CC &lt;= 5){</span></span><br><span class="line"><span class="string">  Top15 = append(Top15,(i))</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string">  }</span></span><br><span class="line"><span class="string">  if(plot_data_noNA$Ontology[i] == "Biological Process"){</span></span><br><span class="line"><span class="string">BP = BP + 1</span></span><br><span class="line"><span class="string">if(BP &lt;= 5){</span></span><br><span class="line"><span class="string">  Top15 = append(Top15,(i))</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string">  }</span></span><br><span class="line"><span class="string">  if(plot_data_noNA$Ontology[i] == "Molecular Function"){</span></span><br><span class="line"><span class="string">MF = MF + 1</span></span><br><span class="line"><span class="string">if(MF &lt;= 5){</span></span><br><span class="line"><span class="string">  Top15 = append(Top15,(i))</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string">  }</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 进行气泡图绘制</span></span><br><span class="line"><span class="string">enrichment_plot = ggplot(plot_data_noNA[Top15,],aes(x = parse_ratio(GeneRatio),y = reorder(%juse%6, Count))) + geom_point(aes(size=Count,color=qvalue,)) +</span></span><br><span class="line"><span class="string">  scale_color_gradient(low = "red", high = "blue") + theme_bw() + ylab(NULL) + xlab("GeneRatio") + </span></span><br><span class="line"><span class="string">  facet_wrap(~Ontology, scale="free",ncol = 1,strip.position = "right") + </span></span><br><span class="line"><span class="string">  theme(text = element_text(size = 15))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">enrichment_plot_top10 = ggplot(plot_data_noNA[1:10,],aes(x = parse_ratio(GeneRatio),y = reorder(%juse%6, Count))) + geom_point(aes(size=Count,color=qvalue,)) +</span></span><br><span class="line"><span class="string">  scale_color_gradient(low = "red", high = "blue") + theme_bw() + ylab(NULL) + xlab("GeneRatio") + </span></span><br><span class="line"><span class="string">  theme(text = element_text(size = 15))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">if(title != "NULL"){</span></span><br><span class="line"><span class="string">  enrichment_plot = enrichment_plot + ggtitle(title)</span></span><br><span class="line"><span class="string">  enrichment_plot_top10 = enrichment_plot_top10 + ggtitle(title)</span></span><br><span class="line"><span class="string">}</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 保存图及富集分析表格</span></span><br><span class="line"><span class="string">pdf("output%1%",width = wid,height = hei)</span></span><br><span class="line"><span class="string">enrichment_plot</span></span><br><span class="line"><span class="string">dev.off()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">pdf("output%2%",width = wid,height = hei)</span></span><br><span class="line"><span class="string">enrichment_plot_top10</span></span><br><span class="line"><span class="string">dev.off()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line">r_code_use = rcode.replace(<span class="string">"%juse%1"</span>, paths[<span class="string">'csv_dir'</span>])\</span><br><span class="line">.replace(<span class="string">"%juse%4"</span>, args.width)\</span><br><span class="line">.replace(<span class="string">"%juse%5"</span>, args.height)\</span><br><span class="line">.replace(<span class="string">"%juse%6"</span>, args.yaxis)\</span><br><span class="line">.replace(<span class="string">"%juse%7"</span>, args.title)\</span><br><span class="line">.replace(<span class="string">"output%1%"</span>, <span class="string">f"<span class="subst">{paths[<span class="string">'output_dir'</span>]}</span>/<span class="subst">{run_time}</span>/enrichment_plot.pdf"</span>)\</span><br><span class="line">.replace(<span class="string">"output%2%"</span>, <span class="string">f"<span class="subst">{paths[<span class="string">'output_dir'</span>]}</span>/<span class="subst">{run_time}</span>/enrichment_plot_top10.pdf"</span>)\</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> r_code_use</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_r_script</span>(<span class="params">r_code, paths, run_time</span>):</span><br><span class="line">os.makedirs(<span class="string">f"<span class="subst">{paths[<span class="string">'output_dir'</span>]}</span>/<span class="subst">{run_time}</span>"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">script_path = <span class="string">f"<span class="subst">{paths[<span class="string">'output_dir'</span>]}</span>/<span class="subst">{run_time}</span>/enrichment_plot.R"</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(script_path, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">f.write(r_code)</span><br><span class="line">os.system(<span class="string">f'Rscript <span class="subst">{script_path}</span>'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">run_time = time.strftime(<span class="string">'%Y%m%d-%H%M%S'</span>)</span><br><span class="line">args = get_args()</span><br><span class="line">paths = get_path(args)</span><br><span class="line">r_code = R_code(args, paths, run_time) <span class="keyword">if</span> args.csv == <span class="string">'NULL'</span> <span class="keyword">else</span> plot_R(args, paths, run_time)</span><br><span class="line">run_r_script(r_code, paths, run_time)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'Finished! See output at <span class="subst">{paths[<span class="string">"output_dir"</span>]}</span>'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">main()</span><br></pre></td></tr></tbody></table></figure><p>脚本的下载可以去 <a href="https://github.com/JuseTiZ/PyScript-for-CT">github</a>，如果无法在服务器上使用 clusterProfiler 也可以把中间那一段 R 代码抄下来在自己的电脑上运行，只需要换掉一些特定的字符即可。</p><p><strong>运行例 ①：</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python enrichment_plot.py -gef all_up.txt \</span></span><br><span class="line"><span class="language-bash">-geb onego.txt -go go_term.list \</span></span><br><span class="line"><span class="language-bash">-o outputdir \</span></span><br><span class="line"><span class="language-bash"><span class="comment">#-t Juse -l 8 -w 8</span></span></span><br></pre></td></tr></tbody></table></figure><p>使用所必须调用的参数：</p><p><code>-gef</code> 分析使用的前景基因集，例如上调或下调的差异表达基因。</p><p><code>-geb</code> 分析使用的背景基因注释集，即之前文章中所得到的一基因对一 GO term 文件。</p><p><code>-go</code> 在需要准备的文件中有提及到的 go_term.list。</p><p><code>-o</code> 输出文件夹。</p><p><strong>运行例 ②：</strong></p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python enrichment_plot.py -c enrichment_analysis.csv \</span></span><br><span class="line"><span class="language-bash">-o outputdir \</span></span><br><span class="line"><span class="language-bash"><span class="comment">#-t Juse -l 8 -w 8</span></span></span><br></pre></td></tr></tbody></table></figure><p>当使用已有的 csv 进行分析时只需调用该 csv 文件即可（列名必须与运行例 ① 中输出的保持一致）。</p><p>在该情况下只会输出对应的图及原始 R 代码，不会再次输出 csv 文件。</p><p>可选参数：</p><p><code>-t</code> 图的标题，默认不设标题；<code>-l</code> <code>-w</code> 图的高和宽，默认都为 8；<code>-y</code> 当为 ID 时，作图的 y 轴标签会替换为 GO 号，默认为 Description 。</p><p>以<strong>运行例 ①</strong> 为标准，运行结束后，会在 outputdir 中出现一个以运行时间作为名字的文件夹，里面包括了以下几个文件：</p><p><img src="/pic/output.png"></p><p><code>enrichment_analysis.csv</code> 为富集分析的结果，其中已被废弃的 NA 项未被去除（运行例 ② 不会输出该文件）。</p><p><code>enrichment_plot.pdf</code> 为富集分析的气泡图，其中去除了 NA 项进行分析，取每个 Ontology 前五显著的 GO term 进行展示（不足五个则取全部）。</p><p><code>enrichment_plot_top10.pdf</code> 为富集分析的气泡图，其中去除了 NA 项进行分析，取最显著的十个 GO term 进行了展示（不分 Ontology）。</p><p><code>enrichment_plot.R</code> 为该次分析的代码。</p><p><img src="/pic/enrichment_plot.png"></p><p><img src="/pic/enrichment_csv.png"></p><p>另：曾在 <strong>比较转录组分析（四）—— 组装的 GO 注释</strong> 中提到过，富集分析里<strong>可以考虑</strong>把一些相关的 term 给删掉一部分，仅保留具有代表性的那个进行可视化，这里可以基于运行例 ① 输出的表格进行修改，删除一些相关 GO 项后再通过运行例 ② 的方法直接可视化。</p><h3 id="通过-DAVID-实现"><a href="#通过-DAVID-实现" class="headerlink" title="通过 DAVID 实现"></a>通过 DAVID 实现</h3><p>DAVID 的分析会严格很多，可能会导致我们得不到什么想要的结果，但是这种严格又未必不是件好事。</p><p>首先 DAVID 的 Document 可以看这里：<a href="https://david.ncifcrf.gov/content.jsp?file=functional_annotation.html">DAVID Bioinformatics Resources (ncifcrf.gov)</a>。</p><p>为什么说 DAVID 严格？因为它在进行分析的时候首先<strong>把重复项删除了</strong>，其次还<strong>把所有原始 ID 中的冗余给去除了</strong>，于是乎很多原来在 clusterProfiler 的分析中具有富集现象的 term 在 DAVID 就失去了显著性。</p><p>这里我就以上面 clusterProfiler 中使用的数据为例，分享如何利用 DAVID 进行 GO 富集分析。</p><p>首先，我们要提取出原来我们 <code>blast against swissprot</code> 得到的注释信息（<code>blastx.outfmt6</code>）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cut</span> -f 2 blastx.outfmt6 &gt; back.txt</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cut</span> -f 2 blastp.outfmt6 &gt; back.txt</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用 blastp 的结果也行，不过需要改一下下面的代码。</span></span><br></pre></td></tr></tbody></table></figure><p>得到背景基因的注释集后，我们再通过上调基因和下调基因的列表，得到背景基因注释集：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> all_up.txt | <span class="keyword">while</span> <span class="built_in">read</span> line;</span></span><br><span class="line">do</span><br><span class="line">grep -e "$line[[:space:]]" blastx.outfmt6 | cut -f 2 &gt;&gt; fore.txt</span><br><span class="line">done</span><br></pre></td></tr></tbody></table></figure><p>有了背景基因和前景基因注释信息后，就可以把它输入进 DAVID 进行分析。</p><p><img src="/pic/david1.png"></p><p><img src="/pic/david2.png"></p><p>Gene List 输入上调或下调的差异表达基因集，Background 输入背景基因注释集，它们是这样的（一行一注释）：</p><p><img src="/pic/david3.png"></p><p>在 Select Identifier 上选择 Uniprot ID。</p><p><img src="/pic/david4.png"></p><p>它会提示检测到基因集中有很多不同的物种，略过即可。</p><p>弄完以后点击右侧 Step2 下面的内容进入下一步分析，如果只需要做 GO 富集分析，则可以先按 clear all，然后勾选这三项：</p><p><img src="/pic/david5.png"></p><p>然后移到最下面有三个选项，其中 <strong>Functional Annotation Chart</strong> 就是 GO 富集结果了。</p><p>DAVID 采取的检验方法为费希尔精确检验，基于对应的 DAVID ID 进行计算 p 值和对应矫正值。以该文中涉及的数据为例，显著富集的 term 如果要以 <code>Benjamini</code> 矫正值为准，那么显著富集的 term 仅有三个，远远低于在 clusterProfiler 中识别到的 44 个。</p><p>后续的可视化步骤同样用 <code>R ggplot2</code> 实现，可以参考上文的代码进行。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p><strong>下一篇预告</strong>：比较转录组分析（七） —— 系统发育分析。</p><p><strong>可能会出的</strong>：基于 Cytoscape 的富集网络图实现。</p><blockquote><p>如果有时间的话…… —— Juse</p></blockquote><h3 id="关于-BH-矫正"><a href="#关于-BH-矫正" class="headerlink" title="关于 BH 矫正"></a>关于 BH 矫正</h3><p>我不打算用过于科学的说法来解释做这个的动机，所以我找了一个很有意思的图片来展示：</p><p><img src="/pic/BH.jpg"></p><p>我再来说一段当初在生物统计学课上听老师讲的故事（内容可能有差异但大致相似）：</p><blockquote><p>有一只被称作神奇章鱼的章鱼，在进行拳击比赛时让它进行猜测谁会赢，结果在二十次比赛里有十九次它的触手都伸到了胜利方的牌子上，也就是说二十次它猜对了十九次，大家觉得这只章鱼是不是真的是一只具有魔力的、神奇的章鱼？</p><p>大家都会觉得比较神奇吧，19/20，95% 的正确率。</p><p>但是我再跟大家说一个事，事实上这个世界上有数千数万只章鱼正在进行这种猜测，但是只有几只章鱼脱颖而出，那么这时候大家还会觉得这是一只神奇的章鱼吗？</p></blockquote><p>这个故事精准地切中了多重比较中存在的问题，也就是子集和整体之间的问题，一个事件的发生概率再怎么样低，如果它重复的次数多了，那么它总会在一次试验中发生并在那次试验中展现出显著性，但实际上放在整体上看如果相信了这个显著性就会给我们带来错误的结论，这也就是我们要进行 p 值矫正的原因。</p><p>BH 矫正的办法就是：<strong>adjust.p = p * n / k</strong></p><p>其中，p 是指原来的 p 值，n 是指这次矫正中有 n 个 p 值，k 是指将 p 值从小到大排列以后该 p 的顺序数。</p><p>当排在前面的 p 值在矫正后比在后面的 p 值大时，排在前面的 p 值又会重新矫正为和后面 p 值相同的值，这也就是在结果中经常能看到好几个矫正后的 p 值都相同的原因。</p><h3 id="clusterProfiler-在-linux-R-上的安装"><a href="#clusterProfiler-在-linux-R-上的安装" class="headerlink" title="clusterProfiler 在 linux R 上的安装"></a>clusterProfiler 在 linux R 上的安装</h3><p>这里简单阐述下我自己是如何解决这个问题的：</p><p>首先，每个 R 包都可以通过 conda 安装，可以在 Bing 上搜索关键词 xxx conda。</p><p>例如可以先搜索： clusterProfiler conda</p><p><img src="/pic/conda1.png"></p><p>点进去，选择上方的 Files，在里面看到不同版本的以及适应不同平台的 R 包文件。</p><p>如果在 linux 系统上安装，则选择开头为 <code>noarch</code> 或者 <code>linux</code> 的文件下载。</p><p><img src="/pic/conda2.png"></p><p>此外，如上图红框所标注为该版本 R 包构建时所基于的 R 版本，因此还需要根据自己的 R 版本选择合适的包。</p><p>例如如果自己的 R 版本是 4.1 的，那么这里就可以选一个 4.0 的下载安装。</p><p>此后在 linux 中输入下列命令用 conda 安装 R 包：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda install xxx.tar.bz2</span></span><br></pre></td></tr></tbody></table></figure><p>这样做仅是把这个包给安装上了，但是众多的依赖项依然没有完备，因此在安装好后进入 R 并尝试加载时，系统会提示缺少什么包。</p><p>此后把缺少的包一个一个用上述方式搜索然后再用 conda 安装，直到依赖项全部弄好为止。</p><p>当然，也可以尝试直接用 R 的 <code>BiocManager::install</code> 安装，但并不总能成功。</p><p>此外，如果安装某个依赖项以后在加载 clusterProfiler 时依然显示缺失该依赖项，换一个依赖项的版本重新安装可能能够解决这个问题。</p><p>全部安装后以后，再进行一次就不会报错了：</p><p><img src="/pic/conda4.png"></p><p>之前我束手无策时选择了这条道路，虽然很笨，但是管用。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 转录组 </tag>
            
            <tag> 比较转录组学 </tag>
            
            <tag> GO富集分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>比较转录组分析（五）—— 转录本定量与差异表达分析</title>
      <link href="/2022/12/11/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%20%E8%BD%AC%E5%BD%95%E6%9C%AC%E5%AE%9A%E9%87%8F%E4%B8%8E%E5%B7%AE%E5%BC%82%E8%A1%A8%E8%BE%BE%E5%88%86%E6%9E%90/"/>
      <url>/2022/12/11/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%20%E8%BD%AC%E5%BD%95%E6%9C%AC%E5%AE%9A%E9%87%8F%E4%B8%8E%E5%B7%AE%E5%BC%82%E8%A1%A8%E8%BE%BE%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><blockquote><div id="portalContainer"></div><script src="/js/ctlink.js"></script><script> generatePortalLinks(5);</script></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前看知乎看到过一篇关于写生物论文的文章，里面有一段很有意思的话，具体的内容我已经忘了，但意思大致是指<u>写生物论文最好 “水” 的就是差异表达分析</u>，我看到的第一反应是<strong>乐</strong>，第二反应是这可能确实是客观存在的。</p><p>不过会的人多用的人多并不代表这个分析烂大街没有含金量，相反，这么多人用应当是证实了这一分析的价值所在。</p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2022.12.12 在 DEG 挑选部分中补充了些关于使用 voom 的内容。</p><p>2022.12.21 更改了关于 log2FoldChange 阈值的说法。</p><p>2022.12.22 补充了题外话中关于软件差异的新发现。</p><p>2023.04.20 补充了题外话中关于软件差异的新发现。</p><p>2023.07.03 精简了内容。</p><h3 id="出现的一些词"><a href="#出现的一些词" class="headerlink" title="出现的一些词"></a>出现的一些词</h3><p><strong>log2FoldChange</strong>：差异倍数，常以 1 作为阈值，有时也可为 1.2 或 1.5（一些单细胞研究中常见这些值）。</p><p>例：若对照组表达量为 1，处理组表达量为 4，则 log2FC = log2(4/1) = 2。正数时为上调，负数时为下调。</p><p><strong>生物学重复</strong>：经过相同方式处理的不同样品，提高生物学重复可以显著提高检测结果的准确性，一般而言一个较为可靠的分析需要<strong>每个处理至少三个重复</strong>。</p><p>例：3 个小鼠放在低温下处理，3 个小鼠放在常温下处理，然后比较不同温度下的小鼠转录组差异。</p><p>关于生物学重复的重要性可以看看这篇综述：</p><blockquote><p>Todd, Erica V et al. “The power and promise of RNA-seq in ecology and evolution.” <em>Molecular ecology</em> vol. 25,6 (2016): 1224-41. doi:10.1111/mec.13526</p></blockquote><p><strong>原始表达矩阵</strong>：进行差异表达分析时需要用到的各基因表达矩阵，里面记录了每个测序数据对应的基因表达量，被称为原始是因为还没进行标准化（不同测序数据的测序深度可能不同，会导致整体表达量的差异），标准化后可减弱测序深度差异带来的影响。</p><p><strong>探索性研究（Exploratory research）</strong>和<strong>描述性研究（Descriptive Research）</strong>的差别：</p><ul><li>Exploratory research is one which aims at providing insights into and an understanding of the problem faced by the researcher. Descriptive research, on the other hand, aims at describing something, mainly functions and characteristics.</li></ul><p><img src="/pic/dif.png"></p><ul><li>Conclusion: Therefore exploratory research results in insights or hypothesis, regardless of the method adopted, the most important thing is that it should remain flexible so that all the facets of the problem can be studied, as and when they arise. Conversely, descriptive research is a comparative design which is prepared according to the study and resources available. Such study minimises bias and maximises reliability.</li></ul><blockquote><p>Reference: <a href="https://keydifferences.com/difference-between-exploratory-and-descriptive-research.html">Difference Between Exploratory and Descriptive Research (with Comparison Chart) - Key Differences</a></p></blockquote><p><strong>批次效应</strong>：<strong>不同时间、不同操作者、不同试剂、不同仪器</strong>导致的实验误差。</p><p>如果批次效应很严重，就可能会和真实的生物学差异相混淆，让结果难以捉摸。</p><h2 id="差异表达分析过程"><a href="#差异表达分析过程" class="headerlink" title="差异表达分析过程"></a>差异表达分析过程</h2><p>可以看到很多用于进行差异表达分析的比对软件，但这里首先要着重说明 <code>Hisat2</code> 这个软件是用于 <strong>有参</strong> 情况的。而对于无参转录组而言主流的比对软件是 <code>Bowtie2</code> ，不过这两个软件也同样是由同一队人开发。</p><p>具体的实现将依靠 Trinity 成熟的内置脚本进行，教程可见 <a href="https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Transcript-Quantification%EF%BC%8C%E8%BF%99%E9%87%8C%E4%B8%BB%E8%A6%81%E5%B0%B1%E6%98%AF%E6%8A%8A%E5%AE%83%E7%BF%BB%E6%88%90%E4%B8%AD%E6%96%87%E3%80%82">https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Transcript-Quantification，这里主要就是把它翻成中文。</a></p><h3 id="估计转录本丰度"><a href="#估计转录本丰度" class="headerlink" title="估计转录本丰度"></a>估计转录本丰度</h3><p>使用的脚本是 Trinity 的 <code>align_and_estimate_abundance.pl</code>，不知道位置可以使用 <code>locate</code> 命令查找（没找到可能是版本不够）。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">nohup</span> align_and_estimate_abundance.pl --transcripts cdhit.fasta \</span></span><br><span class="line"><span class="language-bash">--seqType fq --samples_file sample.txt --est_method RSEM \</span></span><br><span class="line"><span class="language-bash">--aln_method bowtie2 --thread_count 15 --debug --prep_reference \</span></span><br><span class="line"><span class="language-bash"><span class="comment">#--SS_lib_type RF \</span></span></span><br><span class="line"><span class="language-bash">&gt;bowtie.out 2&gt;&amp;1</span></span><br></pre></td></tr></tbody></table></figure><p>此处 <code>nohup</code> 用于避免终端意外退出导致运行中断，如果服务器或主机没有该程序也可去除，在这里：</p><ul><li><p><code>--transcripts</code> 为转录组组装的位置。</p></li><li><p><code>--seqType</code> 用 fq 就行。</p></li><li><p><code>--samples_file</code> 在组装的时候我们用到过，如果不用该参数则替换成相应的 <code>--left</code> 和 <code>--right</code>。</p></li></ul><p>tip：如果在组装时使用过 <code>--trimmomatic</code> ，那么这里的双端数据应该替换成质控后的位置，此外，也有可能参考转录组的组装数据并不是用来做差异表达分析的，因此可以直接在 <code>--transcripts</code> 指定以后，<code>sample.txt</code> 中放进行差异表达分析的数据就行。</p><p>在这里再放一下 <code>sample.txt</code> 所应该有的格式：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cond_A    cond_A_rep1    A_rep1_left.fq    A_rep1_right.fq</span><br><span class="line">cond_A    cond_A_rep2    A_rep2_left.fq    A_rep2_right.fq</span><br><span class="line">cond_A    cond_A_rep3    A_rep3_left.fq    A_rep3_right.fq</span><br><span class="line">cond_B    cond_B_rep1    B_rep1_left.fq    B_rep1_right.fq</span><br><span class="line">cond_B    cond_B_rep2    B_rep2_left.fq    B_rep2_right.fq</span><br><span class="line">cond_B    cond_B_rep3    B_rep3_left.fq    B_rep3_right.fq</span><br></pre></td></tr></tbody></table></figure><p>可把<strong>第一列看成不同的处理</strong>，<strong>第二列看成每个处理的生物学重复</strong>，第三第四列是对应的双端文件（也可为单端）。</p><ul><li><p><code>--est_method</code> 是丰度估计方式，分三个软件，有 <code>RSEM</code> <code>kallisto</code> 和 <code>salmon</code>，这里用 <code>RSEM</code>。</p></li><li><p><code>--aln_method</code> 是 <code>--est_method</code> 选择 <code>RSEM</code> 时需要配置的，可以选择 <code>bowtie</code> 和 <code>bowtie2</code>，此处使用后者。</p></li><li><p><code>--thread_count</code> 线程数，越大越快，但大到某个值以后再加效果有限，所以不必用太多。</p></li><li><p><code>--debug</code> 运行时开启该参数，在运行结束后不会删除中间文件，如果所剩空间不多可以不用加这个参数。</p></li><li><p><code>--prep_reference</code> 自动为转录组建立索引。</p></li><li><p><code>--SS_lib_type</code> 当测序数据为<strong>链特异性</strong>时需要添加，否则会导致定量不准确。</p></li><li><p><code>&gt;bowtie.out 2&gt;&amp;1</code>  最后这一行是为了将运行过程中的屏幕输出储存到 bowtie.out 这个文件中，方便后续查看比对率等信息。</p></li></ul><p>运行结束以后，会跑出来所有的比对结果，以上述 sample.txt 为例，跑出来的各个文件应该长下面这样：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span></span></span><br><span class="line">cond_A_rep1 cond_A_rep2 cond_A_rep3</span><br><span class="line">cond_B_rep1 cond_B_rep2 cond_B_rep3</span><br></pre></td></tr></tbody></table></figure><p>跑出来的都是文件夹，里面的 <code>RSEM.isoforms.results</code> 就是各个重复的定量结果。</p><p><img src="/pic/dljg.png"></p><p>然后，可以用一串命令将这些定量结果统计起来：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> */RSEM.isoforms.results &gt; countfile.txt</span></span><br></pre></td></tr></tbody></table></figure><p>所有的定量结果位置都已统计在 countfile.txt 中，此后运行下列命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">abundance_estimates_to_matrix.pl --est_method RSEM \</span></span><br><span class="line"><span class="language-bash">--gene_trans_map none --quant_files countfile.txt \</span></span><br><span class="line"><span class="language-bash">--name_sample_by_basedir</span></span><br></pre></td></tr></tbody></table></figure><p>此处因为我们选择在 isoform 水平上分析，因此 <code>--gene_trans_map</code> 选用 <code>none</code>。</p><p>使用 <code>--name_sample_by_basedir</code> 以让表达矩阵中的样本名与文件夹一致。</p><p>运行结束后得到的 <code>RSEM.isoform.counts.matrix</code> 就是我们在进行差异表达分析时需要用到的<strong>原始表达矩阵</strong>了。</p><p>接着我们再运行：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cut</span> -f 1,2 sample.txt &gt; sample5.txt</span></span><br></pre></td></tr></tbody></table></figure><p>这里的 sample5.txt 可用于后续的样本质量检查和差异表达分析。</p><h3 id="检查样本质量"><a href="#检查样本质量" class="headerlink" title="检查样本质量"></a>检查样本质量</h3><p>如果觉得需要进行：<a href="https://github.com/trinityrnaseq/trinityrnaseq/wiki/QC-Samples-and-Biological-Replicates">https://github.com/trinityrnaseq/trinityrnaseq/wiki/QC-Samples-and-Biological-Replicates</a></p><p>我个人觉得所有图里最有价值的是 <code>sample_cor_matrix</code> 和 <code>principal_components</code> 的图（相关性热图 &amp; 主成分分析）。</p><p><img src="/pic/sample_cor_matrix.png"></p><p><img src="/pic/PCA.png"></p><p>运行基本都是照官网教的做，而且这个脚本的可设置参数非常多，里面的某些默认参数似乎需要根据自己的数据情况进行微调才更严谨。</p><p>这一步最好还是跑一下，正常的情况应该是：</p><p>①、在 <code>sample_cor_matrix</code> 中，不同处理的各个生物学重复应该要分别聚在一块。</p><p>②、在 <code>principal_components</code> 中，一个处理的各个生物学重复的点应该在邻近的区域内，不同处理的点应该要分开。</p><p>例子：</p><p><img src="/pic/cor.jpg"></p><p><img src="/pic/pca.jpg"></p><p>如果<strong>不同处理混到一起了</strong>有可能是下面的几个情况之一：</p><p>①、样本的变异系数很大，也就是说这个生物即使是在同一处理下，不同个体之间也可能表现出较大的差异，所以彼此之间很离散。</p><p>②、实验方法上的问题，可能样本处理不当等；又或者是样本编号错误。</p><p>如果<strong>同一处理下有很明显分开的两个区块</strong>则可能是：</p><p>①、批次效应，可见 <a href="https://www.jianshu.com/p/0bec17eb301f">批次效应 from 简书</a>。</p><p>②、巧合。    </p><h3 id="差异表达分析"><a href="#差异表达分析" class="headerlink" title="差异表达分析"></a>差异表达分析</h3><p>可选择的软件：<code>edgeR</code>、<code>DESeq2</code>、<code>limma-voom</code>。</p><p>前两者的使用应该是最广泛的，具体使用哪一个可以根据具体情况确定，例如：</p><p>①、如果差异表达基因鉴定数量较少，可以选择得到更多差异表达基因的软件，亦或者是取多个软件的<strong>并集</strong>。</p><p>②、如果差异表达基因鉴定数量很多，可以取多个软件的<strong>交集</strong>。</p><p>关于取并集和交集，两个方法都有人用，探索性（exploratory）的研究用前者也行，但如果是描述性（descriptive）的研究用后者会更合适，因为总的来说肯定是后者更为精准可靠（假阳性率更低）。</p><p>首先，要先检查一下自己的 linux 中是否有所需要的包，不确定可以直接安装试试：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">R <span class="comment">#进入 R</span></span> </span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="keyword">if</span> (!requireNamespace(<span class="string">"BiocManager"</span>, quietly = TRUE))</span></span><br><span class="line">    install.packages("BiocManager")</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">BiocManager::install(c(<span class="string">"edgeR"</span>, <span class="string">"limma"</span>, <span class="string">"DESeq2"</span>, <span class="string">"ctc"</span>, <span class="string">"Biobase"</span>, <span class="string">"gplots"</span>, <span class="string">"ape"</span>, <span class="string">"argparse"</span>))</span></span><br></pre></td></tr></tbody></table></figure><p>安装好以后输出 <code>q()</code> 退出 R，并使用 Trinity 的 pipeline 进行分析，首先你需要这样一份文件：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cond_Acond_B</span><br><span class="line">cond_Ccond_B</span><br></pre></td></tr></tbody></table></figure><p>中间是制表符分列，命名成 contrast.txt。可以是多行也可以是一行，里面不同的 cond 代表不同的处理，每一行代表一次比对，排在后一列的是<strong>对照组</strong>。</p><p>以上述文本为例，后续的差异表达分析将以 cond_B 作为对照组，以 cond_A 和 cond_C 作为处理组分别进行两次比对并输出结果。</p><p>记住<strong>处理组和对照组千万不要放反了，不然后续的分析会全部按照真实情况的相反面进行</strong>，我依然记得在之前生信课上有一个小组汇报的很好，但是由于这一步做错了她们把上调基因当下调分析，下调基因当上调分析，虽然听她们讲的很好但是事实上完全是反着来讲的。</p><p>将 <code>contrast.txt</code> 弄好后运行下列命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">DifferentialExpression/run_DE_analysis.pl  \ <span class="comment"># 老样子，不知道位置可以用 locate 确定。</span></span></span><br><span class="line">--matrix RSEM.isoform.counts.matrix \ # 如果使用的别的定量方法就需要进行相应的替换</span><br><span class="line">--method DESeq2 \</span><br><span class="line">--min_reps_min_cpm 3,1 \</span><br><span class="line">--samples_file sample5.txt --contrasts contrast.txt</span><br></pre></td></tr></tbody></table></figure><ul><li><p><code>--matrix</code> <strong>一定要用原始表达矩阵</strong>！每个软件都有它自己的标准化步骤嵌在分析流程中，所以不需要担心。</p></li><li><p><code>--method</code> 有 <code>DESeq2</code> <code>edgeR</code> 和 <code>limma-voom</code>。</p></li><li><p><code>--min_reps_min_cpm</code> 筛选基因，例如此处的意思是筛选至少在三个样本中出现的且 <strong>count-per-millon</strong> 不低于 1 的基因。</p></li></ul><p>运行结束后会得到一个表格，此后可以用这个表格进行火山图绘制或挑选差异表达基因。</p><h3 id="DEG-挑选"><a href="#DEG-挑选" class="headerlink" title="DEG 挑选"></a>DEG 挑选</h3><p>在差异表达分析结果中以 <code>|log2FC| &gt; 1</code>, <code>q-value (or FDR) &lt; 0.05</code> 作为阈值进行筛选。</p><p>挑选方法：自己手动在 excel 里面筛选或者用 python：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">raw_file = <span class="built_in">open</span>(sys.argv[<span class="number">1</span>],<span class="string">"r"</span>)</span><br><span class="line">out_up_file = <span class="built_in">open</span>(sys.argv[<span class="number">2</span>],<span class="string">"w"</span>)</span><br><span class="line">out_down_file = <span class="built_in">open</span>(sys.argv[<span class="number">3</span>],<span class="string">"w"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> raw_file:</span><br><span class="line">string = line.split(<span class="string">"\t"</span>)</span><br><span class="line"><span class="keyword">if</span> string[<span class="number">0</span>] == <span class="string">'sampleA'</span>:</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(string) == <span class="number">11</span>:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">abs</span>(<span class="built_in">float</span>(string[<span class="number">6</span>])) &gt;= <span class="number">1.0</span> <span class="keyword">and</span> <span class="built_in">float</span>(string[-<span class="number">1</span>]) &lt;= <span class="number">0.05</span>:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">float</span>(string[<span class="number">6</span>]) &gt; <span class="number">0</span>:</span><br><span class="line">out_up_file.write(string[<span class="number">0</span>] + <span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">out_down_file.write(string[<span class="number">0</span>] + <span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">abs</span>(<span class="built_in">float</span>(string[<span class="number">3</span>])) &gt;= <span class="number">1.0</span> <span class="keyword">and</span> <span class="built_in">float</span>(string[-<span class="number">1</span>]) &lt;= <span class="number">0.05</span>:</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">float</span>(string[<span class="number">3</span>]) &gt; <span class="number">0</span>:</span><br><span class="line">out_up_file.write(string[<span class="number">0</span>] + <span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">out_down_file.write(string[<span class="number">0</span>] + <span class="string">'\n'</span>)</span><br></pre></td></tr></tbody></table></figure><p>这个我针对上述脚本输出的文件所写的一个提取差异表达基因的脚本，如果想要更改筛选标准可以在里面做相应的调整，或者添加可指定的参数项。</p><p>使用例：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python de.py xxx.DE_results DEG_up.txt DEG_down.txt</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> *up.txt | <span class="built_in">sort</span> | <span class="built_in">uniq</span> &gt; DEG_all_up.txt</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> *down.txt | <span class="built_in">sort</span> | <span class="built_in">uniq</span> &gt; DEG_all_down.txt</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">wc</span> -l DEGS* &gt; stast.txt <span class="comment"># 统计差异表达基因的数量</span></span></span><br></pre></td></tr></tbody></table></figure><p>输出的 <code>DEG_up.txt</code> 和 <code>DEG_down.txt</code> 里分别是上调和下调的差异表达基因列表（可根据自身需求调整输出的文件名称），后面几步可选择进行，用处主要是合并所有软件得到的差异表达基因以及统计有多少上调和下调的基因。</p><p>获得差异表达基因以后，就可以准备进行后续的富集分析了。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>下一篇预告：比较转录组分析（六）—— GO 富集分析与可视化。</p><p>火山图教程预告（随缘）：基于 GraphPad Prism 的火山图绘制。</p><p>使用 R 绘制火山图的话可以看看这一篇教程：<a href="https://zhuanlan.zhihu.com/p/82785739">R 数据可视化 02 | 火山图 from 知乎</a>。</p><h3 id="①、关于三个转录本丰度估计软件的差异"><a href="#①、关于三个转录本丰度估计软件的差异" class="headerlink" title="①、关于三个转录本丰度估计软件的差异"></a>①、关于三个转录本丰度估计软件的差异</h3><p>RSEM 是需要比对结果进行定量的，可以调用的软件有 STAR Bowtie2 Bowtie 等，文里使用了 Bowtie2。其他两个是不需要进行比对就可以直接进行定量的工具。具体哪个最为准确的问题，感兴趣可以看一下这篇论文：<a href="https://www.sciencedirect.com/science/article/pii/S1874939919300501#bb0230">Interoperable RNA-Seq analysis in the cloud</a>。这篇文章对 salmon 和 kallisto 评价是比较高的（不过和 qPCR 的结果最不相似<del>，事实上和其他的也就差了一丢丢，我个人不排除误差问题</del>），RSEM 的结果和它们相似但是由于运行效能的问题被 diss 了。</p><p>再找，然后在 <a href="https://www.nature.com/articles/nbt.3519/">kallisto 的论文</a>中找到了这张图：</p><p><img src="/pic/bdrj.jpg"></p><p>简单来说就是把每个转录本定量结果的中位数差异作为精确性的指标，然后可以看到 Bowtie2 + RSEM 的组合是最为精准的，kallisto 虽然次了一点点但也不遑多让。而当考虑到运行时间时，Bowtie2 + RSEM 的组合很不幸地被 kallisto 碾压了，还不是一点点的程度。可以看到 kallisto 的定量是非常迅速且也保证了精确度的。所以运行内存有限并且追求精确度的情况下，kallisto 毫无疑问是更好的选择。</p><p>此外在一篇讨论 salmon 精度的文章中，Bowtie2 + RSEM 在某些情况下的精准度比其高（当数据和参考转录组一致的情况下），当参考转录组和 reads 并不完全匹配时，则 salmon 更为精确些。</p><p>文章：<a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8">Alignment and mapping methodology influence transcript abundance estimation</a></p><p>关于不同软件具体的差异在哪里可以精读一下文章，这里我就只搬个结论作为参考。</p><p>软件的效率（速度）是一个非常重要的参考依据，如果想用有限的内存得到最好的效果，那么 kallisto 和 salmon 的优先级要高很多。</p><h3 id="②、不同差异表达分析软件的差异"><a href="#②、不同差异表达分析软件的差异" class="headerlink" title="②、不同差异表达分析软件的差异"></a>②、不同差异表达分析软件的差异</h3><p>找文章，直接找文章：</p><blockquote><p><a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02648-4">Exaggerated false positives by popular differential expression methods when analyzing human population samples</a></p><p>from Genome Biology</p></blockquote><p>这里就不放图了，简单说一下几个结论：</p><p>①、在大样本量时，DESeq2 和 edgeR 具有惊人的假阳性率，两者中 edgeR 更为明显。</p><blockquote><p>造成这些现象的原因是：However, while the three parametric methods were initially designed to address the small-sample-size issue, these population-level studies had much larger sample sizes (at least dozens) and thus no longer needed restrictive parametric assumptions. Moreover, violation of parametric assumptions would lead to ill-behaved <em>p</em>-values and likely failed FDR control, an issue independent of the sample size.</p><p>简单来说，就是这三种方法都有设置相应的假设以应对低样本量的情况（这个假设允许混合有相近表达情况的基因数据以估计方差），然而在大样本量的研究中这一假设不再被需要，如果继续坚持这一假设会导致错误的估计。</p></blockquote><p>②、相比之下大多数情况中 limma-voom 表现更为良好（不管小样本量大样本量）。</p><p>③、推荐在大样本量时使用 wilcoxon 秩和检验，这种非参数的方法在面对异常值时会显得更加可靠。但与此同时，由于其是一种非基于回归的方法，因此无法针对混杂的因素进行调整，因此使用该方法进行 DEG 鉴定前需先标准化或者使用概率指数模型调整协变量。（文中的方法是先用 edgeR 进行过滤和标准化然后再使用 wilcoxon 秩和检验 + Benjamini&amp;Hochberg 矫正）</p><p>tip: 有趣的是我发现网上有关于第一篇文章的介绍，写的非常好，传送门：<a href="https://www.plob.org/article/27145.html">别再用 DEseq2 和 edgeR 进行大样本差异表达基因分析了</a>。</p><p><strong>补充（2023.04.20）：</strong></p><p>事实上我在大概一月份左右就发现了新东西，但是一直没有更新，今天心血来潮突然就想起来，于是乎就进行了补充。</p><p>新的发现就是：</p><ul><li><p>样本多（重复多）时，edgeR 多于 DESeq2。</p></li><li><p>样本少（重复少）时，edgeR 少于 DESeq2。</p></li></ul><p>这可能与它们的算法差异有关，这一点可以看 DESeq2 论文原文片段：</p><blockquote><p>Besides the need to account for the specifics of count data, such as non-normality and a dependence of the variance on the mean, a core challenge is the small number of samples in typical HTS experiments – often as few as two or three replicates per condition. Inferential methods that treat each gene separately suffer here from lack of power, due to the high uncertainty of within-group variance estimates. In high-throughput assays, this limitation can be overcome by pooling information across genes, specifically, by exploiting assumptions about the similarity of the variances of different genes measured in the same experiment.</p><p>Many methods for differential expression analysis of RNA-seq data perform such information sharing across genes for variance (or, equivalently, dispersion) estimation. <em>edgeR</em> moderates the dispersion estimate for each gene toward a common estimate across all genes, or toward a local estimate from genes with similar expression strength, using a weighted conditional likelihood. Our <em>DESeq</em> method detects and corrects dispersion estimates that are too low through modeling of the dependence of the dispersion on the average expression strength over all samples.</p></blockquote><h3 id="③、关于批次效应"><a href="#③、关于批次效应" class="headerlink" title="③、关于批次效应"></a>③、关于批次效应</h3><p>一个会毁坏整个实验的事情。</p><p>事实往往比言语更有力：</p><p><img src="/pic/batch1.png"></p><p>这是一张 NMDS 图，乍一看好像有挺多值得琢磨的东西，比如这三组里面红色组和绿色组的势头是不一样的。</p><p><img src="/pic/batch2.png"></p><p>然而事实上，红圈所框住的地方所对应的样本与其他样本的采集时间是不一致的（相隔了两个季节），导致虽然这些样本的分组和同组其他样本是一样的，但它们的 NMDS 结果却截然不同并且出现分层。</p><p>这就是批次效应，也是很多研究者们想要尽力避免的问题。所以在设计实验时就应当注意，需要把除了自己关注的因素以外的所有其他干扰因素给排除或者尽力降到最低，避免出现部分结论无法解释的现象以及避免产生批次效应。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 转录组 </tag>
            
            <tag> 比较转录组学 </tag>
            
            <tag> 差异表达分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>比较转录组分析（四）—— 组装的 GO 及 KEGG 注释</title>
      <link href="/2022/11/28/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%84%E8%A3%85%E7%9A%84%E6%B3%A8%E9%87%8A/"/>
      <url>/2022/11/28/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%84%E8%A3%85%E7%9A%84%E6%B3%A8%E9%87%8A/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><blockquote><div id="portalContainer"></div><script src="/js/ctlink.js"></script><script> generatePortalLinks(4);</script></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前我们已经讨论了评估组装质量和组装去冗余的方法，在这里我们再来进一步谈一谈组装的注释。</p><p>这一环节应该算得上是转录组的第一个重头分析部分，因为它可以让执行者对自己的组装有一个更清晰的认知。</p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2022.12.29 补充了如何利用 GO 注释信息绘制二级分类图的部分。</p><p>2023.01.11 补充了如何利用 Kofamscan 进行 KEGG 注释。</p><p>2023.07.03 精简了部分内容。</p><h3 id="出现的一些词"><a href="#出现的一些词" class="headerlink" title="出现的一些词"></a>出现的一些词</h3><p><strong>blast</strong>：中文名叫做爆炸，其实是一种比对工具。</p><p><strong>diamond</strong>：中文名叫做钻石，其实也是一种序列比对工具，速度是 blast 的 100-10000 倍，且资源需求低。</p><p><strong>swissprot</strong>：一个<strong>注释非常良好</strong>的蛋白数据库，是 UniProt 数据库的组成之一。</p><p><strong>KEGG</strong>：全名京都基因与基因组百科全书，由日本京都大学生物信息学中心搭建的一个数据库。</p><h3 id="什么是注释"><a href="#什么是注释" class="headerlink" title="什么是注释"></a>什么是注释</h3><p>注释分很多种，但是它们在转录组分析中的最终目的都指向一个共同点 —— <strong>解释组装（或者说基因）</strong>。</p><p>比如说 GO 注释、KEGG 注释、Pfam 注释、nr 注释的注释内容是不一样的，但是最终目的都是想阐明组装中不同的 contig 代表的是哪一种基因或者说执行了什么生物学功能。</p><p>不过注释库都是<strong>人为编写</strong>的，并且<strong>对于每个基因的注释也都是人为划定</strong>的，关于这一点有很多可深入了解的地方，关于 GO 注释可以看一看这两篇文章：<a href="https://www.jianshu.com/p/7177c372243f">GO注释和富集分析概念介绍 from 简书</a> 与 <a href="https://zhuanlan.zhihu.com/p/350544360">Gene Ontology(GO)简介与使用介绍 from 知乎</a>。</p><h2 id="GO-注释"><a href="#GO-注释" class="headerlink" title="GO 注释"></a>GO 注释</h2><p>几点可能需要注意的事情：</p><p>①、GO 注释被分为三大类，分别是<strong>生物过程、细胞组分和分子功能</strong>。</p><p>②、GO terms 之间可能是有关系的，比如一个 term 是另外一个 term 的父级项，整个 GO 的结构是一个<strong>有向无环图</strong>。</p><blockquote><p>关于第 ② 点，我随便举个例子，比如说 <code>吃饭</code> 和 <code>吃下午饭</code> 这两个 term 里，明显可以看出  <code>吃饭</code> 是 <code>吃下午饭</code> 的父项，因此在某个基因上如果出现了 <code>吃下午饭</code> 这个 term，那么它就同时拥有 <code>吃饭</code> 这个 term。</p></blockquote><p>③、基于上述原因，一个基因中可能会出现非常多相关的 GO term 注释，而在后续的富集分析中也会表现出来（比如说前几的都是一些相关联的 GO term），因此在后续的富集分析里<strong>可以考虑</strong>把一些相关的 term 给删掉一部分，仅保留具有代表性的那个。</p><p>④、GO term 的注释事实上是相对宽松的，只要这个基因跟某个功能沾上了边就会有人给它这个功能对应的注释。</p><p>⑤、GO term 是一个一直在保持更新的注释库，因此老旧的注释库数据可能存在某个 term 被废弃掉的情况，因此在某个项目的分析过程中最好保持数据库版本的一致，并在不需要继续使用的时候抽空更新数据库（记录好使用过的版本、做好版本控制，<strong>保证结果的可再现性</strong>）。</p><p>就 GO annotation 而言，可以选择的软件有很多，比如 <code>Interproscan</code>、<code>eggnog-mapper</code>、<code>Trinotate</code>、<code>Blast2GO</code> 等等，包括一些在线网站比如像 <code>Pannzer2</code> 等也能够完成这一任务。</p><p>值得注意的应该是 Trinotate 的开发者也开发过 Trinity ，两个软件之间的衔接非常好，甚至有一些 Trinotate 的功能就是专门为 Trinity 的组装提供的，所以后续我会就 <strong>Trinotate</strong> 的注释方法进行分享介绍。</p><p><img src="/pic/TrinotateLogo.png"></p><h3 id="Trinotate-安装-amp-执行"><a href="#Trinotate-安装-amp-执行" class="headerlink" title="Trinotate 安装 &amp; 执行"></a>Trinotate 安装 &amp; 执行</h3><p>安装可以参照 Trinotate 官网进行（<a href="https://github.com/Trinotate/Trinotate/wiki/Software-installation-and-data-required">传送门</a>），不过在这里提出几点可能可以帮助减少软件配置时间的建议：</p><p>①、如果仅使用 Trinotate 进行 GO 注释<strong>而不进行别的注释</strong>，那么仅安装 Software Required 中的 Trinotate、<a href="http://transdecoder.github.io/">TransDecoder</a>、SQLite 和 NCBI BLAST+ 就可以满足运行需求。</p><p>②、NCBI 的 blast 速度事实上挺慢的，如果转录组较大而且希望运行时间短一些，可以考虑使用 diamond blast 进行后续的步骤。</p><p>Trinotate 的注释原理简单来说，就是首先进行了 <strong>SwissProt</strong> 的注释，然后根据注释信息输入到 SQLite 数据库中并调用出注释蛋白对应的 GO term 注释。因此首先我们会对组装进行蛋白预测和 blast 比对：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">TransDecoder.LongOrfs -t cdhit.fasta</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">TransDecoder.Predict -t cdhit.fasta</span></span><br></pre></td></tr></tbody></table></figure><p>Transdecoder 会预测组装中可能存在的开放阅读框并得到对应的 cds 序列和 pep 序列。</p><p>注意，这里应该使用<strong>去冗余后的组装</strong>作为注释的背景集。此外，<code>TransDecoder.Predict</code> 可使用 <code>--single_best_only</code> 参数使其仅输出每个 contig 预测的最佳 pep 序列和对应 cds（原理是先看同源性再看长度，但貌似大多数时候都是取最长）。</p><p>在这之后，使用 diamond blast（也可以使用 NCBI blast）against swissprot database：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">diamond blastx --query cdhit.fasta --db uniprot --threads 5 --max-target-seqs 1 --outfmt 6 --evalue 1e-5 &gt; blastx.outfmt6</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">diamond blastp --query transdecoder.pep --db uniprot --threads 5 --max-target-seqs 1 --outfmt 6 --evalue 1e-5 &gt; blastp.outfmt6</span></span><br></pre></td></tr></tbody></table></figure><p><code>blastx</code> 是用核苷酸序列去比对蛋白数据库，<code>blastp</code> 是用蛋白序列去比对蛋白数据库，这里以 <code>evalue</code> 为 1e-5 为阈值，按照官网的 1e-3 也没有问题不过在文章中写明就好。</p><p>得到两个 blast 文件后，使用 Trinotate 将其加载到 SQLite 数据库中并输出注释报告：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">Trinotate /path/to/Trinotate/Trinotate.sqlite init --transcript_fasta cdhit.fasta --transdecoder_pep transdecoder.pep --gene_trans_map cdhit.map</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cdhit.map 可以通过 Trinity 的脚本 get_Trinity_gene_to_trans_map.pl 得到，用法如下：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">get_Trinity_gene_to_trans_map.pl cdhit.fasta &gt; cdhit.map</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">Trinotate /path/to/Trinotate/Trinotate.sqlite LOAD_swissprot_blastx blastx.outfmt6</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">Trinotate /path/to/Trinotate/Trinotate.sqlite LOAD_swissprot_blastp blastp.outfmt6</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">Trinotate /path/to/Trinotate/Trinotate.sqlite report &gt; trinotate_annotation_report.xls</span></span><br></pre></td></tr></tbody></table></figure><p>tip：此处的 <code>/path/to/Trinotate/Trinotate.sqlite</code> 需要用户自行进行构建和指定，详细可见 <a href="https://github.com/Trinotate/Trinotate/wiki/Software-installation-and-data-required#2-sequence-databases-required">Trinotate Sequence Databases Required</a>。</p><p>注释报告中详细展示了每个 contig 的注释信息，此后可使用 Trinotate 的脚本输出为 GO 注释文件：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">Trinotate/util/extract_GO_assignments_from_Trinotate_xls.pl \</span></span><br><span class="line"><span class="language-bash">--Trinotate_xls trinotate_annotation_report.xls \</span></span><br><span class="line"><span class="language-bash">-T --include_ancestral_terms \</span></span><br><span class="line"><span class="language-bash">&gt; go_annotation.txt</span></span><br></pre></td></tr></tbody></table></figure><p>其中 <code>-T</code> 指的是在转录组水平上进行，可替换成 <code>-G</code> 在基因水平上进行，但是我们已经进行过去冗余了所以使用 <code>-T</code> 即可。</p><p><code>--include_ancestral_terms</code> 指的是会沿着有向无环图爬取每个 GO term 的父项 term 并输出。</p><p>得到的文件是长这个样子的：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xxx1GO:0003674,GO:0005488,GO:0045216,GO:0045296</span><br><span class="line">xxx2GO:0000139,GO:0000271,GO:0004553,GO:0006629</span><br></pre></td></tr></tbody></table></figure><p>此后，为了后续可以使用 R clusterprofiler 进行 GO enrichment analysis，我们需要把它修正为<strong>一对一</strong>的模式，脚本如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_go_annotations</span>(<span class="params">raw_file, out_file</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(raw_file, <span class="string">"r"</span>) <span class="keyword">as</span> infile, <span class="built_in">open</span>(out_file, <span class="string">"w"</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> infile:</span><br><span class="line">            string = line.split(<span class="string">"\t"</span>)</span><br><span class="line">            gene = string[<span class="number">0</span>]</span><br><span class="line">            go_terms = string[<span class="number">1</span>].strip().split(<span class="string">","</span>)</span><br><span class="line">            <span class="keyword">for</span> goid <span class="keyword">in</span> go_terms:</span><br><span class="line">                output = gene + <span class="string">'\t'</span> + goid + <span class="string">'\n'</span></span><br><span class="line">                outfile.write(output)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">"Process a Trinotate output GO annotation file to create a one-to-one relationship between genes and GO terms."</span>)</span><br><span class="line">    </span><br><span class="line">    parser.add_argument(<span class="string">'-r'</span>, <span class="string">'--raw_file'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">'Path to the Trinotate output raw GO annotation file.'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'-o'</span>, <span class="string">'--out_file'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">'Path to the output file where each gene and GO term will have a one-to-one relationship.'</span>)</span><br><span class="line">    </span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    </span><br><span class="line">    process_go_annotations(args.raw_file, args.out_file)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></tbody></table></figure><p>脚本我放在 github 里了（<a href="https://github.com/JuseTiZ/PyScript-for-CT">传送门</a>），或者你可以将其复制到命名为 <code>onego.py</code> 的脚本中，使用方法如下：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python onego.py -r go_annotation.txt -o onego.txt</span></span><br></pre></td></tr></tbody></table></figure><p>得到的 onego.txt 长这个样子：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">xxx1      GO:0003674</span><br><span class="line">xxx1      GO:0005488</span><br><span class="line">xxx1      GO:0045216</span><br><span class="line">xxx1      GO:0045296</span><br><span class="line">xxx2      GO:0000139</span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure><p>到这里就算获得了组装的背景基因注释集，接下来就是通过差异表达分析获得 DEGs（Differential Expressed Genes）得到前景基因，并通过富集分析判断差异表达基因的功能。</p><h2 id="GO-二级分类柱状图绘制"><a href="#GO-二级分类柱状图绘制" class="headerlink" title="GO 二级分类柱状图绘制"></a>GO 二级分类柱状图绘制</h2><p>一些可用的在线网站：</p><p>网址：<a href="https://wego.genomics.cn/">https://wego.genomics.cn/</a></p><p>网址：<a href="https://www.omicshare.com/tools/Home/Soft/osgo">https://www.omicshare.com/tools/Home/Soft/osgo</a></p><p>上述两个网站的绘图都可以进行相应的参数调整，感兴趣的友们可以自行尝试（格式可能需要进行一定的调整）。也可以自己写脚本然后统计二级分类数量并绘制柱状图。</p><h2 id="KEGG-注释"><a href="#KEGG-注释" class="headerlink" title="KEGG 注释"></a>KEGG 注释</h2><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>最简单的方法是通过官网进行，地址：<a href="https://www.kegg.jp/blastkoala/">https://www.kegg.jp/blastkoala/</a> ，官网中的方法分成了三种，分别是 <code>BlastKOALA</code>、<code>GhostKOALA</code> 以及 <code>KofamKOALA</code>。使用无参转录组进行注释的话需要注意：</p><ul><li>需要使用 pep 序列（可使用 Transdecoder 预测出来的）。</li><li>不要使用 GhostKOALA（用于预测宏基因组），其他两个都可以。</li></ul><p>不过官网注释有个缺陷就是它<strong>有序列数限制</strong>，因此除非我们把自己的 pep 序列分成很多份然后一份份交给它注释，否则这个办法是行不通或者说可行度很低的。</p><p>所以说更好的方式是采取<strong>本地化的注释方法</strong> —— Kofamscan 进行。</p><h3 id="Kofamscan-安装-amp-执行"><a href="#Kofamscan-安装-amp-执行" class="headerlink" title="Kofamscan 安装 &amp; 执行"></a>Kofamscan 安装 &amp; 执行</h3><p>目前网上关于 Kofamscan 的教程还是非常多的，所以这里可以自行 Bing 搜索安装并尝试执行。</p><p>好教程：<a href="https://zhuanlan.zhihu.com/p/375740435">KEGG功能注释及本地化–基于KofamKOALA from 知乎</a></p><p>用于理解 KEGG 注释的好教程：<a href="https://zhuanlan.zhihu.com/p/96008506">一文快速读懂 KEGG 数据库与通路图 from 知乎</a></p><p>输入命令执行 Kofamscan ：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">exec_annotation -o kegganno.detail.csv --cpu xx -E 1e-3 cdhit.pep</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">exec_annotation -o kegganno.csv --cpu xx -E 1e-3 -f mapper cdhit.pep</span></span><br></pre></td></tr></tbody></table></figure><p>其中把 <code>cdhit.pep</code> 换成自己的 pep 序列就行了。</p><p>使用上述第一条命令的输出（未使用 <code>-f mapper</code>），会输出一份详细的注释报告，包括基因得到的 KO 号以及分数、e 值等信息，当基因名前有 * 时代表该基因的分数超过阈值，说明这个注释是可信的。</p><p><img src="/pic/kegg1.png"></p><p>使用上述第二条命令的输出则是会把分数超过阈值且 e 值小于 1e-3 的那些注释输出成一份一基因对一 KO 的格式，这种格式方便我们处理用于后续的富集分析。</p><p><img src="/pic/kegg2.png"></p><p>事实上 Kofamscan 的注释仅仅只是 KO 号，一般而言我们在论文里看到 KEGG 注释和 KEGG 富集分析事实上指的都是 KEGG <strong>通路（pathway）注释和通路的富集分析</strong>，而 KO 号和 kegg 通路之间是有很大差别的。</p><p>在这里我就直接搬上面知乎教程里的讲解展示：</p><p><img src="/pic/kegg3.png"></p><p>KO 的全称即为 <strong>KEGG ORTHOLOGY</strong>，orthology 的意思也即同源。</p><p>而在 KEGG 数据库中，代表着通路的 id 在总库里是由小写的 ko 开头的，细分到具体的物种还会有诸如 hsa 开头（代表人类）等样式的通路 id。而一个基因可能参与到多个生理过程中，因此一个 KO 号可能会涉及到多个通路。</p><p>KO 号不代表通路，因此这里有一种可行的办法就是把 KO 号给映射到 KEGG 通路上，也就是在 KO 注释的基础上进一步给它分配 KEGG pathway 的注释。</p><p>但一个 KO 号代表的是一类基因，可能会出现在多个通路里，而这多个通路可能并不会在同一个物种中出现，比如说一个 KO 表示的基因它可能<strong>在植物中参与到了一个植物独有的代谢通路中，但是在动物中它就没有这样的通路</strong>。</p><p>因此在这里我们需要选择专门的物种进行注释，注释的方法就是从 KEGG 的官网上下载各个 pathway 与 KO id 的对映文件。</p><p>首先 KEGG 数据库所涵盖的物种列表在 <a href="https://www.genome.jp/kegg/catalog/org_list.html">https://www.genome.jp/kegg/catalog/org_list.html</a> 中。</p><p><img src="/pic/kegg4.png"></p><p>红框所示的部位为各个物种对应的物种编号，然后可以输入下列网址进行下载：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.kegg.jp/kegg-bin/download_htext?htext=物种编号00001.keg&amp;format=htext</span><br></pre></td></tr></tbody></table></figure><p>比方说我要下载人类的映射关系文件就可以输入：</p><p><a href="http://www.kegg.jp/kegg-bin/download_htext?htext=hsa00001.keg&amp;format=htext">http://www.kegg.jp/kegg-bin/download_htext?htext=hsa00001.keg&amp;format=htext</a></p><p>总库（拥有所有物种的所有映射关系）的下载：</p><p><a href="http://www.kegg.jp/kegg-bin/download_htext?htext=ko00001.keg&amp;format=htext">http://www.kegg.jp/kegg-bin/download_htext?htext=ko00001.keg&amp;format=htext</a></p><p>下载以后的文件是长这样的：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">A09100 Metabolism</span><br><span class="line">B</span><br><span class="line">B  09101 Carbohydrate metabolism</span><br><span class="line">C    00010 Glycolysis / Gluconeogenesis [PATH:ko00010]</span><br><span class="line">D      K00844  HK; hexokinase [EC:2.7.1.1]</span><br><span class="line">D      K12407  GCK; glucokinase [EC:2.7.1.2]</span><br><span class="line">D      K00845  glk; glucokinase [EC:2.7.1.2]</span><br><span class="line">D      K25026  glk; glucokinase [EC:2.7.1.2]</span><br><span class="line">D      K01810  GPI, pgi; glucose-6-phosphate isomerase [EC:5.3.1.9]</span><br><span class="line">D      K06859  pgi1; glucose-6-phosphate isomerase, archaeal [EC:5.3.1.9]</span><br><span class="line">D      K13810  tal-pgi; transaldolase / glucose-6-phosphate isomerase [EC:2.2.1.2 5.3.1.9]</span><br><span class="line">D      K15916  pgi-pmi; glucose/mannose-6-phosphate isomerase [EC:5.3.1.9 5.3.1.8]</span><br><span class="line">D      K24182  PFK9; 6-phosphofructokinase [EC:2.7.1.11]</span><br><span class="line">D      K00850  pfkA, PFK; 6-phosphofructokinase 1 [EC:2.7.1.11]</span><br><span class="line">D      K16370  pfkB; 6-phosphofructokinase 2 [EC:2.7.1.11]</span><br><span class="line">D      K21071  pfk, pfp; ATP-dependent phosphofructokinase / diphosphate-dependent phosphofructokinase [EC:2.7.1.11 2.7.1.90]</span><br><span class="line">D      K00918  pfkC; ADP-dependent phosphofructokinase/glucokinase [EC:2.7.1.146 2.7.1.147]</span><br><span class="line">D      K00895  pfp, PFP; diphosphate-dependent phosphofructokinase [EC:2.7.1.90]</span><br><span class="line">D      K03841  FBP, fbp; fructose-1,6-bisphosphatase I [EC:3.1.3.11]</span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure><p>这里的等级层次类似于 GO，<strong>以 A 为开头的行代表 KEGG pathway 的 “大类” ，以 B 为开头的行代表二级分类，以 C 为开头的行则代表着不同的通路，后面的名字对应通路名称，其下以 D 为开头的行代表可以注释到这个通路的所有基因和对应 KO 号（一个 KO 号可能对应多个通路）</strong>。</p><p>因此使用 Kofamscan 得到 KO 注释文件后，可以使用对应物种的 pathway-KO 文件给注释相应的 pathway，根据注释信息进行后续富集分析。如果在 KEGG 的官网找不到目标物种，也可以选择一个近缘的进行分析，同样可以提高不少准确性。</p><p>代码在上面提到的知乎教程中那个老哥写的非常好，如果友们有需要也可以去下载一份然后根据个人需求修改。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>更新（来自 2023.1.11）：今天把 KEGG 注释的部分也给补充上了，应该算是补充上了一个相当重要的部分，后续看情况找时间补充 Pfam、nr 和 CAzy 注释的内容，但这几种注释相对于 GO 注释和 KEGG 注释而言会更简单方便，有了 GO 和 KEGG 的经验以后自行学习其他的注释理应上来说是不会存在太大问题的。</p><p>更新（来自 2023.7.03）：精简化了很多无用的内容，真想给喜欢说废话的自己来上一拳。</p><p>更新（来自 2024.8.24）：完善了一些信息，避免可能导致的混淆。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 转录组 </tag>
            
            <tag> 比较转录组学 </tag>
            
            <tag> GO annotation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>比较转录组分析（三）—— 组装的质量检测与去冗余</title>
      <link href="/2022/11/21/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%84%E8%A3%85%E7%9A%84%E8%B4%A8%E9%87%8F%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8E%BB%E5%86%97%E4%BD%99/"/>
      <url>/2022/11/21/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%20%E7%BB%84%E8%A3%85%E7%9A%84%E8%B4%A8%E9%87%8F%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8E%BB%E5%86%97%E4%BD%99/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><blockquote><div id="portalContainer"></div><script src="/js/ctlink.js"></script><script> generatePortalLinks(3);</script></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前文提到怎么组装数据，这里探讨下如何判断组装质量。</p><p>讲完组装质量后，再讲一讲去冗余的概念以及为何要去冗余，去冗余的方法有哪些等。</p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2022.11.22 补充了在进行后续分析前给 Contig 添加物种名前缀的内容，补充了后记内容，添加了部分粗体。</p><p>2022.12.06 补充了一些内容</p><p>2023.07.03 精简了内容</p><h2 id="组装质量评估"><a href="#组装质量评估" class="headerlink" title="组装质量评估"></a>组装质量评估</h2><h3 id="N50-——-评估指标"><a href="#N50-——-评估指标" class="headerlink" title="N50  ——  评估指标"></a>N50  ——  评估指标</h3><p>计算 N50 时，首先会把组装中所有 <strong>碱基</strong> 的个数统计出来，比如 <code>ATCG</code> 就是四个碱基。</p><p>统计出来后，将 Contig 按照它们的长度依次排列，从长到短。</p><p>排列完以后，从最长的 Contig 开始，计算它的碱基数量并加和起来，当计算到某一条 Contig 时所加和起来的碱基数量到达了组装所有碱基数量的一半时，这一条 Contig 的长度就是 N50 的数值大小。</p><p>N50 可以反应组装的细碎程度，当其很小时，表明组装出来的 Contig 整体较短的。</p><p>想要统计这一系列组装信息可以使用 Trinity 自带的脚本进行（低版本没有）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">locate TrinityStats.pl   <span class="comment"># 如果你不知道位置可以使用这个。</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">TrinityStats.pl xxx.fasta &gt; stat.txt</span></span><br></pre></td></tr></tbody></table></figure><h3 id="Bowtie2-比对率"><a href="#Bowtie2-比对率" class="headerlink" title="Bowtie2 比对率"></a>Bowtie2 比对率</h3><p>准确来说，Bowtie2 的比对率反应的是这个组装对于测序数据的代表水平，它的比对率越高，表明 Trintiy 使用测序数据组装的越完好，这个可以作为一个参考。</p><p>比对的方法请见网上教程，在后续事实上也会用到 Bowtie2 去比对定量，因此<strong>这一步可以放在后续的流程中顺便完成</strong>。</p><p>比对出来的信息是长这样的：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">27044147 reads; of these:</span><br><span class="line">  27044147 (100.00%) were paired; of these:</span><br><span class="line">    5116100 (18.92%) aligned concordantly 0 times</span><br><span class="line">    5459447 (20.19%) aligned concordantly exactly 1 time</span><br><span class="line">    16468600 (60.90%) aligned concordantly &gt;1 times</span><br><span class="line">81.08% overall alignment rate</span><br></pre></td></tr></tbody></table></figure><p>该例中取消了不和谐比对的统计（默认参数是会将不和谐比对纳入总比对率中的）。</p><p>快速得到总体比对率：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> bowtie.out | grep <span class="string">"overall alignment rate"</span></span></span><br></pre></td></tr></tbody></table></figure><h3 id="BUSCO-——-应该算是金标准"><a href="#BUSCO-——-应该算是金标准" class="headerlink" title="BUSCO —— 应该算是金标准"></a>BUSCO —— 应该算是金标准</h3><p>BUSCO 相较于上述两者会直观很多，它的全称叫做 <code>Benchmarking Universal Single-Copy Orthologs</code> 。</p><p>原理：它有不同类群物种的保守基因数据库，通过比对判断组装的转录本里包含了多少这些基因，通过这一指标去评判组装的完整性。</p><p>这个软件教程非常成熟，比如：<a href="https://www.jianshu.com/p/5041460f7a5d">BUSCO - 组装质量评估 from 简书</a> 或者 <a href="https://zhuanlan.zhihu.com/p/456518273">知乎</a> 。</p><p>BUSCO 自带画图脚本，跑完后的结果就是长这样的（以上面教程中的为例）：</p><p><img src="/pic/buscosample.png"></p><p>实际结果中可能深蓝色的部分（多拷贝）占比会很多，但不用担心，因为转录组存在冗余是很正常的。</p><p>BUSCO 的结果是判断一个转录组是否能作为物种参考转录组的一个很好的参考，如果在 BUSCO 结果中大多数的基因都未被找到，那么基于这个转录组的分析也会变得不是那么可靠：</p><p><img src="/pic/busco_figure.png"></p><p>具体的代码执行：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">busco --offline --lineage /path/arthropoda_odb10 -i xxx.fasta \</span></span><br><span class="line"><span class="language-bash">-m transcriptome --cpu xx -o xxx \</span></span><br><span class="line"><span class="language-bash">--config /path/config.ini</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对应的文件路径需要自行更改</span></span><br></pre></td></tr></tbody></table></figure><p><code>--offline</code> 和 <code>--lineage</code> 是直接让 BUSCO 离线工作，基于本地的数据库执行命令。</p><p>数据库自己下载会方便很多，虽然 BUSCO 可以指定谱系然后在线下载对应数据库进行比对但是远没有自己下载来的迅速。</p><p>BUSCO 不同 lineage 的下载地址：<a href="https://busco-data.ezlab.org/v4/data/lineages/">这里</a>。</p><h4 id="BUSCO-值得注意的点"><a href="#BUSCO-值得注意的点" class="headerlink" title="BUSCO 值得注意的点"></a>BUSCO 值得注意的点</h4><ul><li>BUSCO 有不同的数据库，要根据自己的需要下载，如果找不到自己要分析的物种类群的话也可以使用真核生物数据库进行。</li></ul><ul><li>BUSCO 的绘图脚本虽然方便，但它的宽 &amp; 高是确定的，可以自己更改脚本进行对应修改，同时也可将输出文件改成 pdf 格式，该脚本基于 R 进行绘制的，R 输出的 pdf 为矢量图，十分清晰。此外 pdf 也便于编辑和修改，后期润色处理会更方便。</li></ul><ul><li>BUSCO 的脚本画的图还挺好看的，如果别的数据也类似于这种格式，可以考虑把这个脚本改成需要的样子，例如我用这个脚本画 Bowtie2 的图：</li></ul><p><img src="/pic/align_figure.png"></p><h3 id="其他评估组装质量的方法"><a href="#其他评估组装质量的方法" class="headerlink" title="其他评估组装质量的方法"></a>其他评估组装质量的方法</h3><p>除了上述提到的方法以外，很多指标也能够当作评估的参考，比如全长转录本的含量、ExN50等等。</p><p>甚至有对应的软件可以给组装打分，比如说 <code>TransRate</code> ，原理其实就是总结了上述几个方法然后根据上述几个方法的结果进行综合评价。</p><h2 id="组装的前缀添加"><a href="#组装的前缀添加" class="headerlink" title="组装的前缀添加"></a>组装的前缀添加</h2><p>如果在组装后仅使用这个组装进行后续的分析，前缀就没有太大的必要添加。</p><p>但<strong>如果后续需要利用转录组进行系统发育分析的话，添加前缀的必要性是很高的</strong>，因为这涉及到后续一系列序列的处理和串联，如果一开始没有加上那么后面会有很多麻烦，而且加上了也会让转录组组装具有物种标识，在之后的分析中不容易弄混。</p><p><strong>对于刚跑出来的组装就可以进行这一个处理</strong>了，具体的代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description = <span class="string">"Modify a fasta file's id name."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-m"</span>, <span class="string">"--mod"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, choices = [<span class="string">'pre'</span>,<span class="string">'suf'</span>,<span class="string">'sim'</span>], <span class="built_in">help</span> = <span class="string">"What do u what to do about id? 'pre' means add a prefix. 'suf' means add a suffix. 'sim' means simplify id."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-f"</span>, <span class="string">"--file"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The path to the fasta file."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-s"</span>, <span class="string">"--string"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The prefix or suffix you want to add, use with --mod."</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-o"</span>, <span class="string">"--output"</span>, <span class="built_in">type</span> = <span class="built_in">str</span>, <span class="built_in">help</span> = <span class="string">"The output file."</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">file = args.file</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(args.output,<span class="string">'w'</span>) <span class="keyword">as</span> output:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file) <span class="keyword">as</span> fasta:</span><br><span class="line">        <span class="keyword">if</span> args.mod == <span class="string">'sim'</span>:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> fasta:</span><br><span class="line">                <span class="keyword">if</span> line.startswith(<span class="string">"&gt;"</span>):</span><br><span class="line">                    seqid = line.split()[<span class="number">0</span>]</span><br><span class="line">                    output.write(seqid + <span class="string">'\n'</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                output.write(line)</span><br><span class="line">        <span class="keyword">if</span> args.mod == <span class="string">'pre'</span>:</span><br><span class="line">            prefix = args.string</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> fasta:</span><br><span class="line">                <span class="keyword">if</span> line.startswith(<span class="string">"&gt;"</span>):</span><br><span class="line">                    seqid = line.split()[<span class="number">0</span>][<span class="number">1</span>:]</span><br><span class="line">                    new_seqid = <span class="string">"&gt;"</span> + prefix + seqid</span><br><span class="line">                    output.write(new_seqid + <span class="string">'\n'</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                output.write(line)</span><br><span class="line">        <span class="keyword">if</span> args.mod == <span class="string">'suf'</span>:</span><br><span class="line">            suffix = args.string</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> fasta:</span><br><span class="line">                <span class="keyword">if</span> line.startswith(<span class="string">"&gt;"</span>):</span><br><span class="line">                    seqid = line.split()[<span class="number">0</span>][<span class="number">1</span>:]</span><br><span class="line">                    new_seqid = <span class="string">"&gt;"</span> + seqid + suffix</span><br><span class="line">                    output.write(new_seqid + <span class="string">'\n'</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                output.write(line)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Done!"</span>)</span><br></pre></td></tr></tbody></table></figure><p>这是我挺久以前写的一个脚本，因为网上的脚本大多只涵盖到了一个功能（比如说只能简化 id 或者只能加前缀），所以我写了个可以加前缀、简化 id、加后缀于一身的脚本。下载地址请见我的 github 或点击<a href="https://github.com/JuseTiZ/pythonscript">此处</a>。</p><p>具体的使用例（加前缀）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python id_modification.py -m pre --string Human@ -o before.fasta -f after.fasta</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">less after.fasta</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">Human@TRINITY_DN417604_c0_g1_i1</span></span><br><span class="line">CGACGAGTTAGGACATCTTATGTTAACTTTCCATAGATTAGGATACCCCAATTGGTTTTT</span><br><span class="line">TTATAAATATGTTTCTGGGGCTAGGAAGAGTTTTTTCGGGTTGGGTTTGCCTGTTGGAGA</span><br><span class="line">TAAGGGTTTGAAGAAGTTTCTAGTGTTACCTTATCATCCAAAGTTAGAAGGATGGGACCA</span><br><span class="line">TGTTTTGAGTCGTGTTAACAAAGA</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">Human@TRINITY_DN417624_c0_g1_i1</span></span><br><span class="line">ATTTATTCCTGACTACATGTTCAGGTCCTCAAAAAAGAAATATCCTGACAACAATAACAT</span><br><span class="line">TACAGGAAAGTGTGAAAACAAAATGCTTAGAGAGAAAAGATATCTGGGGGAAAGAAGTAC</span><br><span class="line">TAGCACGCATAGAGTTTTCTACTGATCCCATTGCTTCTGACTGCATTTACCACCAAAGGT</span><br><span class="line">GTAGTATAATCTTTAGAATTTATAAAGAAATAGGCCTACCTACAGATGATGTGTCAATCG</span><br><span class="line">CAAAAAGACAGAAGCCTGGGAGAAGTGTAGACAGTAGTAGAGAGGGTGCTTTTCTGCAGG</span><br><span class="line">CAGTGAACTATTTTGAAGAAAATGATGAAGAGAAATTAACAGTCAACGATCTAGTAGAGA</span><br><span class="line">AAATGGGTGAGATCAGTGAGCAGCCATTTATTGTGAAACACATGAAACGAAGATTGCAAG</span><br><span class="line">AATATTGTGGTGACAAAATAGTTTTCACTGAAATAAATGGAACTCCAAATATAGTAACTG</span><br><span class="line">GTAGGGTTACAGCTTCAAAAATACTTCAGAACTTCTACAACCGTCCCAAAGAGGATGACA</span><br><span class="line">GTGAAAAGCAGAAACGTGTGATCATCGAAACAGCAGTTGAACTGATTCAGAGTGATAGCA</span><br><span class="line">AGTCACTGGAGGGAAACAAAGACATATATCCTACATCGACAGATATATCAACAGTACATA</span><br><span class="line">ATTGCTTAGAATATCTTCCTGACTCCTGTTTTTGAACAAACTGTTTGTGGGCAAGGTAAC</span><br><span class="line">TACATTGAAGGAAGCAGCAATTGGCCATTGTATAATCCAGGCAGTCAGACCCAAAGCTGT</span><br><span class="line">CATTGCTCCTCTTCAGTTAGGTCTGGCTGTCCAACTTCATCTTGAATACGGATCGCGATT</span><br><span class="line">CCAAATTGAGACACTCAGTGAATTAGGATTCTGCTCCTCTTACTCAGAAGTTCTGAGATT</span><br><span class="line">TCAGCAGAGTGCTTCAGTGTCGCAAAAGCAGGACATCCCAGAAGTTATGGCAAATCAACA</span><br><span class="line">G</span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure><p><code>--string</code> 后的字符串一定要以 @ 结尾并且有且仅有一个 @ （当然使用下划线 <code>_</code> 也行，但所有物种应当统一使用其中某一个）。</p><p>处理后的 fasta 文件前面就都有 <code>Human@</code> 了，这样做的具体用处在之后的分析中会一一提到。</p><h2 id="组装的去冗余"><a href="#组装的去冗余" class="headerlink" title="组装的去冗余"></a>组装的去冗余</h2><p>①、为什么说组装有冗余：</p><p>正如之前所说，无参转录组的组装中，很大概率多条 contig 是同属于一个基因的，而且就算这些 contig 是所谓预测出的可变剪切 isoform，它也并不真实可靠。</p><p>②、有没有必要去冗余：</p><p>Trinity 的官网上是这么说的：</p><ul><li><em>Lots</em> of transcripts is the rule rather than the exception.</li><li>Most of the transcripts are very lowly expressed, and the deeper you sequence and the more complex your genome, the larger the number of lowly expressed transcripts you will be able to assemble. Biological relevance of the lowly expressed transcripts could be questionable - some are bound to be very relevant.</li><li>There’s really no good reason to immediately filter them out. They can be ‘passengers’ throughout all of your data analyses, and if any of them are important, they’ll ideally surface in the relevant study. You can put them all through Trinotate.github.io for annotation/analysis, and you can put them through DE studies just fine (those with insufficent reads will get directly filtered out during the DE analysis protocols to avoid problems associated with multiple hypothesis testing); If the read counts are few or lacking, they simply won’t surface as significant DE entries, but if there’s protein homology or other interesting features, you’ll want to continue to capture this info - hence don’t feel the need to immediately filter!</li></ul><p>简单翻译一下就是，有很多转录本是很正常的，没有充分的理由去把它们马上过滤掉，因为可能它们中的某一些是很重要很有价值的。</p><p>当然，绝大多数人是会进行去冗余的，因为这样做会有这么些好处：减少后续分析所需要的内存资源、提高 reads 映射的准确性、所留下的转录本更具有代表性等等。</p><h3 id="方法①-——-取最长转录本"><a href="#方法①-——-取最长转录本" class="headerlink" title="方法① —— 取最长转录本"></a>方法① —— 取最长转录本</h3><p>顾名思义，将 Trinity 组装出来的同属于一个基因的不同 isoform 中挑取最长的出来作为代表转录本。</p><p>实现方法（基于 python）：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">fasta = <span class="built_in">open</span>(sys.argv[<span class="number">1</span>],<span class="string">"r"</span>)</span><br><span class="line">output = <span class="built_in">open</span>(sys.argv[<span class="number">2</span>],<span class="string">"w"</span>)</span><br><span class="line"></span><br><span class="line">id_seq = {}</span><br><span class="line">gene_id = {}</span><br><span class="line">gene_longest = {}</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fasta:</span><br><span class="line"><span class="keyword">if</span> line.startswith(<span class="string">"&gt;"</span>):</span><br><span class="line">contig_id = line.split()[<span class="number">0</span>][<span class="number">1</span>:]</span><br><span class="line">contig_gene = line.split(<span class="string">"_i"</span>)[<span class="number">0</span>][<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">if</span> contig_gene <span class="keyword">in</span> gene_id.keys():</span><br><span class="line">gene_id[contig_gene].append(contig_id)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">gene_id[contig_gene] = []</span><br><span class="line">gene_id[contig_gene].append(contig_id)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">if</span> contig_id <span class="keyword">in</span> id_seq.keys():</span><br><span class="line">id_seq[contig_id] += line</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">id_seq[contig_id] = line</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> gene <span class="keyword">in</span> gene_id.keys():</span><br><span class="line">contigs = []</span><br><span class="line"><span class="keyword">for</span> contig <span class="keyword">in</span> gene_id[gene]:</span><br><span class="line">contigs.append(id_seq[contig])</span><br><span class="line">longest_contig = <span class="built_in">max</span>(contigs, key = <span class="built_in">len</span>)</span><br><span class="line">gene_longest[gene] = longest_contig</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> gene <span class="keyword">in</span> gene_longest.keys():</span><br><span class="line">output.write(<span class="string">"&gt;"</span> + gene + <span class="string">'\n'</span>)</span><br><span class="line">output.write(gene_longest[gene])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Done"</span>)</span><br></pre></td></tr></tbody></table></figure><p>下载地址在<a href="https://github.com/JuseTiZ/pythonscript">这里</a>，对应用法如下：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python longest_contig.py xxx.fasta longest.fasta</span></span><br></pre></td></tr></tbody></table></figure><p>脚本思路比较简单且仅适用于 Trinity 的输出结果，想在 windows 系统上进行可以考虑使用我弄的 JuseKit（😀）。</p><h3 id="方法②-——-对组装进行聚类去冗余"><a href="#方法②-——-对组装进行聚类去冗余" class="headerlink" title="方法② —— 对组装进行聚类去冗余"></a>方法② —— 对组装进行聚类去冗余</h3><p>这里涉及到了一个由国人大佬开发的软件叫 CDHIT，原理和教程请移步 <a href="https://blog.csdn.net/xmji1/article/details/113828618">CDHIT 聚类算法 from 简书</a>。</p><p>我使用的代码（参考了 <a href="https://github.com/trinityrnaseq/trinityrnaseq/wiki/There-are-too-many-transcripts!-What-do-I-do%3F">Trinity 官网推荐的严格聚类</a>）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cd-hit-est -o cdhit.fasta -c 0.95 -i xxx.fasta -p 1 -d 0 -T 5 -M 10000 -b 3</span></span><br></pre></td></tr></tbody></table></figure><p><code>-c</code> 为相似度阈值，越高时越严格。</p><p><code>-b</code> 为对齐带宽，越低时越严格。</p><p>事实上不加 <code>-b</code> 用默认值也是可以的，但是我一开始就用上了于是乎后面就一直在用。</p><p>去冗余后我们就会把组装认为是由非冗余基因组成的 Unigene 库并用于后续的分析（当然完全不冗余是不太现实的）。</p><p>以前生信课里跑数据的时候，我非常纠结去冗余的方式到底该选哪个好，所以我问了老师，他的回答如下：</p><blockquote><p>有些人去冗余他会采用非常极端的方法，就是把所有的去冗余方式都走一遍，但是这也并不一定算是严格正确的。生信的流程并没有一个统一的标准，你觉得哪个好那就选择哪一个，因为哪种都有它的优点和缺点。</p></blockquote><p>就比如说如果你不去冗余，可能一个蛋白编码基因它的一个 isoform 是上调的，另一个 isoform 是下调的，总的来看的话这个基因就是没有变化的，但是又有说法说更长的 isoform 可能代表了更高的活性，这一系列因素软件是不可能完全考虑到的。去冗余了，也会有之前提到的那几个小问题。</p><p>从这些地方就可以看出来，每个步骤里包含的学问都很多。但不知道怎么办的话，流程千千万，选一条适合自己的就足够。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>关于流程选择的问题，我个人感觉如果课题组里已有师兄师姐做过相同的分析并且发表了文章，那么就跟着课题组前辈们的流程走就好。如果没有的话，那么选一篇自己喜欢的论文照着它的流程走也不失为一个很好的选择。</p><blockquote><p>如果有时间的话……     —— Juse</p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 转录组 </tag>
            
            <tag> 比较转录组学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见的一些 linux 实用命令（持续更新）</title>
      <link href="/2022/11/12/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%80%E4%BA%9B%20linux%20%E5%AE%9E%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2022/11/12/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%80%E4%BA%9B%20linux%20%E5%AE%9E%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><p>这次文涉及到的主要是<strong>我在使用 linux 系统时会常使用的命令</strong>。</p><p>该文仅作笔记用，如果某些奇思妙想能够帮助到其他人也是挺好的。</p><h2 id="screen"><a href="#screen" class="headerlink" title="screen"></a>screen</h2><h3 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h3><p>在服务器上创造一个如果不终止则将一直存在的终端，不随着关闭自己的终端而消失，而是一直存在于服务器的后台里，并执行其中运行的命令。</p><p>常用指令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">screen -R xxx  <span class="comment"># 创建并进入 xxx 终端。</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">screen -r xxx  <span class="comment"># 进入已有的 xxx 终端。</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">screen -d      <span class="comment"># 退出当前终端到自己的终端</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">screen -<span class="built_in">ls</span>     <span class="comment"># 浏览当前所有创建的终端，如果显示 Detached 则表示不在里面，显示 Attached 则反之。</span></span></span><br></pre></td></tr></tbody></table></figure><p>如果要关闭所创建的终端，建议先进入这个终端看看是否还有命令正在运行，确定没有遗漏后，再在这个终端中输入 <code>exit</code> 退出。</p><h2 id="df-h-amp-htop"><a href="#df-h-amp-htop" class="headerlink" title="df -h  &amp;  htop"></a>df -h  &amp;  htop</h2><p><code>df -h</code> 可以知道还剩余多少空间</p><p><code>htop</code> 直观展现内存占用情况，可以根据剩余的内存合理地设置软件的相关参数。</p><h2 id="nohup"><a href="#nohup" class="headerlink" title="nohup"></a>nohup</h2><p>nohup 英文全称 no hang up（不挂起），用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行。</p><p>除了这个作用以外，它还会输出一个名叫 <code>nohup.out</code> 的文件到当前目录下，这个文件记载了所有该指令本来会有的屏幕输出。</p><p>对于在运行时会把有用信息打印在屏幕输出上而不保存在某个文件里的命令（例如 <code>Bowtie2</code> <code>Trimmomatic</code> 等），都适合在前面加一个 nohup 以进行记录，nohup 不会覆盖已有的 nohup.out，而是会在最后进行 append。</p><p>要记录屏幕输出或者改变 nohup 的记录文件也可以通过下列方法实现：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">nohup</span> xxx &gt; out.file 2&gt;&amp;1  <span class="comment"># 不加 nohup 也会将屏幕输出记录到 out.file 中</span></span></span><br></pre></td></tr></tbody></table></figure><h2 id="parallel-并行命令"><a href="#parallel-并行命令" class="headerlink" title="parallel 并行命令"></a>parallel 并行命令</h2><p>这个命令用到的场景比较少，但到了需要它的时候就会显得格外有用。</p><p>例如，要利用大量比对修建后的 fasta 文件通过 iqtree 建树，用 for 循环只能一个一个跑（这种情况下用 &amp; 是不明智的），那么可以这么做：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span> `<span class="built_in">ls</span> -r *.fasta`;</span></span><br><span class="line">do</span><br><span class="line">id=${i%%.fasta}</span><br><span class="line">echo "iqtree -s $i -pre $id -bb 1000 -nt 3" &gt;&gt; iqtree_command</span><br><span class="line">done</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> iqtree_command | parallel --no-notice -j 20</span></span><br></pre></td></tr></tbody></table></figure><p>在这种情况下，linux 就会同时运行 20 个命令并且每当一个命令结束时就直接换下一个命令，其中每个命令都使用 3 个线程执行。</p><p>也可以使用 <code>:::</code> 传入文件进行并行：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">parallel -j 20 <span class="string">'echo {}'</span> ::: *.txt</span></span><br></pre></td></tr></tbody></table></figure><p>上述命令在文件过多时可能会发生 <code>Argument list too long</code> 报错，此时也可以使用 <code>find</code> 传入：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">find ./ -name <span class="string">"*.txt"</span> -<span class="built_in">type</span> f | parallel -j 12 <span class="string">'echo {}'</span></span></span><br></pre></td></tr></tbody></table></figure><h2 id="小命令项"><a href="#小命令项" class="headerlink" title="小命令项"></a>小命令项</h2><h3 id="kill-杀死进程"><a href="#kill-杀死进程" class="headerlink" title="kill 杀死进程"></a>kill 杀死进程</h3><p>命令：<code>kill %n</code> <code>kill -9 PID</code></p><p>其中 <code>kill %n</code> 是终止某个正在运行或被置于后台的进程，这些进程能够通过 <code>job</code> 命令找到。</p><p>而 <code>kill -9 PID</code> 则针对那些无法被 <code>job</code> 查询到的进程（例如在命令后面添加了 <code>&amp;</code> 或者部分特殊的进程如 Java 等），相关进程的 PID 可以通过 <code>top</code> 或 <code>htop</code> 命令查询。</p><h3 id="mv-改名"><a href="#mv-改名" class="headerlink" title="mv 改名"></a>mv 改名</h3><p>命令：<code>mv 1.txt 2.txt</code></p><p>将 1.txt 重命名为 2.txt。</p><p>将某一目录下的文件名中某一字段替换为另一个字段：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> file <span class="keyword">in</span> $(<span class="built_in">ls</span> ./); <span class="keyword">do</span> <span class="comment"># 该示例中指定的为当前目录</span></span></span><br><span class="line">    newname=$(echo $file | sed 's/text1/text2/')</span><br><span class="line">    mv "$file" "$newname" # 若文件名不变则会返回信息</span><br><span class="line">done</span><br></pre></td></tr></tbody></table></figure><p>若要将子目录下的文件也进行该处理，则可以将 <code>ls ./</code> 改为 <code>find . -type f</code>。</p><h3 id="grep-查找文件内容"><a href="#grep-查找文件内容" class="headerlink" title="grep 查找文件内容"></a>grep 查找文件内容</h3><p>命令：<code>grep “123” n.txt</code> 或者 <code>cat n.txt | grep “123”</code></p><p>在 n.txt 中查找 123 的位置并输出所在行。</p><p>也可以在多个文件中进行查找，例如：<code>grep "123" *.txt</code></p><h3 id="less-浏览文件内容"><a href="#less-浏览文件内容" class="headerlink" title="less 浏览文件内容"></a>less 浏览文件内容</h3><p>命令：<code>less 1.txt</code></p><p>浏览 1.txt 的内容，按住空格可以快速向下翻页，按住 u 可以快速向上翻页。</p><p>回车或下方向键显示下一行、按 y 或上方向键显示上一行。</p><h3 id="sed-修改文件内容"><a href="#sed-修改文件内容" class="headerlink" title="sed 修改文件内容"></a>sed 修改文件内容</h3><p>命令：<code>sed -i 's/string1/string2/g' filename</code></p><p>具体使用例子：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -i <span class="string">'s/@/_/g'</span> filename</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 filename 中所有的 @ 替换成 _</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关于 sed 的替换删除等具体指令格式及其正则用法可以查阅教程。</span></span><br></pre></td></tr></tbody></table></figure><p>这个命令在大批量的文件内容处理替换方面有非常突出的效率。</p><p>比如：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -i <span class="string">'s/juse/Juse/g'</span> *</span></span><br></pre></td></tr></tbody></table></figure><p>可以将当前目录中所有文本类文件的 juse 替换成 Juse。同理可用于删除 Transdecoder 预测出的 pep 中的终止密码子 * （存在 * 时输入interproscan 会报错）。</p><h3 id="locate-寻找文件"><a href="#locate-寻找文件" class="headerlink" title="locate 寻找文件"></a>locate 寻找文件</h3><p>命令：<code>locate xxx</code></p><p>出于某些原因，可能是文件放的太过杂乱，亦或是忘了自己在哪跑的命令，使用 locate 就能找到被遗失在某个角落的文件。</p><h3 id="wget-下载-GEO-数据"><a href="#wget-下载-GEO-数据" class="headerlink" title="wget 下载 GEO 数据"></a>wget 下载 GEO 数据</h3><p>命令：<code>wget --content-disposition [link]</code></p><p>部分文件比如 GEO 上的数据等其直接提供的 http 链接是在重定向后才开始文件下载，如果直接使用 <code>wget</code> 只能下载到 <code>html</code> 文件。添加 <code>--content-disposition</code> 参数后可以解决这一问题。</p><h2 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h2><h3 id="去除当前目录下所有失效软链接"><a href="#去除当前目录下所有失效软链接" class="headerlink" title="去除当前目录下所有失效软链接"></a>去除当前目录下所有失效软链接</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ find . -<span class="built_in">type</span> l -xtype l -delete</span><br></pre></td></tr></tbody></table></figure><ul><li><code>-type l</code> 表示查找类型为软链接的文件。</li><li><code>-xtype l</code> 表示额外检查链接类型，只选中那些指向不存在的目标的链接。</li><li><code>-delete</code> 表示执行删除操作。</li></ul><h3 id="查看某个文件的行数"><a href="#查看某个文件的行数" class="headerlink" title="查看某个文件的行数"></a>查看某个文件的行数</h3><p>关键命令：<code>cat</code> <code>wc</code>   进阶应用（查看特定行）：<code>grep</code></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td></tr></tbody></table></figure><p>以上述文件为例，可运行以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> file.txt | <span class="built_in">wc</span> -l</span></span><br><span class="line">6</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意，这里会把空行给算进去，如果想不统计空行可用：</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> file.txt | grep -v <span class="string">"^$"</span> | <span class="built_in">wc</span> -l</span></span><br></pre></td></tr></tbody></table></figure><p>具体的应用场景：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> xxx.fasta | grep <span class="string">"&gt;"</span> | <span class="built_in">wc</span> -l  <span class="comment"># 统计组装的 contig 数量</span></span></span><br><span class="line">114514</span><br></pre></td></tr></tbody></table></figure><h3 id="去除文件中的重复行"><a href="#去除文件中的重复行" class="headerlink" title="去除文件中的重复行"></a>去除文件中的重复行</h3><p>关键命令：<code>cat</code> <code>sort</code> <code>uniq</code> </p><p>例子：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> xxx.txt | <span class="built_in">sort</span> | <span class="built_in">uniq</span> &gt; xxx.txt</span></span><br></pre></td></tr></tbody></table></figure><p>简单来说，就是把这个文件里的行给排列以后，再通过 uniq 去除重复行。</p><h3 id="取出-a-文件中-b-文件不存在的行"><a href="#取出-a-文件中-b-文件不存在的行" class="headerlink" title="取出 a 文件中 b 文件不存在的行"></a>取出 a 文件中 b 文件不存在的行</h3><p>关键命令：<code>grep</code></p><p>假设 b 文件中所有行都为 a 文件中已有行，想取出 a 文件中 b 文件不存在的行（类似于 <code>a-b</code>）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">grep -vFxf b a &gt; c</span></span><br></pre></td></tr></tbody></table></figure><p>其中：</p><ul><li><code>-v</code> 表示只显示不匹配的行。</li><li><code>-F</code> 将模式视为固定字符串。</li><li><code>-x</code> 表示完整匹配整行。</li><li><code>-f b</code> 表示从文件 b 中读取行。</li></ul><h3 id="将正在运行的命令放置在后台"><a href="#将正在运行的命令放置在后台" class="headerlink" title="将正在运行的命令放置在后台"></a>将正在运行的命令放置在后台</h3><p>关键命令：<code>bg</code></p><p>首先 <code>ctrl+z</code> 把命令放入后台，但此时命令会处于暂停状态。</p><p>此后输入 <code>bg</code> 可以使得它继续执行（如果要对特定命令可以先用 <code>job</code> 查看被中断的命令编号然后 <code>bg %编号</code>）。</p><p>此外，在命令的最后面加上 <code>&amp;</code> 也能起到同样的作用。</p><h3 id="中断命令"><a href="#中断命令" class="headerlink" title="中断命令"></a>中断命令</h3><p>关键命令：<code>kill</code></p><p>使用 <code>job </code> 可以看到不同工作的编号，然后把要 <code>cut</code> 的命令用 <code>kill %编号</code> 杀死。</p><p>但一般像这种会把已有的工作给断掉的命令都要<strong>谨慎使用</strong>。</p><h3 id="提高进程可以打开的最大文件数"><a href="#提高进程可以打开的最大文件数" class="headerlink" title="提高进程可以打开的最大文件数"></a>提高进程可以打开的最大文件数</h3><p>关键命令：<code>ulimit -S -s unlimited</code></p><p>在遇到因操作文件过多而引起的迭代错误等报错时，可以通过该命令解决。</p><h3 id="随机复制一定数量的文件"><a href="#随机复制一定数量的文件" class="headerlink" title="随机复制一定数量的文件"></a>随机复制一定数量的文件</h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">find dir1 -<span class="built_in">type</span> f -print0 | <span class="built_in">shuf</span> -n 50 -z | xargs -0 <span class="built_in">cp</span> -t dir2</span></span><br></pre></td></tr></tbody></table></figure><p>从 <code>dir1</code> 中随机挑选 <em><strong>50</strong></em> 个文件并复制到 <code>dir2</code> 中。</p><h2 id="终焉的禁忌之术-——-sudo-rm-rf"><a href="#终焉的禁忌之术-——-sudo-rm-rf" class="headerlink" title="终焉的禁忌之术 —— sudo rm -rf /"></a><del>终焉的禁忌之术 —— sudo rm -rf /</del></h2><p><del>业界俗称删库跑路。记住，在任何情况下都应当小心地使用 rm -rf ，linux 没有回收站，也没有备份。</del></p><p><del>所有的文件在删除前都需小心思考再思考！就算跑出来的文件是错的或者是未符合预期的，都应当好好地评判是否有很大的必要将其马上删除，在大多数时候，所剩的空间可能足够让你暂时保留这些文件并且思考这些文件是否可用。当你发现或许还用的上这个文件但它已经被删除时，所带来的麻烦将比输入 rm -rf 大得多。</del></p><h2 id="其他注意事项"><a href="#其他注意事项" class="headerlink" title="其他注意事项"></a>其他注意事项</h2><ul><li>如果某个环境是专门为某个软件的运行配置好的，那么在不需要运行该软件时尽量不要使用这个环境，如果使用的话就尽量不要进行任何会变动相关依赖项版本的行为，避免后续报错或程序版本控制不一致。</li><li>保持良好的编程习惯，划分好各个项目区域并且记录好所使用的关键命令。</li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>比较转录组分析（二）—— 原始数据的质控与转录组组装</title>
      <link href="/2022/11/06/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%20%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E8%B4%A8%E6%8E%A7%E4%B8%8E%E8%BD%AC%E5%BD%95%E7%BB%84%E7%BB%84%E8%A3%85/"/>
      <url>/2022/11/06/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%20%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E8%B4%A8%E6%8E%A7%E4%B8%8E%E8%BD%AC%E5%BD%95%E7%BB%84%E7%BB%84%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><blockquote><div id="portalContainer"></div><script src="/js/ctlink.js"></script><script> generatePortalLinks(2);</script></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这次文涉及到的主要是<strong>原始数据的质控与转录组组装，包括一些小知识例如如何判断数据受污染</strong>。</p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2022-11-18 补充了在 for loop 和 while loop 中使用 &amp; 的需警惕之处。</p><p>2022-11-21 补充修改了部分内容。</p><p>2022-12-05 更新了物种参考转录组的一些小知识。</p><p>2023-07-03 精简了内容。</p><h2 id="原始数据的质控"><a href="#原始数据的质控" class="headerlink" title="原始数据的质控"></a>原始数据的质控</h2><h3 id="提醒"><a href="#提醒" class="headerlink" title="提醒"></a>提醒</h3><p>后续所提及的测序数据皆为<strong>二代测序的双端数据</strong>。</p><p>二代测序的原理可以搜索 illumina 的下一代测序（NGS）原理介绍视频观看学习（illumina 的测序特点在于桥式扩增，其他测序公司可能略有不同但原理上是一致的，例如 BGI 的滚环扩增）。</p><p>所需要的软件有 <code>FastQC</code>、<code>MultiQC</code>、<code>Trimmomatic</code>、<code>Cutadapter</code>（可选）。</p><p>需要提前了解的：</p><ul><li>测序数据文件中每一行所代表的意思。</li></ul><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@V350095853L2C001R0010000000/1</span><br><span class="line">GCCCCAACGAAACATCTTACTTGATAAGAATAAAAAACCTTAAACTTTGCCTCCAACAAGAAAAATGTAAAGCTTTATAGGGTCTTATC</span><br><span class="line">GACCCACTACATAATTTAAGCCTTTTCACTTAAAAGTAAAATTCAAACTTTACAATTAAAA</span><br><span class="line">+</span><br><span class="line">FFEFFFFFEEFFFFFFFFGFFFFEFFFFFEFGFFFFFFFEFFFFEFEFFFFFFFEFFFFGEFFEFFFFFFFFFFFFFEFFFFEFFFFFE</span><br><span class="line">E@FGFFEFFFGFFFFEFFEEFEFFEEFGFFFDFFFFEFFFFFFAFEFFFFFFFDFEFFFFE</span><br></pre></td></tr></tbody></table></figure><p>以这一段数据为例，第一行 @ 后续的字段为序列名称，<strong>通常在双端数据的两个文件里一个以 /1 结尾，一个以 /2 结尾</strong>。其后的三行是<strong>碱基序列</strong>及其<strong>对应的碱基测序质量</strong>（有两种质量得分模式，大多数采用 <code>Phred-33</code>）。</p><h3 id="FastQC-amp-MultiQC"><a href="#FastQC-amp-MultiQC" class="headerlink" title="FastQC &amp; MultiQC"></a>FastQC &amp; MultiQC</h3><p>作为测序数据质量评估的老牌软件，fastqc 的网上教程已经非常丰富及完善，这里我着重提其中最需要注意的部分。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">fastqc -t 6 -o out_path sample1_1.fq sample1_2.fq</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">t代表线程数，具体该使用多少线程可以视自己的配置或服务器情况而定，可用 htop 命令查看内存和线程的占用情况</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">其他的参数没有什么特定需求采用默认参数即可</span></span><br></pre></td></tr></tbody></table></figure><p>在这里我给出一个并行命令以节省时间的技巧：</p><p>比如当所有双端数据文件都以 _1.fq 和 _2.fq 结尾时，假设我的目录下有（此处以压缩格式为例）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> ./</span></span><br><span class="line">A_1.fq.gzA_2.fq.gzB_1.fq.gzB_2.fq.gzC_1.fq.gzC_2.fq.gz</span><br></pre></td></tr></tbody></table></figure><p>那么我可以这么做以并行命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span> A B C;</span></span><br><span class="line">do</span><br><span class="line">fastqc -t 6 -o out_path "$i"_1.fq.gz "$i"_2.fq.gz &amp;</span><br><span class="line">done</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">双引号在某些情况下可以不加，但是加了一定不会有错</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">结尾的 &amp; 会在运行一个命令时直接将其放至后台，于是乎 <span class="keyword">if</span> 语句的下一个命令就直接开始，起到了同时运行的效果</span></span><br></pre></td></tr></tbody></table></figure><p><strong>注意！如果在 for loop 或 while loop 中所需要运行的命令量非常惊人时，不可使用 &amp;，否则可能造成服务器宕机。</strong></p><p>运行后，fastqc 会输出一份有关测序数据的质检报告（html 格式，每个测序文件一个），里面最需关注的可能先是<strong>序列的碱基质量</strong>，其次是其中是否含有接头序列，其他的报告应当分情况看。</p><p>例子（以上述知乎教程中为例）：</p><p><img src="https://pic2.zhimg.com/80/v2-a5cd2e23e66e6c1cf47bd00be3e92e39_720w.webp"></p><p>让我们来着重讲一下其他可能需要关注的地方。</p><h4 id="GC-含量"><a href="#GC-含量" class="headerlink" title="GC 含量"></a><strong>GC 含量</strong></h4><p>GC 含量能反应什么？事实上对于一种特定的物种而言，它的基因组整体的 GC 含量是相对稳定的，因此所有的序列其 GC 含量会呈现一个正态分布的峰状。因此当这个图存在异常时可能说明了这么几点。</p><p>例子（正常的峰）：</p><p><img src="https://pic2.zhimg.com/80/v2-e75215739f39d5ea389836de54a5c749_720w.webp"></p><h4 id="Contaminated-library（文库受污染）"><a href="#Contaminated-library（文库受污染）" class="headerlink" title="Contaminated library（文库受污染）"></a>Contaminated library（文库受污染）</h4><p>当除了一个很大的峰以外还存在尖峰，说明文库可能混进了接头二聚体（可能性不高）。</p><p>当出现一个宽峰，说明文库可能混进了其他物种的序列。</p><h4 id="Biased-subset（序列偏好）"><a href="#Biased-subset（序列偏好）" class="headerlink" title="Biased subset（序列偏好）"></a>Biased subset（序列偏好）</h4><p>当除了一个很大的峰以外还存在尖峰，可能代表了文库中某类序列较多，这<u>对于转录组来说是比较正常的</u>，因为有部分 mRNA 的表达量可能会非常高。</p><p>此外很多因素也会产生一定的偏差，例如测序时的偏好、PCR 的扩增偏好、在建库过程中利用 PolyA 富集真核生物 mRNA 时可能由于 RNA 的降解导致大部分得到的序列都靠近 3 ‘端等等，但这些应该都不会显著影响 GC 含量的整体正态分布。</p><h4 id="重点"><a href="#重点" class="headerlink" title="重点"></a>重点</h4><p>一般而言，转录组的数据在 fastqc 这里确定有没有污染是不够准确的，我们可以把它当作一个警示，但有些时候，正如上述所说，它出现的警告可能只是转录组会出现的正常现象之一。</p><h4 id="或许有用的小知识"><a href="#或许有用的小知识" class="headerlink" title="或许有用的小知识"></a>或许有用的小知识</h4><p>要确定有无其他物种污染，我们可以看后续使用 Trinity 组装出来的转录组有多大，如果过大的话则说明组装出了多个物种的 contig，要更加精确的判断可以通过 <code>diamond against nr database</code>，提取出 contig 的 taxonomy id 信息，如果大量存在另一类物种的 contig，可以在 NCBI 上下载该物种的基因组并使用 STAR 比对原始数据到基因组上确定 <code>Uniquely mapped reads</code> 和 <code>mismatch rate</code>。</p><h4 id="序列重复等级"><a href="#序列重复等级" class="headerlink" title="序列重复等级"></a>序列重复等级</h4><p>转录组测序的数据在此处基本都是会爆红的，所以不用太担心，毕竟某个高表达 mRNA 的序列会在这里重复上千甚至上万次。</p><p><img src="/pic/sequence_duplication.png"></p><h4 id="MultiQC-执行"><a href="#MultiQC-执行" class="headerlink" title="MultiQC 执行"></a>MultiQC 执行</h4><p>multiqc 用于整合所有质检报告，将所有 fastqc 跑出来的 html 放在一个文件夹后运行以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">multiqc .</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">multiqc . --ignore xxx <span class="comment"># 忽略掉某些文件</span></span></span><br></pre></td></tr></tbody></table></figure><p>此后，它会将所有的报告整理输出一份整合报告，但请注意，不同类型数据的质检报告它是没法整合在一起的（如 50bp 的数据和 150bp 的数据）。</p><p>此外，multiqc 除了整合 fastqc 的结果外还可以整合许多其他的输出结果，内容见下表。</p><p><img src="/pic/multiqc.png"></p><p>详细的教程见：<a href="https://www.jianshu.com/p/f83626fd1fa1">整合QC质控结果的利器 —— MultiQC from 简书</a>。</p><h4 id="可能你会感兴趣的事"><a href="#可能你会感兴趣的事" class="headerlink" title="可能你会感兴趣的事"></a>可能你会感兴趣的事</h4><p>事实上 fastqc 和 multiqc 作为质检工具，虽然它常被用到，但是它的结果很少被直接放在论文之中，很多文章可能会简单地提一句经过 fastqc 和 multiqc 质检数据一切 ok 之类的话，如果要把图放进论文的话可能会要分别标明 multiqc 结果中每个线属于哪个样本之类的（亦或是放进补充材料里）。</p><h3 id="Trimmomatic-amp-Cutadapter-——-质控工具"><a href="#Trimmomatic-amp-Cutadapter-——-质控工具" class="headerlink" title="Trimmomatic &amp; Cutadapter  ——  质控工具"></a>Trimmomatic &amp; Cutadapter  ——  质控工具</h3><p>多数测序数据从测序公司经手到客户手上时一般都被良好地处理过了。</p><p>例如华大它会使用自己开发的 <code>SOAPnuke</code> 对原始数据进行一次数据过滤。</p><p>所以我们对这些 clean data 可以选择：①、不做任何处理直接进行分析；②、再跑一次 Trimmomatic。</p><p>我的老板是这么说的：通常我会自己跑一次 trimmomatic，反正不用太多时间。</p><h4 id="Trimmomatic-执行"><a href="#Trimmomatic-执行" class="headerlink" title="Trimmomatic 执行"></a>Trimmomatic 执行</h4><p>简易版教程请见：<a href="https://zhuanlan.zhihu.com/p/91691632">生信软件 | Trimmomatic (测序数据质控) from 知乎</a></p><p>代码（此处使用了 Trinity 自带的 trimmomatic 默认参数，基于<a href="https://pubmed.ncbi.nlm.nih.gov/24567737/">关于高通量 mRNA 序列数据的最佳修剪</a>设置）：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">nohup</span> trimmomatic PE -phred33 input_forward.fq.gz input_reverse.fq.gz output_forward_paired.fq.gz output_forward_unpaired.fq.gz output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:5 TRAILING:5 SLIDINGWINDOW:4:5 MINLEN:25</span></span><br></pre></td></tr></tbody></table></figure><p>推荐加一个 nohup，这样 trimmomatic 的修剪日志会输出到 nohup.out 中，你可以在其中查看 reads 的修剪情况，而<strong>这个情况一般是可以在 paper 里提一嘴的</strong>。</p><p>例：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Input Reads: 9692546 Surviving: 9123724 (94.13%) Dropped: 568822 (5.87%)</span><br></pre></td></tr></tbody></table></figure><p>需要注意的是，<strong>Trimmomatic 只能识别和去除 Illumina 测序数据中的接头</strong>。</p><p>如果你的数据是在其他测序公司里测得的并且未经过处理，那么你或许需要使用其他的软件（例如 <code>TrimGalore</code> 或者 <code>Cutadapter</code>）。</p><h2 id="转录组的组装-——-Trinity"><a href="#转录组的组装-——-Trinity" class="headerlink" title="转录组的组装 —— Trinity"></a>转录组的组装 —— Trinity</h2><p>作为一个在不断更新老牌 de-novo assemble 软件，目前 Trinity 在无参转录组的组装方面已经有了相当强大的性能，其附带的完整预包装 pipeline 也使得仅使用这一个软件便可以完成绝大多数的无参转录组分析（仅需配置好其他所需软件即可）。</p><p>其他的软件如 <code>SPAdes</code>、<code>TransABySS</code>、<code>SOAPdenovoTrans</code> 大家有兴趣也可进行了解。</p><h3 id="Trinity-执行"><a href="#Trinity-执行" class="headerlink" title="Trinity 执行"></a>Trinity 执行</h3><p>基础教程在网上非常多，最详细的引路：<a href="https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-Trinity">Trinity Github wiki</a></p><p>组装原理简单来讲就是根据序列的 overlap 关系将其拼接成 contig。</p><p>命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">nohup</span> Trinity --seqType fq --SS_lib_type RF --max_memory 40G --trimmomatic \</span></span><br><span class="line"><span class="language-bash">--samples_file sample.txt \</span></span><br><span class="line"><span class="language-bash">--CPU 10</span></span><br></pre></td></tr></tbody></table></figure><p>tip：Trinity 能够使用参数 <code>--trimmomatic</code> 调用软件进行原始数据的过滤，但是建议自己跑 Trimmomatic 以后再写对应的 sample file，不要在此处调用。不过如果仅需组装转录组，那么可以忽视这一条建议。</p><h4 id="–SS-lib-type"><a href="#–SS-lib-type" class="headerlink" title="–SS_lib_type"></a>–SS_lib_type</h4><p>需要格外关注的是 <code>--SS_lib_type</code> 参数，当测序数据文库是通过链特异性建库得到的，那么这里就需要指明链特异性。</p><p>不知道测序数据是否为链特异性：<a href="https://github.com/trinityrnaseq/trinityrnaseq/wiki/Examine-Strand-Specificity">检查 reads 链特异性 from Trinity</a></p><p>了解链特异性建库：<a href="https://www.sohu.com/a/312085077_100126902">说一说转录组链特异性文库的那些事</a>。（定量更准确，可看下图）</p><p><img src="https://pic2.zhimg.com/80/v2-185258cdcb16f7e487d1e9473bd1b8fd_720w.webp"></p><p>链特异性文库如何构建：RNA 的第一条 cDNA 合成后，在第二条 cDNA 合成时用 dUTP 替换 dTTP，因此第二条链中的 T 都变成了 U，接上接头后，使用酶特异性降解带 U 的链，因此只保留了第一条链，并具有明确的方向。</p><p>大部分数据都是非链特异性的，但如果不知道具体情况最好进行检查。</p><h4 id="–samples-file"><a href="#–samples-file" class="headerlink" title="–samples_file"></a>–samples_file</h4><p>如果后续需要进行差异表达分析，那么一开始组装时便使用这个参数会大大节约功夫，因为它是后续分析中 Trinity 所要求的必需输入文件（此处为可选）。</p><p>文件内容示例：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cond_A    cond_A_rep1    A_rep1_left.fq    A_rep1_right.fq</span><br><span class="line">cond_A    cond_A_rep2    A_rep2_left.fq    A_rep2_right.fq</span><br><span class="line">cond_B    cond_B_rep1    B_rep1_left.fq    B_rep1_right.fq</span><br><span class="line">cond_B    cond_B_rep2    B_rep2_left.fq    B_rep2_right.fq</span><br></pre></td></tr></tbody></table></figure><p>其中第一列代表不同的处理，第二列代表处理的不同生物学重复，后两列为双端数据的位置（制表符分列）。</p><p>在使用该文件后，Trinity 会自动将所有双端数据合并进行转录组组装。</p><p>其他参数的介绍可以移步 github 官网或 <a href="https://www.jianshu.com/p/8518a23255f8">使用Trinity进行转录组组装 from 简书</a>。</p><h3 id="Trinity-的输出"><a href="#Trinity-的输出" class="headerlink" title="Trinity 的输出"></a>Trinity 的输出</h3><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;TRINITY_DN417671_c0_g1_i1 len=249 path=[0:0-248]</span><br><span class="line">CCGAACTCCACTTTCAACCCTCGGGGTTCGCTTGAACCTCGACCTTACCCCGGTCAGCGA</span><br><span class="line">GGTTCACTCGAACCTCCTGCTGAGTTGTGCCTCTCCTCTGCATCCCAGAGCTTTTACGAG</span><br><span class="line">GAGAACAATGGACAACCATTGAAGGACGACGACCTTCTATTTGCAGATGCTGAATGTAGA</span><br><span class="line">GTAAACTGGGAGAGAGTAAACAGGCTGAGTAAATTCATTAGTGGATGGCCTTGTCTCCAA</span><br><span class="line">ATTGGGATG</span><br><span class="line">&gt;TRINITY_DN417616_c0_g1_i1 len=423 path=[0:0-422]</span><br><span class="line">TGGGGAACATGTTGTAGATCTGTTCGACCTAGTCAAGAGACCTGAGGGGTAGCACCGTCA</span><br><span class="line">TCGATATGGTGGGCATGGTTCCCGTCGTACAGGGCTAGCCCAACTTCCACAAACCTGAAA</span><br><span class="line">CATTCCGCAAAATCGAATCAGCTGCCATTGAATTCTGCAAACAATAGCAATACTTGAATA</span><br><span class="line">GTTCCCATGTCCCCCTTGTAGCCCGCATCATTGCCTACCAACATGACAACATCTTCTCCG</span><br><span class="line">CCTACCGCAGGTTACCCTAGACTCAAAGGGAGAATTTCATGGATGAACTCTATGACCTCA</span><br><span class="line">ACATTGAGTTGATGGACTCACTCTACCACCAGTTAATAAAGCGTAGACAAGCAGGGGAAG</span><br><span class="line">CAGGCCGTTTGTCAGCCCCTACCTGTTTGGACATGTAGATGATGTTCCAGCAGGAACTGA</span><br><span class="line">CTG</span><br></pre></td></tr></tbody></table></figure><p>以 <code>&gt;</code> 开头的为 Trinity 组装出来的转录本，我们也可以称它为 contig。</p><p>以上述中的 <code>TRINITY_DN417671_c0_g1_i1</code> 为例。</p><p>里面的 <code>TRINITY_DN417671_c0_g1</code>为基因编号，而其后接着的 <code>_i1</code> 则是 isoform 的含义。</p><p>一个基因可以有不同的剪切方式，这种可变剪切会使得一个基因能产生多个转录产物，而 Trinity 则根据测序数据对基因的可变剪切进行了 “预测”。</p><p>这里的预测打双引号的原因在于 Trinity 的 isoform 并不完全精准，因为仅凭转录数据而脱离基因组的无参组装里，并不可能准确的判断出可变剪切情况，因此可变剪切分析一般都要求参考基因组。</p><h3 id="一些题外话"><a href="#一些题外话" class="headerlink" title="一些题外话"></a>一些题外话</h3><p>有些时候，用于差异表达分析的数据也可以用来组装转录组，有些时候则不行。</p><p>因为如果要得到一个物种的参考转录组，一般来说会从它身体的多个组织中进行 RNA 提取和等摩尔混合测序，并且使用更高的测序深度，原因如下：</p><p>①、不同组织的表达景观不同，有些 mRNA 在某些组织中可能含量非常少，而在另外一些组织中则含量很多。所以取多个组织提取 RNA 测序可以保证获得信息足够全面的转录组数据。</p><p>②、更精的测序深度有利于稀有 mRNA 的识别。</p><p>但是用来做差异表达分析的测序数据往往是从某个特定的组织中提取的。所以可以看到一些研究中，研究者们采取 <strong>参考转录组数据</strong> 和 <strong>差异表达分析数据</strong> 分开来的策略。例如，用来组装物种参考转录组的数据是双端 100bp 的，但用于差异表达分析的数据则是单端 50bp 的。</p><p>注意：<strong>参考转录组 ≠ 有参转录组</strong>。</p><p>参考转录组指可以<strong>代表一个物种整体转录 mRNA 情况</strong>的组装。</p><p>有参转录组指<strong>具有参考基因组</strong>的物种的转录组组装。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 转录组 </tag>
            
            <tag> 比较转录组学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>比较转录组分析（一）—— 前提及概要</title>
      <link href="/2022/11/01/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%20%E5%89%8D%E6%8F%90%E5%8F%8A%E6%A6%82%E8%A6%81/"/>
      <url>/2022/11/01/%E6%AF%94%E8%BE%83%E8%BD%AC%E5%BD%95%E7%BB%84%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%20%E5%89%8D%E6%8F%90%E5%8F%8A%E6%A6%82%E8%A6%81/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><hr><blockquote><div id="portalContainer"></div><script src="/js/ctlink.js"></script><script> generatePortalLinks(1);</script></blockquote><h2 id="关于生信分析"><a href="#关于生信分析" class="headerlink" title="关于生信分析"></a>关于生信分析</h2><p>生信分析中会用软件很重要，但我们也应当清楚每一步做了什么以及结果里包含了什么信息，我们能够从这些结果里获得哪些生物学意义，而不是糊里糊涂地跑了一套流程了事。</p><p>所以在很多方面我们还是应当具有基础的知识储备，在跑流程的过程里也<strong>应当清楚自己在做什么，为什么</strong>。</p><h3 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h3><p>2022-11-14 补充了分析的流程图</p><p>2022-11-21 补充修改了部分内容</p><p>2022-12-01 补充修改了部分内容</p><p>2023-07-03 精简了内容</p><p>2024-03-04 先前 RNA-seq Pipeline 文章的网站已经失效，因此进行了一定的补充修改</p><h3 id="所需理论知识"><a href="#所需理论知识" class="headerlink" title="所需理论知识"></a>所需理论知识</h3><ul><li>一些基本的生物学知识。</li><li>一些基本的统计学知识。</li><li>一些基本的编程知识。</li></ul><p>事实上并不是一定要知根知底才行，很多东西是可以边分析边学的，但是最基础的一些概念也要有，这里我推荐<a href="https://book.douban.com/subject/10602325/">艾伯特先生的细胞生物学精要</a>作为生物整体框架的理解，看完以后说不定能激发个人对生物的兴趣。而关于统计学方面的知识可能就看个人需求了，但是应该至少清楚自己在分析中所使用的统计学方法的具体原理和假设，以确定自己的分析应用在了正确的场景中。</p><p>至于编程方面，主要就是 <code>Python</code> 和 <code>R</code>，前者在数据挖掘和数据处理方面异常优秀，而后者则能帮助进行多样的统计及绘图（当然 <code>Python</code> 也可以，不过实现起来可能没有 <code>R</code> 那么方便），因此学会这俩的加分是非常多的。</p><p>补充：对于 <code>Python</code> 的基础入门，我推荐 <a href="https://book.douban.com/subject/35196328/">Python编程：从入门到实践（第2版）</a>。</p><p>补充：对于 <code>R</code> 的基础入门，我推荐 <a href="https://book.douban.com/subject/26785199/">R语言实战 第二版</a>（这里还涉及到了非常多的统计学知识，因此强烈推荐）。</p><h2 id="比较转录组概论"><a href="#比较转录组概论" class="headerlink" title="比较转录组概论"></a>比较转录组概论</h2><h3 id="什么是转录组"><a href="#什么是转录组" class="headerlink" title="什么是转录组"></a>什么是转录组</h3><p>狭义上来说指的是生物的 mRNA 集合，这是一般我们做真核生物转录组分析时涉及到的概念。</p><p>广义上来说指的是生物所有转录产物的集合，包括但不限于 <code>mRNA</code> <code>tRNA</code> <code>lncRNA</code> <code>rRNA</code> <code>miRNA</code> <code>snRNA</code> 等等。</p><p>而如果从广义上出发，就会出现非常多样的转录组分析，感兴趣可以移步 <a href="http://www.bgitechsolutions.com/sequencing?class_id=3">BGI 的研究内容介绍</a>。</p><h3 id="什么是比较"><a href="#什么是比较" class="headerlink" title="什么是比较"></a>什么是比较</h3><p>网上对于 “比较转录组” 的定义多倾向于分析不同物种或亚种间 mRNA 序列差异进而探索近源物种间的亲缘关系，而无参转录组上的差异表达分析则被称作 “转录组的比较” 。但其实许多涉及到基因表达分析的 paper 所指向的主题都是 Comparative transcriptome，随便举几个在 ScienceDirect 上搜的例子：</p><blockquote><p>Comparative transcriptome analysis of sensory genes from the antenna and abdomen of Quadrastichus mendeli Kim</p><p>Co-expression networks regulating cotton fiber initiation generated by comparative transcriptome analysis between fiberless XZ142FLM and GhVIN1i</p><p>Comparative transcriptome analysis of differentially expressed genes in Bradysia odoriphaga Yang et Zhang (Diptera: Sciaridae) at different acute stress temperatures</p></blockquote><p>而对于探索亲缘关系的转录组研究近些年也有个词在兴起，叫做系统发育转录组学（Phylotranscriptomics），不过大部分使用转录组进行系统发育分析的文章挂的关键词依然是 Phylogenomics 所以建议不要仅用前者作为关键词检索文献。</p><p>但说到底每个名词的定义终究是带有主观成分的，所以也不必掐的那么死板，重要的是心里要有个大致的概念和理解。对我来说这两种分析是可以一起做的，因此在这里我就放在一起讨论。</p><h3 id="比较转录组的经典分析流程"><a href="#比较转录组的经典分析流程" class="headerlink" title="比较转录组的经典分析流程"></a>比较转录组的经典分析流程</h3><p>一般的实验及分析流程：</p><ul><li><p>湿实验</p></li><li><p>送测</p></li><li><p>干实验</p><ul><li>数据质控</li><li>转录组组装</li><li>质量检测</li><li>注释</li><li>差异表达分析</li><li>富集分析</li><li>更多拓展（基因家族、进化等相关问题）</li></ul></li></ul><h3 id="比较转录组分析能够做什么"><a href="#比较转录组分析能够做什么" class="headerlink" title="比较转录组分析能够做什么"></a>比较转录组分析能够做什么</h3><p>揭示抗胁迫机制、揭示系统发育关系、揭示受选择基因…</p><p>这个只能说<strong>主要得看为了什么而做这些分析</strong>，而不是看分析后能做什么。</p><p>同时，虽然分析具有指向性，但是分析<strong>不是为了得到想要的结果</strong>，出现很多意料之外的情况也是很正常的事。</p><p>此外也不能说分析的结果如此，真相就是如此，分析的结果只能提供一个见解，而不能得到一个定论。</p><blockquote><p>“Thus evolutionary achievements can be used as hints to suggest possible lines of research, but it is highly dangerous to trust them too much. It is all too easy to make mistaken inferences unless the process involved is already very well understood.“</p><p>—— Francis Crick, <em>What Mad Pursuit: A Personal View of Scientific Discovery</em> (1988)</p></blockquote><h3 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h3><p>有个知乎老哥讲的<a href="https://zhuanlan.zhihu.com/p/222345339">比较转录组</a>介绍写的很好，里面提到的很多事情值得记一记，包括为何选择转录组而不选择基因组等等问题都有介绍，大家感兴趣也可以去看一看。</p><h2 id="如果你觉得转录组分析真的好麻烦"><a href="#如果你觉得转录组分析真的好麻烦" class="headerlink" title="如果你觉得转录组分析真的好麻烦"></a>如果你觉得转录组分析真的好麻烦</h2><blockquote><p>恰好这一段时间看到了一篇论文，讲的是他们那个团队研发了个转录组分析的平台，把一些常见的分析流程给 pipeline 化了（主要是利用了现在 <code>Trinity</code> 完善的 pipeline 包装）。</p><p>我看了下流程还是非常正的，主要的无参转录组分析都有，一些关键参数也可根据实际需求进行相应调整，或许对于一些不是很想花费精力在软件学习上以及对计算机语言真的无感的人会很有帮助，如果感兴趣的话论文传送门在<a href="https://www.sciencedirect.com/science/article/pii/S2405844022015432">这里</a>，网站传送门在<a href="https://atap.psu.ac.th/index.php">这里</a>。</p><p>来自 <code>2024-03-04</code> 补充：</p><p>以上网站已失效，或许是因为作者预想中的高引用并没有出现。</p><p>本想着更新一些新的可用的 Pipeline 放上来，但是经过一番搜查找到的 Pipeline 大多都是针对有参转录组的，考虑到该文章系列的后续内容都是围绕无参转录组展开，因此这里就不再更新，建议想要寻找 Pipeline 的朋友<strong>直接从文章入手</strong>去扒代码。</p><p>当然你也可以尝试使用 <code>snakemake</code> 自己搭建一个 RNA-seq 数据分析的 Pipeline。不过如果 RNA-seq analysis 对你来说并不需要重复很多次，那么也不需要在这上面浪费过多的精力，只需做好代码记录和版本控制即可。</p><p>来自 <code>2024-07-06</code> 补充：</p><p>站内 Snakemake 教程请参阅文章开头传送门。</p></blockquote><p>虽然这个网站上没有涉及到的功能依然有很多，但随着生信领域的迅速发展，越来越多被打包好的 Pipeline 也在不断出现，这些 Pipeline 极大程度地降低了生信分析的难度，即便是一个刚入门的人只需要稍微了解就可以跑一套完整的流程，甚至乎许多顶刊在进行分析的时候也是用的其他研究者开发好的各种参数都进行了精挑细选的 Pipeline。就拿系统发育分析来说，Phylosuite 就是一个很好的例子。</p><p>综上，如果想要在短时间内取得不错的成果（以结果为导向）的话，也可以多看几篇文章，或许就能找到一个不错的 Pipeline（也有可能研究者会把 ta 的代码开源到 github 上，这种情况可以把代码扒过来换成自己的数据运行即可），找不到也并没有什么关系，至少也能学习到相关的方法和分析思路。</p><p>当然如开篇所说，跑流程的过程里也<strong>应当清楚自己在做什么，为什么</strong>。所以即便不想花时间学习各种跑命令和数据处理的方法，也还是需要了解跑的命令中每个参数是什么意思，有什么作用。针对自己的数据设计一个合理的参数，最后得到的结果才会更加清晰准确。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
            <tag> 转录组 </tag>
            
            <tag> 比较转录组学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生信导论</title>
      <link href="/2022/10/29/%E7%94%9F%E4%BF%A1%E5%AF%BC%E8%AE%BA/"/>
      <url>/2022/10/29/%E7%94%9F%E4%BF%A1%E5%AF%BC%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>该前言部分已于 2024 年 6 月更新：</p><p>点看这篇文章看的第一感觉是羞耻，第二感觉是感慨。</p><p>时间过得真的是很快的，写这篇文章的时候我还什么都没有做到。现在也算是累积了一些小成果了，一方面是博客上日均访问人数和访问次数都有了极大提升，另一方面是学术上已经在顶刊（IF=17.3）中参与了审稿返修中算是比较重要的工作。很多技能的熟练度也非两年前可比，甚至感觉一开始写这篇文章时候的自己有些傲慢。</p><p>学术路上，见的越多感觉自己不知道的也越多。只能说无止境的学习是在科研路上走下去的基础之基础，但想了想干什么事不是这样呢，所以以后也需戒骄戒躁，望诸君共勉。希望两年后再看这篇文章，我同样能感受到自己的进步。</p><p>注：以下内容整体结构未变，但根据我<strong>目前的认识</strong>进行了一些修改。</p><h3 id="什么是生信？"><a href="#什么是生信？" class="headerlink" title="什么是生信？"></a>什么是生信？</h3><p>这个问题的答案事实上也很清楚，生物信息学事实上就是一门通过分析生物信息来探索生物的学科，属于生命科学与计算机科学的交叉学科，目前来看，这门学科已经有了相当庞大的规模，事实上随便翻一篇跟生物有关的论文，里面都或多或少夹杂着生信的学问。</p><p>目前国内生信方向的课题组一般来说可以分为两个侧重点：</p><p>①、注重上游方法开发。这些课题组一般来说对于计算机技能及数理知识水平的要求比较高，其侧重于开发上游分析的方法并运用在相关的下游分析中。现在很主流的几个大方向主要是<strong>深度学习技术开发</strong>及<strong>组学数据分析工具开发</strong>。</p><p>②、注重下游结果分析。这些课题组一般来说对于生物学知识水平的要求比较高，并且需要一定的编程和绘图技能以在下游结果分析和可视化中进行灵活的调整（因为很多地方可能没有现成的工具，只能自己通过 coding 编写一套）。</p><h3 id="如何入坑生信？"><a href="#如何入坑生信？" class="headerlink" title="如何入坑生信？"></a>如何入坑生信？</h3><h4 id="入坑生信三大技能"><a href="#入坑生信三大技能" class="headerlink" title="入坑生信三大技能"></a>入坑生信三大技能</h4><ul><li> linux（我个人用的是 Vscode + Xftp）</li><li> R （<a href="https://book.douban.com/subject/26785199/">R 语言实战第二版</a>，该书中还涉及到很多统计学知识，强烈推荐）</li><li> Python（<a href="https://book.douban.com/subject/35196328/">Python编程：从入门到实践（第2版）</a>）</li></ul><p>这三者的教程网上已经非常全面，也可以佐以一些书籍去进行学习，效率会快很多。个人认为 linux 和 python 的掌握是最重要的，并且这两者在考研或保研时复试竞争中具有极大的加分项。</p><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>之前我有写到要明确研究方向和多读英文文献两点，现在我需要对此进行指正。</p><p>对于前者，很多时候写文章需要的不是按部就班，而是整些花活。同一套数据，有些人只能死板跑流程，有些人却可以玩出花来，所以他们能发的期刊等级也不一样。因此，多阅读其他类似领域的文章有助于拓宽分析思路，从而收获意想不到的结果。这也是现在交叉学科很受欢迎的原因。</p><p>对于后者，与其说多读英文文献，不如说多读一些前沿顶刊文献。前沿指的是尽量看最近一两年内发的文章，时间离现在越近越好。顶刊指的是尽量看领域内的 top 期刊，不要把太多精力花在一些 Q2 或以下的期刊文章上。这样非常有利于快速了解领域的前沿研究方法和相关结果。</p><p>除此之外，其他的东西倒也显得没那么多必要去提及了，无非就是要多一些耐心，多一些毅力，这些也是学好所有其他东西的根本前提。</p><p>可能最重要的是，你要相信没有攻克不了的难题，<strong>它们总是能解决的</strong>。</p><blockquote><p>杀不死我的，终会让我变得更为强大。        ——尼采</p></blockquote><h3 id="入坑到现在的感想。"><a href="#入坑到现在的感想。" class="headerlink" title="入坑到现在的感想。"></a>入坑到现在的感想。</h3><p>一开始我决定在生物这条路上继续走下去很大程度上是因为觉得这条路能搞的东西很多不愁没事做，到后来在不断的学习里发现生物确实是有它独特的魅力所在的。</p><p>试想，一个细胞何其之小，里面包含的东西却左右了生物体的形态和行为；一套相同的序列，却能形成各式各样的组织器官，并组成一个功能复杂的生命体。这里面很多问题都是尚待解决的。</p><p>很多人会嘲笑式地反讽二十一世纪是生物的世纪这句话，以前我也是对之嗤之以鼻的，现在我的想法是，<strong>生物这门学科可能不会有那么重的分量，但它确确实实值得这样的评价</strong>。</p><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>写这篇博的过程里我是感觉比较羞愧的，因为一个并没有什么建树的人对一门学科大谈特谈在某种程度上只是彰显了这个人的无知和自满，但是换个角度来讲我也是比较满意的，因为我觉得我把所有对我而言感触较深的地方都比较清晰地表达了出来。</p><p>2023.07.03 更新注：越学越感觉自己菜啊，还得多练啊多练。</p><p>2023.10.09 更新注：上面说得对。</p><p>2024.06.30 更新注：上面说得对。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
          <category> 生信 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
            <tag> 生信 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
