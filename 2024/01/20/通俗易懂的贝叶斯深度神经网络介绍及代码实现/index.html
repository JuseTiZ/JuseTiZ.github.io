<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>通俗易懂的贝叶斯深度神经网络介绍及代码实现 | Juse's Blog</title><meta name="author" content="Juse"><meta name="copyright" content="Juse"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本文将介绍贝叶斯神经网络相较于传统神经网络有什么优势以及如何通过 Python 实现，还有一些使用时的注意事项。">
<meta property="og:type" content="article">
<meta property="og:title" content="通俗易懂的贝叶斯深度神经网络介绍及代码实现">
<meta property="og:url" content="https://biojuse.com/2024/01/20/%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/index.html">
<meta property="og:site_name" content="Juse's Blog">
<meta property="og:description" content="本文将介绍贝叶斯神经网络相较于传统神经网络有什么优势以及如何通过 Python 实现，还有一些使用时的注意事项。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://biojuse.com/pic2/bayesiannncover.png">
<meta property="article:published_time" content="2024-01-20T13:40:00.000Z">
<meta property="article:modified_time" content="2024-06-12T08:54:19.365Z">
<meta property="article:author" content="Juse">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://biojuse.com/pic2/bayesiannncover.png"><link rel="shortcut icon" href="/pic/webiron.png"><link rel="canonical" href="https://biojuse.com/2024/01/20/%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '通俗易懂的贝叶斯深度神经网络介绍及代码实现',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-12 16:54:19'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/mycss.css"><link rel="stylesheet" href="/css/bg.css"><link rel="stylesheet" href="/css/hp.css"><script src="https://cdn1.tianli0.top/npm/vue@2.6.14/dist/vue.min.js"></script><script src="https://cdn1.tianli0.top/npm/element-ui@2.15.6/lib/index.js"></script><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/element-ui@2.15.6/packages/theme-chalk/lib/index.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css">
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Juse's Blog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/pic/cover.gif" data-original="/pic/gitav.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">59</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/myself/"><i class="fa-fw fa fa-id-card"></i><span> 我自己</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-sitemap"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-shoe-prints"></i><span> 杂项</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/talk/"><i class="fa-fw fa fa-book"></i><span> 琐碎的日常</span></a></li><li><a class="site-page child" href="/new/"><i class="fa-fw fa fa-bell"></i><span> 更新日志</span></a></li><li><a class="site-page child" href="/paper/"><i class="fa-fw fa fa-sticky-note"></i><span> 文献笔记阁</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/pic2/bayesiannncover.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Juse's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/myself/"><i class="fa-fw fa fa-id-card"></i><span> 我自己</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-sitemap"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-shoe-prints"></i><span> 杂项</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/talk/"><i class="fa-fw fa fa-book"></i><span> 琐碎的日常</span></a></li><li><a class="site-page child" href="/new/"><i class="fa-fw fa fa-bell"></i><span> 更新日志</span></a></li><li><a class="site-page child" href="/paper/"><i class="fa-fw fa fa-sticky-note"></i><span> 文献笔记阁</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">通俗易懂的贝叶斯深度神经网络介绍及代码实现</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-20T13:40:00.000Z" title="发表于 2024-01-20 21:40:00">2024-01-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-06-12T08:54:19.365Z" title="更新于 2024-06-12 16:54:19">2024-06-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>20分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="通俗易懂的贝叶斯深度神经网络介绍及代码实现"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>最近在课题组里的一些任务涉及到了把模型的架构改成贝叶斯层，让模型输出的结果能够体现不确定性。恶补相关知识的同时正好也能记录下笔记发博客，一举两得。</p>
<p>这篇文章只做概念介绍，不做深入剖析，追求原理的话敬请走下文中相关链接前往原论文。</p>
<h2 id="贝叶斯神经网络是什么"><a href="#贝叶斯神经网络是什么" class="headerlink" title="贝叶斯神经网络是什么"></a>贝叶斯神经网络是什么</h2><p>或许你在很多其他的地方听过<strong>贝叶斯</strong>这个词汇。以下是一些生物学中的例子：</p>
<ul>
<li>系统发育学中的贝叶斯建树（Mrbayes、Phylobayes）。</li>
<li>群体遗传学（种群遗传学）中分析种群结构、估计种群历史等（Structure、ABC）。</li>
<li>在某些基因组比对的工具里也有用到贝叶斯方法（bwa）。</li>
</ul>
<p>贝叶斯方法的大致原理是结合先验知识和实验数据来估计参数或测试假设，这个过程涉及到随机采样，因此其他方法不同，应用贝叶斯法得到的结果往往不会是完全一致的，也就是说，可能每次跑出来的结果之间会相似，但不会完全相同。</p>
<p>这里就提及到了贝叶斯方法的一个宝贵性质 —— <strong>不确定性</strong>。</p>
<p>如果有模型搭建经验的话，你应该知道，对于传统的神经网络架构而言，在你训练好模型后，如果给它相同的输入，那么一般而言它都会产生一致的输出（因为模型内部的<strong>权重是确定的</strong>）。但是有些时候，我们可能想知道：</p>
<ul>
<li>我们模型输出的结果到底多可靠？它的不确定性有多大？波动范围大概是多少？</li>
</ul>
<p>这时候，贝叶斯神经网络就发挥了其优势。</p>
<h3 id="贝叶斯神经网络如何引入不确定性"><a href="#贝叶斯神经网络如何引入不确定性" class="headerlink" title="贝叶斯神经网络如何引入不确定性"></a>贝叶斯神经网络如何引入不确定性</h3><p>我深知过于详尽的数学公式和逻辑论证会让人头昏眼花（数学佬除外），所以我并不打算以过于专业的角度进行解释。如果你对本文涉及到的贝叶斯神经网络个中原理感兴趣，可以去观摩相关的文章：</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1505.05424">Weight Uncertainty in Neural Networks</a></p>
<p>简单来说，贝叶斯神经网络中，每个神经元（或者说节点）之间连接的<strong>权重</strong>并<strong>不是一个固定的值</strong>，而是一个<strong>分布</strong>。假设在一个传统的神经网络架构中，一个权重的值为 0.2，那么这个权重在贝叶斯神经网络中的对应值可能就变为了 0.1-0.3。</p>
<p>只要能够理解上述这点，那么其输出为什么具有不确定性也就不难理解了。在贝叶斯神经网络的前向传播中，权重将会从一个分布中进行采样，因此不同的运行里我们得到的结果会不同，以上面的权重为例，或许这一次模型采样的权重为 0.15，而下一次就变成了 0.25。</p>
<p>这里同样引申出另一个重要的点：贝叶斯神经网络如何得到<strong>结果的不确定性</strong>？不难看出，它引入不确定性是通过权重的随机采样实现的，但是它每次运行输出的结果依然是个确定的值而不是一个分布（因为权重在采样后都是确定的某个值）。不过正如上面所说，因为每次运行得到的结果都会不同，因此我们可以通过<strong>多次预测</strong>得到一组预测结果，<strong>这组预测结果</strong>的平均值和标准差等信息即我们所需要的。</p>
<h3 id="贝叶斯神经网络的优势和不足"><a href="#贝叶斯神经网络的优势和不足" class="headerlink" title="贝叶斯神经网络的优势和不足"></a>贝叶斯神经网络的优势和不足</h3><p>贝叶斯神经网络（BNNs）与传统神经网络相比，优势如下：</p>
<p><strong>不确定性估计</strong>：贝叶斯神经网络能够提供预测的不确定性估计。这是因为 BNNs 使用概率分布而非单一值来表示权重，从而能够在给出预测时同时给出关于这些预测的不确定性信息。</p>
<p>这一优势同时导致了其他方面的优势：</p>
<ul>
<li><strong>减少过拟合</strong>。这其实不难理解，正如被广泛使用的 dropout 一样，两者有一个共通之处 —— 随机性，dropout 体现在丢弃神经元的随机性上，而贝叶斯神经网络体现在权重取值的随机性上。</li>
<li><strong>自适应（鲁棒）性</strong>。通过对权重的不确定性进行建模，可以更好地适应数据分布的变化，从而在面对数据或环境变化时更加 robust。</li>
</ul>
<p>举一些实际例子：</p>
<ul>
<li><p>与传统神经网络相比，贝叶斯神经网络在处理对抗性攻击时表现出更高的鲁棒性 (Uchendu, Campoy, Menart &amp; Hildenbrandt, 2021)。</p>
</li>
<li><p>在经济领域，贝叶斯神经网络在预测任务中的表现优于传统神经网络。这在预测乳金融市场动态等方面得到了应用和验证 (Magris, Shabani &amp; Iosifidis, 2022)。</p>
</li>
</ul>
<p>当然，不确定性是一把双刃剑，并且它不一定会让模型表现得更加出色（免费午餐警告⚠），一些明显的缺点如下：</p>
<ul>
<li><strong>更高的计算成本和更长的训练时间</strong>。这一点在后文的代码实现中能够得到更清晰的解释。</li>
<li><strong>内存需求</strong>。需要存储权重的分布而不是单个权重值。</li>
<li><strong>可解释性问题</strong>。尽管贝叶斯神经网络提供预测的不确定性估计，但它们<strong>本身的结构和决策过程仍然是黑盒</strong>的。</li>
</ul>
<p>关于贝叶斯神经网络的介绍，我强烈推荐以下博客文章：</p>
<p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-gentle-introduction-to-bayesian-deep-learning-d298c7243fd6">A Gentle Introduction to Bayesian Deep Learning</a></p>
<p>这里面稍微涉及到了一些基础的数学知识，理解上并不困难，也是从更易于理解的角度出发进行介绍。</p>
<h2 id="贝叶斯神经网络的代码实现"><a href="#贝叶斯神经网络的代码实现" class="headerlink" title="贝叶斯神经网络的代码实现"></a>贝叶斯神经网络的代码实现</h2><p>在很久之前贝叶斯神经网络需要自己通过 coding 实现，但现在已经有造好的轮子，所以我们只需要搬过来用即可。</p>
<blockquote>
<p>2024/05/20</p>
<p>经与博后师兄讨论，确定了一个更好用的 module：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/IntelLabs/bayesian-torch">https://github.com/IntelLabs/bayesian-torch</a></p>
<p>该 module 中关于 KL divergence 的 loss 参数设定不需要自行调整，且支持直接将传统架构转为贝叶斯架构，并提供了不确定性量化的方法。</p>
<p>安装方法（使用 pip）：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install bayesian-torch</span><br></pre></td></tr></tbody></table></figure>

<p>使用方法：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> bayesian_torch.models.dnn_to_bnn <span class="keyword">import</span> dnn_to_bnn, get_kl_loss</span><br><span class="line"></span><br><span class="line">const_bnn_prior_parameters = {</span><br><span class="line">        <span class="string">"prior_mu"</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">"prior_sigma"</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">"posterior_mu_init"</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">"posterior_rho_init"</span>: -<span class="number">3.0</span>,</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"Reparameterization"</span>,  <span class="comment"># Flipout or Reparameterization</span></span><br><span class="line">        <span class="string">"moped_enable"</span>: <span class="literal">False</span>,  <span class="comment"># True to initialize mu/sigma from the pretrained dnn weights</span></span><br><span class="line">        <span class="string">"moped_delta"</span>: <span class="number">0.5</span>,</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">model = torchvision.models.resnet18()</span><br><span class="line">dnn_to_bnn(model, const_bnn_prior_parameters)</span><br></pre></td></tr></tbody></table></figure>

<p>以上方法将创造一个全新的贝叶斯神经网络模型。此外，如果你已经拥有了一个预训练好的模型，则可以通过将 <code>moped_enable</code> 改为 <code>True</code> 从而使贝叶斯神经网络基于该模型已有权重设置先验和初始化变分参数（该操作有利于大模型的收敛）：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">const_bnn_prior_parameters = {</span><br><span class="line">        <span class="string">"prior_mu"</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">"prior_sigma"</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">"posterior_mu_init"</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">"posterior_rho_init"</span>: -<span class="number">3.0</span>,</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"Reparameterization"</span>,  <span class="comment"># Flipout or Reparameterization</span></span><br><span class="line">        <span class="string">"moped_enable"</span>: <span class="literal">True</span>,  <span class="comment"># True to initialize mu/sigma from the pretrained dnn weights</span></span><br><span class="line">        <span class="string">"moped_delta"</span>: <span class="number">0.5</span>,</span><br><span class="line">}</span><br><span class="line">    </span><br><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">dnn_to_bnn(model, const_bnn_prior_parameters)</span><br></pre></td></tr></tbody></table></figure>

<p>训练、预测和不确定性量化的相关代码详情请见该 module 的 <a target="_blank" rel="noopener" href="https://github.com/IntelLabs/bayesian-torch">github 页面</a>。与下文介绍的 blitz 相比，这里的 bayesian-torch 只需要更简单的命令就可以实现传统神经网络到贝叶斯神经网络的迁移，并且具有更全面的功能和参数设定。</p>
</blockquote>
<h3 id="blitz-安装"><a href="#blitz-安装" class="headerlink" title="blitz 安装"></a>blitz 安装</h3><p>这里会用到 Python 的 <code>blitz</code> module，其具体源码和 document 可见：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/piEsposito/blitz-bayesian-deep-learning">https://github.com/piEsposito/blitz-bayesian-deep-learning</a></p>
<p>pip 安装命令：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install blitz-bayesian-pytorch</span><br></pre></td></tr></tbody></table></figure>

<p>或者你可以使用 conda 完成:</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge blitz-bayesian-pytorch</span><br></pre></td></tr></tbody></table></figure>

<p>亦或者你可以通过 clone 其 GitHub 仓库完成：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda create -n blitz python=3.9</span><br><span class="line">conda activate blitz</span><br><span class="line">git clone https://github.com/piEsposito/blitz-bayesian-deep-learning.git</span><br><span class="line">cd blitz-bayesian-deep-learning</span><br><span class="line">pip install .</span><br></pre></td></tr></tbody></table></figure>

<h3 id="运行范例"><a href="#运行范例" class="headerlink" title="运行范例"></a>运行范例</h3><p>这里使用经典的 LeNet 和 MNIST 数据集进行贝叶斯神经网络和传统神经网络的比较，以下代码将根据 blitz github repository 中的示例代码进行补充和修改，原代码可见：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/piEsposito/blitz-bayesian-deep-learning/blob/master/blitz/examples/bayesian_LeNet_mnist.py">https://github.com/piEsposito/blitz-bayesian-deep-learning/blob/master/blitz/examples/bayesian_LeNet_mnist.py</a></p>
<p>首先 import 需要的库：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> dsets</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> blitz.modules <span class="keyword">import</span> BayesianLinear, BayesianConv2d</span><br><span class="line"><span class="keyword">from</span> blitz.losses <span class="keyword">import</span> kl_divergence_from_nn</span><br><span class="line"><span class="keyword">from</span> blitz.utils <span class="keyword">import</span> variational_estimator</span><br></pre></td></tr></tbody></table></figure>

<p>下载并加载数据：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = dsets.MNIST(root=<span class="string">"./data"</span>,</span><br><span class="line">                             train=<span class="literal">True</span>,</span><br><span class="line">                             transform=transforms.ToTensor(),</span><br><span class="line">                             download=<span class="literal">True</span></span><br><span class="line">                            )</span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset,</span><br><span class="line">                                           batch_size=<span class="number">64</span>,</span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_dataset = dsets.MNIST(root=<span class="string">"./data"</span>,</span><br><span class="line">                             train=<span class="literal">False</span>,</span><br><span class="line">                             transform=transforms.ToTensor(),</span><br><span class="line">                             download=<span class="literal">True</span></span><br><span class="line">                            )</span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset,</span><br><span class="line">                                           batch_size=<span class="number">64</span>,</span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>构建贝叶斯神经网络和传统神经网络：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@variational_estimator</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BayesianCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = BayesianConv2d(<span class="number">1</span>, <span class="number">6</span>, (<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.conv2 = BayesianConv2d(<span class="number">6</span>, <span class="number">16</span>, (<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.fc1   = BayesianLinear(<span class="number">256</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2   = BayesianLinear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3   = BayesianLinear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.relu(self.conv1(x))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = F.relu(self.conv2(out))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = F.relu(self.fc1(out))</span><br><span class="line">        out = F.relu(self.fc2(out))</span><br><span class="line">        out = self.fc3(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">lenet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, (<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, (<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.fc1   = nn.Linear(<span class="number">256</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2   = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3   = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.relu(self.conv1(x))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = F.relu(self.conv2(out))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = F.relu(self.fc1(out))</span><br><span class="line">        out = F.relu(self.fc2(out))</span><br><span class="line">        out = self.fc3(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><code>BayesianCNN</code> 类前的 <code>@variational_estimator</code> 是一种装饰器，它用于拓展包含贝叶斯神经网络的类的功能（例如后面会提到的 <code>.sample_elbo</code>），同时与原先的 <code>nn.Module</code> 适配。</li>
<li><code>nn.Conv2d</code> 层对应 <code>BayesianConv2d</code>，<code>nn.Linear</code> 对应 <code>BayesianLinear</code>。</li>
</ul>
<p>贝叶斯神经网络训练及评估：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Bayesian train &amp; test</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">classifier = BayesianCNN().to(device)</span><br><span class="line">optimizer = optim.Adam(classifier.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">best_accuracy = <span class="number">0</span></span><br><span class="line">waiting = <span class="number">0</span></span><br><span class="line">iteration = <span class="number">0</span></span><br><span class="line">stop = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> stop:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i, (datapoints, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss = classifier.sample_elbo(</span><br><span class="line">            inputs=datapoints.to(device),</span><br><span class="line">            labels=labels.to(device),</span><br><span class="line">            criterion=criterion,</span><br><span class="line">            sample_nbr=<span class="number">3</span>,</span><br><span class="line">            complexity_cost_weight=<span class="number">1</span> / <span class="number">50000</span>,</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># print(loss)</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        iteration += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> iteration % <span class="number">250</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(loss)</span><br><span class="line">            correct = <span class="number">0</span></span><br><span class="line">            total = <span class="number">0</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">                    images, labels = data</span><br><span class="line">                    outputs = classifier(images.to(device))</span><br><span class="line">                    _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">                    total += labels.size(<span class="number">0</span>)</span><br><span class="line">                    correct += (predicted == labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">                accuracy = <span class="number">100</span> * correct / total</span><br><span class="line">                <span class="built_in">print</span>(</span><br><span class="line">                    <span class="string">"Iteration: {} | Accuracy of the network on the 10000 test images: {} %"</span>.<span class="built_in">format</span>(</span><br><span class="line">                        <span class="built_in">str</span>(iteration), <span class="built_in">str</span>(<span class="number">100</span> * correct / total)</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> accuracy &gt; best_accuracy + <span class="number">0.005</span>:</span><br><span class="line">                    best_accuracy = accuracy</span><br><span class="line">                    waiting = <span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    waiting += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> waiting &gt;= <span class="number">4</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f"The best accuracy is <span class="subst">{best_accuracy}</span> for bayesian nn."</span>)</span><br><span class="line">                    stop = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure>

<p>这里把一百个 epoch 全跑完太消时，所以我使用了简陋的早停策略提前终止训练，需要关注的参数主要为：</p>
<ul>
<li><code>.sample_elbo</code>：这是 blitz 中特有的计算 loss 的功能，这里的 <code>sample_nbr</code> 可以当作计算多少次来进行一次梯度更新（因为每次计算都会有不一样的结果），而 <code>complexity_cost_weight</code> 相当于对模型的复杂性进行惩罚，<strong>该值越大，惩罚的力度越高（根据权重的先验分布和后验分布）</strong> 。它的源码如下：</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sample_elbo</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                inputs,</span></span><br><span class="line"><span class="params">                labels,</span></span><br><span class="line"><span class="params">                criterion,</span></span><br><span class="line"><span class="params">                sample_nbr,</span></span><br><span class="line"><span class="params">                complexity_cost_weight=<span class="number">1</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">""" Samples the ELBO Loss for a batch of data, consisting of inputs and corresponding-by-index labels</span></span><br><span class="line"><span class="string">            The ELBO Loss consists of the sum of the KL Divergence of the model</span></span><br><span class="line"><span class="string">             (explained above, interpreted as a "complexity part" of the loss)</span></span><br><span class="line"><span class="string">             with the actual criterion - (loss function) of optimization of our model</span></span><br><span class="line"><span class="string">             (the performance part of the loss).</span></span><br><span class="line"><span class="string">            As we are using variational inference, it takes several (quantified by the parameter sample_nbr) Monte-Carlo</span></span><br><span class="line"><span class="string">             samples of the weights in order to gather a better approximation for the loss.</span></span><br><span class="line"><span class="string">        Parameters:</span></span><br><span class="line"><span class="string">            inputs: torch.tensor -&gt; the input data to the model</span></span><br><span class="line"><span class="string">            labels: torch.tensor -&gt; label data for the performance-part of the loss calculation</span></span><br><span class="line"><span class="string">                    The shape of the labels must match the label-parameter shape of the criterion (one hot encoded or as index, if needed)</span></span><br><span class="line"><span class="string">            criterion: torch.nn.Module, custom criterion (loss) function, torch.nn.functional function -&gt; criterion to gather</span></span><br><span class="line"><span class="string">                        the performance cost for the model</span></span><br><span class="line"><span class="string">            sample_nbr: int -&gt; The number of times of the weight-sampling and predictions done in our Monte-Carlo approach to</span></span><br><span class="line"><span class="string">                        gather the loss to be .backwarded in the optimization of the model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(sample_nbr):</span><br><span class="line">        outputs = self(inputs)</span><br><span class="line">        loss += criterion(outputs, labels)</span><br><span class="line">        loss += self.nn_kl_divergence() * complexity_cost_weight</span><br><span class="line">    <span class="keyword">return</span> loss / sample_nbr</span><br></pre></td></tr></tbody></table></figure>

<details class="toggle" style="border: 1px solid  "><summary class="toggle-button" style="background-color:  ;color:  \#49b1f5">相关概念介绍（非必要内容）</summary><div class="toggle-content"><p>KL 散度是一种衡量两个概率分布差异的方法，关于该概念的理解，可参见：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/100676922?utm_id=0">Kullback-Leibler(KL)散度介绍 from 知乎</a></p>
<p>在贝叶斯神经网络中，使用 KL 散度作为损失函数的一部分是为了实现变分推断。在这个背景下，网络的权重被视为随机变量，遵循某种概率分布。变分推断的目标是寻找一个简单的分布（变分后验分布），以近似复杂的真实后验分布。</p>
<p>贝叶斯神经网络的损失函数通常包含两部分：</p>
<ol>
<li><strong>性能损失</strong>（Performance Loss）：这部分通常是传统神经网络中使用的损失函数（如上述代码中的交叉熵），用于衡量模型预测与实际情况之间的差距。</li>
<li><strong>复杂度损失</strong>（Complexity Loss）：这部分是 KL 散度，用于衡量变分后验分布与先验分布之间的差异。KL 散度越大，表示变分后验分布与先验分布差异越大，模型复杂度越高。</li>
</ol>
<p>那么为什么变分后验分布与先验分布差异越大，模型复杂度越高？</p>
<p>这与贝叶斯推断的本质有关，在贝叶斯方法中，先验分布代表模型权重的初始假设，这时我们通常选择较为简单或宽泛的分布（例如没有信息的均匀分布或分布较广的正态分布等）。在进行训练后，训练数据会对参数估计产生影响，从而导致权重的后验分布产生变化。</p>
<p>这个情况下，后验分布与先验分布相差显著时，模型可能捕捉到了数据中的复杂特征和模式，从而提高了其拟合能力。然而，这也可能意味着模型捕捉到了数据中的噪声，导致过拟合。因此，上述代码中引入了新的超参数 <code>complexity_cost_weight</code> 对这一点进行了限制，以起到一定的正则化作用，保证模型的泛化能力。同时也不难看出，<strong>错误的先验决定也会影响到模型的训练和泛化</strong>。</p>
<p>关于后验分布更新的示例，可以看以下文章：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/266563061">贝叶斯教你如何正确抛硬币 from 知乎</a></p>
<p>以抛硬币为例，<strong>正面向上的概率即</strong> <strong>P(正面向上)</strong> 的先验分布可能是 Beta(1,1)，即一个均匀分布（没有任何信息量），之后我们根据观测数据来更新这个分布得到后验概率分布：</p>
<ol>
<li>第一次抛出正面，后验分布变为 Beta(2,1)。</li>
<li>第二次抛出正面，后验分布变为 Beta(3,1)，此时的概率分布已变为向右倾斜（即正面向上的概率<strong>趋于</strong>更高）。</li>
<li>假设之后又抛了数次，总共出现正面 552 次，反面 539 次。</li>
<li>此时后验分布为 Beta(553, 540)，这个分布是轻微向右倾斜，但峰值很接近 0.5 且很窄。</li>
</ol>
<p><img src="/pic/cover.gif" data-original="/pic2/bata_distri.png"></p>
<p>关于贝塔分布的介绍，可见：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/69606875">深入理解Beta分布 from 知乎</a></p>
<p>你可以使用以下代码进行复现：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> beta</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">553</span>]</span><br><span class="line">b = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">540</span>]</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="built_in">len</span>(a), figsize=(<span class="built_in">len</span>(a)*<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, (suba, subb) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(a, b)):</span><br><span class="line"></span><br><span class="line">    x = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">    y = beta.pdf(x, suba, subb)</span><br><span class="line"></span><br><span class="line">    axes[i].plot(x, y, <span class="string">'r-'</span>, lw=<span class="number">2</span>, alpha=<span class="number">0.6</span>, label=<span class="string">'beta pdf'</span>)</span><br><span class="line">    axes[i].set_xlabel(<span class="string">'x'</span>)</span><br><span class="line">    axes[i].set_xlim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    axes[i].set_title(<span class="string">f'Beta(<span class="subst">{suba}</span>, <span class="subst">{subb}</span>)'</span>)</span><br></pre></td></tr></tbody></table></figure>
</div></details>

<p>需要注意的是，<code>complexity_cost_weight</code> 的值将对结果产生<strong>很大的</strong>影响，在 blitz 的其他示例代码中可以看到这个值一般设为 <code>1/batchsize</code>，但是在 MNIST 数据集中，它使用了 <code>1/50000</code> 作为该超参数的值。经过实测，如果使用 <code>1/batchsize</code>，模型的准确率将在 10% 上下浮动，说明惩罚过严重，导致权重的后验分布无法灵活适应数据。</p>
<p>针对该超参数的选择，blitz 的开发者没有给出 guideline<del>（很多相关 issue 发布多年都没有回复…..）</del>。但从该库源码里 KL 散度的计算中可以看出，模型越复杂（贝叶斯层越多或神经元越多），KL 散度越高，最后的计算复杂度惩罚项越大。因此<strong>对于复杂的模型而言，调低该值或许是一个不错的选择</strong>。</p>
<p>训练和预测结果：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor(4.0596, device='cuda:0', grad_fn=&lt;DivBackward0&gt;)</span><br><span class="line">Iteration: 250 | Accuracy of the network on the 10000 test images: 94.26 %</span><br><span class="line">......</span><br><span class="line">The best accuracy is 98.75 for bayesian nn.</span><br></pre></td></tr></tbody></table></figure>

<p>再换成传统的 Lenet 试试：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Lenet train &amp; test</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">classifier = lenet().to(device)</span><br><span class="line">optimizer = optim.Adam(classifier.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">best_accuracy = <span class="number">0</span></span><br><span class="line">waiting = <span class="number">0</span></span><br><span class="line">iteration = <span class="number">0</span></span><br><span class="line">stop = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> stop:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i, (datapoints, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        datapoints = datapoints.cuda()</span><br><span class="line">        labels = labels.cuda()</span><br><span class="line"></span><br><span class="line">        pred = classifier(datapoints)</span><br><span class="line">        loss = criterion(pred, labels)</span><br><span class="line">        <span class="comment"># print(loss)</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        iteration += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> iteration % <span class="number">250</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(loss)</span><br><span class="line">            correct = <span class="number">0</span></span><br><span class="line">            total = <span class="number">0</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">                    images, labels = data</span><br><span class="line">                    outputs = classifier(images.to(device))</span><br><span class="line">                    _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">                    total += labels.size(<span class="number">0</span>)</span><br><span class="line">                    correct += (predicted == labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">                accuracy = <span class="number">100</span> * correct / total</span><br><span class="line">                <span class="built_in">print</span>(</span><br><span class="line">                    <span class="string">"Iteration: {} | Accuracy of the network on the 10000 test images: {} %"</span>.<span class="built_in">format</span>(</span><br><span class="line">                        <span class="built_in">str</span>(iteration), <span class="built_in">str</span>(<span class="number">100</span> * correct / total)</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> accuracy &gt; best_accuracy + <span class="number">0.005</span>:</span><br><span class="line">                    best_accuracy = accuracy</span><br><span class="line">                    waiting = <span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    waiting += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> waiting &gt;= <span class="number">4</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f"The best accuracy is <span class="subst">{best_accuracy}</span> for lenet nn."</span>)</span><br><span class="line">                    stop = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor(0.2020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)</span><br><span class="line">Iteration: 250 | Accuracy of the network on the 10000 test images: 91.49 %</span><br><span class="line">......</span><br><span class="line">The best accuracy is 99.01 for lenet nn.</span><br></pre></td></tr></tbody></table></figure>

<p>从结果上看，贝叶斯神经网络并没有取得比传统神经网络更好的表现，但是两者仅相差几个千分点，也可能是训练的随机性造成的。不过也能看出，并不是越复杂的网络架构就一定会发挥的更好。</p>
<p>以上代码并没法看出预测的不确定性，接下来将以 blitz 的另一个示例展示其结果的波动：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> blitz.modules <span class="keyword">import</span> BayesianLinear</span><br><span class="line"><span class="keyword">from</span> blitz.utils <span class="keyword">import</span> variational_estimator</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X, y = fetch_california_housing(return_X_y=<span class="literal">True</span>)</span><br><span class="line">X = StandardScaler().fit_transform(X)</span><br><span class="line">y = StandardScaler().fit_transform(np.expand_dims(y, -<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X,</span><br><span class="line">                                                    y,</span><br><span class="line">                                                    test_size=<span class="number">.1</span>,</span><br><span class="line">                                                    random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X_train, y_train = torch.tensor(X_train).<span class="built_in">float</span>(), torch.tensor(y_train).<span class="built_in">float</span>()</span><br><span class="line">X_test, y_test = torch.tensor(X_test).<span class="built_in">float</span>(), torch.tensor(y_test).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line"><span class="meta">@variational_estimator</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BayesianRegressor</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment">#self.linear = nn.Linear(input_dim, output_dim)</span></span><br><span class="line">        self.blinear1 = BayesianLinear(input_dim, input_dim*<span class="number">2</span>)</span><br><span class="line">        self.blinear2 = BayesianLinear(input_dim*<span class="number">2</span>, output_dim)</span><br><span class="line">        <span class="comment"># self.blinear1 = nn.Linear(input_dim, input_dim*2)</span></span><br><span class="line">        <span class="comment"># self.blinear2 = nn.Linear(input_dim*2, output_dim)</span></span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x_ = self.blinear1(x)</span><br><span class="line">        x_ = F.relu(x_)</span><br><span class="line">        <span class="keyword">return</span> self.blinear2(x_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">regressor = BayesianRegressor(<span class="number">8</span>, <span class="number">1</span>)</span><br><span class="line">optimizer = optim.Adam(regressor.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">criterion = torch.nn.MSELoss()</span><br><span class="line"></span><br><span class="line">ds_train = torch.utils.data.TensorDataset(X_train, y_train)</span><br><span class="line">dataloader_train = torch.utils.data.DataLoader(ds_train, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ds_test = torch.utils.data.TensorDataset(X_test, y_test)</span><br><span class="line">dataloader_test = torch.utils.data.DataLoader(ds_test, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> i, (datapoints, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader_train):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        loss = regressor.sample_elbo(inputs=datapoints,</span><br><span class="line">                           labels=labels,</span><br><span class="line">                           criterion=criterion,</span><br><span class="line">                           sample_nbr=<span class="number">3</span>,</span><br><span class="line">                           complexity_cost_weight=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># loss = criterion(regressor(datapoints), labels)</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(loss.item(), end=<span class="string">'\r'</span>)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'Epoch <span class="subst">{epoch+<span class="number">1</span>}</span> finished!'</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(regressor(X_test).detach().numpy()[<span class="number">0</span>:<span class="number">3</span>])</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[[-1.203408  ]</span><br><span class="line"> [-0.32957393]</span><br><span class="line"> [ 1.9057552 ]]</span><br><span class="line">[[-1.2015951 ]</span><br><span class="line"> [-0.32578745]</span><br><span class="line"> [ 1.9102848 ]]</span><br><span class="line">[[-1.2165544 ]</span><br><span class="line"> [-0.33425388]</span><br><span class="line"> [ 1.9049363 ]]</span><br></pre></td></tr></tbody></table></figure>

<p>可以看到，三次运行输出的结果都是不一致的，通过以下命令我们可以获得预测的均值和标准差：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">preds = [regressor(X_test) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>)]</span><br><span class="line">preds = torch.stack(preds)</span><br><span class="line">means = preds.mean(axis=<span class="number">0</span>).detach().numpy().squeeze()</span><br><span class="line">stds = preds.std(axis=<span class="number">0</span>).detach().numpy().squeeze()</span><br></pre></td></tr></tbody></table></figure>

<p>这里需要注意，<u>对于表格数据先需进行标准化，具体原因见注意事项</u>。</p>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>以上就是使用 blitz 实现贝叶斯神经网络的整体流程，同样地，其他的网络架构可以通过将 nn 层替换为对应的贝叶斯层实现：</p>
<ul>
<li>BayesianLinear</li>
<li>BayesianConv1d</li>
<li>BayesianConv2d</li>
<li>BayesianConv3d</li>
<li>BayesianLSTM</li>
<li>BayesianGRU</li>
<li>BayesianEmbedding</li>
</ul>
<p>使用贝叶斯神经网络时，有几点需要注意：</p>
<ol>
<li>新增的超参数中，<code>complexity_cost_weight</code> 非常重要，<strong>该值的选择可能会极大影响模型的表现</strong>。当模型越复杂时，该值应当越低。</li>
<li>要获得结果的不确定性需多次运行模型，这<strong>对于模型过于复杂的任务来说可能极为耗时</strong>。因此需综合考虑自身需求和时间成本。</li>
<li>对于计算机视觉领域中的图片分类问题等，不需要对输入数据进行特别处理。但对于结构化数据（例如上述的 <code>fetch_california_housing</code> 数据集），需要注意特征的尺度是否一致，如果不一致则需要对其进行<strong>标准化处理</strong>。由于贝叶斯层在初始化时，对于每个权重的处理是一致的，因此特征的尺度不同将极大影响后续权重的更新，例如尺度更小的特征可能得到更大的权重，同时相应的复杂度惩罚也就越严重。对于图片分类，每个通道的尺度相同，因此不存在这方面的问题。</li>
</ol>
<h2 id="一些有趣的问题"><a href="#一些有趣的问题" class="headerlink" title="一些有趣的问题"></a>一些有趣的问题</h2><ul>
<li>问 ChatGPT 相同的问题时，它会给出不同的回答。这是为什么？是因为它的模型架构中引入了贝叶斯方法吗？</li>
<li>除了通过对权重进行采样引入正则化以外，贝叶斯神经网络还在其他哪些地方体现出了可以提升模型表现的性质？</li>
<li>你认为分类问题更需要贝叶斯神经网络还是回归问题更需要？为什么？</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li>Robustness of Bayesian Neural Networks to White-Box Adversarial Attacks</li>
<li>Bayesian Bilinear Neural Network for Predicting the Mid-price Dynamics in Limit-Order Book Markets</li>
</ul>
<!-- hexo injector body_end start --> <script data-pjax="">if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://biojuse.com/categories/学习/生信/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 Juseの生信分享 (28)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://biojuse.com/categories/学习/绘图/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 Juseの绘图经验 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://biojuse.com/categories/学习/杂项/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🤹 Juseの琐碎教程 (14)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://biojuse.com/categories/学习/文献阅读/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📕 Juseの文献笔记 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://biojuse.com/categories/软件开发/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🧰 Juseの软件开发 (8)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://biojuse.com/categories/博客/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📑 Juseの博客轻改 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  target="_blank" rel="noopener" href="https://jusetiz.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax="">
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/09/01/JuseKit（八） —— 计算转录组组装指标/" alt=""><img width="48" height="48" src="/pic/cover.gif" data-original="/pic2/jusekit.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-09-01</span><a class="blog-slider__title" href="2023/09/01/JuseKit（八） —— 计算转录组组装指标/" alt="">JuseKit（八） —— 计算转录组组装指标</a><div class="blog-slider__text">本次更新新增了计算转录组组装指标的功能，经实测比 Trinity 快且结果一致。</div><a class="blog-slider__button" href="2023/09/01/JuseKit（八） —— 计算转录组组装指标/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/08/04/JuseKit（七） —— 绘制 GO 富集分析气泡图/" alt=""><img width="48" height="48" src="/pic/cover.gif" data-original="/pic2/jusekit.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-08-04</span><a class="blog-slider__title" href="2023/08/04/JuseKit（七） —— 绘制 GO 富集分析气泡图/" alt="">JuseKit（七） —— 绘制 GO 富集分析气泡图</a><div class="blog-slider__text">本次更新新增 GO 富集气泡图绘制方法，只需文件一键执行！</div><a class="blog-slider__button" href="2023/08/04/JuseKit（七） —— 绘制 GO 富集分析气泡图/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/07/12/DiscoVista 可视化系统发育不一致/" alt=""><img width="48" height="48" src="/pic/cover.gif" data-original="/pic/cover4.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-07-12</span><a class="blog-slider__title" href="2023/07/12/DiscoVista 可视化系统发育不一致/" alt="">DiscoVista 可视化系统发育不一致</a><div class="blog-slider__text">使用合适的工具将系统发育的不一致更加清晰地呈现出来。</div><a class="blog-slider__button" href="2023/07/12/DiscoVista 可视化系统发育不一致/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/05/04/关于 PAML 的一二三事/" alt=""><img width="48" height="48" src="/pic/cover.gif" data-original="/pic/cover4.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-05-04</span><a class="blog-slider__title" href="2023/05/04/关于 PAML 的一二三事/" alt="">关于 PAML 的一二三事</a><div class="blog-slider__text">PAML 进行正选择检测、选择压力分析和物种分歧时间估计的详细介绍，包括诸多需要注意的事项。</div><a class="blog-slider__button" href="2023/05/04/关于 PAML 的一二三事/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/07/04/JuseKit（六） —— 绘制火山图/" alt=""><img width="48" height="48" src="/pic/cover.gif" data-original="/pic2/jusekit.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-07-04</span><a class="blog-slider__title" href="2023/07/04/JuseKit（六） —— 绘制火山图/" alt="">JuseKit（六） —— 绘制火山图</a><div class="blog-slider__text">此次更新新增了绘制火山图的功能，仅需输入对应格式的文件即可一键绘制火山图。</div><a class="blog-slider__button" href="2023/07/04/JuseKit（六） —— 绘制火山图/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/05/14/JuseKit（五） —— 用于系统发育分析的序列过滤/" alt=""><img width="48" height="48" src="/pic/cover.gif" data-original="/pic2/jusekit.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-05-14</span><a class="blog-slider__title" href="2023/05/14/JuseKit（五） —— 用于系统发育分析的序列过滤/" alt="">JuseKit（五） —— 用于系统发育分析的序列过滤</a><div class="blog-slider__text">本次更新带来序列过滤功能，可根据序列长度及物种序列数过滤比对。</div><a class="blog-slider__button" href="2023/05/14/JuseKit（五） —— 用于系统发育分析的序列过滤/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/04/06/文献分享篇（一）—— 系统发育转录组学是否靠谱？/" alt=""><img width="48" height="48" src="/pic/cover.gif" data-original="/pic/wxyd1.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-04-06</span><a class="blog-slider__title" href="2023/04/06/文献分享篇（一）—— 系统发育转录组学是否靠谱？/" alt="">系统发育转录组学是否靠谱？</a><div class="blog-slider__text">随着转录组数据增多，基于转录组进行的系统发育分析研究也不断涌现。本文将介绍系统发育转录组学和系统发育基因组学的差异以及前者的优缺点。</div><a class="blog-slider__button" href="2023/04/06/文献分享篇（一）—— 系统发育转录组学是否靠谱？/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/03/13/单基因-dN、dS-和-ω-的滑动窗口绘制方法/" alt=""><img width="48" height="48" src="/pic/cover.gif" data-original="/pic/slwd.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-03-13</span><a class="blog-slider__title" href="2023/03/13/单基因-dN、dS-和-ω-的滑动窗口绘制方法/" alt="">单基因 dN、dS 和 ω 的滑动窗口绘制方法</a><div class="blog-slider__text">绘制可以观察基因内不同部位选择情况的滑动窗口图，基于 Kaks_calculator 计算。</div><a class="blog-slider__button" href="2023/03/13/单基因-dN、dS-和-ω-的滑动窗口绘制方法/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer="" src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer="" data-pjax="" src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://biojuse.com">Juse</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://biojuse.com">https://biojuse.com</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://biojuse.com" target="_blank">Juse's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/pic2/bayesiannncover.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/02/20/Clashforwindow/"><img class="prev-cover" src="/pic/cover.gif" data-original="/pic/1114180.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Clash for windows 中让某些域名绕过代理</div></div></a></div><div class="next-post pull-right"><a href="/2023/12/30/dNdS%20%E7%9A%84%E8%AE%A1%E7%AE%97%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%90%86%E5%BF%B5/"><img class="next-cover" src="/pic/cover.gif" data-original="/pic2/dnds.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">dN/dS 的计算及其核心理念</div></div></a></div></nav><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/pic/cover.gif" data-original="/pic/gitav.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">Juse</div><div class="author-info__description">偶尔徒步行进倒也不错</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">59</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/JuseTiZ"><i class="fab fa-github"></i><span>Follow Juse</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="/qq.html" target="_blank" title=""><i class="fab fa-qq"></i></a><a class="social-icon" href="https://space.bilibili.com/31269335" target="_blank" title=""><i class="fab fa-bilibili"></i></a><a class="social-icon" href="https://github.com/JuseTiZ" target="_blank" title=""><i class="fab fa-github"></i></a><a class="social-icon" href="https://steamcommunity.com/id/291195857/" target="_blank" title=""><i class="fab fa-steam"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><p align="center"><b>人生是旷野，不是轨道</b><br>⭐⭐🗞️ 阅前须知 📰⭐⭐<br>请保持批判思维<br>请先思考后行动</p></div><div id="welcome-info"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.</span> <span class="toc-text">贝叶斯神经网络是什么</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A6%82%E4%BD%95%E5%BC%95%E5%85%A5%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-number">1.1.</span> <span class="toc-text">贝叶斯神经网络如何引入不确定性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BC%98%E5%8A%BF%E5%92%8C%E4%B8%8D%E8%B6%B3"><span class="toc-number">1.2.</span> <span class="toc-text">贝叶斯神经网络的优势和不足</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.</span> <span class="toc-text">贝叶斯神经网络的代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#blitz-%E5%AE%89%E8%A3%85"><span class="toc-number">2.1.</span> <span class="toc-text">blitz 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E8%8C%83%E4%BE%8B"><span class="toc-number">2.2.</span> <span class="toc-text">运行范例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">2.3.</span> <span class="toc-text">注意事项</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">3.</span> <span class="toc-text">一些有趣的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">4.</span> <span class="toc-text">参考资料</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="ft"><div class="ft-item-1"><div class="t-top"><div class="t-t-l"><p class="ft-t t-l-t">想说的话😉</p><div class="bg-ad"><div>Genes are not destiny. While they play a large role in shaping how we act, how we feel, and how we interact with others, our environment and personal choices have just as much impact on our behavior.</div><div class="btn-xz-box"><a class="btn-xz" target="_blank" rel="noopener" href="https://habitica.com/static/home">游戏人生不游戏 🎯</a></div></div></div><div class="t-t-r"><p class="ft-t t-l-t">仙人指路😝</p><ul class="ft-links"><li><a target="_blank" rel="noopener" href="https://www.fomal.cc/">建站参考</a><a target="_blank" rel="noopener" href="https://emojixd.com/">表情大全</a></li><li><a target="_blank" rel="noopener" href="https://jusetiz.github.io/talk/">看看生活</a><a target="_blank" rel="noopener" href="https://jusetiz.github.io/messageboard/">我要留言</a></li><li><a target="_blank" rel="noopener" href="https://jusetiz.github.io/myself/">关于博主</a><a target="_blank" rel="noopener" href="https://jusetiz.github.io/archives/">文章归档</a></li><li><a target="_blank" rel="noopener" href="https://jusetiz.github.io/categories/">文章分类</a><a target="_blank" rel="noopener" href="https://jusetiz.github.io/tags/">文章标签</a></li><li><a target="_blank" rel="noopener" href="https://jusetiz.github.io/about/">有的没的</a><a target="_blank" rel="noopener" href="https://jusetiz.github.io/new/">更新日志</a></li><li><a target="_blank" rel="noopener" href="https://jusetiz.github.io/link/">友情链接</a><a target="_blank" rel="noopener" href="https://jusetiz.github.io/404.html">404页面</a></li></ul></div></div></div><div class="ft-item-2"><p class="ft-t">友人链接🔗</p><div class="ft-img-group"><div class="img-group-item"><a target="_blank" rel="noopener" href="https://linctanny.github.io/"><img src="/pic/cover.gif" data-original="https://linctanny.github.io/img/p7.jpeg" alt=""></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://robust-vase.github.io/"><img src="/pic/cover.gif" data-original="https://robust-vase.github.io/img/John_King.webp" alt=""></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://blog.stariverfeel.eu.org/"><img src="/pic/cover.gif" data-original="https://avatars.githubusercontent.com/u/26035995?v=4" alt=""></a></div></div></div></div><div class="copyright">©2022 - 2025  @ Juse</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo </a><span class="footer-separator">|</span><span> 主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly </a><span class="footer-separator">|</span><span> 部署 </span><a target="_blank" rel="noopener" href="https://github.com/">GitPage </a><span class="footer-separator">|</span><span> 加速 </span><a target="_blank" rel="noopener" href="https://dash.cloudflare.com/">Cloudflare </a><span class="footer-separator">|</span><span> </span><a href="https://icp.gov.moe/?keyword=20232400" target="_blank">萌ICP备20232400号</a></div><div id="workboard"></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="/"><i class="fa fa-home"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://cn.bing.com/search?q=&quot;+window.getSelection().toString());window.location.reload();"><i class="fa fa-search"></i><span>必应搜索</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="#post-comment"><i class="fas fa-comment"></i><span>空降评论</span></a><a class="rightMenu-item" href="javascript:rmf.copyWordsLink()"><i class="fa fa-link"></i><span>复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="/about/"><i class="fa fa-sitemap"></i><span>有的没的</span></a><a class="rightMenu-item" href="/new/"><i class="fa fa-bell"></i><span>更新日志</span></a><a class="rightMenu-item" href="javascript:rmf.fullScreen();"><i class="fas fa-expand"></i><span>切换全屏</span></a><a class="rightMenu-item" href="javascript:window.print();"><i class="fa-solid fa-print"></i><span>打印页面</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'ORERCz6nkgV8OYWw8FovgBhQ-gzGzoHsz',
      appKey: 'BNxukaAtCZZ0K6TZldZpkY9e',
      avatar: 'mp',
      placeholder: '🐕温馨提示本站不具有邮件提示功能，Juse每隔一段时间会在后台检查评论并回复',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script><script type="text/javascript" src="/js/rightmenu.js"></script><script type="text/javascript" src="/js/txmap.js"></script><script type="text/javascript" src="/js/copy12.js"></script><script type="text/javascript" src="/js/ldex.js"></script><script type="text/javascript" src="/js/runtime.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script><script type="text/javascript" charset="utf-8" src="/js/lazyload-plugin/lazyload.intersectionObserver.min.js"></script></body></html>